{"initialLink":"https://en.wikipedia.org/wiki/Effective_accelerationism","sanitizedLink":"https://en.wikipedia.org/wiki/Effective_accelerationism","finalLink":"https://en.wikipedia.org/wiki/Effective_accelerationism","htmlEmbed":"<script>window.contexterSetup=window.contexterSetup||function(){window.contexterSetupComplete=!0;class ContexterLink extends HTMLAnchorElement{constructor(){super()}connectedCallback(){this.setAttribute(\"target\",\"_blank\")}}customElements.define(\"contexter-link\",ContexterLink,{extends:\"a\"}),customElements.define(\"contexter-inner\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__inner\"}}),customElements.define(\"contexter-thumbnail\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__thumbnail\"}}),customElements.define(\"contexter-byline\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__byline\"}}),customElements.define(\"contexter-keywordset\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__keywordset\"}}),customElements.define(\"contexter-linkset\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__linkset\"}}),customElements.define(\"contexter-meta\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__meta\"}}),customElements.define(\"contexter-summary\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"p-summary entry-summary\"}}),customElements.define(\"contexter-box-head\",class extends HTMLElement{constructor(){super()}connectedCallback(){this.className=\"contexter-box__head\"}}),customElements.define(\"contexter-box-inner\",class extends HTMLElement{constructor(){super()}connectedCallback(){}});class ContexterBox extends HTMLElement{constructor(){super(),this.first=!0,this.shadow=this.attachShadow({mode:\"open\"})}connectedCallback(){if(this.first){this.first=!1;var style=document.createElement(\"style\"),lightDomStyle=(style.innerHTML=`:host {--background: #f5f6f7;--border: darkblue;--blue: #0000ee;--font-color: black;--inner-border: black;font-family: Franklin,Arial,Helvetica,sans-serif;font-size: 14px;background: var(--background);width: 600px;color: var(--font-color);min-height: 90px;display: block;padding: 8px;border: 1px solid var(--border);cursor: pointer;box-sizing: border-box;margin: 6px;contain: content;margin: 6px auto;}// can only select top-level nodes with slotted::slotted(*) {max-width: 100%;display:block;}::slotted([slot=thumbnail]) {max-width: 100%;display:block;}::slotted([slot=header]) {width: 100%;font-size: 1.25rem;font-weight: bold;display:block;margin-bottom: 6px;}::slotted([slot=author]) {max-width: 50%;font-size: 12px;display:inline-block;float: left;}::slotted([slot=time]) {max-width: 50%;font-size: 12px;display:inline-block;float: right;}::slotted([slot=summary]) {width: 100%;margin-top: 6px;padding: 10px 2px;border-top: 1px solid var(--inner-border);font-size: 15px;display:inline-block;margin-bottom: 6px;}contexter-meta {height: auto;margin-bottom: 4px;width: 100%;display: grid;position: relative;min-height: 16px;grid-template-columns: repeat(2, 1fr);}::slotted([slot=keywords]) {width: 80%;padding: 2px 4px;border-top: 1px solid var(--inner-border);font-size: 11px;display: block;float: right;font-style: italic;text-align: right;grid-column: 2/2;grid-row: 1;align-self: end;justify-self: end;}::slotted([slot=keywords]):empty {border-top: 0px solid var(--inner-border);}::slotted([slot=archive-link]) {font-size: 1em;display: inline;}::slotted([slot=archive-link])::after {content: \"|\";display: inline;color: var(--font-color);text-decoration: none;margin: 0 .5em;}::slotted([slot=read-link]) {font-size: 1em;display: inline;}contexter-linkset {width: 80%;padding: 2px 4px;font-size: 13px;float: left;font-weight: bold;grid-row: 1;grid-column: 1/2;align-self: end;justify-self: start;}/* Extra small devices (phones, 600px and down) */@media only screen and (max-width: 600px) {:host {width: 310px;}}/* Small devices (portrait tablets and large phones, 600px and up) */@media only screen and (min-width: 600px) {...}/* Medium devices (landscape tablets, 768px and up) */@media only screen and (min-width: 768px) {...}/* Large devices (laptops/desktops, 992px and up) */@media only screen and (min-width: 992px) {...}/* Extra large devices (large laptops and desktops, 1200px and up) */@media only screen and (min-width: 1200px) {...}@media (prefers-color-scheme: dark){:host {--background: #354150;--border: #1f2b37;--blue: #55b0ff;--font-color: #ffffff;--inner-border: #787a7c;background: var(--background);border: 1px solid var(--border)}}`,document.createElement(\"style\"));lightDomStyle.innerHTML=`contexter-box {contain: content;}contexter-box .read-link {font-weight: bold;}contexter-box a {color: #0000ee;}contexter-box img {width: 100%;border: 0;padding: 0;margin: 0;}/* Extra small devices (phones, 600px and down) */@media only screen and (max-width: 600px) {...}/* Small devices (portrait tablets and large phones, 600px and up) */@media only screen and (min-width: 600px) {...}/* Medium devices (landscape tablets, 768px and up) */@media only screen and (min-width: 768px) {...}/* Large devices (laptops/desktops, 992px and up) */@media only screen and (min-width: 992px) {...}/* Extra large devices (large laptops and desktops, 1200px and up) */@media only screen and (min-width: 1200px) {...}@media (prefers-color-scheme: dark){contexter-box a {color: #55b0ff;}}`,this.appendChild(lightDomStyle),this.shadow.appendChild(style);const innerContainer=document.createElement(\"contexter-box-inner\"),innerSlotThumbnail=(this.shadow.appendChild(innerContainer),document.createElement(\"slot\")),innerSlotHeader=(innerSlotThumbnail.name=\"thumbnail\",innerContainer.appendChild(innerSlotThumbnail),document.createElement(\"slot\")),innerSlotAuthor=(innerSlotHeader.name=\"header\",innerContainer.appendChild(innerSlotHeader),document.createElement(\"slot\")),innerSlotTime=(innerSlotAuthor.name=\"author\",innerContainer.appendChild(innerSlotAuthor),document.createElement(\"slot\")),innerSlotSummary=(innerSlotTime.name=\"time\",innerContainer.appendChild(innerSlotTime),document.createElement(\"slot\")),metaContainer=(innerSlotSummary.name=\"summary\",innerContainer.appendChild(innerSlotSummary),document.createElement(\"contexter-meta\")),innerSlotInfo=(innerContainer.appendChild(metaContainer),document.createElement(\"slot\")),linkContainer=(innerSlotInfo.name=\"keywords\",metaContainer.appendChild(innerSlotInfo),document.createElement(\"contexter-linkset\")),innerSlotArchiveLink=(metaContainer.appendChild(linkContainer),document.createElement(\"slot\")),innerSlotReadLink=(innerSlotArchiveLink.name=\"archive-link\",linkContainer.appendChild(innerSlotArchiveLink),document.createElement(\"slot\"));innerSlotReadLink.name=\"read-link\",linkContainer.appendChild(innerSlotReadLink),this.className=\"contexter-box\",this.onclick=e=>{if(!e.target.className.includes(\"read-link\")&&!e.target.className.includes(\"title-link\")){const mainLinks=this.querySelectorAll(\"a.main-link\");mainLinks[0].click()}}}}}customElements.define(\"contexter-box\",ContexterBox)},window.contexterSetupComplete||window.contexterSetup();</script><contexter-box class=\"link-card h-entry hentry\" itemscope=\"\" itemtype=\"https://schema.org/CreativeWork\"><contexter-thumbnail class=\"thumbnail\" slot=\"thumbnail\"><img src=\"https://upload.wikimedia.org/wikipedia/commons/4/4d/Effective_accelerationism_icon.svg\" alt=\"\" itemprop=\"image\" /></contexter-thumbnail><contexter-box-head slot=\"header\" class=\"p-name entry-title\" itemprop=\"headline\"><contexter-box-head slot=\"header\" class=\"p-name entry-title\" itemprop=\"headline\"><a is=\"contexter-link\" href=\"https://en.wikipedia.org/wiki/Effective_accelerationism\" itemprop=\"url\">philosophical and social movement advocating for a pro-technology stance that seeks to maximize the probability of a technocapital singularity</a></contexter-box-head></contexter-box-head><contexter-byline class=\"p-author author\" slot=\"author\"><span class=\"p-name byline\" rel=\"author\" itemprop=\"author\">Contributors to Wikimedia projects</span></contexter-byline><time class=\"dt-published published\" slot=\"time\" itemprop=\"datePublished\" datetime=\"2023-10-18T07:06:27.000Z\">10/18/2023</time><contexter-summary class=\"p-summary entry-summary\" itemprop=\"abstract\" slot=\"summary\"><p>From Wikipedia, the free encyclopedia</p></contexter-summary><contexter-keywordset itemprop=\"keywords\" slot=\"keywords\"></contexter-keywordset><a is=\"contexter-link\" href=\"https://en.wikipedia.org/wiki/Effective_accelerationism\" class=\"read-link main-link\" itemprop=\"sameAs\" slot=\"read-link\">Read</a></contexter-box>","linkId":"6c290b6493d9986f703d1558d9d3e4e2b029f47a","data":{"originalLink":"https://en.wikipedia.org/wiki/Effective_accelerationism","sanitizedLink":"https://en.wikipedia.org/wiki/Effective_accelerationism","canonical":"https://en.wikipedia.org/wiki/Effective_accelerationism","htmlText":"<!DOCTYPE html>\n<html class=\"client-nojs vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-sticky-header-disabled vector-feature-page-tools-pinned-disabled vector-feature-toc-pinned-clientpref-1 vector-feature-main-menu-pinned-disabled vector-feature-limited-width-clientpref-1 vector-feature-limited-width-content-enabled vector-feature-custom-font-size-clientpref-1 vector-feature-appearance-enabled vector-feature-appearance-pinned-clientpref-1 vector-feature-night-mode-enabled skin-theme-clientpref-day vector-toc-available\" lang=\"en\" dir=\"ltr\">\n<head>\n<meta charset=\"UTF-8\">\n<title>Effective accelerationism - Wikipedia</title>\n<script>(function(){var className=\"client-js vector-feature-language-in-header-enabled vector-feature-language-in-main-page-header-disabled vector-feature-sticky-header-disabled vector-feature-page-tools-pinned-disabled vector-feature-toc-pinned-clientpref-1 vector-feature-main-menu-pinned-disabled vector-feature-limited-width-clientpref-1 vector-feature-limited-width-content-enabled vector-feature-custom-font-size-clientpref-1 vector-feature-appearance-enabled vector-feature-appearance-pinned-clientpref-1 vector-feature-night-mode-enabled skin-theme-clientpref-day vector-toc-available\";var cookie=document.cookie.match(/(?:^|; )enwikimwclientpreferences=([^;]+)/);if(cookie){cookie[1].split('%2C').forEach(function(pref){className=className.replace(new RegExp('(^| )'+pref.replace(/-clientpref-\\w+$|[^\\w-]+/g,'')+'-clientpref-\\\\w+( |$)'),'$1'+pref+'$2');});}document.documentElement.className=className;}());RLCONF={\"wgBreakFrames\":false,\"wgSeparatorTransformTable\":[\"\",\"\"],\"wgDigitTransformTable\":[\n\"\",\"\"],\"wgDefaultDateFormat\":\"dmy\",\"wgMonthNames\":[\"\",\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"],\"wgRequestId\":\"e189ff2a-e3e3-4d90-82c8-47803c41a5b9\",\"wgCanonicalNamespace\":\"\",\"wgCanonicalSpecialPageName\":false,\"wgNamespaceNumber\":0,\"wgPageName\":\"Effective_accelerationism\",\"wgTitle\":\"Effective accelerationism\",\"wgCurRevisionId\":1241702588,\"wgRevisionId\":1241702588,\"wgArticleId\":75085196,\"wgIsArticle\":true,\"wgIsRedirect\":false,\"wgAction\":\"view\",\"wgUserName\":null,\"wgUserGroups\":[\"*\"],\"wgCategories\":[\"CS1 German-language sources (de)\",\"Articles with short description\",\"Short description is different from Wikidata\",\"Use dmy dates from November 2023\",\"Computational neuroscience\",\"Concepts in ethics\",\"Cybernetics\",\"Doomsday scenarios\",\"Effective altruism\",\"Ethics of science and technology\",\"Existential risk from artificial general intelligence\",\"Future problems\",\"Human extinction\",\"Philosophy of artificial intelligence\",\n\"Singularitarianism\",\"Technology hazards\",\"Effective accelerationism\"],\"wgPageViewLanguage\":\"en\",\"wgPageContentLanguage\":\"en\",\"wgPageContentModel\":\"wikitext\",\"wgRelevantPageName\":\"Effective_accelerationism\",\"wgRelevantArticleId\":75085196,\"wgIsProbablyEditable\":true,\"wgRelevantPageIsProbablyEditable\":true,\"wgRestrictionEdit\":[],\"wgRestrictionMove\":[],\"wgNoticeProject\":\"wikipedia\",\"wgCiteReferencePreviewsActive\":false,\"wgFlaggedRevsParams\":{\"tags\":{\"status\":{\"levels\":1}}},\"wgMediaViewerOnClick\":true,\"wgMediaViewerEnabledByDefault\":true,\"wgPopupsFlags\":6,\"wgVisualEditor\":{\"pageLanguageCode\":\"en\",\"pageLanguageDir\":\"ltr\",\"pageVariantFallbacks\":\"en\"},\"wgMFDisplayWikibaseDescriptions\":{\"search\":true,\"watchlist\":true,\"tagline\":false,\"nearby\":true},\"wgWMESchemaEditAttemptStepOversample\":false,\"wgWMEPageLength\":20000,\"wgULSCurrentAutonym\":\"English\",\"wgRelatedArticlesCompat\":[],\"wgCentralAuthMobileDomain\":false,\"wgEditSubmitButtonLabelPublish\":true,\"wgULSPosition\":\"interlanguage\",\n\"wgULSisCompactLinksEnabled\":false,\"wgVector2022LanguageInHeader\":true,\"wgULSisLanguageSelectorEmpty\":false,\"wgWikibaseItemId\":\"Q123509272\",\"wgCheckUserClientHintsHeadersJsApi\":[\"architecture\",\"bitness\",\"brands\",\"fullVersionList\",\"mobile\",\"model\",\"platform\",\"platformVersion\"],\"GEHomepageSuggestedEditsEnableTopics\":true,\"wgGETopicsMatchModeEnabled\":false,\"wgGEStructuredTaskRejectionReasonTextInputEnabled\":false,\"wgGELevelingUpEnabledForUser\":false};RLSTATE={\"ext.globalCssJs.user.styles\":\"ready\",\"site.styles\":\"ready\",\"user.styles\":\"ready\",\"ext.globalCssJs.user\":\"ready\",\"user\":\"ready\",\"user.options\":\"loading\",\"ext.cite.styles\":\"ready\",\"skins.vector.search.codex.styles\":\"ready\",\"skins.vector.styles\":\"ready\",\"skins.vector.icons\":\"ready\",\"jquery.makeCollapsible.styles\":\"ready\",\"ext.wikimediamessages.styles\":\"ready\",\"ext.visualEditor.desktopArticleTarget.noscript\":\"ready\",\"ext.uls.interlanguage\":\"ready\",\"wikibase.client.init\":\"ready\",\"ext.wikimediaBadges\":\"ready\"};RLPAGEMODULES=[\n\"ext.cite.ux-enhancements\",\"mediawiki.page.media\",\"site\",\"mediawiki.page.ready\",\"jquery.makeCollapsible\",\"mediawiki.toc\",\"skins.vector.js\",\"ext.centralNotice.geoIP\",\"ext.centralNotice.startUp\",\"ext.gadget.ReferenceTooltips\",\"ext.gadget.switcher\",\"ext.urlShortener.toolbar\",\"ext.centralauth.centralautologin\",\"mmv.head\",\"mmv.bootstrap.autostart\",\"ext.popups\",\"ext.visualEditor.desktopArticleTarget.init\",\"ext.visualEditor.targetLoader\",\"ext.echo.centralauth\",\"ext.eventLogging\",\"ext.wikimediaEvents\",\"ext.navigationTiming\",\"ext.uls.interface\",\"ext.cx.eventlogging.campaigns\",\"ext.cx.uls.quick.actions\",\"wikibase.client.vector-2022\",\"ext.checkUser.clientHints\",\"ext.growthExperiments.SuggestedEditSession\",\"wikibase.sidebar.tracking\"];</script>\n<script>(RLQ=window.RLQ||[]).push(function(){mw.loader.impl(function(){return[\"user.options@12s5i\",function($,jQuery,require,module){mw.user.tokens.set({\"patrolToken\":\"+\\\\\",\"watchToken\":\"+\\\\\",\"csrfToken\":\"+\\\\\"});\n}];});});</script>\n<link rel=\"stylesheet\" href=\"/w/load.php?lang=en&amp;modules=ext.cite.styles%7Cext.uls.interlanguage%7Cext.visualEditor.desktopArticleTarget.noscript%7Cext.wikimediaBadges%7Cext.wikimediamessages.styles%7Cjquery.makeCollapsible.styles%7Cskins.vector.icons%2Cstyles%7Cskins.vector.search.codex.styles%7Cwikibase.client.init&amp;only=styles&amp;skin=vector-2022\">\n<script async=\"\" src=\"/w/load.php?lang=en&amp;modules=startup&amp;only=scripts&amp;raw=1&amp;skin=vector-2022\"></script>\n<meta name=\"ResourceLoaderDynamicStyles\" content=\"\">\n<link rel=\"stylesheet\" href=\"/w/load.php?lang=en&amp;modules=site.styles&amp;only=styles&amp;skin=vector-2022\">\n<meta name=\"generator\" content=\"MediaWiki 1.43.0-wmf.19\">\n<meta name=\"referrer\" content=\"origin\">\n<meta name=\"referrer\" content=\"origin-when-cross-origin\">\n<meta name=\"robots\" content=\"max-image-preview:standard\">\n<meta name=\"format-detection\" content=\"telephone=no\">\n<meta property=\"og:image\" content=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Effective_accelerationism_icon.svg/1200px-Effective_accelerationism_icon.svg.png\">\n<meta property=\"og:image:width\" content=\"1200\">\n<meta property=\"og:image:height\" content=\"1244\">\n<meta property=\"og:image\" content=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Effective_accelerationism_icon.svg/800px-Effective_accelerationism_icon.svg.png\">\n<meta property=\"og:image:width\" content=\"800\">\n<meta property=\"og:image:height\" content=\"829\">\n<meta property=\"og:image\" content=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Effective_accelerationism_icon.svg/640px-Effective_accelerationism_icon.svg.png\">\n<meta property=\"og:image:width\" content=\"640\">\n<meta property=\"og:image:height\" content=\"663\">\n<meta name=\"viewport\" content=\"width=1120\">\n<meta property=\"og:title\" content=\"Effective accelerationism - Wikipedia\">\n<meta property=\"og:type\" content=\"website\">\n<link rel=\"preconnect\" href=\"//upload.wikimedia.org\">\n<link rel=\"alternate\" media=\"only screen and (max-width: 640px)\" href=\"//en.m.wikipedia.org/wiki/Effective_accelerationism\">\n<link rel=\"alternate\" type=\"application/x-wiki\" title=\"Edit this page\" href=\"/w/index.php?title=Effective_accelerationism&amp;action=edit\">\n<link rel=\"apple-touch-icon\" href=\"/static/apple-touch/wikipedia.png\">\n<link rel=\"icon\" href=\"/static/favicon/wikipedia.ico\">\n<link rel=\"search\" type=\"application/opensearchdescription+xml\" href=\"/w/rest.php/v1/search\" title=\"Wikipedia (en)\">\n<link rel=\"EditURI\" type=\"application/rsd+xml\" href=\"//en.wikipedia.org/w/api.php?action=rsd\">\n<link rel=\"canonical\" href=\"https://en.wikipedia.org/wiki/Effective_accelerationism\">\n<link rel=\"license\" href=\"https://creativecommons.org/licenses/by-sa/4.0/deed.en\">\n<link rel=\"alternate\" type=\"application/atom+xml\" title=\"Wikipedia Atom feed\" href=\"/w/index.php?title=Special:RecentChanges&amp;feed=atom\">\n<link rel=\"dns-prefetch\" href=\"//meta.wikimedia.org\" />\n<link rel=\"dns-prefetch\" href=\"//login.wikimedia.org\">\n</head>\n<body class=\"skin--responsive skin-vector skin-vector-search-vue mediawiki ltr sitedir-ltr mw-hide-empty-elt ns-0 ns-subject mw-editable page-Effective_accelerationism rootpage-Effective_accelerationism skin-vector-2022 action-view\"><a class=\"mw-jump-link\" href=\"#bodyContent\">Jump to content</a>\n<div class=\"vector-header-container\">\n\t<header class=\"vector-header mw-header\">\n\t\t<div class=\"vector-header-start\">\n\t\t\t<nav class=\"vector-main-menu-landmark\" aria-label=\"Site\">\n\t\t\t\t\n<div id=\"vector-main-menu-dropdown\" class=\"vector-dropdown vector-main-menu-dropdown vector-button-flush-left vector-button-flush-right\"  >\n\t<input type=\"checkbox\" id=\"vector-main-menu-dropdown-checkbox\" role=\"button\" aria-haspopup=\"true\" data-event-name=\"ui.dropdown-vector-main-menu-dropdown\" class=\"vector-dropdown-checkbox \"  aria-label=\"Main menu\"  >\n\t<label id=\"vector-main-menu-dropdown-label\" for=\"vector-main-menu-dropdown-checkbox\" class=\"vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only \" aria-hidden=\"true\"  ><span class=\"vector-icon mw-ui-icon-menu mw-ui-icon-wikimedia-menu\"></span>\n\n<span class=\"vector-dropdown-label-text\">Main menu</span>\n\t</label>\n\t<div class=\"vector-dropdown-content\">\n\n\n\t\t\t\t<div id=\"vector-main-menu-unpinned-container\" class=\"vector-unpinned-container\">\n\t\t\n<div id=\"vector-main-menu\" class=\"vector-main-menu vector-pinnable-element\">\n\t<div\n\tclass=\"vector-pinnable-header vector-main-menu-pinnable-header vector-pinnable-header-unpinned\"\n\tdata-feature-name=\"main-menu-pinned\"\n\tdata-pinnable-element-id=\"vector-main-menu\"\n\tdata-pinned-container-id=\"vector-main-menu-pinned-container\"\n\tdata-unpinned-container-id=\"vector-main-menu-unpinned-container\"\n>\n\t<div class=\"vector-pinnable-header-label\">Main menu</div>\n\t<button class=\"vector-pinnable-header-toggle-button vector-pinnable-header-pin-button\" data-event-name=\"pinnable-header.vector-main-menu.pin\">move to sidebar</button>\n\t<button class=\"vector-pinnable-header-toggle-button vector-pinnable-header-unpin-button\" data-event-name=\"pinnable-header.vector-main-menu.unpin\">hide</button>\n</div>\n\n\t\n<div id=\"p-navigation\" class=\"vector-menu mw-portlet mw-portlet-navigation\"  >\n\t<div class=\"vector-menu-heading\">\n\t\tNavigation\n\t</div>\n\t<div class=\"vector-menu-content\">\n\t\t\n\t\t<ul class=\"vector-menu-content-list\">\n\t\t\t\n\t\t\t<li id=\"n-mainpage-description\" class=\"mw-list-item\"><a href=\"/wiki/Main_Page\" title=\"Visit the main page [z]\" accesskey=\"z\"><span>Main page</span></a></li><li id=\"n-contents\" class=\"mw-list-item\"><a href=\"/wiki/Wikipedia:Contents\" title=\"Guides to browsing Wikipedia\"><span>Contents</span></a></li><li id=\"n-currentevents\" class=\"mw-list-item\"><a href=\"/wiki/Portal:Current_events\" title=\"Articles related to current events\"><span>Current events</span></a></li><li id=\"n-randompage\" class=\"mw-list-item\"><a href=\"/wiki/Special:Random\" title=\"Visit a randomly selected article [x]\" accesskey=\"x\"><span>Random article</span></a></li><li id=\"n-aboutsite\" class=\"mw-list-item\"><a href=\"/wiki/Wikipedia:About\" title=\"Learn about Wikipedia and how it works\"><span>About Wikipedia</span></a></li><li id=\"n-contactpage\" class=\"mw-list-item\"><a href=\"//en.wikipedia.org/wiki/Wikipedia:Contact_us\" title=\"How to contact Wikipedia\"><span>Contact us</span></a></li><li id=\"n-sitesupport\" class=\"mw-list-item\"><a href=\"https://donate.wikimedia.org/wiki/Special:FundraiserRedirector?utm_source=donate&amp;utm_medium=sidebar&amp;utm_campaign=C13_en.wikipedia.org&amp;uselang=en\" title=\"Support us by donating to the Wikimedia Foundation\"><span>Donate</span></a></li>\n\t\t</ul>\n\t\t\n\t</div>\n</div>\n\n\t\n\t\n<div id=\"p-interaction\" class=\"vector-menu mw-portlet mw-portlet-interaction\"  >\n\t<div class=\"vector-menu-heading\">\n\t\tContribute\n\t</div>\n\t<div class=\"vector-menu-content\">\n\t\t\n\t\t<ul class=\"vector-menu-content-list\">\n\t\t\t\n\t\t\t<li id=\"n-help\" class=\"mw-list-item\"><a href=\"/wiki/Help:Contents\" title=\"Guidance on how to use and edit Wikipedia\"><span>Help</span></a></li><li id=\"n-introduction\" class=\"mw-list-item\"><a href=\"/wiki/Help:Introduction\" title=\"Learn how to edit Wikipedia\"><span>Learn to edit</span></a></li><li id=\"n-portal\" class=\"mw-list-item\"><a href=\"/wiki/Wikipedia:Community_portal\" title=\"The hub for editors\"><span>Community portal</span></a></li><li id=\"n-recentchanges\" class=\"mw-list-item\"><a href=\"/wiki/Special:RecentChanges\" title=\"A list of recent changes to Wikipedia [r]\" accesskey=\"r\"><span>Recent changes</span></a></li><li id=\"n-upload\" class=\"mw-list-item\"><a href=\"/wiki/Wikipedia:File_upload_wizard\" title=\"Add images or other media for use on Wikipedia\"><span>Upload file</span></a></li>\n\t\t</ul>\n\t\t\n\t</div>\n</div>\n\n</div>\n\n\t\t\t\t</div>\n\n\t</div>\n</div>\n\n\t\t</nav>\n\t\t\t\n<a href=\"/wiki/Main_Page\" class=\"mw-logo\">\n\t<img class=\"mw-logo-icon\" src=\"/static/images/icons/wikipedia.png\" alt=\"\" aria-hidden=\"true\" height=\"50\" width=\"50\">\n\t<span class=\"mw-logo-container skin-invert\">\n\t\t<img class=\"mw-logo-wordmark\" alt=\"Wikipedia\" src=\"/static/images/mobile/copyright/wikipedia-wordmark-en.svg\" style=\"width: 7.5em; height: 1.125em;\">\n\t\t<img class=\"mw-logo-tagline\" alt=\"The Free Encyclopedia\" src=\"/static/images/mobile/copyright/wikipedia-tagline-en.svg\" width=\"117\" height=\"13\" style=\"width: 7.3125em; height: 0.8125em;\">\n\t</span>\n</a>\n\n\t\t</div>\n\t\t<div class=\"vector-header-end\">\n\t\t\t\n<div id=\"p-search\" role=\"search\" class=\"vector-search-box-vue  vector-search-box-collapses vector-search-box-show-thumbnail vector-search-box-auto-expand-width vector-search-box\">\n\t<a href=\"/wiki/Special:Search\" class=\"cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only search-toggle\" title=\"Search Wikipedia [f]\" accesskey=\"f\"><span class=\"vector-icon mw-ui-icon-search mw-ui-icon-wikimedia-search\"></span>\n\n<span>Search</span>\n\t</a>\n\t<div class=\"vector-typeahead-search-container\">\n\t\t<div class=\"cdx-typeahead-search cdx-typeahead-search--show-thumbnail cdx-typeahead-search--auto-expand-width\">\n\t\t\t<form action=\"/w/index.php\" id=\"searchform\" class=\"cdx-search-input cdx-search-input--has-end-button\">\n\t\t\t\t<div id=\"simpleSearch\" class=\"cdx-search-input__input-wrapper\"  data-search-loc=\"header-moved\">\n\t\t\t\t\t<div class=\"cdx-text-input cdx-text-input--has-start-icon\">\n\t\t\t\t\t\t<input\n\t\t\t\t\t\t\tclass=\"cdx-text-input__input\"\n\t\t\t\t\t\t\t type=\"search\" name=\"search\" placeholder=\"Search Wikipedia\" aria-label=\"Search Wikipedia\" autocapitalize=\"sentences\" title=\"Search Wikipedia [f]\" accesskey=\"f\" id=\"searchInput\"\n\t\t\t\t\t\t\t>\n\t\t\t\t\t\t<span class=\"cdx-text-input__icon cdx-text-input__start-icon\"></span>\n\t\t\t\t\t</div>\n\t\t\t\t\t<input type=\"hidden\" name=\"title\" value=\"Special:Search\">\n\t\t\t\t</div>\n\t\t\t\t<button class=\"cdx-button cdx-search-input__end-button\">Search</button>\n\t\t\t</form>\n\t\t</div>\n\t</div>\n</div>\n\n\t\t\t<nav class=\"vector-user-links vector-user-links-wide\" aria-label=\"Personal tools\">\n\t<div class=\"vector-user-links-main\">\n\t\n<div id=\"p-vector-user-menu-preferences\" class=\"vector-menu mw-portlet emptyPortlet\"  >\n\t<div class=\"vector-menu-content\">\n\t\t\n\t\t<ul class=\"vector-menu-content-list\">\n\t\t\t\n\t\t\t\n\t\t</ul>\n\t\t\n\t</div>\n</div>\n\n\t\n<div id=\"p-vector-user-menu-userpage\" class=\"vector-menu mw-portlet emptyPortlet\"  >\n\t<div class=\"vector-menu-content\">\n\t\t\n\t\t<ul class=\"vector-menu-content-list\">\n\t\t\t\n\t\t\t\n\t\t</ul>\n\t\t\n\t</div>\n</div>\n\n\t<nav class=\"vector-appearance-landmark\" aria-label=\"Appearance\">\n\t\t\n<div id=\"vector-appearance-dropdown\" class=\"vector-dropdown \"  >\n\t<input type=\"checkbox\" id=\"vector-appearance-dropdown-checkbox\" role=\"button\" aria-haspopup=\"true\" data-event-name=\"ui.dropdown-vector-appearance-dropdown\" class=\"vector-dropdown-checkbox \"  aria-label=\"Appearance\"  >\n\t<label id=\"vector-appearance-dropdown-label\" for=\"vector-appearance-dropdown-checkbox\" class=\"vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only \" aria-hidden=\"true\"  ><span class=\"vector-icon mw-ui-icon-appearance mw-ui-icon-wikimedia-appearance\"></span>\n\n<span class=\"vector-dropdown-label-text\">Appearance</span>\n\t</label>\n\t<div class=\"vector-dropdown-content\">\n\n\n\t\t\t<div id=\"vector-appearance-unpinned-container\" class=\"vector-unpinned-container\">\n\t\t\t\t\n\t\t\t</div>\n\t\t\n\t</div>\n</div>\n\n\t</nav>\n\t\n<div id=\"p-vector-user-menu-notifications\" class=\"vector-menu mw-portlet emptyPortlet\"  >\n\t<div class=\"vector-menu-content\">\n\t\t\n\t\t<ul class=\"vector-menu-content-list\">\n\t\t\t\n\t\t\t\n\t\t</ul>\n\t\t\n\t</div>\n</div>\n\n\t\n<div id=\"p-vector-user-menu-overflow\" class=\"vector-menu mw-portlet\"  >\n\t<div class=\"vector-menu-content\">\n\t\t\n\t\t<ul class=\"vector-menu-content-list\">\n\t\t\t<li id=\"pt-createaccount-2\" class=\"user-links-collapsible-item mw-list-item user-links-collapsible-item\"><a data-mw=\"interface\" href=\"/w/index.php?title=Special:CreateAccount&amp;returnto=Effective+accelerationism\" title=\"You are encouraged to create an account and log in; however, it is not mandatory\" class=\"\"><span>Create account</span></a>\n</li>\n<li id=\"pt-login-2\" class=\"user-links-collapsible-item mw-list-item user-links-collapsible-item\"><a data-mw=\"interface\" href=\"/w/index.php?title=Special:UserLogin&amp;returnto=Effective+accelerationism\" title=\"You&#039;re encouraged to log in; however, it&#039;s not mandatory. [o]\" accesskey=\"o\" class=\"\"><span>Log in</span></a>\n</li>\n\n\t\t\t\n\t\t</ul>\n\t\t\n\t</div>\n</div>\n\n\t</div>\n\t\n<div id=\"vector-user-links-dropdown\" class=\"vector-dropdown vector-user-menu vector-button-flush-right vector-user-menu-logged-out\"  title=\"Log in and more options\" >\n\t<input type=\"checkbox\" id=\"vector-user-links-dropdown-checkbox\" role=\"button\" aria-haspopup=\"true\" data-event-name=\"ui.dropdown-vector-user-links-dropdown\" class=\"vector-dropdown-checkbox \"  aria-label=\"Personal tools\"  >\n\t<label id=\"vector-user-links-dropdown-label\" for=\"vector-user-links-dropdown-checkbox\" class=\"vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only \" aria-hidden=\"true\"  ><span class=\"vector-icon mw-ui-icon-ellipsis mw-ui-icon-wikimedia-ellipsis\"></span>\n\n<span class=\"vector-dropdown-label-text\">Personal tools</span>\n\t</label>\n\t<div class=\"vector-dropdown-content\">\n\n\n\t\t\n<div id=\"p-personal\" class=\"vector-menu mw-portlet mw-portlet-personal user-links-collapsible-item\"  title=\"User menu\" >\n\t<div class=\"vector-menu-content\">\n\t\t\n\t\t<ul class=\"vector-menu-content-list\">\n\t\t\t\n\t\t\t<li id=\"pt-createaccount\" class=\"user-links-collapsible-item mw-list-item\"><a href=\"/w/index.php?title=Special:CreateAccount&amp;returnto=Effective+accelerationism\" title=\"You are encouraged to create an account and log in; however, it is not mandatory\"><span class=\"vector-icon mw-ui-icon-userAdd mw-ui-icon-wikimedia-userAdd\"></span> <span>Create account</span></a></li><li id=\"pt-login\" class=\"user-links-collapsible-item mw-list-item\"><a href=\"/w/index.php?title=Special:UserLogin&amp;returnto=Effective+accelerationism\" title=\"You&#039;re encouraged to log in; however, it&#039;s not mandatory. [o]\" accesskey=\"o\"><span class=\"vector-icon mw-ui-icon-logIn mw-ui-icon-wikimedia-logIn\"></span> <span>Log in</span></a></li>\n\t\t</ul>\n\t\t\n\t</div>\n</div>\n\n<div id=\"p-user-menu-anon-editor\" class=\"vector-menu mw-portlet mw-portlet-user-menu-anon-editor\"  >\n\t<div class=\"vector-menu-heading\">\n\t\tPages for logged out editors <a href=\"/wiki/Help:Introduction\" aria-label=\"Learn more about editing\"><span>learn more</span></a>\n\t</div>\n\t<div class=\"vector-menu-content\">\n\t\t\n\t\t<ul class=\"vector-menu-content-list\">\n\t\t\t\n\t\t\t<li id=\"pt-anoncontribs\" class=\"mw-list-item\"><a href=\"/wiki/Special:MyContributions\" title=\"A list of edits made from this IP address [y]\" accesskey=\"y\"><span>Contributions</span></a></li><li id=\"pt-anontalk\" class=\"mw-list-item\"><a href=\"/wiki/Special:MyTalk\" title=\"Discussion about edits from this IP address [n]\" accesskey=\"n\"><span>Talk</span></a></li>\n\t\t</ul>\n\t\t\n\t</div>\n</div>\n\n\t\n\t</div>\n</div>\n\n</nav>\n\n\t\t</div>\n\t</header>\n</div>\n<div class=\"mw-page-container\">\n\t<div class=\"mw-page-container-inner\">\n\t\t<div class=\"vector-sitenotice-container\">\n\t\t\t<div id=\"siteNotice\" class=\"notheme\"><!-- CentralNotice --></div>\n\t\t</div>\n\t\t<div class=\"vector-column-start\">\n\t\t\t<div class=\"vector-main-menu-container\">\n\t\t<div id=\"mw-navigation\">\n\t\t\t<nav id=\"mw-panel\" class=\"vector-main-menu-landmark\" aria-label=\"Site\">\n\t\t\t\t<div id=\"vector-main-menu-pinned-container\" class=\"vector-pinned-container\">\n\t\t\t\t\n\t\t\t\t</div>\n\t\t</nav>\n\t\t</div>\n\t</div>\n\t<div class=\"vector-sticky-pinned-container\">\n\t\t\t\t<nav id=\"mw-panel-toc\" aria-label=\"Contents\" data-event-name=\"ui.sidebar-toc\" class=\"mw-table-of-contents-container vector-toc-landmark\">\n\t\t\t\t\t<div id=\"vector-toc-pinned-container\" class=\"vector-pinned-container\">\n\t\t\t\t\t<div id=\"vector-toc\" class=\"vector-toc vector-pinnable-element\">\n\t<div\n\tclass=\"vector-pinnable-header vector-toc-pinnable-header vector-pinnable-header-pinned\"\n\tdata-feature-name=\"toc-pinned\"\n\tdata-pinnable-element-id=\"vector-toc\"\n\t\n\t\n>\n\t<h2 class=\"vector-pinnable-header-label\">Contents</h2>\n\t<button class=\"vector-pinnable-header-toggle-button vector-pinnable-header-pin-button\" data-event-name=\"pinnable-header.vector-toc.pin\">move to sidebar</button>\n\t<button class=\"vector-pinnable-header-toggle-button vector-pinnable-header-unpin-button\" data-event-name=\"pinnable-header.vector-toc.unpin\">hide</button>\n</div>\n\n\n\t<ul class=\"vector-toc-contents\" id=\"mw-panel-toc-list\">\n\t\t<li id=\"toc-mw-content-text\"\n\t\t\tclass=\"vector-toc-list-item vector-toc-level-1\">\n\t\t\t<a href=\"#\" class=\"vector-toc-link\">\n\t\t\t\t<div class=\"vector-toc-text\">(Top)</div>\n\t\t\t</a>\n\t\t</li>\n\t\t<li id=\"toc-Etymology_and_central_beliefs\"\n\t\tclass=\"vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded\">\n\t\t<a class=\"vector-toc-link\" href=\"#Etymology_and_central_beliefs\">\n\t\t\t<div class=\"vector-toc-text\">\n\t\t\t\t<span class=\"vector-toc-numb\">1</span>\n\t\t\t\t<span>Etymology and central beliefs</span>\n\t\t\t</div>\n\t\t</a>\n\t\t\n\t\t<ul id=\"toc-Etymology_and_central_beliefs-sublist\" class=\"vector-toc-list\">\n\t\t</ul>\n\t</li>\n\t<li id=\"toc-History\"\n\t\tclass=\"vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded\">\n\t\t<a class=\"vector-toc-link\" href=\"#History\">\n\t\t\t<div class=\"vector-toc-text\">\n\t\t\t\t<span class=\"vector-toc-numb\">2</span>\n\t\t\t\t<span>History</span>\n\t\t\t</div>\n\t\t</a>\n\t\t\n\t\t\t<button aria-controls=\"toc-History-sublist\" class=\"cdx-button cdx-button--weight-quiet cdx-button--icon-only vector-toc-toggle\">\n\t\t\t\t<span class=\"vector-icon mw-ui-icon-wikimedia-expand\"></span>\n\t\t\t\t<span>Toggle History subsection</span>\n\t\t\t</button>\n\t\t\n\t\t<ul id=\"toc-History-sublist\" class=\"vector-toc-list\">\n\t\t\t<li id=\"toc-Intellectual_origins\"\n\t\t\tclass=\"vector-toc-list-item vector-toc-level-2\">\n\t\t\t<a class=\"vector-toc-link\" href=\"#Intellectual_origins\">\n\t\t\t\t<div class=\"vector-toc-text\">\n\t\t\t\t\t<span class=\"vector-toc-numb\">2.1</span>\n\t\t\t\t\t<span>Intellectual origins</span>\n\t\t\t\t</div>\n\t\t\t</a>\n\t\t\t\n\t\t\t<ul id=\"toc-Intellectual_origins-sublist\" class=\"vector-toc-list\">\n\t\t\t</ul>\n\t\t</li>\n\t\t<li id=\"toc-Disclosure_of_the_identity_of_BasedBeffJezos\"\n\t\t\tclass=\"vector-toc-list-item vector-toc-level-2\">\n\t\t\t<a class=\"vector-toc-link\" href=\"#Disclosure_of_the_identity_of_BasedBeffJezos\">\n\t\t\t\t<div class=\"vector-toc-text\">\n\t\t\t\t\t<span class=\"vector-toc-numb\">2.2</span>\n\t\t\t\t\t<span>Disclosure of the identity of BasedBeffJezos</span>\n\t\t\t\t</div>\n\t\t\t</a>\n\t\t\t\n\t\t\t<ul id=\"toc-Disclosure_of_the_identity_of_BasedBeffJezos-sublist\" class=\"vector-toc-list\">\n\t\t\t</ul>\n\t\t</li>\n\t</ul>\n\t</li>\n\t<li id=\"toc-Relation_to_other_movements\"\n\t\tclass=\"vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded\">\n\t\t<a class=\"vector-toc-link\" href=\"#Relation_to_other_movements\">\n\t\t\t<div class=\"vector-toc-text\">\n\t\t\t\t<span class=\"vector-toc-numb\">3</span>\n\t\t\t\t<span>Relation to other movements</span>\n\t\t\t</div>\n\t\t</a>\n\t\t\n\t\t\t<button aria-controls=\"toc-Relation_to_other_movements-sublist\" class=\"cdx-button cdx-button--weight-quiet cdx-button--icon-only vector-toc-toggle\">\n\t\t\t\t<span class=\"vector-icon mw-ui-icon-wikimedia-expand\"></span>\n\t\t\t\t<span>Toggle Relation to other movements subsection</span>\n\t\t\t</button>\n\t\t\n\t\t<ul id=\"toc-Relation_to_other_movements-sublist\" class=\"vector-toc-list\">\n\t\t\t<li id=\"toc-Traditional_accelerationism\"\n\t\t\tclass=\"vector-toc-list-item vector-toc-level-2\">\n\t\t\t<a class=\"vector-toc-link\" href=\"#Traditional_accelerationism\">\n\t\t\t\t<div class=\"vector-toc-text\">\n\t\t\t\t\t<span class=\"vector-toc-numb\">3.1</span>\n\t\t\t\t\t<span>Traditional accelerationism</span>\n\t\t\t\t</div>\n\t\t\t</a>\n\t\t\t\n\t\t\t<ul id=\"toc-Traditional_accelerationism-sublist\" class=\"vector-toc-list\">\n\t\t\t</ul>\n\t\t</li>\n\t\t<li id=\"toc-Effective_altruism\"\n\t\t\tclass=\"vector-toc-list-item vector-toc-level-2\">\n\t\t\t<a class=\"vector-toc-link\" href=\"#Effective_altruism\">\n\t\t\t\t<div class=\"vector-toc-text\">\n\t\t\t\t\t<span class=\"vector-toc-numb\">3.2</span>\n\t\t\t\t\t<span>Effective altruism</span>\n\t\t\t\t</div>\n\t\t\t</a>\n\t\t\t\n\t\t\t<ul id=\"toc-Effective_altruism-sublist\" class=\"vector-toc-list\">\n\t\t\t</ul>\n\t\t</li>\n\t\t<li id=\"toc-d/acc\"\n\t\t\tclass=\"vector-toc-list-item vector-toc-level-2\">\n\t\t\t<a class=\"vector-toc-link\" href=\"#d/acc\">\n\t\t\t\t<div class=\"vector-toc-text\">\n\t\t\t\t\t<span class=\"vector-toc-numb\">3.3</span>\n\t\t\t\t\t<span>d/acc</span>\n\t\t\t\t</div>\n\t\t\t</a>\n\t\t\t\n\t\t\t<ul id=\"toc-d/acc-sublist\" class=\"vector-toc-list\">\n\t\t\t</ul>\n\t\t</li>\n\t\t<li id=\"toc-Degrowth\"\n\t\t\tclass=\"vector-toc-list-item vector-toc-level-2\">\n\t\t\t<a class=\"vector-toc-link\" href=\"#Degrowth\">\n\t\t\t\t<div class=\"vector-toc-text\">\n\t\t\t\t\t<span class=\"vector-toc-numb\">3.4</span>\n\t\t\t\t\t<span>Degrowth</span>\n\t\t\t\t</div>\n\t\t\t</a>\n\t\t\t\n\t\t\t<ul id=\"toc-Degrowth-sublist\" class=\"vector-toc-list\">\n\t\t\t</ul>\n\t\t</li>\n\t</ul>\n\t</li>\n\t<li id=\"toc-Reception\"\n\t\tclass=\"vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded\">\n\t\t<a class=\"vector-toc-link\" href=\"#Reception\">\n\t\t\t<div class=\"vector-toc-text\">\n\t\t\t\t<span class=\"vector-toc-numb\">4</span>\n\t\t\t\t<span>Reception</span>\n\t\t\t</div>\n\t\t</a>\n\t\t\n\t\t<ul id=\"toc-Reception-sublist\" class=\"vector-toc-list\">\n\t\t</ul>\n\t</li>\n\t<li id=\"toc-See_also\"\n\t\tclass=\"vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded\">\n\t\t<a class=\"vector-toc-link\" href=\"#See_also\">\n\t\t\t<div class=\"vector-toc-text\">\n\t\t\t\t<span class=\"vector-toc-numb\">5</span>\n\t\t\t\t<span>See also</span>\n\t\t\t</div>\n\t\t</a>\n\t\t\n\t\t<ul id=\"toc-See_also-sublist\" class=\"vector-toc-list\">\n\t\t</ul>\n\t</li>\n\t<li id=\"toc-References\"\n\t\tclass=\"vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded\">\n\t\t<a class=\"vector-toc-link\" href=\"#References\">\n\t\t\t<div class=\"vector-toc-text\">\n\t\t\t\t<span class=\"vector-toc-numb\">6</span>\n\t\t\t\t<span>References</span>\n\t\t\t</div>\n\t\t</a>\n\t\t\n\t\t<ul id=\"toc-References-sublist\" class=\"vector-toc-list\">\n\t\t</ul>\n\t</li>\n\t<li id=\"toc-External_links\"\n\t\tclass=\"vector-toc-list-item vector-toc-level-1 vector-toc-list-item-expanded\">\n\t\t<a class=\"vector-toc-link\" href=\"#External_links\">\n\t\t\t<div class=\"vector-toc-text\">\n\t\t\t\t<span class=\"vector-toc-numb\">7</span>\n\t\t\t\t<span>External links</span>\n\t\t\t</div>\n\t\t</a>\n\t\t\n\t\t<ul id=\"toc-External_links-sublist\" class=\"vector-toc-list\">\n\t\t</ul>\n\t</li>\n</ul>\n</div>\n\n\t\t\t\t\t</div>\n\t\t</nav>\n\t\t\t</div>\n\t\t</div>\n\t\t<div class=\"mw-content-container\">\n\t\t\t<main id=\"content\" class=\"mw-body\">\n\t\t\t\t<header class=\"mw-body-header vector-page-titlebar\">\n\t\t\t\t\t<nav aria-label=\"Contents\" class=\"vector-toc-landmark\">\n\t\t\t\t\t\t\n<div id=\"vector-page-titlebar-toc\" class=\"vector-dropdown vector-page-titlebar-toc vector-button-flush-left\"  >\n\t<input type=\"checkbox\" id=\"vector-page-titlebar-toc-checkbox\" role=\"button\" aria-haspopup=\"true\" data-event-name=\"ui.dropdown-vector-page-titlebar-toc\" class=\"vector-dropdown-checkbox \"  aria-label=\"Toggle the table of contents\"  >\n\t<label id=\"vector-page-titlebar-toc-label\" for=\"vector-page-titlebar-toc-checkbox\" class=\"vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--icon-only \" aria-hidden=\"true\"  ><span class=\"vector-icon mw-ui-icon-listBullet mw-ui-icon-wikimedia-listBullet\"></span>\n\n<span class=\"vector-dropdown-label-text\">Toggle the table of contents</span>\n\t</label>\n\t<div class=\"vector-dropdown-content\">\n\n\n\t\t\t\t\t\t\t<div id=\"vector-page-titlebar-toc-unpinned-container\" class=\"vector-unpinned-container\">\n\t\t\t</div>\n\t\t\n\t</div>\n</div>\n\n\t\t\t\t\t</nav>\n\t\t\t\t\t<h1 id=\"firstHeading\" class=\"firstHeading mw-first-heading\"><span class=\"mw-page-title-main\">Effective accelerationism</span></h1>\n\t\t\t\t\t\t\t\n<div id=\"p-lang-btn\" class=\"vector-dropdown mw-portlet mw-portlet-lang\"  >\n\t<input type=\"checkbox\" id=\"p-lang-btn-checkbox\" role=\"button\" aria-haspopup=\"true\" data-event-name=\"ui.dropdown-p-lang-btn\" class=\"vector-dropdown-checkbox mw-interlanguage-selector\" aria-label=\"Go to an article in another language. Available in 8 languages\"   >\n\t<label id=\"p-lang-btn-label\" for=\"p-lang-btn-checkbox\" class=\"vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet cdx-button--action-progressive mw-portlet-lang-heading-8\" aria-hidden=\"true\"  ><span class=\"vector-icon mw-ui-icon-language-progressive mw-ui-icon-wikimedia-language-progressive\"></span>\n\n<span class=\"vector-dropdown-label-text\">8 languages</span>\n\t</label>\n\t<div class=\"vector-dropdown-content\">\n\n\t\t<div class=\"vector-menu-content\">\n\t\t\t\n\t\t\t<ul class=\"vector-menu-content-list\">\n\t\t\t\t\n\t\t\t\t<li class=\"interlanguage-link interwiki-ar mw-list-item\"><a href=\"https://ar.wikipedia.org/wiki/%D8%AA%D8%B3%D8%B1%D9%8A%D8%B9%D9%8A%D8%A9_%D9%81%D8%B9%D8%A7%D9%84%D8%A9\" title=\"تسريعية فعالة – Arabic\" lang=\"ar\" hreflang=\"ar\" data-title=\"تسريعية فعالة\" data-language-autonym=\"العربية\" data-language-local-name=\"Arabic\" class=\"interlanguage-link-target\"><span>العربية</span></a></li><li class=\"interlanguage-link interwiki-de mw-list-item\"><a href=\"https://de.wikipedia.org/wiki/Effektiver_Akzelerationismus\" title=\"Effektiver Akzelerationismus – German\" lang=\"de\" hreflang=\"de\" data-title=\"Effektiver Akzelerationismus\" data-language-autonym=\"Deutsch\" data-language-local-name=\"German\" class=\"interlanguage-link-target\"><span>Deutsch</span></a></li><li class=\"interlanguage-link interwiki-es mw-list-item\"><a href=\"https://es.wikipedia.org/wiki/Aceleracionismo_eficaz\" title=\"Aceleracionismo eficaz – Spanish\" lang=\"es\" hreflang=\"es\" data-title=\"Aceleracionismo eficaz\" data-language-autonym=\"Español\" data-language-local-name=\"Spanish\" class=\"interlanguage-link-target\"><span>Español</span></a></li><li class=\"interlanguage-link interwiki-fr mw-list-item\"><a href=\"https://fr.wikipedia.org/wiki/Acc%C3%A9l%C3%A9rationnisme_efficace\" title=\"Accélérationnisme efficace – French\" lang=\"fr\" hreflang=\"fr\" data-title=\"Accélérationnisme efficace\" data-language-autonym=\"Français\" data-language-local-name=\"French\" class=\"interlanguage-link-target\"><span>Français</span></a></li><li class=\"interlanguage-link interwiki-ko mw-list-item\"><a href=\"https://ko.wikipedia.org/wiki/%ED%9A%A8%EA%B3%BC%EC%A0%81_%EA%B0%80%EC%86%8D%EC%A3%BC%EC%9D%98\" title=\"효과적 가속주의 – Korean\" lang=\"ko\" hreflang=\"ko\" data-title=\"효과적 가속주의\" data-language-autonym=\"한국어\" data-language-local-name=\"Korean\" class=\"interlanguage-link-target\"><span>한국어</span></a></li><li class=\"interlanguage-link interwiki-ja mw-list-item\"><a href=\"https://ja.wikipedia.org/wiki/%E5%8A%B9%E6%9E%9C%E7%9A%84%E5%8A%A0%E9%80%9F%E4%B8%BB%E7%BE%A9\" title=\"効果的加速主義 – Japanese\" lang=\"ja\" hreflang=\"ja\" data-title=\"効果的加速主義\" data-language-autonym=\"日本語\" data-language-local-name=\"Japanese\" class=\"interlanguage-link-target\"><span>日本語</span></a></li><li class=\"interlanguage-link interwiki-tr mw-list-item\"><a href=\"https://tr.wikipedia.org/wiki/Etkili_ivmecilik\" title=\"Etkili ivmecilik – Turkish\" lang=\"tr\" hreflang=\"tr\" data-title=\"Etkili ivmecilik\" data-language-autonym=\"Türkçe\" data-language-local-name=\"Turkish\" class=\"interlanguage-link-target\"><span>Türkçe</span></a></li><li class=\"interlanguage-link interwiki-zh mw-list-item\"><a href=\"https://zh.wikipedia.org/wiki/%E6%9C%89%E6%95%88%E5%8A%A0%E9%80%9F%E4%B8%BB%E7%BE%A9\" title=\"有效加速主義 – Chinese\" lang=\"zh\" hreflang=\"zh\" data-title=\"有效加速主義\" data-language-autonym=\"中文\" data-language-local-name=\"Chinese\" class=\"interlanguage-link-target\"><span>中文</span></a></li>\n\t\t\t</ul>\n\t\t\t<div class=\"after-portlet after-portlet-lang\"><span class=\"wb-langlinks-edit wb-langlinks-link\"><a href=\"https://www.wikidata.org/wiki/Special:EntityPage/Q123509272#sitelinks-wikipedia\" title=\"Edit interlanguage links\" class=\"wbc-editpage\">Edit links</a></span></div>\n\t\t</div>\n\n\t</div>\n</div>\n</header>\n\t\t\t\t<div class=\"vector-page-toolbar\">\n\t\t\t\t\t<div class=\"vector-page-toolbar-container\">\n\t\t\t\t\t\t<div id=\"left-navigation\">\n\t\t\t\t\t\t\t<nav aria-label=\"Namespaces\">\n\t\t\t\t\t\t\t\t\n<div id=\"p-associated-pages\" class=\"vector-menu vector-menu-tabs mw-portlet mw-portlet-associated-pages\"  >\n\t<div class=\"vector-menu-content\">\n\t\t\n\t\t<ul class=\"vector-menu-content-list\">\n\t\t\t\n\t\t\t<li id=\"ca-nstab-main\" class=\"selected vector-tab-noicon mw-list-item\"><a href=\"/wiki/Effective_accelerationism\" title=\"View the content page [c]\" accesskey=\"c\"><span>Article</span></a></li><li id=\"ca-talk\" class=\"vector-tab-noicon mw-list-item\"><a href=\"/wiki/Talk:Effective_accelerationism\" rel=\"discussion\" title=\"Discuss improvements to the content page [t]\" accesskey=\"t\"><span>Talk</span></a></li>\n\t\t</ul>\n\t\t\n\t</div>\n</div>\n\n\t\t\t\t\t\t\t\t\n<div id=\"vector-variants-dropdown\" class=\"vector-dropdown emptyPortlet\"  >\n\t<input type=\"checkbox\" id=\"vector-variants-dropdown-checkbox\" role=\"button\" aria-haspopup=\"true\" data-event-name=\"ui.dropdown-vector-variants-dropdown\" class=\"vector-dropdown-checkbox \" aria-label=\"Change language variant\"   >\n\t<label id=\"vector-variants-dropdown-label\" for=\"vector-variants-dropdown-checkbox\" class=\"vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet\" aria-hidden=\"true\"  ><span class=\"vector-dropdown-label-text\">English</span>\n\t</label>\n\t<div class=\"vector-dropdown-content\">\n\n\n\t\t\t\t\t\n<div id=\"p-variants\" class=\"vector-menu mw-portlet mw-portlet-variants emptyPortlet\"  >\n\t<div class=\"vector-menu-content\">\n\t\t\n\t\t<ul class=\"vector-menu-content-list\">\n\t\t\t\n\t\t\t\n\t\t</ul>\n\t\t\n\t</div>\n</div>\n\n\t\t\t\t\n\t</div>\n</div>\n\n\t\t\t\t\t\t\t</nav>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t\t<div id=\"right-navigation\" class=\"vector-collapsible\">\n\t\t\t\t\t\t\t<nav aria-label=\"Views\">\n\t\t\t\t\t\t\t\t\n<div id=\"p-views\" class=\"vector-menu vector-menu-tabs mw-portlet mw-portlet-views\"  >\n\t<div class=\"vector-menu-content\">\n\t\t\n\t\t<ul class=\"vector-menu-content-list\">\n\t\t\t\n\t\t\t<li id=\"ca-view\" class=\"selected vector-tab-noicon mw-list-item\"><a href=\"/wiki/Effective_accelerationism\"><span>Read</span></a></li><li id=\"ca-edit\" class=\"vector-tab-noicon mw-list-item\"><a href=\"/w/index.php?title=Effective_accelerationism&amp;action=edit\" title=\"Edit this page [e]\" accesskey=\"e\"><span>Edit</span></a></li><li id=\"ca-history\" class=\"vector-tab-noicon mw-list-item\"><a href=\"/w/index.php?title=Effective_accelerationism&amp;action=history\" title=\"Past revisions of this page [h]\" accesskey=\"h\"><span>View history</span></a></li>\n\t\t</ul>\n\t\t\n\t</div>\n</div>\n\n\t\t\t\t\t\t\t</nav>\n\t\t\t\t\n\t\t\t\t\t\t\t<nav class=\"vector-page-tools-landmark\" aria-label=\"Page tools\">\n\t\t\t\t\t\t\t\t\n<div id=\"vector-page-tools-dropdown\" class=\"vector-dropdown vector-page-tools-dropdown\"  >\n\t<input type=\"checkbox\" id=\"vector-page-tools-dropdown-checkbox\" role=\"button\" aria-haspopup=\"true\" data-event-name=\"ui.dropdown-vector-page-tools-dropdown\" class=\"vector-dropdown-checkbox \"  aria-label=\"Tools\"  >\n\t<label id=\"vector-page-tools-dropdown-label\" for=\"vector-page-tools-dropdown-checkbox\" class=\"vector-dropdown-label cdx-button cdx-button--fake-button cdx-button--fake-button--enabled cdx-button--weight-quiet\" aria-hidden=\"true\"  ><span class=\"vector-dropdown-label-text\">Tools</span>\n\t</label>\n\t<div class=\"vector-dropdown-content\">\n\n\n\t\t\t\t\t\t\t\t\t<div id=\"vector-page-tools-unpinned-container\" class=\"vector-unpinned-container\">\n\t\t\t\t\t\t\n<div id=\"vector-page-tools\" class=\"vector-page-tools vector-pinnable-element\">\n\t<div\n\tclass=\"vector-pinnable-header vector-page-tools-pinnable-header vector-pinnable-header-unpinned\"\n\tdata-feature-name=\"page-tools-pinned\"\n\tdata-pinnable-element-id=\"vector-page-tools\"\n\tdata-pinned-container-id=\"vector-page-tools-pinned-container\"\n\tdata-unpinned-container-id=\"vector-page-tools-unpinned-container\"\n>\n\t<div class=\"vector-pinnable-header-label\">Tools</div>\n\t<button class=\"vector-pinnable-header-toggle-button vector-pinnable-header-pin-button\" data-event-name=\"pinnable-header.vector-page-tools.pin\">move to sidebar</button>\n\t<button class=\"vector-pinnable-header-toggle-button vector-pinnable-header-unpin-button\" data-event-name=\"pinnable-header.vector-page-tools.unpin\">hide</button>\n</div>\n\n\t\n<div id=\"p-cactions\" class=\"vector-menu mw-portlet mw-portlet-cactions emptyPortlet vector-has-collapsible-items\"  title=\"More options\" >\n\t<div class=\"vector-menu-heading\">\n\t\tActions\n\t</div>\n\t<div class=\"vector-menu-content\">\n\t\t\n\t\t<ul class=\"vector-menu-content-list\">\n\t\t\t\n\t\t\t<li id=\"ca-more-view\" class=\"selected vector-more-collapsible-item mw-list-item\"><a href=\"/wiki/Effective_accelerationism\"><span>Read</span></a></li><li id=\"ca-more-edit\" class=\"vector-more-collapsible-item mw-list-item\"><a href=\"/w/index.php?title=Effective_accelerationism&amp;action=edit\" title=\"Edit this page [e]\" accesskey=\"e\"><span>Edit</span></a></li><li id=\"ca-more-history\" class=\"vector-more-collapsible-item mw-list-item\"><a href=\"/w/index.php?title=Effective_accelerationism&amp;action=history\"><span>View history</span></a></li>\n\t\t</ul>\n\t\t\n\t</div>\n</div>\n\n<div id=\"p-tb\" class=\"vector-menu mw-portlet mw-portlet-tb\"  >\n\t<div class=\"vector-menu-heading\">\n\t\tGeneral\n\t</div>\n\t<div class=\"vector-menu-content\">\n\t\t\n\t\t<ul class=\"vector-menu-content-list\">\n\t\t\t\n\t\t\t<li id=\"t-whatlinkshere\" class=\"mw-list-item\"><a href=\"/wiki/Special:WhatLinksHere/Effective_accelerationism\" title=\"List of all English Wikipedia pages containing links to this page [j]\" accesskey=\"j\"><span>What links here</span></a></li><li id=\"t-recentchangeslinked\" class=\"mw-list-item\"><a href=\"/wiki/Special:RecentChangesLinked/Effective_accelerationism\" rel=\"nofollow\" title=\"Recent changes in pages linked from this page [k]\" accesskey=\"k\"><span>Related changes</span></a></li><li id=\"t-upload\" class=\"mw-list-item\"><a href=\"/wiki/Wikipedia:File_Upload_Wizard\" title=\"Upload files [u]\" accesskey=\"u\"><span>Upload file</span></a></li><li id=\"t-specialpages\" class=\"mw-list-item\"><a href=\"/wiki/Special:SpecialPages\" title=\"A list of all special pages [q]\" accesskey=\"q\"><span>Special pages</span></a></li><li id=\"t-permalink\" class=\"mw-list-item\"><a href=\"/w/index.php?title=Effective_accelerationism&amp;oldid=1241702588\" title=\"Permanent link to this revision of this page\"><span>Permanent link</span></a></li><li id=\"t-info\" class=\"mw-list-item\"><a href=\"/w/index.php?title=Effective_accelerationism&amp;action=info\" title=\"More information about this page\"><span>Page information</span></a></li><li id=\"t-cite\" class=\"mw-list-item\"><a href=\"/w/index.php?title=Special:CiteThisPage&amp;page=Effective_accelerationism&amp;id=1241702588&amp;wpFormIdentifier=titleform\" title=\"Information on how to cite this page\"><span>Cite this page</span></a></li><li id=\"t-urlshortener\" class=\"mw-list-item\"><a href=\"/w/index.php?title=Special:UrlShortener&amp;url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FEffective_accelerationism\"><span>Get shortened URL</span></a></li><li id=\"t-urlshortener-qrcode\" class=\"mw-list-item\"><a href=\"/w/index.php?title=Special:QrCode&amp;url=https%3A%2F%2Fen.wikipedia.org%2Fwiki%2FEffective_accelerationism\"><span>Download QR code</span></a></li><li id=\"t-wikibase\" class=\"mw-list-item\"><a href=\"https://www.wikidata.org/wiki/Special:EntityPage/Q123509272\" title=\"Structured data on this page hosted by Wikidata [g]\" accesskey=\"g\"><span>Wikidata item</span></a></li>\n\t\t</ul>\n\t\t\n\t</div>\n</div>\n\n<div id=\"p-coll-print_export\" class=\"vector-menu mw-portlet mw-portlet-coll-print_export\"  >\n\t<div class=\"vector-menu-heading\">\n\t\tPrint/export\n\t</div>\n\t<div class=\"vector-menu-content\">\n\t\t\n\t\t<ul class=\"vector-menu-content-list\">\n\t\t\t\n\t\t\t<li id=\"coll-download-as-rl\" class=\"mw-list-item\"><a href=\"/w/index.php?title=Special:DownloadAsPdf&amp;page=Effective_accelerationism&amp;action=show-download-screen\" title=\"Download this page as a PDF file\"><span>Download as PDF</span></a></li><li id=\"t-print\" class=\"mw-list-item\"><a href=\"/w/index.php?title=Effective_accelerationism&amp;printable=yes\" title=\"Printable version of this page [p]\" accesskey=\"p\"><span>Printable version</span></a></li>\n\t\t</ul>\n\t\t\n\t</div>\n</div>\n\n</div>\n\n\t\t\t\t\t\t\t\t\t</div>\n\t\t\t\t\n\t</div>\n</div>\n\n\t\t\t\t\t\t\t</nav>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"vector-column-end\">\n\t\t\t\t\t<div class=\"vector-sticky-pinned-container\">\n\t\t\t\t\t\t<nav class=\"vector-page-tools-landmark\" aria-label=\"Page tools\">\n\t\t\t\t\t\t\t<div id=\"vector-page-tools-pinned-container\" class=\"vector-pinned-container\">\n\t\t\t\t\n\t\t\t\t\t\t\t</div>\n\t\t</nav>\n\t\t\t\t\t\t<nav class=\"vector-appearance-landmark\" aria-label=\"Appearance\">\n\t\t\t\t\t\t\t<div id=\"vector-appearance-pinned-container\" class=\"vector-pinned-container\">\n\t\t\t\t<div id=\"vector-appearance\" class=\"vector-appearance vector-pinnable-element\">\n\t<div\n\tclass=\"vector-pinnable-header vector-appearance-pinnable-header vector-pinnable-header-pinned\"\n\tdata-feature-name=\"appearance-pinned\"\n\tdata-pinnable-element-id=\"vector-appearance\"\n\tdata-pinned-container-id=\"vector-appearance-pinned-container\"\n\tdata-unpinned-container-id=\"vector-appearance-unpinned-container\"\n>\n\t<div class=\"vector-pinnable-header-label\">Appearance</div>\n\t<button class=\"vector-pinnable-header-toggle-button vector-pinnable-header-pin-button\" data-event-name=\"pinnable-header.vector-appearance.pin\">move to sidebar</button>\n\t<button class=\"vector-pinnable-header-toggle-button vector-pinnable-header-unpin-button\" data-event-name=\"pinnable-header.vector-appearance.unpin\">hide</button>\n</div>\n\n\n</div>\n\n\t\t\t\t\t\t\t</div>\n\t\t</nav>\n\t\t\t\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t<div id=\"bodyContent\" class=\"vector-body\" aria-labelledby=\"firstHeading\" data-mw-ve-target-container>\n\t\t\t\t\t<div class=\"vector-body-before-content\">\n\t\t\t\t\t\t\t<div class=\"mw-indicators\">\n\t\t</div>\n\n\t\t\t\t\t\t<div id=\"siteSub\" class=\"noprint\">From Wikipedia, the free encyclopedia</div>\n\t\t\t\t\t</div>\n\t\t\t\t\t<div id=\"contentSub\"><div id=\"mw-content-subtitle\"></div></div>\n\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\t<div id=\"mw-content-text\" class=\"mw-body-content\"><div class=\"mw-content-ltr mw-parser-output\" lang=\"en\" dir=\"ltr\"><div class=\"shortdescription nomobile noexcerpt noprint searchaux\" style=\"display:none\">Philosophical and social movement</div>\n<p class=\"mw-empty-elt\">\n</p>\n<figure class=\"mw-default-size mw-halign-right\" typeof=\"mw:File/Thumb\"><a href=\"/wiki/File:Effective_accelerationism_icon.svg\" class=\"mw-file-description\"><img src=\"//upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Effective_accelerationism_icon.svg/220px-Effective_accelerationism_icon.svg.png\" decoding=\"async\" width=\"220\" height=\"228\" class=\"mw-file-element\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Effective_accelerationism_icon.svg/330px-Effective_accelerationism_icon.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Effective_accelerationism_icon.svg/440px-Effective_accelerationism_icon.svg.png 2x\" data-file-width=\"246\" data-file-height=\"255\" /></a><figcaption>e/acc hyperbolic curve logo designed by Will DePue of <a href=\"/wiki/OpenAI\" title=\"OpenAI\">OpenAI</a><sup id=\"cite_ref-1\" class=\"reference\"><a href=\"#cite_note-1\"><span class=\"cite-bracket\">&#91;</span>1<span class=\"cite-bracket\">&#93;</span></a></sup>&#8212;likely an allusion to the idea of a <a href=\"/wiki/Technological_singularity\" title=\"Technological singularity\">technological singularity</a>.</figcaption></figure>\n<p><b>Effective accelerationism</b>, often abbreviated as \"<b>e/acc</b>\", is a 21st-century philosophical movement that advocates for an explicitly <a href=\"/wiki/Technological_utopianism\" title=\"Technological utopianism\">pro-technology</a> stance. Its proponents believe that unrestricted <a href=\"/wiki/Technological_change\" title=\"Technological change\">technological progress</a> (especially driven by <a href=\"/wiki/Artificial_intelligence\" title=\"Artificial intelligence\">artificial intelligence</a>) is a solution to universal human problems like poverty, war and climate change.<sup id=\"cite_ref-:5_2-0\" class=\"reference\"><a href=\"#cite_note-:5-2\"><span class=\"cite-bracket\">&#91;</span>2<span class=\"cite-bracket\">&#93;</span></a></sup> They see themselves as a counterweight to more cautious views on technological innovation, often giving their opponents the derogatory labels of \"doomers\" or \"decels\" (short for <a href=\"/wiki/Degrowth\" title=\"Degrowth\">deceleration</a>).<sup id=\"cite_ref-:5_2-1\" class=\"reference\"><a href=\"#cite_note-:5-2\"><span class=\"cite-bracket\">&#91;</span>2<span class=\"cite-bracket\">&#93;</span></a></sup><sup id=\"cite_ref-:0_3-0\" class=\"reference\"><a href=\"#cite_note-:0-3\"><span class=\"cite-bracket\">&#91;</span>3<span class=\"cite-bracket\">&#93;</span></a></sup> \n</p><p>The movement carries <a href=\"/wiki/Utopia\" title=\"Utopia\">utopian</a> undertones and argues that humans need to develop and build faster to ensure their survival and propagate <a href=\"/wiki/Consciousness\" title=\"Consciousness\">consciousness</a> throughout the universe.<sup id=\"cite_ref-:2_4-0\" class=\"reference\"><a href=\"#cite_note-:2-4\"><span class=\"cite-bracket\">&#91;</span>4<span class=\"cite-bracket\">&#93;</span></a></sup> Its founders Guillaume Verdon and the pseudonymous Bayeslord see it as a way to \"usher in the next evolution of consciousness, creating unthinkable next-generation lifeforms.\"<sup id=\"cite_ref-:4_5-0\" class=\"reference\"><a href=\"#cite_note-:4-5\"><span class=\"cite-bracket\">&#91;</span>5<span class=\"cite-bracket\">&#93;</span></a></sup>\n</p><p>Although effective accelerationism has been described as a fringe movement and as cult-like, it has gained mainstream visibility in 2023.<sup id=\"cite_ref-6\" class=\"reference\"><a href=\"#cite_note-6\"><span class=\"cite-bracket\">&#91;</span>6<span class=\"cite-bracket\">&#93;</span></a></sup><sup id=\"cite_ref-:4_5-1\" class=\"reference\"><a href=\"#cite_note-:4-5\"><span class=\"cite-bracket\">&#91;</span>5<span class=\"cite-bracket\">&#93;</span></a></sup><sup id=\"cite_ref-7\" class=\"reference\"><a href=\"#cite_note-7\"><span class=\"cite-bracket\">&#91;</span>7<span class=\"cite-bracket\">&#93;</span></a></sup><sup id=\"cite_ref-8\" class=\"reference\"><a href=\"#cite_note-8\"><span class=\"cite-bracket\">&#91;</span>8<span class=\"cite-bracket\">&#93;</span></a></sup><sup id=\"cite_ref-:1_9-0\" class=\"reference\"><a href=\"#cite_note-:1-9\"><span class=\"cite-bracket\">&#91;</span>9<span class=\"cite-bracket\">&#93;</span></a></sup> A number of high-profile <a href=\"/wiki/Silicon_Valley\" title=\"Silicon Valley\">Silicon Valley</a> figures, including investors <a href=\"/wiki/Marc_Andreessen\" title=\"Marc Andreessen\">Marc Andreessen</a> and <a href=\"/wiki/Garry_Tan\" title=\"Garry Tan\">Garry Tan</a> explicitly endorsed it by adding \"e/acc\" to their public social media profiles.<sup id=\"cite_ref-:4_5-2\" class=\"reference\"><a href=\"#cite_note-:4-5\"><span class=\"cite-bracket\">&#91;</span>5<span class=\"cite-bracket\">&#93;</span></a></sup><sup id=\"cite_ref-:1_9-1\" class=\"reference\"><a href=\"#cite_note-:1-9\"><span class=\"cite-bracket\">&#91;</span>9<span class=\"cite-bracket\">&#93;</span></a></sup>\n</p>\n<meta property=\"mw:PageProp/toc\" />\n<div class=\"mw-heading mw-heading2\"><h2 id=\"Etymology_and_central_beliefs\">Etymology and central beliefs</h2><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Effective_accelerationism&amp;action=edit&amp;section=1\" title=\"Edit section: Etymology and central beliefs\"><span>edit</span></a><span class=\"mw-editsection-bracket\">]</span></span></div>\n<p>Effective accelerationism, a portmanteau of \"<a href=\"/wiki/Effective_altruism\" title=\"Effective altruism\">effective altruism</a>\" and \"<a href=\"/wiki/Accelerationism\" title=\"Accelerationism\">accelerationism</a>\",<sup id=\"cite_ref-:0_3-1\" class=\"reference\"><a href=\"#cite_note-:0-3\"><span class=\"cite-bracket\">&#91;</span>3<span class=\"cite-bracket\">&#93;</span></a></sup> is a fundamentally <a href=\"/wiki/Techno-optimism\" class=\"mw-redirect\" title=\"Techno-optimism\">techno-optimist</a> movement.<sup id=\"cite_ref-:7_10-0\" class=\"reference\"><a href=\"#cite_note-:7-10\"><span class=\"cite-bracket\">&#91;</span>10<span class=\"cite-bracket\">&#93;</span></a></sup> According to Guillaume Verdon, one of the movement's founders, its aim is for <a href=\"/wiki/Human_civilization\" class=\"mw-redirect\" title=\"Human civilization\">human civilization</a> to \"clim[b] the Kardashev gradient\", meaning its purpose is for human civilization to rise to next levels on the <a href=\"/wiki/Kardashev_scale\" title=\"Kardashev scale\">Kardashev scale</a> by maximizing energy usage.<sup id=\"cite_ref-:7_10-1\" class=\"reference\"><a href=\"#cite_note-:7-10\"><span class=\"cite-bracket\">&#91;</span>10<span class=\"cite-bracket\">&#93;</span></a></sup>\n</p><p>To achieve this goal, effective accelerationism wants to accelerate technological progress. It is strongly focused on <a href=\"/wiki/Artificial_general_intelligence\" title=\"Artificial general intelligence\">artificial general intelligence</a> (AGI), because it sees AGI as fundamental for climbing the Kardashev scale.<sup id=\"cite_ref-:7_10-2\" class=\"reference\"><a href=\"#cite_note-:7-10\"><span class=\"cite-bracket\">&#91;</span>10<span class=\"cite-bracket\">&#93;</span></a></sup> The movement therefore advocates for unrestricted development and deployment of artificial intelligence.<sup id=\"cite_ref-11\" class=\"reference\"><a href=\"#cite_note-11\"><span class=\"cite-bracket\">&#91;</span>11<span class=\"cite-bracket\">&#93;</span></a></sup> Regulation of artificial intelligence and government intervention in markets more generally is met with opposition. Many of its proponents have <a href=\"/wiki/Libertarianism\" title=\"Libertarianism\">libertarian</a> views and think that AGI will be most <a href=\"/wiki/AI_alignment\" title=\"AI alignment\">aligned</a> if many AGIs compete against each other on the marketplace.<sup id=\"cite_ref-:7_10-3\" class=\"reference\"><a href=\"#cite_note-:7-10\"><span class=\"cite-bracket\">&#91;</span>10<span class=\"cite-bracket\">&#93;</span></a></sup>\n</p><p>The founders of the movement see it as rooted in <a href=\"/wiki/Jeremy_England\" title=\"Jeremy England\">Jeremy England</a>'s theory on the <a href=\"/wiki/Abiogenesis\" title=\"Abiogenesis\">origin of life</a>, which is focused on <a href=\"/wiki/Entropy\" title=\"Entropy\">entropy</a> and <a href=\"/wiki/Thermodynamics\" title=\"Thermodynamics\">thermodynamics</a>.<sup id=\"cite_ref-:7_10-4\" class=\"reference\"><a href=\"#cite_note-:7-10\"><span class=\"cite-bracket\">&#91;</span>10<span class=\"cite-bracket\">&#93;</span></a></sup> According to them, the universe aims to increase entropy, and life is a way of increasing it. By spreading life throughout the universe and making life use up ever increasing amounts of energy, the universe's purpose would thus be fulfilled.<sup id=\"cite_ref-:7_10-5\" class=\"reference\"><a href=\"#cite_note-:7-10\"><span class=\"cite-bracket\">&#91;</span>10<span class=\"cite-bracket\">&#93;</span></a></sup>\n</p>\n<div class=\"mw-heading mw-heading2\"><h2 id=\"History\">History</h2><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Effective_accelerationism&amp;action=edit&amp;section=2\" title=\"Edit section: History\"><span>edit</span></a><span class=\"mw-editsection-bracket\">]</span></span></div>\n<div class=\"mw-heading mw-heading3\"><h3 id=\"Intellectual_origins\">Intellectual origins</h3><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Effective_accelerationism&amp;action=edit&amp;section=3\" title=\"Edit section: Intellectual origins\"><span>edit</span></a><span class=\"mw-editsection-bracket\">]</span></span></div>\n<p>While <a href=\"/wiki/Nick_Land\" title=\"Nick Land\">Nick Land</a> is seen as the intellectual originator of contemporary <a href=\"/wiki/Accelerationism\" title=\"Accelerationism\">accelerationism</a> in general,<sup id=\"cite_ref-:1_9-2\" class=\"reference\"><a href=\"#cite_note-:1-9\"><span class=\"cite-bracket\">&#91;</span>9<span class=\"cite-bracket\">&#93;</span></a></sup><sup id=\"cite_ref-:4_5-3\" class=\"reference\"><a href=\"#cite_note-:4-5\"><span class=\"cite-bracket\">&#91;</span>5<span class=\"cite-bracket\">&#93;</span></a></sup> the precise origins of effective accelerationism remain unclear. The earliest known reference to the movement can be traced back to a May 2022 newsletter published by four <a href=\"/wiki/Pen_name\" title=\"Pen name\">pseudonymous</a> authors known by their <a href=\"/wiki/Twitter\" title=\"Twitter\">X</a> (formerly Twitter) usernames @BasedBeffJezos, @bayeslord, @zestular and @creatine_cycle.<sup id=\"cite_ref-:1_9-3\" class=\"reference\"><a href=\"#cite_note-:1-9\"><span class=\"cite-bracket\">&#91;</span>9<span class=\"cite-bracket\">&#93;</span></a></sup>\n</p><p>Effective accelerationism incorporates elements of older Silicon Valley subcultures such as <a href=\"/wiki/Transhumanism\" title=\"Transhumanism\">transhumanism</a> and <a href=\"/wiki/Extropianism\" title=\"Extropianism\">extropianism</a>, which similarly emphasized the value of progress and resisted efforts to restrain the development of technology, as well as the work of the <a href=\"/wiki/Cybernetic_Culture_Research_Unit\" title=\"Cybernetic Culture Research Unit\">Cybernetic Culture Research Unit</a>.<sup id=\"cite_ref-:4_5-4\" class=\"reference\"><a href=\"#cite_note-:4-5\"><span class=\"cite-bracket\">&#91;</span>5<span class=\"cite-bracket\">&#93;</span></a></sup><sup id=\"cite_ref-12\" class=\"reference\"><a href=\"#cite_note-12\"><span class=\"cite-bracket\">&#91;</span>12<span class=\"cite-bracket\">&#93;</span></a></sup><sup id=\"cite_ref-:7_10-6\" class=\"reference\"><a href=\"#cite_note-:7-10\"><span class=\"cite-bracket\">&#91;</span>10<span class=\"cite-bracket\">&#93;</span></a></sup>\n</p>\n<div class=\"mw-heading mw-heading3\"><h3 id=\"Disclosure_of_the_identity_of_BasedBeffJezos\">Disclosure of the identity of BasedBeffJezos</h3><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Effective_accelerationism&amp;action=edit&amp;section=4\" title=\"Edit section: Disclosure of the identity of BasedBeffJezos\"><span>edit</span></a><span class=\"mw-editsection-bracket\">]</span></span></div>\n<p><i><a href=\"/wiki/Forbes\" title=\"Forbes\">Forbes</a></i> disclosed in December 2023 that the @BasedBeffJezos persona is maintained by Guillaume Verdon, a Canadian former Google <a href=\"/wiki/Quantum_computing\" title=\"Quantum computing\">quantum computing</a> engineer and <a href=\"/wiki/Theoretical_physics\" title=\"Theoretical physics\">theoretical physicist</a>.<sup id=\"cite_ref-:6_13-0\" class=\"reference\"><a href=\"#cite_note-:6-13\"><span class=\"cite-bracket\">&#91;</span>13<span class=\"cite-bracket\">&#93;</span></a></sup> The revelation was supported by a voice analysis conducted by the National Center for Media Forensics of the <a href=\"/wiki/University_of_Colorado_Denver\" title=\"University of Colorado Denver\">University of Colorado Denver</a>, which further confirmed the match between Jezos and Verdon. The magazine justified its decision to disclose Verdon's identity on the grounds of it being \"in the <a href=\"/wiki/Public_interest\" title=\"Public interest\">public interest</a>\".<sup id=\"cite_ref-:6_13-1\" class=\"reference\"><a href=\"#cite_note-:6-13\"><span class=\"cite-bracket\">&#91;</span>13<span class=\"cite-bracket\">&#93;</span></a></sup> \n</p><p>On 29 December 2023 Guillaume Verdon was interviewed by <a href=\"/wiki/Lex_Fridman\" title=\"Lex Fridman\">Lex Fridman</a> on the <i><a href=\"/wiki/Lex_Fridman_Podcast\" class=\"mw-redirect\" title=\"Lex Fridman Podcast\">Lex Fridman Podcast</a></i> and introduced as the \"founder of [the] e/acc (effective accelerationism) movement\".<sup id=\"cite_ref-14\" class=\"reference\"><a href=\"#cite_note-14\"><span class=\"cite-bracket\">&#91;</span>14<span class=\"cite-bracket\">&#93;</span></a></sup>\n</p>\n<div class=\"mw-heading mw-heading2\"><h2 id=\"Relation_to_other_movements\">Relation to other movements</h2><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Effective_accelerationism&amp;action=edit&amp;section=5\" title=\"Edit section: Relation to other movements\"><span>edit</span></a><span class=\"mw-editsection-bracket\">]</span></span></div>\n<div class=\"mw-heading mw-heading3\"><h3 id=\"Traditional_accelerationism\">Traditional accelerationism</h3><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Effective_accelerationism&amp;action=edit&amp;section=6\" title=\"Edit section: Traditional accelerationism\"><span>edit</span></a><span class=\"mw-editsection-bracket\">]</span></span></div>\n<p>Traditional accelerationism, as developed by the British philosopher <a href=\"/wiki/Nick_Land\" title=\"Nick Land\">Nick Land</a>, sees the acceleration of technological change as a way to bring about a fundamental transformation of current culture, society, and the political economy.<sup id=\"cite_ref-:5_2-2\" class=\"reference\"><a href=\"#cite_note-:5-2\"><span class=\"cite-bracket\">&#91;</span>2<span class=\"cite-bracket\">&#93;</span></a></sup> In his earlier writings he saw the acceleration of <a href=\"/wiki/Capitalism\" title=\"Capitalism\">capitalism</a> as a way to overcome this economic system itself.<sup id=\"cite_ref-:5_2-3\" class=\"reference\"><a href=\"#cite_note-:5-2\"><span class=\"cite-bracket\">&#91;</span>2<span class=\"cite-bracket\">&#93;</span></a></sup> In contrast, effective accelerationism does not seek to overcome capitalism or to introduce radical societal change but tries to maximize the probability of a <a href=\"/wiki/Technological_singularity\" title=\"Technological singularity\">technocapital singularity</a>, triggering an <a href=\"/wiki/Technological_singularity#Intelligence_explosion\" title=\"Technological singularity\">intelligence explosion</a> throughout the universe and maximizing energy usage.<sup id=\"cite_ref-:1_9-4\" class=\"reference\"><a href=\"#cite_note-:1-9\"><span class=\"cite-bracket\">&#91;</span>9<span class=\"cite-bracket\">&#93;</span></a></sup><sup id=\"cite_ref-:7_10-7\" class=\"reference\"><a href=\"#cite_note-:7-10\"><span class=\"cite-bracket\">&#91;</span>10<span class=\"cite-bracket\">&#93;</span></a></sup> \n</p>\n<div class=\"mw-heading mw-heading3\"><h3 id=\"Effective_altruism\">Effective altruism</h3><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Effective_accelerationism&amp;action=edit&amp;section=7\" title=\"Edit section: Effective altruism\"><span>edit</span></a><span class=\"mw-editsection-bracket\">]</span></span></div>\n<p>Effective accelerationism also diverges from the principles of <a href=\"/wiki/Effective_altruism\" title=\"Effective altruism\">effective altruism</a>, which prioritizes using evidence and reasoning to identify the most effective ways to altruistically improve the world.<sup id=\"cite_ref-:5_2-4\" class=\"reference\"><a href=\"#cite_note-:5-2\"><span class=\"cite-bracket\">&#91;</span>2<span class=\"cite-bracket\">&#93;</span></a></sup> This divergence comes primarily from one of the causes effective altruists focus on – <a href=\"/wiki/AI_existential_risk\" class=\"mw-redirect\" title=\"AI existential risk\">AI existential risk</a>. Effective altruists argue that AI companies should be cautious and strive to develop <a href=\"/wiki/AI_safety\" title=\"AI safety\">safe AI systems</a>, as they fear that any misaligned AGI could eventually lead to <a href=\"/wiki/Existential_risk_from_artificial_general_intelligence\" title=\"Existential risk from artificial general intelligence\">human extinction</a>.<sup id=\"cite_ref-:7_10-8\" class=\"reference\"><a href=\"#cite_note-:7-10\"><span class=\"cite-bracket\">&#91;</span>10<span class=\"cite-bracket\">&#93;</span></a></sup> Proponents of Effective Accelerationism generally consider that <a href=\"/wiki/Existential_risk_from_artificial_general_intelligence\" title=\"Existential risk from artificial general intelligence\">existential risks from AGI</a> are negligible, and that even if they were not, decentralized free markets would much better mitigate this risk than centralized governmental regulation.<sup id=\"cite_ref-:7_10-9\" class=\"reference\"><a href=\"#cite_note-:7-10\"><span class=\"cite-bracket\">&#91;</span>10<span class=\"cite-bracket\">&#93;</span></a></sup>\n</p>\n<div class=\"mw-heading mw-heading3\"><h3 id=\"d/acc\"><span id=\"d.2Facc\"></span>d/acc</h3><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Effective_accelerationism&amp;action=edit&amp;section=8\" title=\"Edit section: d/acc\"><span>edit</span></a><span class=\"mw-editsection-bracket\">]</span></span></div>\n<p>Introduced by <a href=\"/wiki/Vitalik_Buterin\" title=\"Vitalik Buterin\">Vitalik Buterin</a> in November 2023, d/acc is pro-technology like e/acc. But it assumes that maximizing profit does not automatically lead to the best outcome. The \"d\" in d/acc primarily means \"defensive\", but can also refer to \"decentralization\" or \"differential\". d/acc acknowledges existential risks and seeks a more targeted approach to technological development than e/acc, intentionally prioritizing technologies that are expected to make the world better or safer.<sup id=\"cite_ref-15\" class=\"reference\"><a href=\"#cite_note-15\"><span class=\"cite-bracket\">&#91;</span>15<span class=\"cite-bracket\">&#93;</span></a></sup><sup id=\"cite_ref-16\" class=\"reference\"><a href=\"#cite_note-16\"><span class=\"cite-bracket\">&#91;</span>16<span class=\"cite-bracket\">&#93;</span></a></sup>\n</p>\n<div class=\"mw-heading mw-heading3\"><h3 id=\"Degrowth\">Degrowth</h3><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Effective_accelerationism&amp;action=edit&amp;section=9\" title=\"Edit section: Degrowth\"><span>edit</span></a><span class=\"mw-editsection-bracket\">]</span></span></div>\n<p>Effective accelerationism also stands in stark contrast with the <a href=\"/wiki/Degrowth\" title=\"Degrowth\">degrowth</a> movement, sometimes described by it as \"decelerationism\" or \"decels\". The degrowth movement advocates for reducing economic activity and consumption to address ecological and social issues. Effective accelerationism on the contrary embraces technological progress, energy consumption and the dynamics of capitalism, rather than advocating for a reduction in economic activity.<sup id=\"cite_ref-tc_17-0\" class=\"reference\"><a href=\"#cite_note-tc-17\"><span class=\"cite-bracket\">&#91;</span>17<span class=\"cite-bracket\">&#93;</span></a></sup>\n</p>\n<div class=\"mw-heading mw-heading2\"><h2 id=\"Reception\">Reception</h2><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Effective_accelerationism&amp;action=edit&amp;section=10\" title=\"Edit section: Reception\"><span>edit</span></a><span class=\"mw-editsection-bracket\">]</span></span></div>\n<p>The \"<a href=\"/wiki/Techno-Optimist_Manifesto\" title=\"Techno-Optimist Manifesto\">Techno-Optimist Manifesto</a>\",<sup id=\"cite_ref-ma_18-0\" class=\"reference\"><a href=\"#cite_note-ma-18\"><span class=\"cite-bracket\">&#91;</span>18<span class=\"cite-bracket\">&#93;</span></a></sup> a 2023 essay by <a href=\"/wiki/Marc_Andreessen\" title=\"Marc Andreessen\">Marc Andreessen</a>, has been described by the <i><a href=\"/wiki/Financial_Times\" title=\"Financial Times\">Financial Times</a></i> and the German <i><a href=\"/wiki/S%C3%BCddeutsche_Zeitung\" title=\"Süddeutsche Zeitung\">Süddeutsche Zeitung</a></i> as espousing the views of effective accelerationism.<sup id=\"cite_ref-:2_4-1\" class=\"reference\"><a href=\"#cite_note-:2-4\"><span class=\"cite-bracket\">&#91;</span>4<span class=\"cite-bracket\">&#93;</span></a></sup><sup id=\"cite_ref-19\" class=\"reference\"><a href=\"#cite_note-19\"><span class=\"cite-bracket\">&#91;</span>19<span class=\"cite-bracket\">&#93;</span></a></sup>\n</p><p>David Swan of the <i><a href=\"/wiki/The_Sydney_Morning_Herald\" title=\"The Sydney Morning Herald\">The Sydney Morning Herald</a></i> has criticized effective accelerationism due to its opposition to government and industry self-regulation. He argues that \"innovations like AI needs thoughtful regulations and guardrails [...] to avoid the myriad mistakes Silicon Valley has already made\".<sup id=\"cite_ref-20\" class=\"reference\"><a href=\"#cite_note-20\"><span class=\"cite-bracket\">&#91;</span>20<span class=\"cite-bracket\">&#93;</span></a></sup> During the 2023 <a href=\"/wiki/Ronald_Reagan_Presidential_Library\" title=\"Ronald Reagan Presidential Library\">Reagan National Defense Forum</a>, <a href=\"/wiki/United_States_Secretary_of_Commerce\" title=\"United States Secretary of Commerce\">U.S. Secretary of Commerce</a> <a href=\"/wiki/Gina_Raimondo\" title=\"Gina Raimondo\">Gina Raimondo</a> cautioned against embracing the \"move fast and break things\" mentality associated with \"effective acceleration&#32;&#91;<i><a href=\"/wiki/Sic\" title=\"Sic\">sic</a></i>&#93;\". She emphasized the need to exercise caution in dealing with AI, stating \"that's too dangerous. You can't break things when you are talking about AI\".<sup id=\"cite_ref-:4_5-5\" class=\"reference\"><a href=\"#cite_note-:4-5\"><span class=\"cite-bracket\">&#91;</span>5<span class=\"cite-bracket\">&#93;</span></a></sup><sup id=\"cite_ref-21\" class=\"reference\"><a href=\"#cite_note-21\"><span class=\"cite-bracket\">&#91;</span>21<span class=\"cite-bracket\">&#93;</span></a></sup> In a similar vein, Ellen Huet argued on <i><a href=\"/wiki/Bloomberg_News\" title=\"Bloomberg News\">Bloomberg News</a></i> that some of the ideas of the movement were \"deeply unsettling\", focusing especially on Guillaume Verdon's \"post-humanism\" and the view that \"natural selection could lead AI to replace us [humans] as the dominant species.\"<sup id=\"cite_ref-22\" class=\"reference\"><a href=\"#cite_note-22\"><span class=\"cite-bracket\">&#91;</span>22<span class=\"cite-bracket\">&#93;</span></a></sup>\n</p>\n<div class=\"mw-heading mw-heading2\"><h2 id=\"See_also\">See also</h2><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Effective_accelerationism&amp;action=edit&amp;section=11\" title=\"Edit section: See also\"><span>edit</span></a><span class=\"mw-editsection-bracket\">]</span></span></div>\n<ul><li><a href=\"/wiki/Technological_utopianism\" title=\"Technological utopianism\">Technological utopianism</a></li>\n<li><a href=\"/wiki/Transhumanism\" title=\"Transhumanism\">Transhumanism</a></li></ul>\n<div class=\"mw-heading mw-heading2\"><h2 id=\"References\">References</h2><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Effective_accelerationism&amp;action=edit&amp;section=12\" title=\"Edit section: References\"><span>edit</span></a><span class=\"mw-editsection-bracket\">]</span></span></div>\n<style data-mw-deduplicate=\"TemplateStyles:r1239543626\">.mw-parser-output .reflist{margin-bottom:0.5em;list-style-type:decimal}@media screen{.mw-parser-output .reflist{font-size:90%}}.mw-parser-output .reflist .references{font-size:100%;margin-bottom:0;list-style-type:inherit}.mw-parser-output .reflist-columns-2{column-width:30em}.mw-parser-output .reflist-columns-3{column-width:25em}.mw-parser-output .reflist-columns{margin-top:0.3em}.mw-parser-output .reflist-columns ol{margin-top:0}.mw-parser-output .reflist-columns li{page-break-inside:avoid;break-inside:avoid-column}.mw-parser-output .reflist-upper-alpha{list-style-type:upper-alpha}.mw-parser-output .reflist-upper-roman{list-style-type:upper-roman}.mw-parser-output .reflist-lower-alpha{list-style-type:lower-alpha}.mw-parser-output .reflist-lower-greek{list-style-type:lower-greek}.mw-parser-output .reflist-lower-roman{list-style-type:lower-roman}</style><div class=\"reflist\">\n<div class=\"mw-references-wrap mw-references-columns\"><ol class=\"references\">\n<li id=\"cite_note-1\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-1\">^</a></b></span> <span class=\"reference-text\"><style data-mw-deduplicate=\"TemplateStyles:r1238218222\">.mw-parser-output cite.citation{font-style:inherit;word-wrap:break-word}.mw-parser-output .citation q{quotes:\"\\\"\"\"\\\"\"\"'\"\"'\"}.mw-parser-output .citation:target{background-color:rgba(0,127,255,0.133)}.mw-parser-output .id-lock-free.id-lock-free a{background:url(\"//upload.wikimedia.org/wikipedia/commons/6/65/Lock-green.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-limited.id-lock-limited a,.mw-parser-output .id-lock-registration.id-lock-registration a{background:url(\"//upload.wikimedia.org/wikipedia/commons/d/d6/Lock-gray-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .id-lock-subscription.id-lock-subscription a{background:url(\"//upload.wikimedia.org/wikipedia/commons/a/aa/Lock-red-alt-2.svg\")right 0.1em center/9px no-repeat}.mw-parser-output .cs1-ws-icon a{background:url(\"//upload.wikimedia.org/wikipedia/commons/4/4c/Wikisource-logo.svg\")right 0.1em center/12px no-repeat}body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-free a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-limited a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-registration a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .id-lock-subscription a,body:not(.skin-timeless):not(.skin-minerva) .mw-parser-output .cs1-ws-icon a{background-size:contain;padding:0 1em 0 0}.mw-parser-output .cs1-code{color:inherit;background:inherit;border:none;padding:inherit}.mw-parser-output .cs1-hidden-error{display:none;color:var(--color-error,#d33)}.mw-parser-output .cs1-visible-error{color:var(--color-error,#d33)}.mw-parser-output .cs1-maint{display:none;color:#085;margin-left:0.3em}.mw-parser-output .cs1-kern-left{padding-left:0.2em}.mw-parser-output .cs1-kern-right{padding-right:0.2em}.mw-parser-output .citation .mw-selflink{font-weight:inherit}@media screen{.mw-parser-output .cs1-format{font-size:95%}html.skin-theme-clientpref-night .mw-parser-output .cs1-maint{color:#18911f}}@media screen and (prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .cs1-maint{color:#18911f}}</style><cite id=\"CITEREFSteinberg,_Julia2023\" class=\"citation web cs1\">Steinberg, Julia (19 December 2023). <a rel=\"nofollow\" class=\"external text\" href=\"https://www.thefp.com/p/move-fast-and-make-things-e-acc-ai-altman\">\"Move Fast and Make Things\"</a>. The Free Press<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">1 July</span> 2024</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Move+Fast+and+Make+Things&amp;rft.pub=The+Free+Press&amp;rft.date=2023-12-19&amp;rft.au=Steinberg%2C+Julia&amp;rft_id=https%3A%2F%2Fwww.thefp.com%2Fp%2Fmove-fast-and-make-things-e-acc-ai-altman&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\" class=\"Z3988\"></span></span>\n</li>\n<li id=\"cite_note-:5-2\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-:5_2-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-:5_2-1\"><sup><i><b>b</b></i></sup></a> <a href=\"#cite_ref-:5_2-2\"><sup><i><b>c</b></i></sup></a> <a href=\"#cite_ref-:5_2-3\"><sup><i><b>d</b></i></sup></a> <a href=\"#cite_ref-:5_2-4\"><sup><i><b>e</b></i></sup></a></span> <span class=\"reference-text\"><link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1238218222\"><cite id=\"CITEREFSoufi2024\" class=\"citation web cs1\">Soufi, Daniel (6 January 2024). <a rel=\"nofollow\" class=\"external text\" href=\"https://english.elpais.com/technology/2024-01-06/accelerate-or-die-the-controversial-ideology-that-proposes-the-unlimited-advance-of-artificial-intelligence.html\">\"<span class=\"cs1-kern-left\"></span>'Accelerate or die,' the controversial ideology that proposes the unlimited advance of artificial intelligence\"</a>. <i><a href=\"/wiki/El_Pa%C3%ADs\" title=\"El País\">El País</a></i>. <a rel=\"nofollow\" class=\"external text\" href=\"https://web.archive.org/web/20240120202224/https://english.elpais.com/technology/2024-01-06/accelerate-or-die-the-controversial-ideology-that-proposes-the-unlimited-advance-of-artificial-intelligence.html\">Archived</a> from the original on 20 January 2024<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">20 January</span> 2024</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=El+Pa%C3%ADs&amp;rft.atitle=%27Accelerate+or+die%2C%27+the+controversial+ideology+that+proposes+the+unlimited+advance+of+artificial+intelligence&amp;rft.date=2024-01-06&amp;rft.aulast=Soufi&amp;rft.aufirst=Daniel&amp;rft_id=https%3A%2F%2Fenglish.elpais.com%2Ftechnology%2F2024-01-06%2Faccelerate-or-die-the-controversial-ideology-that-proposes-the-unlimited-advance-of-artificial-intelligence.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\" class=\"Z3988\"></span></span>\n</li>\n<li id=\"cite_note-:0-3\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-:0_3-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-:0_3-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\"><link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1238218222\"><cite id=\"CITEREFMacColl2023\" class=\"citation web cs1\">MacColl, Margaux (7 October 2023). <a rel=\"nofollow\" class=\"external text\" href=\"https://www.theinformation.com/articles/its-a-cult-inside-effective-accelerationism-the-pro-ai-movement-taking-over-silicon-valley\">\"It's a Cult': Inside Effective Accelerationism, the Pro-AI Movement Taking Over Silicon Valley\"</a>. <i><a href=\"/wiki/The_Information_(website)\" title=\"The Information (website)\">The Information</a></i>. <a rel=\"nofollow\" class=\"external text\" href=\"https://web.archive.org/web/20231120211028/https://www.theinformation.com/articles/its-a-cult-inside-effective-accelerationism-the-pro-ai-movement-taking-over-silicon-valley\">Archived</a> from the original on 20 November 2023<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">20 November</span> 2023</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=The+Information&amp;rft.atitle=It%27s+a+Cult%27%3A+Inside+Effective+Accelerationism%2C+the+Pro-AI+Movement+Taking+Over+Silicon+Valley&amp;rft.date=2023-10-07&amp;rft.aulast=MacColl&amp;rft.aufirst=Margaux&amp;rft_id=https%3A%2F%2Fwww.theinformation.com%2Farticles%2Fits-a-cult-inside-effective-accelerationism-the-pro-ai-movement-taking-over-silicon-valley&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\" class=\"Z3988\"></span></span>\n</li>\n<li id=\"cite_note-:2-4\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-:2_4-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-:2_4-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\"><link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1238218222\"><cite id=\"CITEREFHurtz2023\" class=\"citation web cs1 cs1-prop-foreign-lang-source\">Hurtz, Simon (10 November 2023). <a rel=\"nofollow\" class=\"external text\" href=\"https://archive.today/20231110220123/https://www.sueddeutsche.de/wirtschaft/ki-silicon-valley-andreessen-effective-accelerationism-1.6301648\">\"Tech-Szene im Silicon Valley: Ihr Gott ist die KI\"</a>. <i><a href=\"/wiki/S%C3%BCddeutsche_Zeitung\" title=\"Süddeutsche Zeitung\">Süddeutsche Zeitung</a></i> (in German). Archived from <a rel=\"nofollow\" class=\"external text\" href=\"https://www.sueddeutsche.de/wirtschaft/ki-silicon-valley-andreessen-effective-accelerationism-1.6301648\">the original</a> on 10 November 2023<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">24 November</span> 2023</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=S%C3%BCddeutsche+Zeitung&amp;rft.atitle=Tech-Szene+im+Silicon+Valley%3A+Ihr+Gott+ist+die+KI&amp;rft.date=2023-11-10&amp;rft.aulast=Hurtz&amp;rft.aufirst=Simon&amp;rft_id=https%3A%2F%2Fwww.sueddeutsche.de%2Fwirtschaft%2Fki-silicon-valley-andreessen-effective-accelerationism-1.6301648&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\" class=\"Z3988\"></span></span>\n</li>\n<li id=\"cite_note-:4-5\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-:4_5-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-:4_5-1\"><sup><i><b>b</b></i></sup></a> <a href=\"#cite_ref-:4_5-2\"><sup><i><b>c</b></i></sup></a> <a href=\"#cite_ref-:4_5-3\"><sup><i><b>d</b></i></sup></a> <a href=\"#cite_ref-:4_5-4\"><sup><i><b>e</b></i></sup></a> <a href=\"#cite_ref-:4_5-5\"><sup><i><b>f</b></i></sup></a></span> <span class=\"reference-text\"><link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1238218222\"><cite id=\"CITEREFRoose2023\" class=\"citation news cs1\">Roose, Kevin (10 December 2023). <a rel=\"nofollow\" class=\"external text\" href=\"https://www.nytimes.com/2023/12/10/technology/ai-acceleration.html\">\"This A.I. Subculture's Motto: Go, Go, Go\"</a>. <i><a href=\"/wiki/The_New_York_Times\" title=\"The New York Times\">The New York Times</a></i>. <a rel=\"nofollow\" class=\"external text\" href=\"https://web.archive.org/web/20231211220106/https://www.nytimes.com/2023/12/10/technology/ai-acceleration.html\">Archived</a> from the original on 11 December 2023<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">10 December</span> 2023</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+New+York+Times&amp;rft.atitle=This+A.I.+Subculture%27s+Motto%3A+Go%2C+Go%2C+Go&amp;rft.date=2023-12-10&amp;rft.aulast=Roose&amp;rft.aufirst=Kevin&amp;rft_id=https%3A%2F%2Fwww.nytimes.com%2F2023%2F12%2F10%2Ftechnology%2Fai-acceleration.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\" class=\"Z3988\"></span></span>\n</li>\n<li id=\"cite_note-6\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-6\">^</a></b></span> <span class=\"reference-text\"><link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1238218222\"><cite class=\"citation web cs1\"><a rel=\"nofollow\" class=\"external text\" href=\"https://www.theinformation.com/articles/its-a-cult-inside-effective-accelerationism-the-pro-ai-movement-taking-over-silicon-valley\">\"<span class=\"cs1-kern-left\"></span>'It's a cult': Inside effective accelerationism, the pro-AI movement taking over Silicon Valley\"</a>. <i>The Information</i>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=The+Information&amp;rft.atitle=%E2%80%98It%E2%80%99s+a+cult%E2%80%99%3A+Inside+effective+accelerationism%2C+the+pro-AI+movement+taking+over+Silicon+Valley&amp;rft_id=https%3A%2F%2Fwww.theinformation.com%2Farticles%2Fits-a-cult-inside-effective-accelerationism-the-pro-ai-movement-taking-over-silicon-valley&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\" class=\"Z3988\"></span></span>\n</li>\n<li id=\"cite_note-7\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-7\">^</a></b></span> <span class=\"reference-text\"><link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1238218222\"><cite class=\"citation web cs1\"><a rel=\"nofollow\" class=\"external text\" href=\"https://www.independent.co.uk/tech/openai-sam-altman-effective-accelerationism-b2492430.html\">\"Inside the political split between AI designers that could decide our future\"</a>. <i>The Independent</i>. 7 February 2024<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">17 August</span> 2024</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=The+Independent&amp;rft.atitle=Inside+the+political+split+between+AI+designers+that+could+decide+our+future&amp;rft.date=2024-02-07&amp;rft_id=https%3A%2F%2Fwww.independent.co.uk%2Ftech%2Fopenai-sam-altman-effective-accelerationism-b2492430.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\" class=\"Z3988\"></span></span>\n</li>\n<li id=\"cite_note-8\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-8\">^</a></b></span> <span class=\"reference-text\"><link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1238218222\"><cite id=\"CITEREFBites\" class=\"citation web cs1\">Bites, Ben's. <a rel=\"nofollow\" class=\"external text\" href=\"https://bensbites.beehiiv.com/p/inside-eacc-new-religion-silicon-valley\">\"Inside e/acc, the new religion in Silicon Valley\"</a>. <i>Ben's Bites</i><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">17 August</span> 2024</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Ben%27s+Bites&amp;rft.atitle=Inside+e%2Facc%2C+the+new+religion+in+Silicon+Valley.&amp;rft.aulast=Bites&amp;rft.aufirst=Ben%27s&amp;rft_id=https%3A%2F%2Fbensbites.beehiiv.com%2Fp%2Finside-eacc-new-religion-silicon-valley&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\" class=\"Z3988\"></span></span>\n</li>\n<li id=\"cite_note-:1-9\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-:1_9-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-:1_9-1\"><sup><i><b>b</b></i></sup></a> <a href=\"#cite_ref-:1_9-2\"><sup><i><b>c</b></i></sup></a> <a href=\"#cite_ref-:1_9-3\"><sup><i><b>d</b></i></sup></a> <a href=\"#cite_ref-:1_9-4\"><sup><i><b>e</b></i></sup></a></span> <span class=\"reference-text\"><link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1238218222\"><cite id=\"CITEREFChowdhury2023\" class=\"citation web cs1\">Chowdhury, Hasan (28 July 2023). <a rel=\"nofollow\" class=\"external text\" href=\"https://www.businessinsider.com/silicon-valley-tech-leaders-accelerationism-eacc-twitter-profiles-2023-7\">\"Silicon Valley's favorite obscure theory about progress at all costs, which has been embraced by Marc Andreessen\"</a>. <i><a href=\"/wiki/Business_Insider\" title=\"Business Insider\">Business Insider</a></i>. <a rel=\"nofollow\" class=\"external text\" href=\"https://web.archive.org/web/20231120191620/https://www.businessinsider.com/silicon-valley-tech-leaders-accelerationism-eacc-twitter-profiles-2023-7\">Archived</a> from the original on 20 November 2023<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">20 November</span> 2023</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Business+Insider&amp;rft.atitle=Silicon+Valley%27s+favorite+obscure+theory+about+progress+at+all+costs%2C+which+has+been+embraced+by+Marc+Andreessen&amp;rft.date=2023-07-28&amp;rft.aulast=Chowdhury&amp;rft.aufirst=Hasan&amp;rft_id=https%3A%2F%2Fwww.businessinsider.com%2Fsilicon-valley-tech-leaders-accelerationism-eacc-twitter-profiles-2023-7&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\" class=\"Z3988\"></span></span>\n</li>\n<li id=\"cite_note-:7-10\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-:7_10-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-:7_10-1\"><sup><i><b>b</b></i></sup></a> <a href=\"#cite_ref-:7_10-2\"><sup><i><b>c</b></i></sup></a> <a href=\"#cite_ref-:7_10-3\"><sup><i><b>d</b></i></sup></a> <a href=\"#cite_ref-:7_10-4\"><sup><i><b>e</b></i></sup></a> <a href=\"#cite_ref-:7_10-5\"><sup><i><b>f</b></i></sup></a> <a href=\"#cite_ref-:7_10-6\"><sup><i><b>g</b></i></sup></a> <a href=\"#cite_ref-:7_10-7\"><sup><i><b>h</b></i></sup></a> <a href=\"#cite_ref-:7_10-8\"><sup><i><b>i</b></i></sup></a> <a href=\"#cite_ref-:7_10-9\"><sup><i><b>j</b></i></sup></a></span> <span class=\"reference-text\"><link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1238218222\"><cite id=\"CITEREFTorres2023\" class=\"citation web cs1\">Torres, Émile P. (14 December 2023). <a rel=\"nofollow\" class=\"external text\" href=\"https://www.truthdig.com/articles/effective-accelerationism-and-the-pursuit-of-cosmic-utopia/\">\"<span class=\"cs1-kern-left\"></span>'Effective Accelerationism' and the Pursuit of Cosmic Utopia\"</a>. <i><a href=\"/wiki/Truthdig\" title=\"Truthdig\">Truthdig</a></i>. <a rel=\"nofollow\" class=\"external text\" href=\"https://web.archive.org/web/20231218005411/https://www.truthdig.com/articles/effective-accelerationism-and-the-pursuit-of-cosmic-utopia/\">Archived</a> from the original on 18 December 2023<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">20 January</span> 2024</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Truthdig&amp;rft.atitle=%27Effective+Accelerationism%27+and+the+Pursuit+of+Cosmic+Utopia&amp;rft.date=2023-12-14&amp;rft.aulast=Torres&amp;rft.aufirst=%C3%89mile+P.&amp;rft_id=https%3A%2F%2Fwww.truthdig.com%2Farticles%2Feffective-accelerationism-and-the-pursuit-of-cosmic-utopia%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\" class=\"Z3988\"></span></span>\n</li>\n<li id=\"cite_note-11\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-11\">^</a></b></span> <span class=\"reference-text\"><link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1238218222\"><cite id=\"CITEREFJones2023\" class=\"citation web cs1\">Jones, Rachyl (16 October 2023). <a rel=\"nofollow\" class=\"external text\" href=\"https://fortune.com/2023/10/16/marc-andreessen-techno-optimist-manifesto-ai-50-billion-people-billionaire-vc/\">\"Marc Andreessen just dropped a 'Techno-Optimist Manifesto' that sees a world of 50 billion people settling other planets\"</a>. <i><a href=\"/wiki/Fortune_(magazine)\" title=\"Fortune (magazine)\">Fortune</a></i>. <a rel=\"nofollow\" class=\"external text\" href=\"https://web.archive.org/web/20231128105444/https://fortune.com/2023/10/16/marc-andreessen-techno-optimist-manifesto-ai-50-billion-people-billionaire-vc/\">Archived</a> from the original on 28 November 2023<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">26 November</span> 2023</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Fortune&amp;rft.atitle=Marc+Andreessen+just+dropped+a+%27Techno-Optimist+Manifesto%27+that+sees+a+world+of+50+billion+people+settling+other+planets&amp;rft.date=2023-10-16&amp;rft.aulast=Jones&amp;rft.aufirst=Rachyl&amp;rft_id=https%3A%2F%2Ffortune.com%2F2023%2F10%2F16%2Fmarc-andreessen-techno-optimist-manifesto-ai-50-billion-people-billionaire-vc%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\" class=\"Z3988\"></span></span>\n</li>\n<li id=\"cite_note-12\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-12\">^</a></b></span> <span class=\"reference-text\"><link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1238218222\"><cite id=\"CITEREFBreland2023\" class=\"citation magazine cs1\">Breland, Ali (6 December 2023). <a rel=\"nofollow\" class=\"external text\" href=\"https://www.motherjones.com/politics/2023/12/effective-accelerationism/\">\"Meet the Silicon Valley CEOs who say greed is good—even if it kills us all\"</a>. <i><a href=\"/wiki/Mother_Jones_(magazine)\" title=\"Mother Jones (magazine)\">Mother Jones</a></i>. <a rel=\"nofollow\" class=\"external text\" href=\"https://web.archive.org/web/20231208175056/https://www.motherjones.com/politics/2023/12/effective-accelerationism/\">Archived</a> from the original on 8 December 2023<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">14 December</span> 2023</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Mother+Jones&amp;rft.atitle=Meet+the+Silicon+Valley+CEOs+who+say+greed+is+good%E2%80%94even+if+it+kills+us+all&amp;rft.date=2023-12-06&amp;rft.aulast=Breland&amp;rft.aufirst=Ali&amp;rft_id=https%3A%2F%2Fwww.motherjones.com%2Fpolitics%2F2023%2F12%2Feffective-accelerationism%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\" class=\"Z3988\"></span></span>\n</li>\n<li id=\"cite_note-:6-13\"><span class=\"mw-cite-backlink\">^ <a href=\"#cite_ref-:6_13-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-:6_13-1\"><sup><i><b>b</b></i></sup></a></span> <span class=\"reference-text\"><link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1238218222\"><cite id=\"CITEREFBaker-White2023\" class=\"citation news cs1\">Baker-White, Emily (1 December 2023). <a rel=\"nofollow\" class=\"external text\" href=\"https://www.forbes.com/sites/emilybaker-white/2023/12/01/who-is-basedbeffjezos-the-leader-of-effective-accelerationism-eacc/\">\"Who Is @BasedBeffJezos, The Leader Of The Tech Elite's 'E/Acc' Movement?\"</a>. <i><a href=\"/wiki/Forbes\" title=\"Forbes\">Forbes</a></i>. <a rel=\"nofollow\" class=\"external text\" href=\"https://web.archive.org/web/20231211190358/https://www.forbes.com/sites/emilybaker-white/2023/12/01/who-is-basedbeffjezos-the-leader-of-effective-accelerationism-eacc/\">Archived</a> from the original on 11 December 2023<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">3 December</span> 2023</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Forbes&amp;rft.atitle=Who+Is+%40BasedBeffJezos%2C+The+Leader+Of+The+Tech+Elite%27s+%27E%2FAcc%27+Movement%3F&amp;rft.date=2023-12-01&amp;rft.aulast=Baker-White&amp;rft.aufirst=Emily&amp;rft_id=https%3A%2F%2Fwww.forbes.com%2Fsites%2Femilybaker-white%2F2023%2F12%2F01%2Fwho-is-basedbeffjezos-the-leader-of-effective-accelerationism-eacc%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\" class=\"Z3988\"></span></span>\n</li>\n<li id=\"cite_note-14\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-14\">^</a></b></span> <span class=\"reference-text\"><link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1238218222\"><cite class=\"citation audio-visual cs1\"><a rel=\"nofollow\" class=\"external text\" href=\"https://www.youtube.com/watch?v=8fEEbKJoNbU\"><i>Guillaume Verdon: Beff Jezos, E/acc Movement, Physics, Computation &amp; AGI</i></a> (Podcast). <a href=\"/wiki/Lex_Fridman_Podcast\" class=\"mw-redirect\" title=\"Lex Fridman Podcast\">Lex Fridman Podcast</a>. Vol.&#160;407. 29 December 2023. <a rel=\"nofollow\" class=\"external text\" href=\"https://web.archive.org/web/20231230191421/https://www.youtube.com/watch?v=8fEEbKJoNbU\">Archived</a> from the original on 30 December 2023<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">30 December</span> 2023</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Guillaume+Verdon%3A+Beff+Jezos%2C+E%2Facc+Movement%2C+Physics%2C+Computation+%26+AGI&amp;rft.series=Lex+Fridman+Podcast&amp;rft.date=2023-12-29&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3D8fEEbKJoNbU&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\" class=\"Z3988\"></span></span>\n</li>\n<li id=\"cite_note-15\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-15\">^</a></b></span> <span class=\"reference-text\"><link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1238218222\"><cite class=\"citation web cs1\"><a rel=\"nofollow\" class=\"external text\" href=\"https://vitalik.eth.limo/general/2023/11/27/techno_optimism.html\">\"My techno-optimism\"</a>. <i>vitalik.eth.limo</i><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">17 August</span> 2024</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=vitalik.eth.limo&amp;rft.atitle=My+techno-optimism&amp;rft_id=https%3A%2F%2Fvitalik.eth.limo%2Fgeneral%2F2023%2F11%2F27%2Ftechno_optimism.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\" class=\"Z3988\"></span></span>\n</li>\n<li id=\"cite_note-16\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-16\">^</a></b></span> <span class=\"reference-text\"><link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1238218222\"><cite id=\"CITEREFNelson2023\" class=\"citation web cs1\">Nelson, Jason (28 November 2023). <a rel=\"nofollow\" class=\"external text\" href=\"https://decrypt.co/207692/ai-turns-mars-not-safe-ethereum-creator-vitalik-buterin\">\"Ethereum Creator Vitalik Buterin: If AI Turns on Us 'Even Mars May Not Be Safe'<span class=\"cs1-kern-right\"></span>\"</a>. <i>Decrypt</i><span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">17 August</span> 2024</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Decrypt&amp;rft.atitle=Ethereum+Creator+Vitalik+Buterin%3A+If+AI+Turns+on+Us+%27Even+Mars+May+Not+Be+Safe%27&amp;rft.date=2023-11-28&amp;rft.aulast=Nelson&amp;rft.aufirst=Jason&amp;rft_id=https%3A%2F%2Fdecrypt.co%2F207692%2Fai-turns-mars-not-safe-ethereum-creator-vitalik-buterin&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\" class=\"Z3988\"></span></span>\n</li>\n<li id=\"cite_note-tc-17\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-tc_17-0\">^</a></b></span> <span class=\"reference-text\"><link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1238218222\"><cite id=\"CITEREFWilhelm2023\" class=\"citation web cs1\">Wilhelm, Alex (20 November 2023). <a rel=\"nofollow\" class=\"external text\" href=\"https://techcrunch.com/2023/11/20/e-acc-doomers-decels-openai-altman/\">\"Effective accelerationism, doomers, decels, and how to flaunt your AI priors\"</a>. <i><a href=\"/wiki/TechCrunch\" title=\"TechCrunch\">TechCrunch</a></i>. <a rel=\"nofollow\" class=\"external text\" href=\"https://web.archive.org/web/20231123115648/https://techcrunch.com/2023/11/20/e-acc-doomers-decels-openai-altman/\">Archived</a> from the original on 23 November 2023<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">24 November</span> 2023</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=TechCrunch&amp;rft.atitle=Effective+accelerationism%2C+doomers%2C+decels%2C+and+how+to+flaunt+your+AI+priors&amp;rft.date=2023-11-20&amp;rft.aulast=Wilhelm&amp;rft.aufirst=Alex&amp;rft_id=https%3A%2F%2Ftechcrunch.com%2F2023%2F11%2F20%2Fe-acc-doomers-decels-openai-altman%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\" class=\"Z3988\"></span></span>\n</li>\n<li id=\"cite_note-ma-18\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-ma_18-0\">^</a></b></span> <span class=\"reference-text\"><link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1238218222\"><cite id=\"CITEREFAndreessen2023\" class=\"citation web cs1\"><a href=\"/wiki/Marc_Andreessen\" title=\"Marc Andreessen\">Andreessen, Marc</a> (16 October 2023). <a rel=\"nofollow\" class=\"external text\" href=\"https://a16z.com/the-techno-optimist-manifesto/\">\"The Techno-Optimist Manifesto\"</a>. <i><a href=\"/wiki/Andreessen_Horowitz\" title=\"Andreessen Horowitz\">Andreessen Horowitz</a></i>. <a rel=\"nofollow\" class=\"external text\" href=\"https://web.archive.org/web/20231123234238/https://a16z.com/the-techno-optimist-manifesto/\">Archived</a> from the original on 23 November 2023<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">24 November</span> 2023</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Andreessen+Horowitz&amp;rft.atitle=The+Techno-Optimist+Manifesto&amp;rft.date=2023-10-16&amp;rft.aulast=Andreessen&amp;rft.aufirst=Marc&amp;rft_id=https%3A%2F%2Fa16z.com%2Fthe-techno-optimist-manifesto%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\" class=\"Z3988\"></span></span>\n</li>\n<li id=\"cite_note-19\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-19\">^</a></b></span> <span class=\"reference-text\"><link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1238218222\"><cite id=\"CITEREFKelly2023\" class=\"citation web cs1\">Kelly, Jemima (22 October 2023). <a rel=\"nofollow\" class=\"external text\" href=\"https://www.ft.com/content/7eeb105d-7d79-4a59-89be-e18cd47be68f\">\"I read Andreessen's 'techno-optimist manifesto' so you don't have to\"</a>. <i><a href=\"/wiki/Financial_Times\" title=\"Financial Times\">Financial Times</a></i>. <a rel=\"nofollow\" class=\"external text\" href=\"https://web.archive.org/web/20240114055702/https://www.ft.com/content/7eeb105d-7d79-4a59-89be-e18cd47be68f\">Archived</a> from the original on 14 January 2024<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">20 January</span> 2024</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Financial+Times&amp;rft.atitle=I+read+Andreessen%27s+%27techno-optimist+manifesto%27+so+you+don%27t+have+to&amp;rft.date=2023-10-22&amp;rft.aulast=Kelly&amp;rft.aufirst=Jemima&amp;rft_id=https%3A%2F%2Fwww.ft.com%2Fcontent%2F7eeb105d-7d79-4a59-89be-e18cd47be68f&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\" class=\"Z3988\"></span></span>\n</li>\n<li id=\"cite_note-20\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-20\">^</a></b></span> <span class=\"reference-text\"><link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1238218222\"><cite id=\"CITEREFSwan2023\" class=\"citation web cs1\">Swan, David (29 October 2023). <a rel=\"nofollow\" class=\"external text\" href=\"https://www.smh.com.au/technology/we-are-conquerors-why-silicon-valley-s-latest-fad-is-its-deadliest-20231027-p5efho.html\">\"<span class=\"cs1-kern-left\"></span>'We are conquerors': Why Silicon Valley's latest fad is its deadliest\"</a>. <i><a href=\"/wiki/The_Sydney_Morning_Herald\" title=\"The Sydney Morning Herald\">The Sydney Morning Herald</a></i>. <a rel=\"nofollow\" class=\"external text\" href=\"https://web.archive.org/web/20231113124449/https://www.smh.com.au/technology/we-are-conquerors-why-silicon-valley-s-latest-fad-is-its-deadliest-20231027-p5efho.html\">Archived</a> from the original on 13 November 2023<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">24 November</span> 2023</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=The+Sydney+Morning+Herald&amp;rft.atitle=%27We+are+conquerors%27%3A+Why+Silicon+Valley%27s+latest+fad+is+its+deadliest&amp;rft.date=2023-10-29&amp;rft.aulast=Swan&amp;rft.aufirst=David&amp;rft_id=https%3A%2F%2Fwww.smh.com.au%2Ftechnology%2Fwe-are-conquerors-why-silicon-valley-s-latest-fad-is-its-deadliest-20231027-p5efho.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\" class=\"Z3988\"></span></span>\n</li>\n<li id=\"cite_note-21\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-21\">^</a></b></span> <span class=\"reference-text\"><link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1238218222\"><cite class=\"citation audio-visual cs1\"><a rel=\"nofollow\" class=\"external text\" href=\"https://www.youtube.com/watch?v=YZWJCMUd_yQ\"><i>Reagan National Defense Forum</i></a>. <a href=\"/wiki/Simi_Valley,_California\" title=\"Simi Valley, California\">Simi Valley</a>: <a href=\"/wiki/Ronald_Reagan_Presidential_Library\" title=\"Ronald Reagan Presidential Library\">Ronald Reagan Presidential Foundation &amp; Institute</a>. 2 December 2023.  Event occurs at 21:03. <a rel=\"nofollow\" class=\"external text\" href=\"https://web.archive.org/web/20231212051956/https://www.youtube.com/watch?v=YZWJCMUd_yQ\">Archived</a> from the original on 12 December 2023<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">14 December</span> 2023</span> &#8211; via <a href=\"/wiki/YouTube\" title=\"YouTube\">YouTube</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Reagan+National+Defense+Forum&amp;rft.place=Simi+Valley&amp;rft.pub=Ronald+Reagan+Presidential+Foundation+%26+Institute&amp;rft.date=2023-12-02&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DYZWJCMUd_yQ&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\" class=\"Z3988\"></span></span>\n</li>\n<li id=\"cite_note-22\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-22\">^</a></b></span> <span class=\"reference-text\"><link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1238218222\"><cite id=\"CITEREFHuet2023\" class=\"citation news cs1\">Huet, Ellen (6 December 2023). <a rel=\"nofollow\" class=\"external text\" href=\"https://www.bloomberg.com/news/newsletters/2023-12-06/effective-accelerationism-and-beff-jezos-form-new-tech-tribe\">\"A Cultural Divide Over AI Forms in Silicon Valley\"</a>. <i><a href=\"/wiki/Bloomberg_News\" title=\"Bloomberg News\">Bloomberg News</a></i>. <a rel=\"nofollow\" class=\"external text\" href=\"https://web.archive.org/web/20231230195448/https://www.bloomberg.com/news/newsletters/2023-12-06/effective-accelerationism-and-beff-jezos-form-new-tech-tribe\">Archived</a> from the original on 30 December 2023<span class=\"reference-accessdate\">. Retrieved <span class=\"nowrap\">30 December</span> 2023</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Bloomberg+News&amp;rft.atitle=A+Cultural+Divide+Over+AI+Forms+in+Silicon+Valley&amp;rft.date=2023-12-06&amp;rft.aulast=Huet&amp;rft.aufirst=Ellen&amp;rft_id=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Fnewsletters%2F2023-12-06%2Feffective-accelerationism-and-beff-jezos-form-new-tech-tribe&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\" class=\"Z3988\"></span></span>\n</li>\n</ol></div></div>\n<div class=\"mw-heading mw-heading2\"><h2 id=\"External_links\">External links</h2><span class=\"mw-editsection\"><span class=\"mw-editsection-bracket\">[</span><a href=\"/w/index.php?title=Effective_accelerationism&amp;action=edit&amp;section=13\" title=\"Edit section: External links\"><span>edit</span></a><span class=\"mw-editsection-bracket\">]</span></span></div>\n<ul><li><link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1238218222\"><cite id=\"CITEREFJezosBayeslord2022\" class=\"citation web cs1\">Jezos, Beff; Bayeslord (10 July 2022). <a rel=\"nofollow\" class=\"external text\" href=\"https://beff.substack.com/p/notes-on-eacc-principles-and-tenets\">\"Notes on e/acc principles and tenets\"</a>. <i>Beff's Newsletter</i>. <a href=\"/wiki/Substack\" title=\"Substack\">Substack</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Beff%27s+Newsletter&amp;rft.atitle=Notes+on+e%2Facc+principles+and+tenets&amp;rft.date=2022-07-10&amp;rft.aulast=Jezos&amp;rft.aufirst=Beff&amp;rft.au=Bayeslord&amp;rft_id=https%3A%2F%2Fbeff.substack.com%2Fp%2Fnotes-on-eacc-principles-and-tenets&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\" class=\"Z3988\"></span></li></ul>\n<div class=\"navbox-styles\"><style data-mw-deduplicate=\"TemplateStyles:r1129693374\">.mw-parser-output .hlist dl,.mw-parser-output .hlist ol,.mw-parser-output .hlist ul{margin:0;padding:0}.mw-parser-output .hlist dd,.mw-parser-output .hlist dt,.mw-parser-output .hlist li{margin:0;display:inline}.mw-parser-output .hlist.inline,.mw-parser-output .hlist.inline dl,.mw-parser-output .hlist.inline ol,.mw-parser-output .hlist.inline ul,.mw-parser-output .hlist dl dl,.mw-parser-output .hlist dl ol,.mw-parser-output .hlist dl ul,.mw-parser-output .hlist ol dl,.mw-parser-output .hlist ol ol,.mw-parser-output .hlist ol ul,.mw-parser-output .hlist ul dl,.mw-parser-output .hlist ul ol,.mw-parser-output .hlist ul ul{display:inline}.mw-parser-output .hlist .mw-empty-li{display:none}.mw-parser-output .hlist dt::after{content:\": \"}.mw-parser-output .hlist dd::after,.mw-parser-output .hlist li::after{content:\" · \";font-weight:bold}.mw-parser-output .hlist dd:last-child::after,.mw-parser-output .hlist dt:last-child::after,.mw-parser-output .hlist li:last-child::after{content:none}.mw-parser-output .hlist dd dd:first-child::before,.mw-parser-output .hlist dd dt:first-child::before,.mw-parser-output .hlist dd li:first-child::before,.mw-parser-output .hlist dt dd:first-child::before,.mw-parser-output .hlist dt dt:first-child::before,.mw-parser-output .hlist dt li:first-child::before,.mw-parser-output .hlist li dd:first-child::before,.mw-parser-output .hlist li dt:first-child::before,.mw-parser-output .hlist li li:first-child::before{content:\" (\";font-weight:normal}.mw-parser-output .hlist dd dd:last-child::after,.mw-parser-output .hlist dd dt:last-child::after,.mw-parser-output .hlist dd li:last-child::after,.mw-parser-output .hlist dt dd:last-child::after,.mw-parser-output .hlist dt dt:last-child::after,.mw-parser-output .hlist dt li:last-child::after,.mw-parser-output .hlist li dd:last-child::after,.mw-parser-output .hlist li dt:last-child::after,.mw-parser-output .hlist li li:last-child::after{content:\")\";font-weight:normal}.mw-parser-output .hlist ol{counter-reset:listitem}.mw-parser-output .hlist ol>li{counter-increment:listitem}.mw-parser-output .hlist ol>li::before{content:\" \"counter(listitem)\"\\a0 \"}.mw-parser-output .hlist dd ol>li:first-child::before,.mw-parser-output .hlist dt ol>li:first-child::before,.mw-parser-output .hlist li ol>li:first-child::before{content:\" (\"counter(listitem)\"\\a0 \"}</style><style data-mw-deduplicate=\"TemplateStyles:r1236075235\">.mw-parser-output .navbox{box-sizing:border-box;border:1px solid #a2a9b1;width:100%;clear:both;font-size:88%;text-align:center;padding:1px;margin:1em auto 0}.mw-parser-output .navbox .navbox{margin-top:0}.mw-parser-output .navbox+.navbox,.mw-parser-output .navbox+.navbox-styles+.navbox{margin-top:-1px}.mw-parser-output .navbox-inner,.mw-parser-output .navbox-subgroup{width:100%}.mw-parser-output .navbox-group,.mw-parser-output .navbox-title,.mw-parser-output .navbox-abovebelow{padding:0.25em 1em;line-height:1.5em;text-align:center}.mw-parser-output .navbox-group{white-space:nowrap;text-align:right}.mw-parser-output .navbox,.mw-parser-output .navbox-subgroup{background-color:#fdfdfd}.mw-parser-output .navbox-list{line-height:1.5em;border-color:#fdfdfd}.mw-parser-output .navbox-list-with-group{text-align:left;border-left-width:2px;border-left-style:solid}.mw-parser-output tr+tr>.navbox-abovebelow,.mw-parser-output tr+tr>.navbox-group,.mw-parser-output tr+tr>.navbox-image,.mw-parser-output tr+tr>.navbox-list{border-top:2px solid #fdfdfd}.mw-parser-output .navbox-title{background-color:#ccf}.mw-parser-output .navbox-abovebelow,.mw-parser-output .navbox-group,.mw-parser-output .navbox-subgroup .navbox-title{background-color:#ddf}.mw-parser-output .navbox-subgroup .navbox-group,.mw-parser-output .navbox-subgroup .navbox-abovebelow{background-color:#e6e6ff}.mw-parser-output .navbox-even{background-color:#f7f7f7}.mw-parser-output .navbox-odd{background-color:transparent}.mw-parser-output .navbox .hlist td dl,.mw-parser-output .navbox .hlist td ol,.mw-parser-output .navbox .hlist td ul,.mw-parser-output .navbox td.hlist dl,.mw-parser-output .navbox td.hlist ol,.mw-parser-output .navbox td.hlist ul{padding:0.125em 0}.mw-parser-output .navbox .navbar{display:block;font-size:100%}.mw-parser-output .navbox-title .navbar{float:left;text-align:left;margin-right:0.5em}body.skin--responsive .mw-parser-output .navbox-image img{max-width:none!important}@media print{body.ns-0 .mw-parser-output .navbox{display:none!important}}</style></div><div role=\"navigation\" class=\"navbox\" aria-labelledby=\"Existential_risk_from_artificial_intelligence\" style=\"padding:3px\"><table class=\"nowraplinks mw-collapsible expanded navbox-inner\" style=\"border-spacing:0;background:transparent;color:inherit\"><tbody><tr><th scope=\"col\" class=\"navbox-title\" colspan=\"2\"><link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"><style data-mw-deduplicate=\"TemplateStyles:r1239400231\">.mw-parser-output .navbar{display:inline;font-size:88%;font-weight:normal}.mw-parser-output .navbar-collapse{float:left;text-align:left}.mw-parser-output .navbar-boxtext{word-spacing:0}.mw-parser-output .navbar ul{display:inline-block;white-space:nowrap;line-height:inherit}.mw-parser-output .navbar-brackets::before{margin-right:-0.125em;content:\"[ \"}.mw-parser-output .navbar-brackets::after{margin-left:-0.125em;content:\" ]\"}.mw-parser-output .navbar li{word-spacing:-0.125em}.mw-parser-output .navbar a>span,.mw-parser-output .navbar a>abbr{text-decoration:inherit}.mw-parser-output .navbar-mini abbr{font-variant:small-caps;border-bottom:none;text-decoration:none;cursor:inherit}.mw-parser-output .navbar-ct-full{font-size:114%;margin:0 7em}.mw-parser-output .navbar-ct-mini{font-size:114%;margin:0 4em}html.skin-theme-clientpref-night .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}@media(prefers-color-scheme:dark){html.skin-theme-clientpref-os .mw-parser-output .navbar li a abbr{color:var(--color-base)!important}}@media print{.mw-parser-output .navbar{display:none!important}}</style><div class=\"navbar plainlinks hlist navbar-mini\"><ul><li class=\"nv-view\"><a href=\"/wiki/Template:Existential_risk_from_artificial_intelligence\" title=\"Template:Existential risk from artificial intelligence\"><abbr title=\"View this template\">v</abbr></a></li><li class=\"nv-talk\"><a href=\"/wiki/Template_talk:Existential_risk_from_artificial_intelligence\" title=\"Template talk:Existential risk from artificial intelligence\"><abbr title=\"Discuss this template\">t</abbr></a></li><li class=\"nv-edit\"><a href=\"/wiki/Special:EditPage/Template:Existential_risk_from_artificial_intelligence\" title=\"Special:EditPage/Template:Existential risk from artificial intelligence\"><abbr title=\"Edit this template\">e</abbr></a></li></ul></div><div id=\"Existential_risk_from_artificial_intelligence\" style=\"font-size:114%;margin:0 4em\"><a href=\"/wiki/Existential_risk_from_artificial_general_intelligence\" title=\"Existential risk from artificial general intelligence\">Existential risk</a> from <a href=\"/wiki/Artificial_intelligence\" title=\"Artificial intelligence\">artificial intelligence</a></div></th></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%\">Concepts</th><td class=\"navbox-list-with-group navbox-list navbox-odd hlist\" style=\"width:100%;padding:0\"><div style=\"padding:0 0.25em\">\n<ul><li><a href=\"/wiki/Artificial_general_intelligence\" title=\"Artificial general intelligence\">AGI</a></li>\n<li><a href=\"/wiki/AI_alignment\" title=\"AI alignment\">AI alignment</a></li>\n<li><a href=\"/wiki/AI_capability_control\" title=\"AI capability control\">AI capability control</a></li>\n<li><a href=\"/wiki/AI_safety\" title=\"AI safety\">AI safety</a></li>\n<li><a href=\"/wiki/AI_takeover\" title=\"AI takeover\">AI takeover</a></li>\n<li><a href=\"/wiki/Consequentialism\" title=\"Consequentialism\">Consequentialism</a></li>\n<li><a class=\"mw-selflink selflink\">Effective accelerationism</a></li>\n<li><a href=\"/wiki/Ethics_of_artificial_intelligence\" title=\"Ethics of artificial intelligence\">Ethics of artificial intelligence</a></li>\n<li><a href=\"/wiki/Existential_risk_from_artificial_general_intelligence\" title=\"Existential risk from artificial general intelligence\">Existential risk from artificial general intelligence</a></li>\n<li><a href=\"/wiki/Friendly_artificial_intelligence\" title=\"Friendly artificial intelligence\">Friendly artificial intelligence</a></li>\n<li><a href=\"/wiki/Instrumental_convergence\" title=\"Instrumental convergence\">Instrumental convergence</a></li>\n<li><a href=\"/wiki/Intelligence_explosion\" class=\"mw-redirect\" title=\"Intelligence explosion\">Intelligence explosion</a></li>\n<li><a href=\"/wiki/Longtermism\" title=\"Longtermism\">Longtermism</a></li>\n<li><a href=\"/wiki/Machine_ethics\" title=\"Machine ethics\">Machine ethics</a></li>\n<li><a href=\"/wiki/Suffering_risks\" title=\"Suffering risks\">Suffering risks</a></li>\n<li><a href=\"/wiki/Superintelligence\" title=\"Superintelligence\">Superintelligence</a></li>\n<li><a href=\"/wiki/Technological_singularity\" title=\"Technological singularity\">Technological singularity</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%\">Organizations</th><td class=\"navbox-list-with-group navbox-list navbox-even hlist\" style=\"width:100%;padding:0\"><div style=\"padding:0 0.25em\">\n<ul><li><a href=\"/wiki/Alignment_Research_Center\" title=\"Alignment Research Center\">Alignment Research Center</a></li>\n<li><a href=\"/wiki/Center_for_AI_Safety\" title=\"Center for AI Safety\">Center for AI Safety</a></li>\n<li><a href=\"/wiki/Center_for_Applied_Rationality\" title=\"Center for Applied Rationality\">Center for Applied Rationality</a></li>\n<li><a href=\"/wiki/Center_for_Human-Compatible_Artificial_Intelligence\" title=\"Center for Human-Compatible Artificial Intelligence\">Center for Human-Compatible Artificial Intelligence</a></li>\n<li><a href=\"/wiki/Centre_for_the_Study_of_Existential_Risk\" title=\"Centre for the Study of Existential Risk\">Centre for the Study of Existential Risk</a></li>\n<li><a href=\"/wiki/EleutherAI\" title=\"EleutherAI\">EleutherAI</a></li>\n<li><a href=\"/wiki/Future_of_Humanity_Institute\" title=\"Future of Humanity Institute\">Future of Humanity Institute</a></li>\n<li><a href=\"/wiki/Future_of_Life_Institute\" title=\"Future of Life Institute\">Future of Life Institute</a></li>\n<li><a href=\"/wiki/Google_DeepMind\" title=\"Google DeepMind\">Google DeepMind</a></li>\n<li><a href=\"/wiki/Humanity%2B\" title=\"Humanity+\">Humanity+</a></li>\n<li><a href=\"/wiki/Institute_for_Ethics_and_Emerging_Technologies\" title=\"Institute for Ethics and Emerging Technologies\">Institute for Ethics and Emerging Technologies</a></li>\n<li><a href=\"/wiki/Leverhulme_Centre_for_the_Future_of_Intelligence\" title=\"Leverhulme Centre for the Future of Intelligence\">Leverhulme Centre for the Future of Intelligence</a></li>\n<li><a href=\"/wiki/Machine_Intelligence_Research_Institute\" title=\"Machine Intelligence Research Institute\">Machine Intelligence Research Institute</a></li>\n<li><a href=\"/wiki/OpenAI\" title=\"OpenAI\">OpenAI</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%\">People</th><td class=\"navbox-list-with-group navbox-list navbox-odd hlist\" style=\"width:100%;padding:0\"><div style=\"padding:0 0.25em\">\n<ul><li><a href=\"/wiki/Slate_Star_Codex\" title=\"Slate Star Codex\">Scott Alexander</a></li>\n<li><a href=\"/wiki/Sam_Altman\" title=\"Sam Altman\">Sam Altman</a></li>\n<li><a href=\"/wiki/Yoshua_Bengio\" title=\"Yoshua Bengio\">Yoshua Bengio</a></li>\n<li><a href=\"/wiki/Nick_Bostrom\" title=\"Nick Bostrom\">Nick Bostrom</a></li>\n<li><a href=\"/wiki/Paul_Christiano_(researcher)\" title=\"Paul Christiano (researcher)\">Paul Christiano</a></li>\n<li><a href=\"/wiki/K._Eric_Drexler\" title=\"K. Eric Drexler\">Eric Drexler</a></li>\n<li><a href=\"/wiki/Sam_Harris\" title=\"Sam Harris\">Sam Harris</a></li>\n<li><a href=\"/wiki/Stephen_Hawking\" title=\"Stephen Hawking\">Stephen Hawking</a></li>\n<li><a href=\"/wiki/Dan_Hendrycks\" title=\"Dan Hendrycks\">Dan Hendrycks</a></li>\n<li><a href=\"/wiki/Geoffrey_Hinton\" title=\"Geoffrey Hinton\">Geoffrey Hinton</a></li>\n<li><a href=\"/wiki/Bill_Joy\" title=\"Bill Joy\">Bill Joy</a></li>\n<li><a href=\"/wiki/Shane_Legg\" title=\"Shane Legg\">Shane Legg</a></li>\n<li><a href=\"/wiki/Elon_Musk\" title=\"Elon Musk\">Elon Musk</a></li>\n<li><a href=\"/wiki/Steve_Omohundro\" title=\"Steve Omohundro\">Steve Omohundro</a></li>\n<li><a href=\"/wiki/Huw_Price\" title=\"Huw Price\">Huw Price</a></li>\n<li><a href=\"/wiki/Martin_Rees\" title=\"Martin Rees\">Martin Rees</a></li>\n<li><a href=\"/wiki/Stuart_J._Russell\" title=\"Stuart J. Russell\">Stuart J. Russell</a></li>\n<li><a href=\"/wiki/Jaan_Tallinn\" title=\"Jaan Tallinn\">Jaan Tallinn</a></li>\n<li><a href=\"/wiki/Max_Tegmark\" title=\"Max Tegmark\">Max Tegmark</a></li>\n<li><a href=\"/wiki/Frank_Wilczek\" title=\"Frank Wilczek\">Frank Wilczek</a></li>\n<li><a href=\"/wiki/Roman_Yampolskiy\" title=\"Roman Yampolskiy\">Roman Yampolskiy</a></li>\n<li><a href=\"/wiki/Eliezer_Yudkowsky\" title=\"Eliezer Yudkowsky\">Eliezer Yudkowsky</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%\">Other</th><td class=\"navbox-list-with-group navbox-list navbox-even hlist\" style=\"width:100%;padding:0\"><div style=\"padding:0 0.25em\">\n<ul><li><a href=\"/wiki/Statement_on_AI_risk_of_extinction\" title=\"Statement on AI risk of extinction\">Statement on AI risk of extinction</a></li>\n<li><i><a href=\"/wiki/Human_Compatible\" title=\"Human Compatible\">Human Compatible</a></i></li>\n<li><a href=\"/wiki/Open_letter_on_artificial_intelligence_(2015)\" title=\"Open letter on artificial intelligence (2015)\">Open letter on artificial intelligence (2015)</a></li>\n<li><i><a href=\"/wiki/Our_Final_Invention\" title=\"Our Final Invention\">Our Final Invention</a></i></li>\n<li><i><a href=\"/wiki/The_Precipice:_Existential_Risk_and_the_Future_of_Humanity\" title=\"The Precipice: Existential Risk and the Future of Humanity\">The Precipice</a></i></li>\n<li><i><a href=\"/wiki/Superintelligence:_Paths,_Dangers,_Strategies\" title=\"Superintelligence: Paths, Dangers, Strategies\">Superintelligence: Paths, Dangers, Strategies</a></i></li>\n<li><i><a href=\"/wiki/Do_You_Trust_This_Computer%3F\" title=\"Do You Trust This Computer?\">Do You Trust This Computer?</a></i></li>\n<li><a href=\"/wiki/Artificial_Intelligence_Act\" title=\"Artificial Intelligence Act\">Artificial Intelligence Act</a></li></ul>\n</div></td></tr><tr><td class=\"navbox-abovebelow\" colspan=\"2\"><div><span class=\"noviewer\" typeof=\"mw:File\"><span title=\"Category\"><img alt=\"\" src=\"//upload.wikimedia.org/wikipedia/en/thumb/9/96/Symbol_category_class.svg/16px-Symbol_category_class.svg.png\" decoding=\"async\" width=\"16\" height=\"16\" class=\"mw-file-element\" srcset=\"//upload.wikimedia.org/wikipedia/en/thumb/9/96/Symbol_category_class.svg/23px-Symbol_category_class.svg.png 1.5x, //upload.wikimedia.org/wikipedia/en/thumb/9/96/Symbol_category_class.svg/31px-Symbol_category_class.svg.png 2x\" data-file-width=\"180\" data-file-height=\"185\" /></span></span> <a href=\"/wiki/Category:Existential_risk_from_artificial_general_intelligence\" title=\"Category:Existential risk from artificial general intelligence\">Category</a></div></td></tr></tbody></table></div>\n<div class=\"navbox-styles\"><link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"><link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1236075235\"></div><div role=\"navigation\" class=\"navbox\" aria-labelledby=\"Effective_altruism\" style=\"padding:3px\"><table class=\"nowraplinks mw-collapsible mw-collapsed navbox-inner\" style=\"border-spacing:0;background:transparent;color:inherit\"><tbody><tr><th scope=\"col\" class=\"navbox-title\" colspan=\"2\"><link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1129693374\"><link rel=\"mw-deduplicated-inline-style\" href=\"mw-data:TemplateStyles:r1239400231\"><div class=\"navbar plainlinks hlist navbar-mini\"><ul><li class=\"nv-view\"><a href=\"/wiki/Template:Effective_altruism\" title=\"Template:Effective altruism\"><abbr title=\"View this template\">v</abbr></a></li><li class=\"nv-talk\"><a href=\"/wiki/Template_talk:Effective_altruism\" title=\"Template talk:Effective altruism\"><abbr title=\"Discuss this template\">t</abbr></a></li><li class=\"nv-edit\"><a href=\"/wiki/Special:EditPage/Template:Effective_altruism\" title=\"Special:EditPage/Template:Effective altruism\"><abbr title=\"Edit this template\">e</abbr></a></li></ul></div><div id=\"Effective_altruism\" style=\"font-size:114%;margin:0 4em\"><a href=\"/wiki/Effective_altruism\" title=\"Effective altruism\">Effective altruism</a></div></th></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%\">Concepts</th><td class=\"navbox-list-with-group navbox-list navbox-odd hlist\" style=\"width:100%;padding:0\"><div style=\"padding:0 0.25em\">\n<ul><li><a href=\"/wiki/Aid_effectiveness\" title=\"Aid effectiveness\">Aid effectiveness</a></li>\n<li><a href=\"/wiki/Charity_assessment\" title=\"Charity assessment\">Charity assessment</a></li>\n<li><a href=\"/wiki/Demandingness_objection\" title=\"Demandingness objection\">Demandingness objection</a></li>\n<li><a href=\"/wiki/Disability-adjusted_life_year\" title=\"Disability-adjusted life year\">Disability-adjusted life year</a></li>\n<li><a href=\"/wiki/Disease_burden\" title=\"Disease burden\">Disease burden</a></li>\n<li><a href=\"/wiki/Distributional_cost-effectiveness_analysis\" title=\"Distributional cost-effectiveness analysis\">Distributional cost-effectiveness analysis</a></li>\n<li><a href=\"/wiki/Earning_to_give\" title=\"Earning to give\">Earning to give</a></li>\n<li><a href=\"/wiki/Equal_consideration_of_interests\" title=\"Equal consideration of interests\">Equal consideration of interests</a></li>\n<li><a href=\"/wiki/Longtermism\" title=\"Longtermism\">Longtermism</a></li>\n<li><a href=\"/wiki/Marginal_utility\" title=\"Marginal utility\">Marginal utility</a></li>\n<li><a href=\"/wiki/Moral_circle_expansion\" title=\"Moral circle expansion\">Moral circle expansion</a></li>\n<li><a href=\"/wiki/Psychological_barriers_to_effective_altruism\" title=\"Psychological barriers to effective altruism\">Psychological barriers to effective altruism</a></li>\n<li><a href=\"/wiki/Quality-adjusted_life_year\" title=\"Quality-adjusted life year\">Quality-adjusted life year</a></li>\n<li><a href=\"/wiki/Utilitarianism\" title=\"Utilitarianism\">Utilitarianism</a></li>\n<li><a href=\"/wiki/Venture_philanthropy\" title=\"Venture philanthropy\">Venture philanthropy</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%\">Key figures</th><td class=\"navbox-list-with-group navbox-list navbox-even hlist\" style=\"width:100%;padding:0\"><div style=\"padding:0 0.25em\">\n<ul><li><a href=\"/wiki/Sam_Bankman-Fried\" title=\"Sam Bankman-Fried\">Sam Bankman-Fried</a></li>\n<li><a href=\"/wiki/Liv_Boeree\" title=\"Liv Boeree\">Liv Boeree</a></li>\n<li><a href=\"/wiki/Nick_Bostrom\" title=\"Nick Bostrom\">Nick Bostrom</a></li>\n<li><a href=\"/wiki/Hilary_Greaves\" title=\"Hilary Greaves\">Hilary Greaves</a></li>\n<li><a href=\"/wiki/Holden_Karnofsky\" title=\"Holden Karnofsky\">Holden Karnofsky</a></li>\n<li><a href=\"/wiki/William_MacAskill\" title=\"William MacAskill\">William MacAskill</a></li>\n<li><a href=\"/wiki/Dustin_Moskovitz\" title=\"Dustin Moskovitz\">Dustin Moskovitz</a></li>\n<li><a href=\"/wiki/Yew-Kwang_Ng\" title=\"Yew-Kwang Ng\">Yew-Kwang Ng</a></li>\n<li><a href=\"/wiki/Toby_Ord\" title=\"Toby Ord\">Toby Ord</a></li>\n<li><a href=\"/wiki/Derek_Parfit\" title=\"Derek Parfit\">Derek Parfit</a></li>\n<li><a href=\"/wiki/Peter_Singer\" title=\"Peter Singer\">Peter Singer</a></li>\n<li><a href=\"/wiki/Cari_Tuna\" title=\"Cari Tuna\">Cari Tuna</a></li>\n<li><a href=\"/wiki/Eliezer_Yudkowsky\" title=\"Eliezer Yudkowsky\">Eliezer Yudkowsky</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%\">Organizations</th><td class=\"navbox-list-with-group navbox-list navbox-odd hlist\" style=\"width:100%;padding:0\"><div style=\"padding:0 0.25em\">\n<ul><li><a href=\"/wiki/80,000_Hours\" title=\"80,000 Hours\">80,000 Hours</a></li>\n<li><a href=\"/wiki/Against_Malaria_Foundation\" title=\"Against Malaria Foundation\">Against Malaria Foundation</a></li>\n<li><a href=\"/wiki/All-Party_Parliamentary_Group_for_Future_Generations\" title=\"All-Party Parliamentary Group for Future Generations\">All-Party Parliamentary Group for Future Generations</a></li>\n<li><a href=\"/wiki/Animal_Charity_Evaluators\" title=\"Animal Charity Evaluators\">Animal Charity Evaluators</a></li>\n<li><a href=\"/wiki/Animal_Ethics_(organization)\" title=\"Animal Ethics (organization)\">Animal Ethics</a></li>\n<li><a href=\"/wiki/Centre_for_Effective_Altruism\" title=\"Centre for Effective Altruism\">Centre for Effective Altruism</a></li>\n<li><a href=\"/wiki/Centre_for_Enabling_EA_Learning_%26_Research\" title=\"Centre for Enabling EA Learning &amp; Research\">Centre for Enabling EA Learning &amp; Research</a></li>\n<li><a href=\"/wiki/Center_for_High_Impact_Philanthropy\" title=\"Center for High Impact Philanthropy\">Center for High Impact Philanthropy</a></li>\n<li><a href=\"/wiki/Centre_for_the_Study_of_Existential_Risk\" title=\"Centre for the Study of Existential Risk\">Centre for the Study of Existential Risk</a></li>\n<li><a href=\"/wiki/Development_Media_International\" title=\"Development Media International\">Development Media International</a></li>\n<li><a href=\"/wiki/Evidence_Action\" title=\"Evidence Action\">Evidence Action</a></li>\n<li><a href=\"/wiki/Faunalytics\" title=\"Faunalytics\">Faunalytics</a></li>\n<li><a href=\"/wiki/Fistula_Foundation\" title=\"Fistula Foundation\">Fistula Foundation</a></li>\n<li><a href=\"/wiki/Future_of_Humanity_Institute\" title=\"Future of Humanity Institute\">Future of Humanity Institute</a></li>\n<li><a href=\"/wiki/Future_of_Life_Institute\" title=\"Future of Life Institute\">Future of Life Institute</a></li>\n<li><a href=\"/wiki/Founders_Pledge\" title=\"Founders Pledge\">Founders Pledge</a></li>\n<li><a href=\"/wiki/GiveDirectly\" title=\"GiveDirectly\">GiveDirectly</a></li>\n<li><a href=\"/wiki/GiveWell\" title=\"GiveWell\">GiveWell</a></li>\n<li><a href=\"/wiki/Giving_What_We_Can\" title=\"Giving What We Can\">Giving What We Can</a></li>\n<li><a href=\"/wiki/Good_Food_Fund\" title=\"Good Food Fund\">Good Food Fund</a></li>\n<li><a href=\"/wiki/The_Good_Food_Institute\" title=\"The Good Food Institute\">The Good Food Institute</a></li>\n<li><a href=\"/wiki/Good_Ventures\" title=\"Good Ventures\">Good Ventures</a></li>\n<li><a href=\"/wiki/The_Humane_League\" title=\"The Humane League\">The Humane League</a></li>\n<li><a href=\"/wiki/Mercy_for_Animals\" title=\"Mercy for Animals\">Mercy for Animals</a></li>\n<li><a href=\"/wiki/Machine_Intelligence_Research_Institute\" title=\"Machine Intelligence Research Institute\">Machine Intelligence Research Institute</a></li>\n<li><a href=\"/wiki/Malaria_Consortium\" title=\"Malaria Consortium\">Malaria Consortium</a></li>\n<li><a href=\"/wiki/Nuclear_Threat_Initiative\" title=\"Nuclear Threat Initiative\">Nuclear Threat Initiative</a></li>\n<li><a href=\"/wiki/Open_Philanthropy_(organization)\" class=\"mw-redirect\" title=\"Open Philanthropy (organization)\">Open Philanthropy</a></li>\n<li><a href=\"/wiki/Raising_for_Effective_Giving\" title=\"Raising for Effective Giving\">Raising for Effective Giving</a></li>\n<li><a href=\"/wiki/Sentience_Institute\" title=\"Sentience Institute\">Sentience Institute</a></li>\n<li><a href=\"/wiki/Unlimit_Health\" title=\"Unlimit Health\">Unlimit Health</a></li>\n<li><a href=\"/wiki/Wild_Animal_Initiative\" title=\"Wild Animal Initiative\">Wild Animal Initiative</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%\">Focus areas</th><td class=\"navbox-list-with-group navbox-list navbox-even hlist\" style=\"width:100%;padding:0\"><div style=\"padding:0 0.25em\">\n<ul><li><a href=\"/wiki/Biotechnology_risk\" title=\"Biotechnology risk\">Biotechnology risk</a></li>\n<li><a href=\"/wiki/Climate_change\" title=\"Climate change\">Climate change</a></li>\n<li><a href=\"/wiki/Cultured_meat\" title=\"Cultured meat\">Cultured meat</a></li>\n<li><a href=\"/wiki/Economic_stability\" title=\"Economic stability\">Economic stability</a></li>\n<li><a href=\"/wiki/Existential_risk_from_artificial_general_intelligence\" title=\"Existential risk from artificial general intelligence\">Existential risk from artificial general intelligence</a></li>\n<li><a href=\"/wiki/Global_catastrophic_risk\" title=\"Global catastrophic risk\">Global catastrophic risk</a></li>\n<li><a href=\"/wiki/Global_health\" title=\"Global health\">Global health</a></li>\n<li><a href=\"/wiki/Global_poverty\" class=\"mw-redirect\" title=\"Global poverty\">Global poverty</a></li>\n<li><a href=\"/wiki/Immigration_reform\" title=\"Immigration reform\">Immigration reform</a></li>\n<li><a href=\"/wiki/Intensive_animal_farming\" title=\"Intensive animal farming\">Intensive animal farming</a></li>\n<li><a href=\"/wiki/Land_use\" title=\"Land use\">Land use reform</a></li>\n<li><a href=\"/wiki/Life_extension\" title=\"Life extension\">Life extension</a></li>\n<li><a href=\"/wiki/Malaria_prevention\" class=\"mw-redirect\" title=\"Malaria prevention\">Malaria prevention</a></li>\n<li><a href=\"/wiki/Mass_deworming\" title=\"Mass deworming\">Mass deworming</a></li>\n<li><a href=\"/wiki/Neglected_tropical_diseases\" title=\"Neglected tropical diseases\">Neglected tropical diseases</a></li>\n<li><a href=\"/wiki/Suffering_risks\" title=\"Suffering risks\">Suffering risks</a></li>\n<li><a href=\"/wiki/Wild_animal_suffering\" title=\"Wild animal suffering\">Wild animal suffering</a></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%\">Literature</th><td class=\"navbox-list-with-group navbox-list navbox-odd hlist\" style=\"width:100%;padding:0\"><div style=\"padding:0 0.25em\">\n<ul><li><i><a href=\"/wiki/Doing_Good_Better\" title=\"Doing Good Better\">Doing Good Better</a></i></li>\n<li><i><a href=\"/wiki/The_End_of_Animal_Farming\" title=\"The End of Animal Farming\">The End of Animal Farming</a></i></li>\n<li><i><a href=\"/wiki/Famine,_Affluence,_and_Morality\" title=\"Famine, Affluence, and Morality\">Famine, Affluence, and Morality</a></i></li>\n<li><i><a href=\"/wiki/The_Life_You_Can_Save\" title=\"The Life You Can Save\">The Life You Can Save</a></i></li>\n<li><i><a href=\"/wiki/Living_High_and_Letting_Die\" title=\"Living High and Letting Die\">Living High and Letting Die</a></i></li>\n<li><i><a href=\"/wiki/The_Most_Good_You_Can_Do\" title=\"The Most Good You Can Do\">The Most Good You Can Do</a></i></li>\n<li><i><a href=\"/wiki/Practical_Ethics\" title=\"Practical Ethics\">Practical Ethics</a></i></li>\n<li><i><a href=\"/wiki/The_Precipice:_Existential_Risk_and_the_Future_of_Humanity\" title=\"The Precipice: Existential Risk and the Future of Humanity\">The Precipice</a></i></li>\n<li><i><a href=\"/wiki/Superintelligence:_Paths,_Dangers,_Strategies\" title=\"Superintelligence: Paths, Dangers, Strategies\">Superintelligence: Paths, Dangers, Strategies</a></i></li>\n<li><i><a href=\"/wiki/What_We_Owe_the_Future\" title=\"What We Owe the Future\">What We Owe the Future</a></i></li></ul>\n</div></td></tr><tr><th scope=\"row\" class=\"navbox-group\" style=\"width:1%\">Events</th><td class=\"navbox-list-with-group navbox-list navbox-even hlist\" style=\"width:100%;padding:0\"><div style=\"padding:0 0.25em\">\n<ul><li><a href=\"/wiki/Effective_Altruism_Global\" title=\"Effective Altruism Global\">Effective Altruism Global</a></li></ul>\n</div></td></tr></tbody></table></div>\n<!-- \nNewPP limit report\nParsed by mw‐web.eqiad.main‐5696db9cdd‐ssjmm\nCached time: 20240826132731\nCache expiry: 2592000\nReduced expiry: false\nComplications: [vary‐revision‐sha1, show‐toc]\nCPU time usage: 0.532 seconds\nReal time usage: 0.732 seconds\nPreprocessor visited node count: 1808/1000000\nPost‐expand include size: 75638/2097152 bytes\nTemplate argument size: 750/2097152 bytes\nHighest expansion depth: 12/100\nExpensive parser function count: 2/500\nUnstrip recursion depth: 1/20\nUnstrip post‐expand size: 105169/5000000 bytes\nLua time usage: 0.325/10.000 seconds\nLua memory usage: 5017662/52428800 bytes\nNumber of Wikibase entities loaded: 0/400\n-->\n<!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00%  574.104      1 -total\n 45.48%  261.111      1 Template:Reflist\n 33.90%  194.639     17 Template:Cite_web\n 21.49%  123.372      1 Template:Short_description\n 21.23%  121.855      2 Template:Navbox\n 20.50%  117.704      1 Template:Existential_risk_from_artificial_intelligence\n 14.23%   81.680      2 Template:Pagetype\n  4.43%   25.451      4 Template:Main_other\n  4.19%   24.066      1 Template:Use_dmy_dates\n  3.88%   22.298      1 Template:SDcat\n-->\n\n<!-- Saved in parser cache with key enwiki:pcache:idhash:75085196-0!canonical and timestamp 20240826132731 and revision id 1241702588. Rendering was triggered because: page-view\n -->\n</div><!--esi <esi:include src=\"/esitest-fa8a495983347898/content\" /> --><noscript><img src=\"https://login.wikimedia.org/wiki/Special:CentralAutoLogin/start?type=1x1\" alt=\"\" width=\"1\" height=\"1\" style=\"border: none; position: absolute;\"></noscript>\n<div class=\"printfooter\" data-nosnippet=\"\">Retrieved from \"<a dir=\"ltr\" href=\"https://en.wikipedia.org/w/index.php?title=Effective_accelerationism&amp;oldid=1241702588\">https://en.wikipedia.org/w/index.php?title=Effective_accelerationism&amp;oldid=1241702588</a>\"</div></div>\n\t\t\t\t\t<div id=\"catlinks\" class=\"catlinks\" data-mw=\"interface\"><div id=\"mw-normal-catlinks\" class=\"mw-normal-catlinks\"><a href=\"/wiki/Help:Category\" title=\"Help:Category\">Categories</a>: <ul><li><a href=\"/wiki/Category:Computational_neuroscience\" title=\"Category:Computational neuroscience\">Computational neuroscience</a></li><li><a href=\"/wiki/Category:Concepts_in_ethics\" title=\"Category:Concepts in ethics\">Concepts in ethics</a></li><li><a href=\"/wiki/Category:Cybernetics\" title=\"Category:Cybernetics\">Cybernetics</a></li><li><a href=\"/wiki/Category:Doomsday_scenarios\" title=\"Category:Doomsday scenarios\">Doomsday scenarios</a></li><li><a href=\"/wiki/Category:Effective_altruism\" title=\"Category:Effective altruism\">Effective altruism</a></li><li><a href=\"/wiki/Category:Ethics_of_science_and_technology\" title=\"Category:Ethics of science and technology\">Ethics of science and technology</a></li><li><a href=\"/wiki/Category:Existential_risk_from_artificial_general_intelligence\" title=\"Category:Existential risk from artificial general intelligence\">Existential risk from artificial general intelligence</a></li><li><a href=\"/wiki/Category:Future_problems\" title=\"Category:Future problems\">Future problems</a></li><li><a href=\"/wiki/Category:Human_extinction\" title=\"Category:Human extinction\">Human extinction</a></li><li><a href=\"/wiki/Category:Philosophy_of_artificial_intelligence\" title=\"Category:Philosophy of artificial intelligence\">Philosophy of artificial intelligence</a></li><li><a href=\"/wiki/Category:Singularitarianism\" title=\"Category:Singularitarianism\">Singularitarianism</a></li><li><a href=\"/wiki/Category:Technology_hazards\" title=\"Category:Technology hazards\">Technology hazards</a></li><li><a href=\"/wiki/Category:Effective_accelerationism\" title=\"Category:Effective accelerationism\">Effective accelerationism</a></li></ul></div><div id=\"mw-hidden-catlinks\" class=\"mw-hidden-catlinks mw-hidden-cats-hidden\">Hidden categories: <ul><li><a href=\"/wiki/Category:CS1_German-language_sources_(de)\" title=\"Category:CS1 German-language sources (de)\">CS1 German-language sources (de)</a></li><li><a href=\"/wiki/Category:Articles_with_short_description\" title=\"Category:Articles with short description\">Articles with short description</a></li><li><a href=\"/wiki/Category:Short_description_is_different_from_Wikidata\" title=\"Category:Short description is different from Wikidata\">Short description is different from Wikidata</a></li><li><a href=\"/wiki/Category:Use_dmy_dates_from_November_2023\" title=\"Category:Use dmy dates from November 2023\">Use dmy dates from November 2023</a></li></ul></div></div>\n\t\t\t\t</div>\n\t\t\t</main>\n\t\t\t\n\t\t</div>\n\t\t<div class=\"mw-footer-container\">\n\t\t\t\n<footer id=\"footer\" class=\"mw-footer\" >\n\t<ul id=\"footer-info\">\n\t<li id=\"footer-info-lastmod\"> This page was last edited on 22 August 2024, at 17:49<span class=\"anonymous-show\">&#160;(UTC)</span>.</li>\n\t<li id=\"footer-info-copyright\">Text is available under the <a rel=\"license\" href=\"//en.wikipedia.org/wiki/Wikipedia:Text_of_the_Creative_Commons_Attribution-ShareAlike_4.0_International_License\">Creative Commons Attribution-ShareAlike License 4.0</a><a rel=\"license\" href=\"//en.wikipedia.org/wiki/Wikipedia:Text_of_the_Creative_Commons_Attribution-ShareAlike_4.0_International_License\" style=\"display:none;\"></a>;\nadditional terms may apply. By using this site, you agree to the <a href=\"//foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Terms_of_Use\">Terms of Use</a> and <a href=\"//foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Privacy_policy\">Privacy Policy</a>. Wikipedia® is a registered trademark of the <a href=\"//wikimediafoundation.org/\">Wikimedia Foundation, Inc.</a>, a non-profit organization.</li>\n</ul>\n\n\t<ul id=\"footer-places\">\n\t<li id=\"footer-places-privacy\"><a href=\"https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Privacy_policy\">Privacy policy</a></li>\n\t<li id=\"footer-places-about\"><a href=\"/wiki/Wikipedia:About\">About Wikipedia</a></li>\n\t<li id=\"footer-places-disclaimers\"><a href=\"/wiki/Wikipedia:General_disclaimer\">Disclaimers</a></li>\n\t<li id=\"footer-places-contact\"><a href=\"//en.wikipedia.org/wiki/Wikipedia:Contact_us\">Contact Wikipedia</a></li>\n\t<li id=\"footer-places-wm-codeofconduct\"><a href=\"https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Universal_Code_of_Conduct\">Code of Conduct</a></li>\n\t<li id=\"footer-places-developers\"><a href=\"https://developer.wikimedia.org\">Developers</a></li>\n\t<li id=\"footer-places-statslink\"><a href=\"https://stats.wikimedia.org/#/en.wikipedia.org\">Statistics</a></li>\n\t<li id=\"footer-places-cookiestatement\"><a href=\"https://foundation.wikimedia.org/wiki/Special:MyLanguage/Policy:Cookie_statement\">Cookie statement</a></li>\n\t<li id=\"footer-places-mobileview\"><a href=\"//en.m.wikipedia.org/w/index.php?title=Effective_accelerationism&amp;mobileaction=toggle_view_mobile\" class=\"noprint stopMobileRedirectToggle\">Mobile view</a></li>\n</ul>\n\n\t<ul id=\"footer-icons\" class=\"noprint\">\n\t<li id=\"footer-copyrightico\"><a class=\"cdx-button cdx-button--fake-button cdx-button--size-large cdx-button--fake-button--enabled\" style=\"padding-left: 8px; padding-right: 8px;\" href=\"https://wikimediafoundation.org/\" target=\"https://wikimediafoundation.org/\"><img src=\"/static/images/footer/wikimedia-button.svg\" width=\"84\" height=\"29\" alt=\"Wikimedia Foundation\"></a></li>\n\t<li id=\"footer-poweredbyico\"><a class=\"cdx-button cdx-button--fake-button cdx-button--size-large cdx-button--fake-button--enabled\" style=\"padding-left: 8px; padding-right: 8px;\" href=\"https://www.mediawiki.org\" target=\"https://www.mediawiki.org\"><img src=\"/static/images/footer/poweredby_mediawiki.svg\" width=\"84\" height=\"29\" alt=\"Powered by MediaWiki\"></a></li>\n</ul>\n\n</footer>\n\n\t\t</div>\n\t</div> \n</div> \n<div class=\"vector-settings\" id=\"p-dock-bottom\">\n\t<ul>\n\t\t<li>\n\t\t</li>\n\t</ul>\n</div>\n<script>(RLQ=window.RLQ||[]).push(function(){mw.config.set({\"wgHostname\":\"mw-web.eqiad.main-5c99b86ddc-7hdc6\",\"wgBackendResponseTime\":214,\"wgPageParseReport\":{\"limitreport\":{\"cputime\":\"0.532\",\"walltime\":\"0.732\",\"ppvisitednodes\":{\"value\":1808,\"limit\":1000000},\"postexpandincludesize\":{\"value\":75638,\"limit\":2097152},\"templateargumentsize\":{\"value\":750,\"limit\":2097152},\"expansiondepth\":{\"value\":12,\"limit\":100},\"expensivefunctioncount\":{\"value\":2,\"limit\":500},\"unstrip-depth\":{\"value\":1,\"limit\":20},\"unstrip-size\":{\"value\":105169,\"limit\":5000000},\"entityaccesscount\":{\"value\":0,\"limit\":400},\"timingprofile\":[\"100.00%  574.104      1 -total\",\" 45.48%  261.111      1 Template:Reflist\",\" 33.90%  194.639     17 Template:Cite_web\",\" 21.49%  123.372      1 Template:Short_description\",\" 21.23%  121.855      2 Template:Navbox\",\" 20.50%  117.704      1 Template:Existential_risk_from_artificial_intelligence\",\" 14.23%   81.680      2 Template:Pagetype\",\"  4.43%   25.451      4 Template:Main_other\",\"  4.19%   24.066      1 Template:Use_dmy_dates\",\"  3.88%   22.298      1 Template:SDcat\"]},\"scribunto\":{\"limitreport-timeusage\":{\"value\":\"0.325\",\"limit\":\"10.000\"},\"limitreport-memusage\":{\"value\":5017662,\"limit\":52428800}},\"cachereport\":{\"origin\":\"mw-web.eqiad.main-5696db9cdd-ssjmm\",\"timestamp\":\"20240826132731\",\"ttl\":2592000,\"transientcontent\":false}}});});</script>\n<script type=\"application/ld+json\">{\"@context\":\"https:\\/\\/schema.org\",\"@type\":\"Article\",\"name\":\"Effective accelerationism\",\"url\":\"https:\\/\\/en.wikipedia.org\\/wiki\\/Effective_accelerationism\",\"sameAs\":\"http:\\/\\/www.wikidata.org\\/entity\\/Q123509272\",\"mainEntity\":\"http:\\/\\/www.wikidata.org\\/entity\\/Q123509272\",\"author\":{\"@type\":\"Organization\",\"name\":\"Contributors to Wikimedia projects\"},\"publisher\":{\"@type\":\"Organization\",\"name\":\"Wikimedia Foundation, Inc.\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https:\\/\\/www.wikimedia.org\\/static\\/images\\/wmf-hor-googpub.png\"}},\"datePublished\":\"2023-10-18T07:06:27Z\",\"dateModified\":\"2024-08-22T17:49:40Z\",\"image\":\"https:\\/\\/upload.wikimedia.org\\/wikipedia\\/commons\\/4\\/4d\\/Effective_accelerationism_icon.svg\",\"headline\":\"philosophical and social movement advocating for a pro-technology stance that seeks to maximize the probability of a technocapital singularity\"}</script>\n</body>\n</html>","oembed":false,"readabilityObject":{"title":"Effective accelerationism","content":"<div id=\"readability-page-1\" class=\"page\"><div>\n\t\t\t\t\t\t\t\n\n\t\t\t\t\t\t<p>From Wikipedia, the free encyclopedia</p>\n\t\t\t\t\t</div><div lang=\"en\" dir=\"ltr\" id=\"mw-content-text\">\n\n<figure typeof=\"mw:File/Thumb\"><a href=\"/wiki/File:Effective_accelerationism_icon.svg\"><img src=\"//upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Effective_accelerationism_icon.svg/220px-Effective_accelerationism_icon.svg.png\" decoding=\"async\" width=\"220\" height=\"228\" srcset=\"//upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Effective_accelerationism_icon.svg/330px-Effective_accelerationism_icon.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Effective_accelerationism_icon.svg/440px-Effective_accelerationism_icon.svg.png 2x\" data-file-width=\"246\" data-file-height=\"255\"></a><figcaption>e/acc hyperbolic curve logo designed by Will DePue of <a href=\"/wiki/OpenAI\" title=\"OpenAI\">OpenAI</a><sup id=\"cite_ref-1\"><a href=\"#cite_note-1\"><span>[</span>1<span>]</span></a></sup>—likely an allusion to the idea of a <a href=\"/wiki/Technological_singularity\" title=\"Technological singularity\">technological singularity</a>.</figcaption></figure>\n<p><b>Effective accelerationism</b>, often abbreviated as \"<b>e/acc</b>\", is a 21st-century philosophical movement that advocates for an explicitly <a href=\"/wiki/Technological_utopianism\" title=\"Technological utopianism\">pro-technology</a> stance. Its proponents believe that unrestricted <a href=\"/wiki/Technological_change\" title=\"Technological change\">technological progress</a> (especially driven by <a href=\"/wiki/Artificial_intelligence\" title=\"Artificial intelligence\">artificial intelligence</a>) is a solution to universal human problems like poverty, war and climate change.<sup id=\"cite_ref-:5_2-0\"><a href=\"#cite_note-:5-2\"><span>[</span>2<span>]</span></a></sup> They see themselves as a counterweight to more cautious views on technological innovation, often giving their opponents the derogatory labels of \"doomers\" or \"decels\" (short for <a href=\"/wiki/Degrowth\" title=\"Degrowth\">deceleration</a>).<sup id=\"cite_ref-:5_2-1\"><a href=\"#cite_note-:5-2\"><span>[</span>2<span>]</span></a></sup><sup id=\"cite_ref-:0_3-0\"><a href=\"#cite_note-:0-3\"><span>[</span>3<span>]</span></a></sup> \n</p><p>The movement carries <a href=\"/wiki/Utopia\" title=\"Utopia\">utopian</a> undertones and argues that humans need to develop and build faster to ensure their survival and propagate <a href=\"/wiki/Consciousness\" title=\"Consciousness\">consciousness</a> throughout the universe.<sup id=\"cite_ref-:2_4-0\"><a href=\"#cite_note-:2-4\"><span>[</span>4<span>]</span></a></sup> Its founders Guillaume Verdon and the pseudonymous Bayeslord see it as a way to \"usher in the next evolution of consciousness, creating unthinkable next-generation lifeforms.\"<sup id=\"cite_ref-:4_5-0\"><a href=\"#cite_note-:4-5\"><span>[</span>5<span>]</span></a></sup>\n</p><p>Although effective accelerationism has been described as a fringe movement and as cult-like, it has gained mainstream visibility in 2023.<sup id=\"cite_ref-6\"><a href=\"#cite_note-6\"><span>[</span>6<span>]</span></a></sup><sup id=\"cite_ref-:4_5-1\"><a href=\"#cite_note-:4-5\"><span>[</span>5<span>]</span></a></sup><sup id=\"cite_ref-7\"><a href=\"#cite_note-7\"><span>[</span>7<span>]</span></a></sup><sup id=\"cite_ref-8\"><a href=\"#cite_note-8\"><span>[</span>8<span>]</span></a></sup><sup id=\"cite_ref-:1_9-0\"><a href=\"#cite_note-:1-9\"><span>[</span>9<span>]</span></a></sup> A number of high-profile <a href=\"/wiki/Silicon_Valley\" title=\"Silicon Valley\">Silicon Valley</a> figures, including investors <a href=\"/wiki/Marc_Andreessen\" title=\"Marc Andreessen\">Marc Andreessen</a> and <a href=\"/wiki/Garry_Tan\" title=\"Garry Tan\">Garry Tan</a> explicitly endorsed it by adding \"e/acc\" to their public social media profiles.<sup id=\"cite_ref-:4_5-2\"><a href=\"#cite_note-:4-5\"><span>[</span>5<span>]</span></a></sup><sup id=\"cite_ref-:1_9-1\"><a href=\"#cite_note-:1-9\"><span>[</span>9<span>]</span></a></sup>\n</p>\n<meta property=\"mw:PageProp/toc\">\n<div><h2 id=\"Etymology_and_central_beliefs\">Etymology and central beliefs</h2><p><span><span>[</span><a href=\"/w/index.php?title=Effective_accelerationism&amp;action=edit&amp;section=1\" title=\"Edit section: Etymology and central beliefs\"><span>edit</span></a><span>]</span></span></p></div>\n<p>Effective accelerationism, a portmanteau of \"<a href=\"/wiki/Effective_altruism\" title=\"Effective altruism\">effective altruism</a>\" and \"<a href=\"/wiki/Accelerationism\" title=\"Accelerationism\">accelerationism</a>\",<sup id=\"cite_ref-:0_3-1\"><a href=\"#cite_note-:0-3\"><span>[</span>3<span>]</span></a></sup> is a fundamentally <a href=\"/wiki/Techno-optimism\" title=\"Techno-optimism\">techno-optimist</a> movement.<sup id=\"cite_ref-:7_10-0\"><a href=\"#cite_note-:7-10\"><span>[</span>10<span>]</span></a></sup> According to Guillaume Verdon, one of the movement's founders, its aim is for <a href=\"/wiki/Human_civilization\" title=\"Human civilization\">human civilization</a> to \"clim[b] the Kardashev gradient\", meaning its purpose is for human civilization to rise to next levels on the <a href=\"/wiki/Kardashev_scale\" title=\"Kardashev scale\">Kardashev scale</a> by maximizing energy usage.<sup id=\"cite_ref-:7_10-1\"><a href=\"#cite_note-:7-10\"><span>[</span>10<span>]</span></a></sup>\n</p><p>To achieve this goal, effective accelerationism wants to accelerate technological progress. It is strongly focused on <a href=\"/wiki/Artificial_general_intelligence\" title=\"Artificial general intelligence\">artificial general intelligence</a> (AGI), because it sees AGI as fundamental for climbing the Kardashev scale.<sup id=\"cite_ref-:7_10-2\"><a href=\"#cite_note-:7-10\"><span>[</span>10<span>]</span></a></sup> The movement therefore advocates for unrestricted development and deployment of artificial intelligence.<sup id=\"cite_ref-11\"><a href=\"#cite_note-11\"><span>[</span>11<span>]</span></a></sup> Regulation of artificial intelligence and government intervention in markets more generally is met with opposition. Many of its proponents have <a href=\"/wiki/Libertarianism\" title=\"Libertarianism\">libertarian</a> views and think that AGI will be most <a href=\"/wiki/AI_alignment\" title=\"AI alignment\">aligned</a> if many AGIs compete against each other on the marketplace.<sup id=\"cite_ref-:7_10-3\"><a href=\"#cite_note-:7-10\"><span>[</span>10<span>]</span></a></sup>\n</p><p>The founders of the movement see it as rooted in <a href=\"/wiki/Jeremy_England\" title=\"Jeremy England\">Jeremy England</a>'s theory on the <a href=\"/wiki/Abiogenesis\" title=\"Abiogenesis\">origin of life</a>, which is focused on <a href=\"/wiki/Entropy\" title=\"Entropy\">entropy</a> and <a href=\"/wiki/Thermodynamics\" title=\"Thermodynamics\">thermodynamics</a>.<sup id=\"cite_ref-:7_10-4\"><a href=\"#cite_note-:7-10\"><span>[</span>10<span>]</span></a></sup> According to them, the universe aims to increase entropy, and life is a way of increasing it. By spreading life throughout the universe and making life use up ever increasing amounts of energy, the universe's purpose would thus be fulfilled.<sup id=\"cite_ref-:7_10-5\"><a href=\"#cite_note-:7-10\"><span>[</span>10<span>]</span></a></sup>\n</p>\n\n<div><h3 id=\"Intellectual_origins\">Intellectual origins</h3><p><span><span>[</span><a href=\"/w/index.php?title=Effective_accelerationism&amp;action=edit&amp;section=3\" title=\"Edit section: Intellectual origins\"><span>edit</span></a><span>]</span></span></p></div>\n<p>While <a href=\"/wiki/Nick_Land\" title=\"Nick Land\">Nick Land</a> is seen as the intellectual originator of contemporary <a href=\"/wiki/Accelerationism\" title=\"Accelerationism\">accelerationism</a> in general,<sup id=\"cite_ref-:1_9-2\"><a href=\"#cite_note-:1-9\"><span>[</span>9<span>]</span></a></sup><sup id=\"cite_ref-:4_5-3\"><a href=\"#cite_note-:4-5\"><span>[</span>5<span>]</span></a></sup> the precise origins of effective accelerationism remain unclear. The earliest known reference to the movement can be traced back to a May 2022 newsletter published by four <a href=\"/wiki/Pen_name\" title=\"Pen name\">pseudonymous</a> authors known by their <a href=\"/wiki/Twitter\" title=\"Twitter\">X</a> (formerly Twitter) usernames @BasedBeffJezos, @bayeslord, @zestular and @creatine_cycle.<sup id=\"cite_ref-:1_9-3\"><a href=\"#cite_note-:1-9\"><span>[</span>9<span>]</span></a></sup>\n</p><p>Effective accelerationism incorporates elements of older Silicon Valley subcultures such as <a href=\"/wiki/Transhumanism\" title=\"Transhumanism\">transhumanism</a> and <a href=\"/wiki/Extropianism\" title=\"Extropianism\">extropianism</a>, which similarly emphasized the value of progress and resisted efforts to restrain the development of technology, as well as the work of the <a href=\"/wiki/Cybernetic_Culture_Research_Unit\" title=\"Cybernetic Culture Research Unit\">Cybernetic Culture Research Unit</a>.<sup id=\"cite_ref-:4_5-4\"><a href=\"#cite_note-:4-5\"><span>[</span>5<span>]</span></a></sup><sup id=\"cite_ref-12\"><a href=\"#cite_note-12\"><span>[</span>12<span>]</span></a></sup><sup id=\"cite_ref-:7_10-6\"><a href=\"#cite_note-:7-10\"><span>[</span>10<span>]</span></a></sup>\n</p>\n<div><h3 id=\"Disclosure_of_the_identity_of_BasedBeffJezos\">Disclosure of the identity of BasedBeffJezos</h3><p><span><span>[</span><a href=\"/w/index.php?title=Effective_accelerationism&amp;action=edit&amp;section=4\" title=\"Edit section: Disclosure of the identity of BasedBeffJezos\"><span>edit</span></a><span>]</span></span></p></div>\n<p><i><a href=\"/wiki/Forbes\" title=\"Forbes\">Forbes</a></i> disclosed in December 2023 that the @BasedBeffJezos persona is maintained by Guillaume Verdon, a Canadian former Google <a href=\"/wiki/Quantum_computing\" title=\"Quantum computing\">quantum computing</a> engineer and <a href=\"/wiki/Theoretical_physics\" title=\"Theoretical physics\">theoretical physicist</a>.<sup id=\"cite_ref-:6_13-0\"><a href=\"#cite_note-:6-13\"><span>[</span>13<span>]</span></a></sup> The revelation was supported by a voice analysis conducted by the National Center for Media Forensics of the <a href=\"/wiki/University_of_Colorado_Denver\" title=\"University of Colorado Denver\">University of Colorado Denver</a>, which further confirmed the match between Jezos and Verdon. The magazine justified its decision to disclose Verdon's identity on the grounds of it being \"in the <a href=\"/wiki/Public_interest\" title=\"Public interest\">public interest</a>\".<sup id=\"cite_ref-:6_13-1\"><a href=\"#cite_note-:6-13\"><span>[</span>13<span>]</span></a></sup> \n</p><p>On 29 December 2023 Guillaume Verdon was interviewed by <a href=\"/wiki/Lex_Fridman\" title=\"Lex Fridman\">Lex Fridman</a> on the <i><a href=\"/wiki/Lex_Fridman_Podcast\" title=\"Lex Fridman Podcast\">Lex Fridman Podcast</a></i> and introduced as the \"founder of [the] e/acc (effective accelerationism) movement\".<sup id=\"cite_ref-14\"><a href=\"#cite_note-14\"><span>[</span>14<span>]</span></a></sup>\n</p>\n<div><h2 id=\"Relation_to_other_movements\">Relation to other movements</h2><p><span><span>[</span><a href=\"/w/index.php?title=Effective_accelerationism&amp;action=edit&amp;section=5\" title=\"Edit section: Relation to other movements\"><span>edit</span></a><span>]</span></span></p></div>\n<div><h3 id=\"Traditional_accelerationism\">Traditional accelerationism</h3><p><span><span>[</span><a href=\"/w/index.php?title=Effective_accelerationism&amp;action=edit&amp;section=6\" title=\"Edit section: Traditional accelerationism\"><span>edit</span></a><span>]</span></span></p></div>\n<p>Traditional accelerationism, as developed by the British philosopher <a href=\"/wiki/Nick_Land\" title=\"Nick Land\">Nick Land</a>, sees the acceleration of technological change as a way to bring about a fundamental transformation of current culture, society, and the political economy.<sup id=\"cite_ref-:5_2-2\"><a href=\"#cite_note-:5-2\"><span>[</span>2<span>]</span></a></sup> In his earlier writings he saw the acceleration of <a href=\"/wiki/Capitalism\" title=\"Capitalism\">capitalism</a> as a way to overcome this economic system itself.<sup id=\"cite_ref-:5_2-3\"><a href=\"#cite_note-:5-2\"><span>[</span>2<span>]</span></a></sup> In contrast, effective accelerationism does not seek to overcome capitalism or to introduce radical societal change but tries to maximize the probability of a <a href=\"/wiki/Technological_singularity\" title=\"Technological singularity\">technocapital singularity</a>, triggering an <a href=\"/wiki/Technological_singularity#Intelligence_explosion\" title=\"Technological singularity\">intelligence explosion</a> throughout the universe and maximizing energy usage.<sup id=\"cite_ref-:1_9-4\"><a href=\"#cite_note-:1-9\"><span>[</span>9<span>]</span></a></sup><sup id=\"cite_ref-:7_10-7\"><a href=\"#cite_note-:7-10\"><span>[</span>10<span>]</span></a></sup> \n</p>\n\n<p>Effective accelerationism also diverges from the principles of <a href=\"/wiki/Effective_altruism\" title=\"Effective altruism\">effective altruism</a>, which prioritizes using evidence and reasoning to identify the most effective ways to altruistically improve the world.<sup id=\"cite_ref-:5_2-4\"><a href=\"#cite_note-:5-2\"><span>[</span>2<span>]</span></a></sup> This divergence comes primarily from one of the causes effective altruists focus on – <a href=\"/wiki/AI_existential_risk\" title=\"AI existential risk\">AI existential risk</a>. Effective altruists argue that AI companies should be cautious and strive to develop <a href=\"/wiki/AI_safety\" title=\"AI safety\">safe AI systems</a>, as they fear that any misaligned AGI could eventually lead to <a href=\"/wiki/Existential_risk_from_artificial_general_intelligence\" title=\"Existential risk from artificial general intelligence\">human extinction</a>.<sup id=\"cite_ref-:7_10-8\"><a href=\"#cite_note-:7-10\"><span>[</span>10<span>]</span></a></sup> Proponents of Effective Accelerationism generally consider that <a href=\"/wiki/Existential_risk_from_artificial_general_intelligence\" title=\"Existential risk from artificial general intelligence\">existential risks from AGI</a> are negligible, and that even if they were not, decentralized free markets would much better mitigate this risk than centralized governmental regulation.<sup id=\"cite_ref-:7_10-9\"><a href=\"#cite_note-:7-10\"><span>[</span>10<span>]</span></a></sup>\n</p>\n\n<p>Introduced by <a href=\"/wiki/Vitalik_Buterin\" title=\"Vitalik Buterin\">Vitalik Buterin</a> in November 2023, d/acc is pro-technology like e/acc. But it assumes that maximizing profit does not automatically lead to the best outcome. The \"d\" in d/acc primarily means \"defensive\", but can also refer to \"decentralization\" or \"differential\". d/acc acknowledges existential risks and seeks a more targeted approach to technological development than e/acc, intentionally prioritizing technologies that are expected to make the world better or safer.<sup id=\"cite_ref-15\"><a href=\"#cite_note-15\"><span>[</span>15<span>]</span></a></sup><sup id=\"cite_ref-16\"><a href=\"#cite_note-16\"><span>[</span>16<span>]</span></a></sup>\n</p>\n\n<p>Effective accelerationism also stands in stark contrast with the <a href=\"/wiki/Degrowth\" title=\"Degrowth\">degrowth</a> movement, sometimes described by it as \"decelerationism\" or \"decels\". The degrowth movement advocates for reducing economic activity and consumption to address ecological and social issues. Effective accelerationism on the contrary embraces technological progress, energy consumption and the dynamics of capitalism, rather than advocating for a reduction in economic activity.<sup id=\"cite_ref-tc_17-0\"><a href=\"#cite_note-tc-17\"><span>[</span>17<span>]</span></a></sup>\n</p>\n\n<p>The \"<a href=\"/wiki/Techno-Optimist_Manifesto\" title=\"Techno-Optimist Manifesto\">Techno-Optimist Manifesto</a>\",<sup id=\"cite_ref-ma_18-0\"><a href=\"#cite_note-ma-18\"><span>[</span>18<span>]</span></a></sup> a 2023 essay by <a href=\"/wiki/Marc_Andreessen\" title=\"Marc Andreessen\">Marc Andreessen</a>, has been described by the <i><a href=\"/wiki/Financial_Times\" title=\"Financial Times\">Financial Times</a></i> and the German <i><a href=\"/wiki/S%C3%BCddeutsche_Zeitung\" title=\"Süddeutsche Zeitung\">Süddeutsche Zeitung</a></i> as espousing the views of effective accelerationism.<sup id=\"cite_ref-:2_4-1\"><a href=\"#cite_note-:2-4\"><span>[</span>4<span>]</span></a></sup><sup id=\"cite_ref-19\"><a href=\"#cite_note-19\"><span>[</span>19<span>]</span></a></sup>\n</p><p>David Swan of the <i><a href=\"/wiki/The_Sydney_Morning_Herald\" title=\"The Sydney Morning Herald\">The Sydney Morning Herald</a></i> has criticized effective accelerationism due to its opposition to government and industry self-regulation. He argues that \"innovations like AI needs thoughtful regulations and guardrails [...] to avoid the myriad mistakes Silicon Valley has already made\".<sup id=\"cite_ref-20\"><a href=\"#cite_note-20\"><span>[</span>20<span>]</span></a></sup> During the 2023 <a href=\"/wiki/Ronald_Reagan_Presidential_Library\" title=\"Ronald Reagan Presidential Library\">Reagan National Defense Forum</a>, <a href=\"/wiki/United_States_Secretary_of_Commerce\" title=\"United States Secretary of Commerce\">U.S. Secretary of Commerce</a> <a href=\"/wiki/Gina_Raimondo\" title=\"Gina Raimondo\">Gina Raimondo</a> cautioned against embracing the \"move fast and break things\" mentality associated with \"effective acceleration [<i><a href=\"/wiki/Sic\" title=\"Sic\">sic</a></i>]\". She emphasized the need to exercise caution in dealing with AI, stating \"that's too dangerous. You can't break things when you are talking about AI\".<sup id=\"cite_ref-:4_5-5\"><a href=\"#cite_note-:4-5\"><span>[</span>5<span>]</span></a></sup><sup id=\"cite_ref-21\"><a href=\"#cite_note-21\"><span>[</span>21<span>]</span></a></sup> In a similar vein, Ellen Huet argued on <i><a href=\"/wiki/Bloomberg_News\" title=\"Bloomberg News\">Bloomberg News</a></i> that some of the ideas of the movement were \"deeply unsettling\", focusing especially on Guillaume Verdon's \"post-humanism\" and the view that \"natural selection could lead AI to replace us [humans] as the dominant species.\"<sup id=\"cite_ref-22\"><a href=\"#cite_note-22\"><span>[</span>22<span>]</span></a></sup>\n</p>\n\n<ul><li><a href=\"/wiki/Technological_utopianism\" title=\"Technological utopianism\">Technological utopianism</a></li>\n<li><a href=\"/wiki/Transhumanism\" title=\"Transhumanism\">Transhumanism</a></li></ul>\n\n<div><ol>\n<li id=\"cite_note-1\"><span><b><a href=\"#cite_ref-1\">^</a></b></span> <span><cite id=\"CITEREFSteinberg,_Julia2023\">Steinberg, Julia (19 December 2023). <a rel=\"nofollow\" href=\"https://www.thefp.com/p/move-fast-and-make-things-e-acc-ai-altman\">\"Move Fast and Make Things\"</a>. The Free Press<span>. Retrieved <span>1 July</span> 2024</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Move+Fast+and+Make+Things&amp;rft.pub=The+Free+Press&amp;rft.date=2023-12-19&amp;rft.au=Steinberg%2C+Julia&amp;rft_id=https%3A%2F%2Fwww.thefp.com%2Fp%2Fmove-fast-and-make-things-e-acc-ai-altman&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\"></span></span>\n</li>\n<li id=\"cite_note-:5-2\"><span>^ <a href=\"#cite_ref-:5_2-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-:5_2-1\"><sup><i><b>b</b></i></sup></a> <a href=\"#cite_ref-:5_2-2\"><sup><i><b>c</b></i></sup></a> <a href=\"#cite_ref-:5_2-3\"><sup><i><b>d</b></i></sup></a> <a href=\"#cite_ref-:5_2-4\"><sup><i><b>e</b></i></sup></a></span> <span><cite id=\"CITEREFSoufi2024\">Soufi, Daniel (6 January 2024). <a rel=\"nofollow\" href=\"https://english.elpais.com/technology/2024-01-06/accelerate-or-die-the-controversial-ideology-that-proposes-the-unlimited-advance-of-artificial-intelligence.html\">\"<span></span>'Accelerate or die,' the controversial ideology that proposes the unlimited advance of artificial intelligence\"</a>. <i><a href=\"/wiki/El_Pa%C3%ADs\" title=\"El País\">El País</a></i>. <a rel=\"nofollow\" href=\"https://web.archive.org/web/20240120202224/https://english.elpais.com/technology/2024-01-06/accelerate-or-die-the-controversial-ideology-that-proposes-the-unlimited-advance-of-artificial-intelligence.html\">Archived</a> from the original on 20 January 2024<span>. Retrieved <span>20 January</span> 2024</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=El+Pa%C3%ADs&amp;rft.atitle=%27Accelerate+or+die%2C%27+the+controversial+ideology+that+proposes+the+unlimited+advance+of+artificial+intelligence&amp;rft.date=2024-01-06&amp;rft.aulast=Soufi&amp;rft.aufirst=Daniel&amp;rft_id=https%3A%2F%2Fenglish.elpais.com%2Ftechnology%2F2024-01-06%2Faccelerate-or-die-the-controversial-ideology-that-proposes-the-unlimited-advance-of-artificial-intelligence.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\"></span></span>\n</li>\n<li id=\"cite_note-:0-3\"><span>^ <a href=\"#cite_ref-:0_3-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-:0_3-1\"><sup><i><b>b</b></i></sup></a></span> <span><cite id=\"CITEREFMacColl2023\">MacColl, Margaux (7 October 2023). <a rel=\"nofollow\" href=\"https://www.theinformation.com/articles/its-a-cult-inside-effective-accelerationism-the-pro-ai-movement-taking-over-silicon-valley\">\"It's a Cult': Inside Effective Accelerationism, the Pro-AI Movement Taking Over Silicon Valley\"</a>. <i><a href=\"/wiki/The_Information_(website)\" title=\"The Information (website)\">The Information</a></i>. <a rel=\"nofollow\" href=\"https://web.archive.org/web/20231120211028/https://www.theinformation.com/articles/its-a-cult-inside-effective-accelerationism-the-pro-ai-movement-taking-over-silicon-valley\">Archived</a> from the original on 20 November 2023<span>. Retrieved <span>20 November</span> 2023</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=The+Information&amp;rft.atitle=It%27s+a+Cult%27%3A+Inside+Effective+Accelerationism%2C+the+Pro-AI+Movement+Taking+Over+Silicon+Valley&amp;rft.date=2023-10-07&amp;rft.aulast=MacColl&amp;rft.aufirst=Margaux&amp;rft_id=https%3A%2F%2Fwww.theinformation.com%2Farticles%2Fits-a-cult-inside-effective-accelerationism-the-pro-ai-movement-taking-over-silicon-valley&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\"></span></span>\n</li>\n<li id=\"cite_note-:2-4\"><span>^ <a href=\"#cite_ref-:2_4-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-:2_4-1\"><sup><i><b>b</b></i></sup></a></span> <span><cite id=\"CITEREFHurtz2023\">Hurtz, Simon (10 November 2023). <a rel=\"nofollow\" href=\"https://archive.today/20231110220123/https://www.sueddeutsche.de/wirtschaft/ki-silicon-valley-andreessen-effective-accelerationism-1.6301648\">\"Tech-Szene im Silicon Valley: Ihr Gott ist die KI\"</a>. <i><a href=\"/wiki/S%C3%BCddeutsche_Zeitung\" title=\"Süddeutsche Zeitung\">Süddeutsche Zeitung</a></i> (in German). Archived from <a rel=\"nofollow\" href=\"https://www.sueddeutsche.de/wirtschaft/ki-silicon-valley-andreessen-effective-accelerationism-1.6301648\">the original</a> on 10 November 2023<span>. Retrieved <span>24 November</span> 2023</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=S%C3%BCddeutsche+Zeitung&amp;rft.atitle=Tech-Szene+im+Silicon+Valley%3A+Ihr+Gott+ist+die+KI&amp;rft.date=2023-11-10&amp;rft.aulast=Hurtz&amp;rft.aufirst=Simon&amp;rft_id=https%3A%2F%2Fwww.sueddeutsche.de%2Fwirtschaft%2Fki-silicon-valley-andreessen-effective-accelerationism-1.6301648&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\"></span></span>\n</li>\n<li id=\"cite_note-:4-5\"><span>^ <a href=\"#cite_ref-:4_5-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-:4_5-1\"><sup><i><b>b</b></i></sup></a> <a href=\"#cite_ref-:4_5-2\"><sup><i><b>c</b></i></sup></a> <a href=\"#cite_ref-:4_5-3\"><sup><i><b>d</b></i></sup></a> <a href=\"#cite_ref-:4_5-4\"><sup><i><b>e</b></i></sup></a> <a href=\"#cite_ref-:4_5-5\"><sup><i><b>f</b></i></sup></a></span> <span><cite id=\"CITEREFRoose2023\">Roose, Kevin (10 December 2023). <a rel=\"nofollow\" href=\"https://www.nytimes.com/2023/12/10/technology/ai-acceleration.html\">\"This A.I. Subculture's Motto: Go, Go, Go\"</a>. <i><a href=\"/wiki/The_New_York_Times\" title=\"The New York Times\">The New York Times</a></i>. <a rel=\"nofollow\" href=\"https://web.archive.org/web/20231211220106/https://www.nytimes.com/2023/12/10/technology/ai-acceleration.html\">Archived</a> from the original on 11 December 2023<span>. Retrieved <span>10 December</span> 2023</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=The+New+York+Times&amp;rft.atitle=This+A.I.+Subculture%27s+Motto%3A+Go%2C+Go%2C+Go&amp;rft.date=2023-12-10&amp;rft.aulast=Roose&amp;rft.aufirst=Kevin&amp;rft_id=https%3A%2F%2Fwww.nytimes.com%2F2023%2F12%2F10%2Ftechnology%2Fai-acceleration.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\"></span></span>\n</li>\n<li id=\"cite_note-6\"><span><b><a href=\"#cite_ref-6\">^</a></b></span> <span><cite><a rel=\"nofollow\" href=\"https://www.theinformation.com/articles/its-a-cult-inside-effective-accelerationism-the-pro-ai-movement-taking-over-silicon-valley\">\"<span></span>'It's a cult': Inside effective accelerationism, the pro-AI movement taking over Silicon Valley\"</a>. <i>The Information</i>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=The+Information&amp;rft.atitle=%E2%80%98It%E2%80%99s+a+cult%E2%80%99%3A+Inside+effective+accelerationism%2C+the+pro-AI+movement+taking+over+Silicon+Valley&amp;rft_id=https%3A%2F%2Fwww.theinformation.com%2Farticles%2Fits-a-cult-inside-effective-accelerationism-the-pro-ai-movement-taking-over-silicon-valley&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\"></span></span>\n</li>\n<li id=\"cite_note-7\"><span><b><a href=\"#cite_ref-7\">^</a></b></span> <span><cite><a rel=\"nofollow\" href=\"https://www.independent.co.uk/tech/openai-sam-altman-effective-accelerationism-b2492430.html\">\"Inside the political split between AI designers that could decide our future\"</a>. <i>The Independent</i>. 7 February 2024<span>. Retrieved <span>17 August</span> 2024</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=The+Independent&amp;rft.atitle=Inside+the+political+split+between+AI+designers+that+could+decide+our+future&amp;rft.date=2024-02-07&amp;rft_id=https%3A%2F%2Fwww.independent.co.uk%2Ftech%2Fopenai-sam-altman-effective-accelerationism-b2492430.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\"></span></span>\n</li>\n<li id=\"cite_note-8\"><span><b><a href=\"#cite_ref-8\">^</a></b></span> <span><cite id=\"CITEREFBites\">Bites, Ben's. <a rel=\"nofollow\" href=\"https://bensbites.beehiiv.com/p/inside-eacc-new-religion-silicon-valley\">\"Inside e/acc, the new religion in Silicon Valley\"</a>. <i>Ben's Bites</i><span>. Retrieved <span>17 August</span> 2024</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Ben%27s+Bites&amp;rft.atitle=Inside+e%2Facc%2C+the+new+religion+in+Silicon+Valley.&amp;rft.aulast=Bites&amp;rft.aufirst=Ben%27s&amp;rft_id=https%3A%2F%2Fbensbites.beehiiv.com%2Fp%2Finside-eacc-new-religion-silicon-valley&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\"></span></span>\n</li>\n<li id=\"cite_note-:1-9\"><span>^ <a href=\"#cite_ref-:1_9-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-:1_9-1\"><sup><i><b>b</b></i></sup></a> <a href=\"#cite_ref-:1_9-2\"><sup><i><b>c</b></i></sup></a> <a href=\"#cite_ref-:1_9-3\"><sup><i><b>d</b></i></sup></a> <a href=\"#cite_ref-:1_9-4\"><sup><i><b>e</b></i></sup></a></span> <span><cite id=\"CITEREFChowdhury2023\">Chowdhury, Hasan (28 July 2023). <a rel=\"nofollow\" href=\"https://www.businessinsider.com/silicon-valley-tech-leaders-accelerationism-eacc-twitter-profiles-2023-7\">\"Silicon Valley's favorite obscure theory about progress at all costs, which has been embraced by Marc Andreessen\"</a>. <i><a href=\"/wiki/Business_Insider\" title=\"Business Insider\">Business Insider</a></i>. <a rel=\"nofollow\" href=\"https://web.archive.org/web/20231120191620/https://www.businessinsider.com/silicon-valley-tech-leaders-accelerationism-eacc-twitter-profiles-2023-7\">Archived</a> from the original on 20 November 2023<span>. Retrieved <span>20 November</span> 2023</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Business+Insider&amp;rft.atitle=Silicon+Valley%27s+favorite+obscure+theory+about+progress+at+all+costs%2C+which+has+been+embraced+by+Marc+Andreessen&amp;rft.date=2023-07-28&amp;rft.aulast=Chowdhury&amp;rft.aufirst=Hasan&amp;rft_id=https%3A%2F%2Fwww.businessinsider.com%2Fsilicon-valley-tech-leaders-accelerationism-eacc-twitter-profiles-2023-7&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\"></span></span>\n</li>\n<li id=\"cite_note-:7-10\"><span>^ <a href=\"#cite_ref-:7_10-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-:7_10-1\"><sup><i><b>b</b></i></sup></a> <a href=\"#cite_ref-:7_10-2\"><sup><i><b>c</b></i></sup></a> <a href=\"#cite_ref-:7_10-3\"><sup><i><b>d</b></i></sup></a> <a href=\"#cite_ref-:7_10-4\"><sup><i><b>e</b></i></sup></a> <a href=\"#cite_ref-:7_10-5\"><sup><i><b>f</b></i></sup></a> <a href=\"#cite_ref-:7_10-6\"><sup><i><b>g</b></i></sup></a> <a href=\"#cite_ref-:7_10-7\"><sup><i><b>h</b></i></sup></a> <a href=\"#cite_ref-:7_10-8\"><sup><i><b>i</b></i></sup></a> <a href=\"#cite_ref-:7_10-9\"><sup><i><b>j</b></i></sup></a></span> <span><cite id=\"CITEREFTorres2023\">Torres, Émile P. (14 December 2023). <a rel=\"nofollow\" href=\"https://www.truthdig.com/articles/effective-accelerationism-and-the-pursuit-of-cosmic-utopia/\">\"<span></span>'Effective Accelerationism' and the Pursuit of Cosmic Utopia\"</a>. <i><a href=\"/wiki/Truthdig\" title=\"Truthdig\">Truthdig</a></i>. <a rel=\"nofollow\" href=\"https://web.archive.org/web/20231218005411/https://www.truthdig.com/articles/effective-accelerationism-and-the-pursuit-of-cosmic-utopia/\">Archived</a> from the original on 18 December 2023<span>. Retrieved <span>20 January</span> 2024</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Truthdig&amp;rft.atitle=%27Effective+Accelerationism%27+and+the+Pursuit+of+Cosmic+Utopia&amp;rft.date=2023-12-14&amp;rft.aulast=Torres&amp;rft.aufirst=%C3%89mile+P.&amp;rft_id=https%3A%2F%2Fwww.truthdig.com%2Farticles%2Feffective-accelerationism-and-the-pursuit-of-cosmic-utopia%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\"></span></span>\n</li>\n<li id=\"cite_note-11\"><span><b><a href=\"#cite_ref-11\">^</a></b></span> <span><cite id=\"CITEREFJones2023\">Jones, Rachyl (16 October 2023). <a rel=\"nofollow\" href=\"https://fortune.com/2023/10/16/marc-andreessen-techno-optimist-manifesto-ai-50-billion-people-billionaire-vc/\">\"Marc Andreessen just dropped a 'Techno-Optimist Manifesto' that sees a world of 50 billion people settling other planets\"</a>. <i><a href=\"/wiki/Fortune_(magazine)\" title=\"Fortune (magazine)\">Fortune</a></i>. <a rel=\"nofollow\" href=\"https://web.archive.org/web/20231128105444/https://fortune.com/2023/10/16/marc-andreessen-techno-optimist-manifesto-ai-50-billion-people-billionaire-vc/\">Archived</a> from the original on 28 November 2023<span>. Retrieved <span>26 November</span> 2023</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Fortune&amp;rft.atitle=Marc+Andreessen+just+dropped+a+%27Techno-Optimist+Manifesto%27+that+sees+a+world+of+50+billion+people+settling+other+planets&amp;rft.date=2023-10-16&amp;rft.aulast=Jones&amp;rft.aufirst=Rachyl&amp;rft_id=https%3A%2F%2Ffortune.com%2F2023%2F10%2F16%2Fmarc-andreessen-techno-optimist-manifesto-ai-50-billion-people-billionaire-vc%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\"></span></span>\n</li>\n<li id=\"cite_note-12\"><span><b><a href=\"#cite_ref-12\">^</a></b></span> <span><cite id=\"CITEREFBreland2023\">Breland, Ali (6 December 2023). <a rel=\"nofollow\" href=\"https://www.motherjones.com/politics/2023/12/effective-accelerationism/\">\"Meet the Silicon Valley CEOs who say greed is good—even if it kills us all\"</a>. <i><a href=\"/wiki/Mother_Jones_(magazine)\" title=\"Mother Jones (magazine)\">Mother Jones</a></i>. <a rel=\"nofollow\" href=\"https://web.archive.org/web/20231208175056/https://www.motherjones.com/politics/2023/12/effective-accelerationism/\">Archived</a> from the original on 8 December 2023<span>. Retrieved <span>14 December</span> 2023</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Mother+Jones&amp;rft.atitle=Meet+the+Silicon+Valley+CEOs+who+say+greed+is+good%E2%80%94even+if+it+kills+us+all&amp;rft.date=2023-12-06&amp;rft.aulast=Breland&amp;rft.aufirst=Ali&amp;rft_id=https%3A%2F%2Fwww.motherjones.com%2Fpolitics%2F2023%2F12%2Feffective-accelerationism%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\"></span></span>\n</li>\n<li id=\"cite_note-:6-13\"><span>^ <a href=\"#cite_ref-:6_13-0\"><sup><i><b>a</b></i></sup></a> <a href=\"#cite_ref-:6_13-1\"><sup><i><b>b</b></i></sup></a></span> <span><cite id=\"CITEREFBaker-White2023\">Baker-White, Emily (1 December 2023). <a rel=\"nofollow\" href=\"https://www.forbes.com/sites/emilybaker-white/2023/12/01/who-is-basedbeffjezos-the-leader-of-effective-accelerationism-eacc/\">\"Who Is @BasedBeffJezos, The Leader Of The Tech Elite's 'E/Acc' Movement?\"</a>. <i><a href=\"/wiki/Forbes\" title=\"Forbes\">Forbes</a></i>. <a rel=\"nofollow\" href=\"https://web.archive.org/web/20231211190358/https://www.forbes.com/sites/emilybaker-white/2023/12/01/who-is-basedbeffjezos-the-leader-of-effective-accelerationism-eacc/\">Archived</a> from the original on 11 December 2023<span>. Retrieved <span>3 December</span> 2023</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Forbes&amp;rft.atitle=Who+Is+%40BasedBeffJezos%2C+The+Leader+Of+The+Tech+Elite%27s+%27E%2FAcc%27+Movement%3F&amp;rft.date=2023-12-01&amp;rft.aulast=Baker-White&amp;rft.aufirst=Emily&amp;rft_id=https%3A%2F%2Fwww.forbes.com%2Fsites%2Femilybaker-white%2F2023%2F12%2F01%2Fwho-is-basedbeffjezos-the-leader-of-effective-accelerationism-eacc%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\"></span></span>\n</li>\n<li id=\"cite_note-14\"><span><b><a href=\"#cite_ref-14\">^</a></b></span> <span><cite><a rel=\"nofollow\" href=\"https://www.youtube.com/watch?v=8fEEbKJoNbU\"><i>Guillaume Verdon: Beff Jezos, E/acc Movement, Physics, Computation &amp; AGI</i></a> (Podcast). <a href=\"/wiki/Lex_Fridman_Podcast\" title=\"Lex Fridman Podcast\">Lex Fridman Podcast</a>. Vol.&nbsp;407. 29 December 2023. <a rel=\"nofollow\" href=\"https://web.archive.org/web/20231230191421/https://www.youtube.com/watch?v=8fEEbKJoNbU\">Archived</a> from the original on 30 December 2023<span>. Retrieved <span>30 December</span> 2023</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Guillaume+Verdon%3A+Beff+Jezos%2C+E%2Facc+Movement%2C+Physics%2C+Computation+%26+AGI&amp;rft.series=Lex+Fridman+Podcast&amp;rft.date=2023-12-29&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3D8fEEbKJoNbU&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\"></span></span>\n</li>\n<li id=\"cite_note-15\"><span><b><a href=\"#cite_ref-15\">^</a></b></span> <span><cite><a rel=\"nofollow\" href=\"https://vitalik.eth.limo/general/2023/11/27/techno_optimism.html\">\"My techno-optimism\"</a>. <i>vitalik.eth.limo</i><span>. Retrieved <span>17 August</span> 2024</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=vitalik.eth.limo&amp;rft.atitle=My+techno-optimism&amp;rft_id=https%3A%2F%2Fvitalik.eth.limo%2Fgeneral%2F2023%2F11%2F27%2Ftechno_optimism.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\"></span></span>\n</li>\n<li id=\"cite_note-16\"><span><b><a href=\"#cite_ref-16\">^</a></b></span> <span><cite id=\"CITEREFNelson2023\">Nelson, Jason (28 November 2023). <a rel=\"nofollow\" href=\"https://decrypt.co/207692/ai-turns-mars-not-safe-ethereum-creator-vitalik-buterin\">\"Ethereum Creator Vitalik Buterin: If AI Turns on Us 'Even Mars May Not Be Safe'<span></span>\"</a>. <i>Decrypt</i><span>. Retrieved <span>17 August</span> 2024</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Decrypt&amp;rft.atitle=Ethereum+Creator+Vitalik+Buterin%3A+If+AI+Turns+on+Us+%27Even+Mars+May+Not+Be+Safe%27&amp;rft.date=2023-11-28&amp;rft.aulast=Nelson&amp;rft.aufirst=Jason&amp;rft_id=https%3A%2F%2Fdecrypt.co%2F207692%2Fai-turns-mars-not-safe-ethereum-creator-vitalik-buterin&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\"></span></span>\n</li>\n<li id=\"cite_note-tc-17\"><span><b><a href=\"#cite_ref-tc_17-0\">^</a></b></span> <span><cite id=\"CITEREFWilhelm2023\">Wilhelm, Alex (20 November 2023). <a rel=\"nofollow\" href=\"https://techcrunch.com/2023/11/20/e-acc-doomers-decels-openai-altman/\">\"Effective accelerationism, doomers, decels, and how to flaunt your AI priors\"</a>. <i><a href=\"/wiki/TechCrunch\" title=\"TechCrunch\">TechCrunch</a></i>. <a rel=\"nofollow\" href=\"https://web.archive.org/web/20231123115648/https://techcrunch.com/2023/11/20/e-acc-doomers-decels-openai-altman/\">Archived</a> from the original on 23 November 2023<span>. Retrieved <span>24 November</span> 2023</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=TechCrunch&amp;rft.atitle=Effective+accelerationism%2C+doomers%2C+decels%2C+and+how+to+flaunt+your+AI+priors&amp;rft.date=2023-11-20&amp;rft.aulast=Wilhelm&amp;rft.aufirst=Alex&amp;rft_id=https%3A%2F%2Ftechcrunch.com%2F2023%2F11%2F20%2Fe-acc-doomers-decels-openai-altman%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\"></span></span>\n</li>\n<li id=\"cite_note-ma-18\"><span><b><a href=\"#cite_ref-ma_18-0\">^</a></b></span> <span><cite id=\"CITEREFAndreessen2023\"><a href=\"/wiki/Marc_Andreessen\" title=\"Marc Andreessen\">Andreessen, Marc</a> (16 October 2023). <a rel=\"nofollow\" href=\"https://a16z.com/the-techno-optimist-manifesto/\">\"The Techno-Optimist Manifesto\"</a>. <i><a href=\"/wiki/Andreessen_Horowitz\" title=\"Andreessen Horowitz\">Andreessen Horowitz</a></i>. <a rel=\"nofollow\" href=\"https://web.archive.org/web/20231123234238/https://a16z.com/the-techno-optimist-manifesto/\">Archived</a> from the original on 23 November 2023<span>. Retrieved <span>24 November</span> 2023</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Andreessen+Horowitz&amp;rft.atitle=The+Techno-Optimist+Manifesto&amp;rft.date=2023-10-16&amp;rft.aulast=Andreessen&amp;rft.aufirst=Marc&amp;rft_id=https%3A%2F%2Fa16z.com%2Fthe-techno-optimist-manifesto%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\"></span></span>\n</li>\n<li id=\"cite_note-19\"><span><b><a href=\"#cite_ref-19\">^</a></b></span> <span><cite id=\"CITEREFKelly2023\">Kelly, Jemima (22 October 2023). <a rel=\"nofollow\" href=\"https://www.ft.com/content/7eeb105d-7d79-4a59-89be-e18cd47be68f\">\"I read Andreessen's 'techno-optimist manifesto' so you don't have to\"</a>. <i><a href=\"/wiki/Financial_Times\" title=\"Financial Times\">Financial Times</a></i>. <a rel=\"nofollow\" href=\"https://web.archive.org/web/20240114055702/https://www.ft.com/content/7eeb105d-7d79-4a59-89be-e18cd47be68f\">Archived</a> from the original on 14 January 2024<span>. Retrieved <span>20 January</span> 2024</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Financial+Times&amp;rft.atitle=I+read+Andreessen%27s+%27techno-optimist+manifesto%27+so+you+don%27t+have+to&amp;rft.date=2023-10-22&amp;rft.aulast=Kelly&amp;rft.aufirst=Jemima&amp;rft_id=https%3A%2F%2Fwww.ft.com%2Fcontent%2F7eeb105d-7d79-4a59-89be-e18cd47be68f&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\"></span></span>\n</li>\n<li id=\"cite_note-20\"><span><b><a href=\"#cite_ref-20\">^</a></b></span> <span><cite id=\"CITEREFSwan2023\">Swan, David (29 October 2023). <a rel=\"nofollow\" href=\"https://www.smh.com.au/technology/we-are-conquerors-why-silicon-valley-s-latest-fad-is-its-deadliest-20231027-p5efho.html\">\"<span></span>'We are conquerors': Why Silicon Valley's latest fad is its deadliest\"</a>. <i><a href=\"/wiki/The_Sydney_Morning_Herald\" title=\"The Sydney Morning Herald\">The Sydney Morning Herald</a></i>. <a rel=\"nofollow\" href=\"https://web.archive.org/web/20231113124449/https://www.smh.com.au/technology/we-are-conquerors-why-silicon-valley-s-latest-fad-is-its-deadliest-20231027-p5efho.html\">Archived</a> from the original on 13 November 2023<span>. Retrieved <span>24 November</span> 2023</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=The+Sydney+Morning+Herald&amp;rft.atitle=%27We+are+conquerors%27%3A+Why+Silicon+Valley%27s+latest+fad+is+its+deadliest&amp;rft.date=2023-10-29&amp;rft.aulast=Swan&amp;rft.aufirst=David&amp;rft_id=https%3A%2F%2Fwww.smh.com.au%2Ftechnology%2Fwe-are-conquerors-why-silicon-valley-s-latest-fad-is-its-deadliest-20231027-p5efho.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\"></span></span>\n</li>\n<li id=\"cite_note-21\"><span><b><a href=\"#cite_ref-21\">^</a></b></span> <span><cite><a rel=\"nofollow\" href=\"https://www.youtube.com/watch?v=YZWJCMUd_yQ\"><i>Reagan National Defense Forum</i></a>. <a href=\"/wiki/Simi_Valley,_California\" title=\"Simi Valley, California\">Simi Valley</a>: <a href=\"/wiki/Ronald_Reagan_Presidential_Library\" title=\"Ronald Reagan Presidential Library\">Ronald Reagan Presidential Foundation &amp; Institute</a>. 2 December 2023.  Event occurs at 21:03. <a rel=\"nofollow\" href=\"https://web.archive.org/web/20231212051956/https://www.youtube.com/watch?v=YZWJCMUd_yQ\">Archived</a> from the original on 12 December 2023<span>. Retrieved <span>14 December</span> 2023</span> – via <a href=\"/wiki/YouTube\" title=\"YouTube\">YouTube</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=Reagan+National+Defense+Forum&amp;rft.place=Simi+Valley&amp;rft.pub=Ronald+Reagan+Presidential+Foundation+%26+Institute&amp;rft.date=2023-12-02&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DYZWJCMUd_yQ&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\"></span></span>\n</li>\n<li id=\"cite_note-22\"><span><b><a href=\"#cite_ref-22\">^</a></b></span> <span><cite id=\"CITEREFHuet2023\">Huet, Ellen (6 December 2023). <a rel=\"nofollow\" href=\"https://www.bloomberg.com/news/newsletters/2023-12-06/effective-accelerationism-and-beff-jezos-form-new-tech-tribe\">\"A Cultural Divide Over AI Forms in Silicon Valley\"</a>. <i><a href=\"/wiki/Bloomberg_News\" title=\"Bloomberg News\">Bloomberg News</a></i>. <a rel=\"nofollow\" href=\"https://web.archive.org/web/20231230195448/https://www.bloomberg.com/news/newsletters/2023-12-06/effective-accelerationism-and-beff-jezos-form-new-tech-tribe\">Archived</a> from the original on 30 December 2023<span>. Retrieved <span>30 December</span> 2023</span>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Bloomberg+News&amp;rft.atitle=A+Cultural+Divide+Over+AI+Forms+in+Silicon+Valley&amp;rft.date=2023-12-06&amp;rft.aulast=Huet&amp;rft.aufirst=Ellen&amp;rft_id=https%3A%2F%2Fwww.bloomberg.com%2Fnews%2Fnewsletters%2F2023-12-06%2Feffective-accelerationism-and-beff-jezos-form-new-tech-tribe&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\"></span></span>\n</li>\n</ol></div>\n\n<ul><li><cite id=\"CITEREFJezosBayeslord2022\">Jezos, Beff; Bayeslord (10 July 2022). <a rel=\"nofollow\" href=\"https://beff.substack.com/p/notes-on-eacc-principles-and-tenets\">\"Notes on e/acc principles and tenets\"</a>. <i>Beff's Newsletter</i>. <a href=\"/wiki/Substack\" title=\"Substack\">Substack</a>.</cite><span title=\"ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Beff%27s+Newsletter&amp;rft.atitle=Notes+on+e%2Facc+principles+and+tenets&amp;rft.date=2022-07-10&amp;rft.aulast=Jezos&amp;rft.aufirst=Beff&amp;rft.au=Bayeslord&amp;rft_id=https%3A%2F%2Fbeff.substack.com%2Fp%2Fnotes-on-eacc-principles-and-tenets&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AEffective+accelerationism\"></span></li></ul>\n\n\n<!-- \nNewPP limit report\nParsed by mw‐web.eqiad.main‐5696db9cdd‐ssjmm\nCached time: 20240826132731\nCache expiry: 2592000\nReduced expiry: false\nComplications: [vary‐revision‐sha1, show‐toc]\nCPU time usage: 0.532 seconds\nReal time usage: 0.732 seconds\nPreprocessor visited node count: 1808/1000000\nPost‐expand include size: 75638/2097152 bytes\nTemplate argument size: 750/2097152 bytes\nHighest expansion depth: 12/100\nExpensive parser function count: 2/500\nUnstrip recursion depth: 1/20\nUnstrip post‐expand size: 105169/5000000 bytes\nLua time usage: 0.325/10.000 seconds\nLua memory usage: 5017662/52428800 bytes\nNumber of Wikibase entities loaded: 0/400\n-->\n<!--\nTransclusion expansion time report (%,ms,calls,template)\n100.00%  574.104      1 -total\n 45.48%  261.111      1 Template:Reflist\n 33.90%  194.639     17 Template:Cite_web\n 21.49%  123.372      1 Template:Short_description\n 21.23%  121.855      2 Template:Navbox\n 20.50%  117.704      1 Template:Existential_risk_from_artificial_intelligence\n 14.23%   81.680      2 Template:Pagetype\n  4.43%   25.451      4 Template:Main_other\n  4.19%   24.066      1 Template:Use_dmy_dates\n  3.88%   22.298      1 Template:SDcat\n-->\n\n<!-- Saved in parser cache with key enwiki:pcache:idhash:75085196-0!canonical and timestamp 20240826132731 and revision id 1241702588. Rendering was triggered because: page-view\n -->\n</div></div>","textContent":"\n\t\t\t\t\t\t\t\n\n\t\t\t\t\t\tFrom Wikipedia, the free encyclopedia\n\t\t\t\t\t\n\ne/acc hyperbolic curve logo designed by Will DePue of OpenAI[1]—likely an allusion to the idea of a technological singularity.\nEffective accelerationism, often abbreviated as \"e/acc\", is a 21st-century philosophical movement that advocates for an explicitly pro-technology stance. Its proponents believe that unrestricted technological progress (especially driven by artificial intelligence) is a solution to universal human problems like poverty, war and climate change.[2] They see themselves as a counterweight to more cautious views on technological innovation, often giving their opponents the derogatory labels of \"doomers\" or \"decels\" (short for deceleration).[2][3] \nThe movement carries utopian undertones and argues that humans need to develop and build faster to ensure their survival and propagate consciousness throughout the universe.[4] Its founders Guillaume Verdon and the pseudonymous Bayeslord see it as a way to \"usher in the next evolution of consciousness, creating unthinkable next-generation lifeforms.\"[5]\nAlthough effective accelerationism has been described as a fringe movement and as cult-like, it has gained mainstream visibility in 2023.[6][5][7][8][9] A number of high-profile Silicon Valley figures, including investors Marc Andreessen and Garry Tan explicitly endorsed it by adding \"e/acc\" to their public social media profiles.[5][9]\n\n\nEtymology and central beliefs[edit]\nEffective accelerationism, a portmanteau of \"effective altruism\" and \"accelerationism\",[3] is a fundamentally techno-optimist movement.[10] According to Guillaume Verdon, one of the movement's founders, its aim is for human civilization to \"clim[b] the Kardashev gradient\", meaning its purpose is for human civilization to rise to next levels on the Kardashev scale by maximizing energy usage.[10]\nTo achieve this goal, effective accelerationism wants to accelerate technological progress. It is strongly focused on artificial general intelligence (AGI), because it sees AGI as fundamental for climbing the Kardashev scale.[10] The movement therefore advocates for unrestricted development and deployment of artificial intelligence.[11] Regulation of artificial intelligence and government intervention in markets more generally is met with opposition. Many of its proponents have libertarian views and think that AGI will be most aligned if many AGIs compete against each other on the marketplace.[10]\nThe founders of the movement see it as rooted in Jeremy England's theory on the origin of life, which is focused on entropy and thermodynamics.[10] According to them, the universe aims to increase entropy, and life is a way of increasing it. By spreading life throughout the universe and making life use up ever increasing amounts of energy, the universe's purpose would thus be fulfilled.[10]\n\n\nIntellectual origins[edit]\nWhile Nick Land is seen as the intellectual originator of contemporary accelerationism in general,[9][5] the precise origins of effective accelerationism remain unclear. The earliest known reference to the movement can be traced back to a May 2022 newsletter published by four pseudonymous authors known by their X (formerly Twitter) usernames @BasedBeffJezos, @bayeslord, @zestular and @creatine_cycle.[9]\nEffective accelerationism incorporates elements of older Silicon Valley subcultures such as transhumanism and extropianism, which similarly emphasized the value of progress and resisted efforts to restrain the development of technology, as well as the work of the Cybernetic Culture Research Unit.[5][12][10]\n\nDisclosure of the identity of BasedBeffJezos[edit]\nForbes disclosed in December 2023 that the @BasedBeffJezos persona is maintained by Guillaume Verdon, a Canadian former Google quantum computing engineer and theoretical physicist.[13] The revelation was supported by a voice analysis conducted by the National Center for Media Forensics of the University of Colorado Denver, which further confirmed the match between Jezos and Verdon. The magazine justified its decision to disclose Verdon's identity on the grounds of it being \"in the public interest\".[13] \nOn 29 December 2023 Guillaume Verdon was interviewed by Lex Fridman on the Lex Fridman Podcast and introduced as the \"founder of [the] e/acc (effective accelerationism) movement\".[14]\n\nRelation to other movements[edit]\nTraditional accelerationism[edit]\nTraditional accelerationism, as developed by the British philosopher Nick Land, sees the acceleration of technological change as a way to bring about a fundamental transformation of current culture, society, and the political economy.[2] In his earlier writings he saw the acceleration of capitalism as a way to overcome this economic system itself.[2] In contrast, effective accelerationism does not seek to overcome capitalism or to introduce radical societal change but tries to maximize the probability of a technocapital singularity, triggering an intelligence explosion throughout the universe and maximizing energy usage.[9][10] \n\n\nEffective accelerationism also diverges from the principles of effective altruism, which prioritizes using evidence and reasoning to identify the most effective ways to altruistically improve the world.[2] This divergence comes primarily from one of the causes effective altruists focus on – AI existential risk. Effective altruists argue that AI companies should be cautious and strive to develop safe AI systems, as they fear that any misaligned AGI could eventually lead to human extinction.[10] Proponents of Effective Accelerationism generally consider that existential risks from AGI are negligible, and that even if they were not, decentralized free markets would much better mitigate this risk than centralized governmental regulation.[10]\n\n\nIntroduced by Vitalik Buterin in November 2023, d/acc is pro-technology like e/acc. But it assumes that maximizing profit does not automatically lead to the best outcome. The \"d\" in d/acc primarily means \"defensive\", but can also refer to \"decentralization\" or \"differential\". d/acc acknowledges existential risks and seeks a more targeted approach to technological development than e/acc, intentionally prioritizing technologies that are expected to make the world better or safer.[15][16]\n\n\nEffective accelerationism also stands in stark contrast with the degrowth movement, sometimes described by it as \"decelerationism\" or \"decels\". The degrowth movement advocates for reducing economic activity and consumption to address ecological and social issues. Effective accelerationism on the contrary embraces technological progress, energy consumption and the dynamics of capitalism, rather than advocating for a reduction in economic activity.[17]\n\n\nThe \"Techno-Optimist Manifesto\",[18] a 2023 essay by Marc Andreessen, has been described by the Financial Times and the German Süddeutsche Zeitung as espousing the views of effective accelerationism.[4][19]\nDavid Swan of the The Sydney Morning Herald has criticized effective accelerationism due to its opposition to government and industry self-regulation. He argues that \"innovations like AI needs thoughtful regulations and guardrails [...] to avoid the myriad mistakes Silicon Valley has already made\".[20] During the 2023 Reagan National Defense Forum, U.S. Secretary of Commerce Gina Raimondo cautioned against embracing the \"move fast and break things\" mentality associated with \"effective acceleration [sic]\". She emphasized the need to exercise caution in dealing with AI, stating \"that's too dangerous. You can't break things when you are talking about AI\".[5][21] In a similar vein, Ellen Huet argued on Bloomberg News that some of the ideas of the movement were \"deeply unsettling\", focusing especially on Guillaume Verdon's \"post-humanism\" and the view that \"natural selection could lead AI to replace us [humans] as the dominant species.\"[22]\n\n\nTechnological utopianism\nTranshumanism\n\n\n^ Steinberg, Julia (19 December 2023). \"Move Fast and Make Things\". The Free Press. Retrieved 1 July 2024.\n\n^ a b c d e Soufi, Daniel (6 January 2024). \"'Accelerate or die,' the controversial ideology that proposes the unlimited advance of artificial intelligence\". El País. Archived from the original on 20 January 2024. Retrieved 20 January 2024.\n\n^ a b MacColl, Margaux (7 October 2023). \"It's a Cult': Inside Effective Accelerationism, the Pro-AI Movement Taking Over Silicon Valley\". The Information. Archived from the original on 20 November 2023. Retrieved 20 November 2023.\n\n^ a b Hurtz, Simon (10 November 2023). \"Tech-Szene im Silicon Valley: Ihr Gott ist die KI\". Süddeutsche Zeitung (in German). Archived from the original on 10 November 2023. Retrieved 24 November 2023.\n\n^ a b c d e f Roose, Kevin (10 December 2023). \"This A.I. Subculture's Motto: Go, Go, Go\". The New York Times. Archived from the original on 11 December 2023. Retrieved 10 December 2023.\n\n^ \"'It's a cult': Inside effective accelerationism, the pro-AI movement taking over Silicon Valley\". The Information.\n\n^ \"Inside the political split between AI designers that could decide our future\". The Independent. 7 February 2024. Retrieved 17 August 2024.\n\n^ Bites, Ben's. \"Inside e/acc, the new religion in Silicon Valley\". Ben's Bites. Retrieved 17 August 2024.\n\n^ a b c d e Chowdhury, Hasan (28 July 2023). \"Silicon Valley's favorite obscure theory about progress at all costs, which has been embraced by Marc Andreessen\". Business Insider. Archived from the original on 20 November 2023. Retrieved 20 November 2023.\n\n^ a b c d e f g h i j Torres, Émile P. (14 December 2023). \"'Effective Accelerationism' and the Pursuit of Cosmic Utopia\". Truthdig. Archived from the original on 18 December 2023. Retrieved 20 January 2024.\n\n^ Jones, Rachyl (16 October 2023). \"Marc Andreessen just dropped a 'Techno-Optimist Manifesto' that sees a world of 50 billion people settling other planets\". Fortune. Archived from the original on 28 November 2023. Retrieved 26 November 2023.\n\n^ Breland, Ali (6 December 2023). \"Meet the Silicon Valley CEOs who say greed is good—even if it kills us all\". Mother Jones. Archived from the original on 8 December 2023. Retrieved 14 December 2023.\n\n^ a b Baker-White, Emily (1 December 2023). \"Who Is @BasedBeffJezos, The Leader Of The Tech Elite's 'E/Acc' Movement?\". Forbes. Archived from the original on 11 December 2023. Retrieved 3 December 2023.\n\n^ Guillaume Verdon: Beff Jezos, E/acc Movement, Physics, Computation & AGI (Podcast). Lex Fridman Podcast. Vol. 407. 29 December 2023. Archived from the original on 30 December 2023. Retrieved 30 December 2023.\n\n^ \"My techno-optimism\". vitalik.eth.limo. Retrieved 17 August 2024.\n\n^ Nelson, Jason (28 November 2023). \"Ethereum Creator Vitalik Buterin: If AI Turns on Us 'Even Mars May Not Be Safe'\". Decrypt. Retrieved 17 August 2024.\n\n^ Wilhelm, Alex (20 November 2023). \"Effective accelerationism, doomers, decels, and how to flaunt your AI priors\". TechCrunch. Archived from the original on 23 November 2023. Retrieved 24 November 2023.\n\n^ Andreessen, Marc (16 October 2023). \"The Techno-Optimist Manifesto\". Andreessen Horowitz. Archived from the original on 23 November 2023. Retrieved 24 November 2023.\n\n^ Kelly, Jemima (22 October 2023). \"I read Andreessen's 'techno-optimist manifesto' so you don't have to\". Financial Times. Archived from the original on 14 January 2024. Retrieved 20 January 2024.\n\n^ Swan, David (29 October 2023). \"'We are conquerors': Why Silicon Valley's latest fad is its deadliest\". The Sydney Morning Herald. Archived from the original on 13 November 2023. Retrieved 24 November 2023.\n\n^ Reagan National Defense Forum. Simi Valley: Ronald Reagan Presidential Foundation & Institute. 2 December 2023.  Event occurs at 21:03. Archived from the original on 12 December 2023. Retrieved 14 December 2023 – via YouTube.\n\n^ Huet, Ellen (6 December 2023). \"A Cultural Divide Over AI Forms in Silicon Valley\". Bloomberg News. Archived from the original on 30 December 2023. Retrieved 30 December 2023.\n\n\n\nJezos, Beff; Bayeslord (10 July 2022). \"Notes on e/acc principles and tenets\". Beff's Newsletter. Substack.\n\n\n\n\n\n\n","length":12165,"excerpt":"From Wikipedia, the free encyclopedia","byline":"Contributors to Wikimedia projects","dir":"ltr","siteName":"Wikimedia Foundation, Inc.","lang":"en"},"finalizedMeta":{"title":"philosophical and social movement advocating for a pro-technology stance that seeks to maximize the probability of a technocapital singularity","description":"From Wikipedia, the free encyclopedia","author":"Contributors to Wikimedia projects","creator":"Contributors to Wikimedia projects","publisher":"Wikimedia Foundation, Inc.","date":"2024-08-22T17:49:40Z","image":"https://upload.wikimedia.org/wikipedia/commons/4/4d/Effective_accelerationism_icon.svg","topics":[]},"jsonLd":{"@type":"Article","headline":"philosophical and social movement advocating for a pro-technology stance that seeks to maximize the probability of a technocapital singularity","description":false,"image":"https://upload.wikimedia.org/wikipedia/commons/4/4d/Effective_accelerationism_icon.svg","mainEntityOfPage":{"@type":false,"@id":false},"datePublished":"2023-10-18T07:06:27Z","dateModified":"2024-08-22T17:49:40Z","isAccessibleForFree":false,"isPartOf":{"@type":[],"name":false,"productID":false},"discussionUrl":false,"license":false,"author":{"@type":"Organization","name":"Contributors to Wikimedia projects"},"publisher":{"@type":"Organization","name":"Wikimedia Foundation, Inc.","logo":{"@type":"ImageObject","url":"https://www.wikimedia.org/static/images/wmf-hor-googpub.png"}},"editor":{"@type":false,"name":false,"description":false,"sameAs":false,"image":{"@type":false,"url":false},"givenName":false,"familyName":false,"alternateName":false,"publishingPrinciples":false},"@context":"https://schema.org","name":"Effective accelerationism","url":"https://en.wikipedia.org/wiki/Effective_accelerationism","sameAs":"http://www.wikidata.org/entity/Q123509272","mainEntity":"http://www.wikidata.org/entity/Q123509272"},"twitterObj":false,"status":200,"metadata":{"author":false,"title":"Effective accelerationism - Wikipedia","description":false,"canonical":"https://en.wikipedia.org/wiki/Effective_accelerationism","keywords":[],"image":"/static/images/icons/wikipedia.png","firstParagraph":"\n"},"dublinCore":{},"opengraph":{"title":"Effective accelerationism - Wikipedia","description":false,"url":false,"site_name":false,"locale":false,"type":"website","typeObject":{"published_time":false,"modified_time":false,"author":false,"publisher":false,"section":false,"tag":[]},"image":["https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Effective_accelerationism_icon.svg/1200px-Effective_accelerationism_icon.svg.png","https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Effective_accelerationism_icon.svg/800px-Effective_accelerationism_icon.svg.png","https://upload.wikimedia.org/wikipedia/commons/thumb/4/4d/Effective_accelerationism_icon.svg/640px-Effective_accelerationism_icon.svg.png"],"image:width":["1200","800","640"],"image:height":["1244","829","663"]},"twitter":{"site":false,"description":false,"card":false,"creator":false,"title":false,"image":false},"archivedData":{"link":false,"wayback":false}}}