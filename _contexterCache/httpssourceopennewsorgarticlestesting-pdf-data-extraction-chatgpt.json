{"initialLink":"https://source.opennews.org/articles/testing-pdf-data-extraction-chatgpt/","sanitizedLink":"https://source.opennews.org/articles/testing-pdf-data-extraction-chatgpt/","finalLink":"https://source.opennews.org/articles/testing-pdf-data-extraction-chatgpt/","htmlEmbed":"<script>window.contexterSetup=window.contexterSetup||function(){window.contexterSetupComplete=!0;class ContexterLink extends HTMLAnchorElement{constructor(){super()}connectedCallback(){this.setAttribute(\"target\",\"_blank\")}}customElements.define(\"contexter-link\",ContexterLink,{extends:\"a\"}),customElements.define(\"contexter-inner\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__inner\"}}),customElements.define(\"contexter-thumbnail\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__thumbnail\"}}),customElements.define(\"contexter-byline\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__byline\"}}),customElements.define(\"contexter-keywordset\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__keywordset\"}}),customElements.define(\"contexter-linkset\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__linkset\"}}),customElements.define(\"contexter-meta\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__meta\"}}),customElements.define(\"contexter-summary\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"p-summary entry-summary\"}}),customElements.define(\"contexter-box-head\",class extends HTMLElement{constructor(){super()}connectedCallback(){this.className=\"contexter-box__head\"}}),customElements.define(\"contexter-box-inner\",class extends HTMLElement{constructor(){super()}connectedCallback(){}});class ContexterBox extends HTMLElement{constructor(){super(),this.first=!0,this.shadow=this.attachShadow({mode:\"open\"})}connectedCallback(){if(this.first){this.first=!1;var style=document.createElement(\"style\"),lightDomStyle=(style.innerHTML=`:host {--background: #f5f6f7;--border: darkblue;--blue: #0000ee;--font-color: black;--inner-border: black;font-family: Franklin,Arial,Helvetica,sans-serif;font-size: 14px;background: var(--background);width: 600px;color: var(--font-color);min-height: 90px;display: block;padding: 8px;border: 1px solid var(--border);cursor: pointer;box-sizing: border-box;margin: 6px;contain: content;margin: 6px auto;}// can only select top-level nodes with slotted::slotted(*) {max-width: 100%;display:block;}::slotted([slot=thumbnail]) {max-width: 100%;display:block;}::slotted([slot=header]) {width: 100%;font-size: 1.25rem;font-weight: bold;display:block;margin-bottom: 6px;}::slotted([slot=author]) {max-width: 50%;font-size: 12px;display:inline-block;float: left;}::slotted([slot=time]) {max-width: 50%;font-size: 12px;display:inline-block;float: right;}::slotted([slot=summary]) {width: 100%;margin-top: 6px;padding: 10px 2px;border-top: 1px solid var(--inner-border);font-size: 15px;display:inline-block;margin-bottom: 6px;}contexter-meta {height: auto;margin-bottom: 4px;width: 100%;display: grid;position: relative;min-height: 16px;grid-template-columns: repeat(2, 1fr);}::slotted([slot=keywords]) {width: 80%;padding: 2px 4px;border-top: 1px solid var(--inner-border);font-size: 11px;display: block;float: right;font-style: italic;text-align: right;grid-column: 2/2;grid-row: 1;align-self: end;justify-self: end;}::slotted([slot=keywords]):empty {border-top: 0px solid var(--inner-border);}::slotted([slot=archive-link]) {font-size: 1em;display: inline;}::slotted([slot=archive-link])::after {content: \"|\";display: inline;color: var(--font-color);text-decoration: none;margin: 0 .5em;}::slotted([slot=read-link]) {font-size: 1em;display: inline;}contexter-linkset {width: 80%;padding: 2px 4px;font-size: 13px;float: left;font-weight: bold;grid-row: 1;grid-column: 1/2;align-self: end;justify-self: start;}/* Extra small devices (phones, 600px and down) */@media only screen and (max-width: 600px) {:host {width: 310px;}}/* Small devices (portrait tablets and large phones, 600px and up) */@media only screen and (min-width: 600px) {...}/* Medium devices (landscape tablets, 768px and up) */@media only screen and (min-width: 768px) {...}/* Large devices (laptops/desktops, 992px and up) */@media only screen and (min-width: 992px) {...}/* Extra large devices (large laptops and desktops, 1200px and up) */@media only screen and (min-width: 1200px) {...}@media (prefers-color-scheme: dark){:host {--background: #354150;--border: #1f2b37;--blue: #55b0ff;--font-color: #ffffff;--inner-border: #787a7c;background: var(--background);border: 1px solid var(--border)}}`,document.createElement(\"style\"));lightDomStyle.innerHTML=`contexter-box {contain: content;}contexter-box .read-link {font-weight: bold;}contexter-box a {color: #0000ee;}contexter-box img {width: 100%;border: 0;padding: 0;margin: 0;}/* Extra small devices (phones, 600px and down) */@media only screen and (max-width: 600px) {...}/* Small devices (portrait tablets and large phones, 600px and up) */@media only screen and (min-width: 600px) {...}/* Medium devices (landscape tablets, 768px and up) */@media only screen and (min-width: 768px) {...}/* Large devices (laptops/desktops, 992px and up) */@media only screen and (min-width: 992px) {...}/* Extra large devices (large laptops and desktops, 1200px and up) */@media only screen and (min-width: 1200px) {...}@media (prefers-color-scheme: dark){contexter-box a {color: #55b0ff;}}`,this.appendChild(lightDomStyle),this.shadow.appendChild(style);const innerContainer=document.createElement(\"contexter-box-inner\"),innerSlotThumbnail=(this.shadow.appendChild(innerContainer),document.createElement(\"slot\")),innerSlotHeader=(innerSlotThumbnail.name=\"thumbnail\",innerContainer.appendChild(innerSlotThumbnail),document.createElement(\"slot\")),innerSlotAuthor=(innerSlotHeader.name=\"header\",innerContainer.appendChild(innerSlotHeader),document.createElement(\"slot\")),innerSlotTime=(innerSlotAuthor.name=\"author\",innerContainer.appendChild(innerSlotAuthor),document.createElement(\"slot\")),innerSlotSummary=(innerSlotTime.name=\"time\",innerContainer.appendChild(innerSlotTime),document.createElement(\"slot\")),metaContainer=(innerSlotSummary.name=\"summary\",innerContainer.appendChild(innerSlotSummary),document.createElement(\"contexter-meta\")),innerSlotInfo=(innerContainer.appendChild(metaContainer),document.createElement(\"slot\")),linkContainer=(innerSlotInfo.name=\"keywords\",metaContainer.appendChild(innerSlotInfo),document.createElement(\"contexter-linkset\")),innerSlotArchiveLink=(metaContainer.appendChild(linkContainer),document.createElement(\"slot\")),innerSlotReadLink=(innerSlotArchiveLink.name=\"archive-link\",linkContainer.appendChild(innerSlotArchiveLink),document.createElement(\"slot\"));innerSlotReadLink.name=\"read-link\",linkContainer.appendChild(innerSlotReadLink),this.className=\"contexter-box\",this.onclick=e=>{if(!e.target.className.includes(\"read-link\")&&!e.target.className.includes(\"title-link\")){const mainLinks=this.querySelectorAll(\"a.main-link\");mainLinks[0].click()}}}}}customElements.define(\"contexter-box\",ContexterBox)},window.contexterSetupComplete||window.contexterSetup();</script><contexter-box class=\"link-card h-entry hentry\" itemscope=\"\" itemtype=\"https://schema.org/CreativeWork\"><contexter-thumbnail class=\"thumbnail\" slot=\"thumbnail\"></contexter-thumbnail><contexter-box-head slot=\"header\" class=\"p-name entry-title\" itemprop=\"headline\"><contexter-box-head slot=\"header\" class=\"p-name entry-title\" itemprop=\"headline\"><a is=\"contexter-link\" href=\"https://source.opennews.org/articles/testing-pdf-data-extraction-chatgpt/\" itemprop=\"url\">I tested how well ChatGPT can pull data out of messy PDFs (and here's a script so you can too)</a></contexter-box-head></contexter-box-head><time class=\"dt-published published\" slot=\"time\" itemprop=\"datePublished\" datetime=\"2023-04-24T14:13:30.444Z\">4/24/2023</time><contexter-summary class=\"p-summary entry-summary\" itemprop=\"abstract\" slot=\"summary\"><p>Scattered errors and hallucinated data make it an exploratory tool, not a shortcut to analysis</p></contexter-summary><contexter-keywordset itemprop=\"keywords\" slot=\"keywords\"></contexter-keywordset><a is=\"contexter-link\" href=\"https://source.opennews.org/articles/testing-pdf-data-extraction-chatgpt/\" class=\"read-link main-link\" itemprop=\"sameAs\" slot=\"read-link\">Read</a></contexter-box>","linkId":"caf03faff021a33e79d58676bb44a107439a9413","data":{"originalLink":"https://source.opennews.org/articles/testing-pdf-data-extraction-chatgpt/","sanitizedLink":"https://source.opennews.org/articles/testing-pdf-data-extraction-chatgpt/","canonical":"https://source.opennews.org/articles/testing-pdf-data-extraction-chatgpt/","htmlText":"<!DOCTYPE html>\n<!--[if IE]><![endif]-->\n<!--[if lte IE 9]>  <html class=\"ie oldie\" lang=\"en\"> <![endif]-->\n<!--[if !IE]><!--> <html lang=\"en\"> <!--<![endif]-->\n<head>\n    <meta charset=\"utf-8\" />\n\n    <title>I tested how well ChatGPT can pull data out of messy PDFs (and here&#39;s a script so you can too) - Features - Source: An OpenNews project</title>\n\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n\n    <meta name=\"grunticon\" content=\"/static/base/_v2/dist/svg/\" />\n    <meta name=\"fullJS\" content=\"/static/base/_v2/dist/js/main.js\" />\n    <meta name=\"fullCSS\" content=\"/static/base/_v2/dist/css/main.css\" />\n\n    \n\n\n    <script src=\"/static/base/_v2/dist/js/initial.js\"></script>\n\n    \n    <link href=\"/static/base/_v2/dist/css/main.css\" rel=\"stylesheet\" />\n    \n    \n\n    <script>document.createElement( \"picture\" );</script>\n    <script src=\"/static/base/_v2/dist/js/lib/picturefill.js\" async></script>\n\n    <noscript><link href=\"/static/base/_v2/dist/svg/icons.fallback.css\" rel=\"stylesheet\" /></noscript>\n\n    \n    <script>\n      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\n      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\n      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\n      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');\n\n      ga('create', 'UA-91317400-1', 'auto');\n      ga('send', 'pageview');\n    </script>\n    \n    <link rel=\"shortcut icon\" href=\"/static/base/_v2/img/favicon.ico\" />\n\n    \n    <!-— facebook open graph tags -->\n    <meta property=\"og:type\" content=\"article\" />\n    <meta property=\"og:url\" content=\"https://source.opennews.org/articles/testing-pdf-data-extraction-chatgpt/\" />\n    <meta property=\"og:title\" content=\"I tested how well ChatGPT can pull data out of messy PDFs (and here&#39;s a script so you can too)\" />\n    <meta property=\"og:description\" content=\"Scattered errors and hallucinated data make it an exploratory tool, not a shortcut to analysis\" />\n    <meta property=\"og:image\" content=\"https://media.opennews.org/cache/55/72/5572c19d70123378f22bc4917cbc0552.jpg\" />\n \n    <!-— twitter card tags additive with the og: tags -->\n    <meta name=\"twitter:card\" content=\"summary_large_image\">\n    <meta name=\"twitter:domain\" value=\"https://source.opennews.org\" />\n    <meta name=\"twitter:title\" value=\"I tested how well ChatGPT can pull data out of messy PDFs (and here&#39;s a script so you can too)\" />\n    <meta name=\"twitter:description\" value=\"Scattered errors and hallucinated data make it an exploratory tool, not a shortcut to analysis\" />\n    <meta name=\"twitter:image\" content=\"https://media.opennews.org/cache/1b/59/1b59eb4d2a88f06e1c9b5d23c7ed7029.jpg\" />\n    <meta name=\"twitter:image:alt\" content=\"&lt;a href=&#34;https://www.youtube.com/watch?v=wsSqRv-y1r4&#34;&gt;A video demo&lt;/a&gt; of the data extraction process for this experiment.\" />\n    <meta name=\"twitter:url\" value=\"https://source.opennews.org/articles/testing-pdf-data-extraction-chatgpt/\" />\n    <meta name=\"twitter:site\" value=\"@source\" />\n\n    \n\n\n</head>\n\n<body class=\"tmpl-article\">\n\n    <div class=\"page\">\n\n        <header>\n            <div class=\"site-header\">\n\n                <div class=\"header-main\">\n                    <h1 class=\"site-logo\">\n                        <a href=\"/\">\n                            <picture>\n                                <source srcset=\"/static/base/_v2/svg/logo-source.svg\" type=\"image/svg+xml\" />\n                                <img src=\"/static/base/_v2/dist/svg/png/logo-source.png\" alt=\"Source\" />\n                            </picture>\n                        </a>\n                    </h1>\n\n                    <a data-collapsible-target class=\"header-toggle nav-toggle\" href=\"#nav-primary\">\n                        <span class=\"icon icon-menu\">Jump to site navigation</span>\n                    </a>\n\n                    <a data-collapsible-target class=\"header-toggle search-toggle\" href=\"#search\">\n                        <span class=\"icon icon-search\">Search this site</span>\n                    </a>\n                </div><!-- /end .header-main -->\n\n                \n                <div class=\"site-nav collapsible collapsible-collapsed\" id=\"nav-primary\">\n                    <h2 class=\"a11y\" href=\"#nav-primary\">\n                        <span class=\"icon icon-menu\">Navigation</span>\n                    </h2>\n\n                    <ul class=\"site-nav-links\">\n                    \n                        <li><a href=\"/articles/\" aria-describedby=\"current-page\" class=\"is-active\">Articles</a></li>\n                    \n                        <li><a href=\"/guides/\">Guides</a></li>\n                    \n                        <li><a href=\"/community/\">Community</a></li>\n                    \n                        <li><a href=\"/jobs/\">Jobs</a></li>\n                    \n                        <li><a href=\"https://opennews.org/donate/\">Donate</a></li>\n                    \n                    </ul><!-- /end .site-nav-links -->\n                </div><!-- /end .site-nav -->\n\n            </div><!-- /end .site-header -->\n        </header>\n\n        <hr />\n\n        <main>\n            <div class=\"page-main\">\n                \n\n            <div class=\"article-matter-front\">\n                <p class=\"hed-label\">Features<span class=\"a11y\">:</span></p>\n\n                <h1 class=\"page-title-lead\">I tested how well ChatGPT can pull data out of messy PDFs (and here&#8217;s a script so you can&nbsp;too)</h1>\n\n                <h2 class=\"article-subtitle-lead\">Scattered errors and hallucinated data make it an exploratory tool, not a shortcut to&nbsp;analysis</h2>\n\n                <ul class=\"list-tags\">\n                    <li><a class=\"tag\" href=\"/articles/tags/ai/\">AI</a></li>\n                    <li><a class=\"tag\" href=\"/articles/tags/data-extraction/\">data extraction</a></li>\n                </ul><!-- /end .list-tags -->\n\n                <div class=\"article-meta\">\n                    <p class=\"article-byline\">By <a href=\"/people/brandon-roberts/\">Brandon Roberts</a></p>\n\n                    <p class=\"article-date\">Posted on: <time datetime=\"2023-03-01\">March 1,&nbsp;2023</time></p>\n                </div><!-- /end .article-meta -->\n            </div><!-- /end .article-matter-front -->\n\n            <hr />\n\n            \n            <div class=\"figure figure-article-lead\">\n                <figure>\n                    <img src=\"https://media.opennews.org/cache/55/72/5572c19d70123378f22bc4917cbc0552.jpg\" alt=\"\" />\n                    \n                    <figcaption>\n                        <p><a href=\"https://www.youtube.com/watch?v=wsSqRv-y1r4\">A video demo</a> of the data extraction process for this&nbsp;experiment.</p>\n                    </figcaption>\n                </figure>\n            </div><!-- /end .figure.figure-article-lead -->\n            \n            \n            <div class=\"article-main\">\n                <p>I convert a ton of text documents like PDFs to spreadsheets. It’s tedious and expensive work. So every time a new iteration of <span class=\"caps\">AI</span> technology arrives, I wonder if it’s capable of doing what so many people ask for: to hand off a <span class=\"caps\">PDF</span>, ask for a spreadsheet, and get one back. After throwing a couple programming problems at OpenAI’s ChatGPT and getting a viable result, I wondered if we were finally&nbsp;there.</p>\r\n\r\n<p>Back when OpenAI’s <span class=\"caps\">GPT</span>-3 was the hot new thing, I saw Montreal journalist Roberto Rocha <a href=\"https://robertorocha.info/getting-tabular-data-from-unstructured-text-with-gpt-3-an-ongoing-experiment/\">attempt a similar test</a>. The results were lackluster, but ChatGPT, OpenAI’s newest model, has several improvements that make it better suited to extraction: It’s 10x larger than <span class=\"caps\">GPT</span>-3 and is generally more coherent as a result, it’s been trained <a href=\"https://openai.com/blog/instruction-following/\">to explicitly follow instructions</a>, and it understands programming&nbsp;languages.</p>\r\n\r\n<p>To test how well ChatGPT could extract structured data from PDFs, I wrote a Python script (which I’ll share at the end!) to convert two document sets to&nbsp;spreadsheets:</p>\r\n\r\n<ul>\r\n\t<li>A 7,000-page <span class=\"caps\">PDF</span> of New York data breach notification forms. There were five different forms, bad <span class=\"caps\">OCR</span>, and some freeform letters mixed&nbsp;in.</li>\r\n\t<li>1,400 memos from internal police investigations. These were completely unstructured and contained emails and document scans. Super&nbsp;messy.</li>\r\n</ul>\r\n\r\n<p>My overall strategy was the&nbsp;following:</p>\r\n\r\n<ol>\r\n\t<li>Redo the <span class=\"caps\">OCR</span>, using the <a href=\"https://github.com/freedmand/textra\">highest quality tools possible</a>. This was critically important because ChatGPT refused to work with poorly <span class=\"caps\">OCR</span>’d&nbsp;text.</li>\r\n\t<li>Clean the data as well as I could, maintaining physical layout and removing garbage characters and boilerplate&nbsp;text.</li>\r\n\t<li>Break the documents into individual&nbsp;records.</li>\r\n\t<li>Ask ChatGPT to turn each record into <span class=\"caps\">JSON</span>.</li>\r\n</ol>\r\n\r\n<p>I spent about a week getting familiarized with both datasets and doing all this preprocessing. Once it’s done, getting ChatGPT to convert a piece of text into <span class=\"caps\">JSON</span> is really easy. You can paste in a record and say <em>“return a <span class=\"caps\">JSON</span> representation of this”</em> and it will do it. But doing this for multiple records is a bad idea because ChatGPT will invent its own schema, using randomly chosen field names from the text. It will also decide on its own way to parse values. Addresses, for example, will sometimes end up as a string and sometimes as a <span class=\"caps\">JSON</span> object or an array, with the constituent parts of an address split&nbsp;up.</p>\r\n\r\n<p><a href=\"https://github.com/dair-ai/Prompt-Engineering-Guide/blob/main/guides/prompts-intro.md\">Prompt design</a> is the most important factor in getting consistent results, and your language choices make a huge difference. One tip: Figure out what wording ChatGPT uses when referring to a task and mimic that. (If you don’t know, you can always ask: <em>“Explain how you’d _____ using _______.”</em>)</p>\r\n\r\n<p>Because ChatGPT understands code, I designed my prompt around asking for <span class=\"caps\">JSON</span> that conforms to a given <a href=\"https://json-schema.org/\"><span class=\"caps\">JSON</span> schema</a>. This was my&nbsp;prompt:</p>\r\n\r\n<pre class=\"prettyprint\">\r\n```\r\nText document goes here, truncated if longer than 4000 chars\r\n```\r\n\r\nFor the given text, can you provide a JSON representation that strictly follows this schema:\r\n\r\n```\r\n{\r\n      \"type\": \"object\",\r\n      \"additionalProperties\": false,\r\n      \"properties\": {\r\n        \"descriptive name of field here\": { \"type\": \"data type here\" },\r\n        ...\r\n      }\r\n}\r\n```\r\n</pre>\r\n\r\n<p>I tried to extract a <span class=\"caps\">JSON</span> object from every response and run some validation checks against it. Two checks were particularly important: 1) making sure the <span class=\"caps\">JSON</span> was complete, not truncated or broken, and 2) making sure the keys and values matched the schema. I retried if the validation check failed, and usually I’d get valid <span class=\"caps\">JSON</span> back on the second or third attempts. If it continued to fail, I’d make a note of it and skip the record. Some records ChatGPT just doesn’t&nbsp;like.</p>\r\n\r\n<h2>Results</h2>\r\n\r\n<p>Impressively, ChatGPT built a <em>mostly</em> usable dataset. At first glance, I even thought I had a perfectly extracted dataset. But once I went through the pages and compared values, I started to notice errors. Some names were misspelled. Some were missing entirely. Some numbers were&nbsp;wrong.</p>\r\n\r\n<div class=\"image-wrapper\" style=\"margin-bottom: 1.5em; width: 100%;\">\r\n    <iframe width=\"100%\" style=\"aspect-ratio: 16/9;\" src=\"https://www.youtube-nocookie.com/embed/wsSqRv-y1r4\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\r\n    <p class=\"caption\"><em>Here&#8217;s a video demo of the data extraction I tried for this&nbsp;article.</em></p>\r\n</div>\r\n\r\n<p>The errors, although subtle and relatively infrequent, were enough to prevent me from doing the basic analyses that most data journalists want to do. Averages, histograms, mins and maxes were&nbsp;out.</p>\r\n\r\n<p>But for my projects, the mistakes were tolerable. I wanted to find big players in the breach database, so I didn’t care if some of the names were wrong or if some numeric values were off by a zero. For the police data, I was basically looking for a summary to identify certain incidents and the individuals involved. If I missed something, it would be <span class=\"caps\">OK</span>.</p>\r\n\r\n<p>Overall, these are the types of errors ChatGPT&nbsp;introduced:</p>\r\n\r\n<ul>\r\n\t<li><strong>ChatGPT <a href=\"https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence)\">hallucinated</a> data, meaning it made things up.</strong> Often in subtle and hard-to-detect ways. For example, it turned “2222 Colony Road, <strong><em>Moor</em></strong>croft” (note the “r”) into “2222 Colony Road, <strong><em>Moon</em></strong>croft”. The word “Mooncroft” (with an “n”) doesn’t appear anywhere in the text. ChatGPT seemed to be making a connection between the words <em>colony</em> and <em>moon</em>. How&nbsp;quaint.</li>\r\n\t<li><strong>It stumbled on people’s names and assumed gender.</strong> Some forms had a “salutation” field, which seemed to cause ChatGPT to add salutations (“Miss”, “Mr”) when inappropriate and omit them even when given (“Dr” and “Prof”). It also failed to use the correct name when multiple names appeared in a record, preferring whichever came&nbsp;last.</li>\r\n\t<li><strong>ChatGPT remembered previous prompts, causing mixups.</strong> Occasionally it would use a name or a business entity from an earlier record, despite a perfectly valid one appearing in the current record’s text. For example, in one record it used the names of a lawyer and law firm last seen 150 and 30 pages earlier, respectively. This problem forced me to make sure names and entities actually existed in the current&nbsp;record.</li>\r\n\t<li><strong>Words it thought were typos got “corrected.”</strong> Usually this was helpful, but sometimes it introduced an error. This was particularly problematic with email&nbsp;addresses.</li>\r\n\t<li><strong>Errors were scattered seemingly randomly throughout the data.</strong> While certain columns contained more errors than others, all columns had error rates ranging from 1% to upwards of 6%. The errors were scattered across rows, too. Combined, this meant that I’d basically need to compare every row with every record to get a fully valid dataset—the very work I was trying to avoid in the first&nbsp;place.</li>\r\n</ul>\r\n\r\n<p>Problems with large language models have been <a href=\"https://medium.com/fair-bytes/how-biased-is-gpt-3-5b2b91f1177\">well</a> <a href=\"https://interaktiv.br.de/ai-generated-fact-boxes/\">documented</a> by now. Even with the great advances in ChatGPT, some of them reared their head in my experiments. Attempts to ignore these problems and shovel ChatGPT-derived work directly to readers will inevitably <a href=\"https://gizmodo.com/cnet-ai-chatgpt-news-robot-1849996151\">lead to disastrous failures</a>.</p>\r\n\r\n\r\n<div class=\"image-wrapper\" style=\"margin-bottom: 1.5em; width: 100%;\">\r\n    <img src=\"https://media.opennews.org/img/uploads/article_images/chatgpt_experiment.png\" alt=\"\">\r\n    <p class=\"caption\"><em>Sometimes ChatGPT simply refuses to work with a document and gives a boilerplate response. It responded with concerns about “sensitive information” on several documents in both the police memos and the <span class=\"caps\">NY</span> data breach datasets, despite them both being public&nbsp;documents.</em></p>\r\n</div>\r\n\r\n<h2>Will ChatGPT revolutionize data&nbsp;journalism?</h2>\r\n\r\n<p>I don&#8217;t think so, for three&nbsp;reasons:</p>\r\n\r\n<ol>\r\n\t<li><strong>No, for technical reasons:</strong> Working with ChatGPT via OpenAI’s <span class=\"caps\">API</span> is painfully slow. It took nearly three weeks to extract approximately 2,500 records from the data breach <span class=\"caps\">PDF</span> alone. This is even more significant considering I started this project before ChatGPT hit the mainstream and was able to use it for two weeks before rate limiting was imposed. The <span class=\"caps\">API</span> is also unreliable and exhibits frequent downtime and interruptions, although <a href=\"https://openai.com/blog/chatgpt-plus/\">this may improve</a> in the&nbsp;future.</li>\r\n\t<li><strong>No, for economic reasons:</strong> With ChatGPT I’m convinced we’re trading one form of manual labor for another. We’re trading programming and transcription for cleaning, fact-checking and validation. Because any row can potentially be incorrect, every field must be checked in order to build confidence. In the end, I’m not convinced we save much&nbsp;work.</li>\r\n\t<li><strong>No, for editorial reasons:</strong> The problems with data hallucination and other mixups restrict this approach to internal or journalist-facing uses, in my opinion. It’s a better tip generator than story generator. Putting ChatGPT at the end of a journalistic workflow risks exchanging more speed and quantity for less&nbsp;credibility.</li>\r\n</ol>\r\n\r\n<p>The totality of these problems make most uses of ChatGPT editorially impractical, especially at scale. But I think it still has a place. For small, under-resourced newsrooms that need to turn a small <span class=\"caps\">PDF</span> into a table, this could be workable (<em>Hey ChatGPT, can you turn this text into an array of <span class=\"caps\">JSON</span> objects?</em>).</p>\r\n\r\n<p>Some PDFs are also just so messy and non-uniform that writing an extraction script is too time consuming. I’ve had countless projects die due to problems like that. ChatGPT extraction has the potential to breathe life into such&nbsp;projects.</p>\r\n\r\n<p>ChatGPT extraction could also serve well as an exploratory tool or a lead generator, in use cases where mistakes and missing values are tolerable, or speculative situations where you want to get a taste of the data before sinking weeks into a real cleanup and&nbsp;analysis.</p>\r\n\r\n<h2>Try it&nbsp;yourself</h2>\r\n\r\n<p>I made my ChatGPT extractor script <a href=\"https://github.com/brandonrobertz/chatgpt-document-extraction\">available on GitHub</a>. Maybe you have a troublesome data project and want to try this for yourself. Or maybe you want to see the possibilities and limitations face-to-face. I’m secretly hoping someone will finally crack the <a href=\"https://publicfiles.fcc.gov/\"><span class=\"caps\">FCC</span> <span class=\"caps\">TV</span> and cable political ad disclosure</a> dataset, closing the chapter <a href=\"https://wandb.ai/deepform/political-ad-extraction/benchmark\">left open</a> since <a href=\"https://projects.propublica.org/free-the-files/\">ProPublica’s Free The Files</a>&nbsp;project.</p>\r\n\r\n<p>Either way, I have a feeling we’ll be reporting on and using this technology for some time to come. And the best way to get acquainted with any technology is to use&nbsp;it.</p>\n                \n                \n\n                <ul class=\"links-article-social\">\n                    \n                    <li><a class=\"icon icon-twitter\" href=\"#\" onclick=\"window.open('https://twitter.com/intent/tweet?via=source&text=I tested how well ChatGPT can pull data out of messy PDFs (and here\\u0027s a script so you can too)&url='+encodeURIComponent(location.href), 'twitter-share-dialog', 'width=626,height=436'); return false;\">Share on Twitter</a></li>\n                    <li><a class=\"icon icon-facebook\" href=\"#\" onclick=\"window.open('https://www.facebook.com/sharer/sharer.php?u='+encodeURIComponent(location.href), 'facebook-share-dialog', 'width=626,height=436'); return false;\">Share on Facebook</a></li>\n                </ul><!-- /end .links-article-social -->\n            </div><!-- /end .article.main -->\n\n            <div class=\"article-links-relevant\">\n                \n\n                \n\n                \n            </div><!-- /end .article-links-relevant -->\n\n            <div class=\"article-matter-back\">\n                \n                <div class=\"mod article-credits\">\n                    <h2 class=\"hed-label\">Credits</h2>\n\n                    <ul>\n                        <li class=\"profile h-card\">\n                            <h3 class=\"profile-name\">\n                                <a href=\"/people/brandon-roberts/\">\n                                    <img class=\"profile-photo u-photo\" src=\"https://media.opennews.org/cache/53/dc/53dceb470bbefe71ef3c019c9aee0c3e.png\" alt=\"\" />\n                                    <cite class=\"p-name\">Brandon Roberts</cite>\n                                </a>\n                            </h3>\n                            \n                            \n                            <p class=\"profile-bio\">I&#8217;m Brandon Roberts. I&#8217;m an independent data journalist specializing in open source and bringing computational techniques to journalism projects. You can read more on my site: <a href=\"https://bxroberts.org\">bxroberts.org</a></p>\n\n                            <ul class=\"profile-links\">\n                                \n                                <li><a class=\"icon-twitter-alt\" href=\"https://twitter.com/bxroberts\">@bxroberts</a></li>\n                                \n                            </ul>\n                        </li><!-- /end .profile-person -->\n                    </ul>\n                </div><!-- /end .article-credits -->\n                \n\n                \n\n                <div class=\"mod article-related\">\n                    <h2 class=\"hed-label\">Recently</h2>\n\n                    <ul class=\"list-promos\">\n                        <li class=\"src-promo\">\n                            <a href=\"/articles/how-newsrooms-pay-journalist-coders-2023/\">\n                                <img src=\"https://media.opennews.org/cache/db/1b/db1b5aa3a3f5c03e66cf8f77dce5e5e6.jpg\" alt=\"\" />\n                                \n                                <h3 class=\"hed-promo\">How newsrooms pay journalist-coders&nbsp;today</h3>\n                            </a>\n                        </li><!-- /end .src-promo -->\n                        <li class=\"src-promo\">\n                            <a href=\"/articles/data-community-inequality-mongolia/\">\n                                <img src=\"https://media.opennews.org/cache/3d/87/3d87b92650f14e00de51c71d7dd1b092.jpg\" alt=\"\" />\n                                \n                                <h3 class=\"hed-promo\">Using data to investigate inequality, and building a network to find&nbsp;solutions</h3>\n                            </a>\n                        </li><!-- /end .src-promo -->\n                        <li class=\"src-promo\">\n                            <a href=\"/articles/story-of-your-work-five-step-process/\">\n                                <img src=\"https://media.opennews.org/cache/46/16/461657f4c8fb9c4f8838a0fe26f78317.jpg\" alt=\"\" />\n                                \n                                <h3 class=\"hed-promo\">How to tell the story of your work (or, one journalist’s process for career&nbsp;success)</h3>\n                            </a>\n                        </li><!-- /end .src-promo -->\n                    </ul><!-- /end .list-promos -->\n                </div><!-- /end .article-related -->\n            </div><!-- /end .article-matter-back -->\n\n\n\n                \n                                <div class=\"site-search collapsible collapsible-collapsed\" id=\"search\">\n                    <h2 class=\"a11y\">\n                        <span class=\"icon icon-search\">Search this site</span>\n                    </h2>\n                    <div class=\"site-search-inner\">\n                        <form class=\"form-search\" method=\"get\" action=\"/search/\">\n                            <label class=\"hed-search\" for=\"text-search\">Search SOURCE:</label>\n                            <p class=\"fields-search\">\n                                <input class=\"text-search\" id=\"text-search\" type=\"search\" name=\"q\" value=\"\" />\n                                <input class=\"btn-search icon-search\" type=\"submit\" value=\"Search\" />\n                            </p><!-- /end .fields-search -->\n                        </form><!-- /end .form-search -->\n\n                        <div class=\"article-tease\">\n                            <h2 class=\"hed-search\">From our Archives:</h2>\n                            \n                            <h3 class=\"hed-article-tease-search\">\n                                <a href=\"/articles/story-of-your-work-five-step-process/\">\n                                    <img src=\"https://media.opennews.org/cache/46/16/461657f4c8fb9c4f8838a0fe26f78317.jpg\" alt=\"\" />\n                                    \n                                    How to tell the story of your work (or, one journalist’s process for career success)\n                                </a>\n                            </h3>\n                        </div><!-- /end .article-tease -->\n                    </div><!-- /end .site-search-inner -->\n                </div><!-- /end .site-search -->\n                \n            </div><!-- /end .page-main -->\n        </main>\n\n        <footer>\n        <div class=\"page-footer\">\n\n            <div class=\"foot-main foot-source\">\n                <div class=\"foot-content\">\n                    <h2 class=\"foot-logo\">\n                        <a href=\"/\">\n                            <picture>\n                                <source srcset=\"/static/base/_v2/svg/logo-source.svg\" type=\"image/svg+xml\" />\n                                <img src=\"/static/base/_v2/dist/svg/png/logo-source.png\" alt=\"Source\" />\n                            </picture>\n                        </a>\n                    </h2>\n\n                    <p>Source is an OpenNews project designed to amplify the impact of journalism code and the community of developers, designers, journalists, and editors who make it.</p>\n\n                    <p>Learn more <a href=\"/about/\">about the project</a> or <a href=\"/contribute/\">contribute your work</a>. <a href=\"mailto:source@opennews.org\">Contact us</a>.</p>\n\n                    <p class=\"donate\"><a href=\"https://opennews.org/donate/\">Donate</a> to OpenNews.</p>\n\n                    <p><a class=\"link-cc\" href=\"https://creativecommons.org/licenses/by/3.0/\"><img src=\"/static/base/_v2/img/cc.png\" alt=\"\" />CC Attribution 3.0</a></p>\n                </div><!-- /end .foot-content -->\n                <div class=\"foot-aside\">\n                    <h3 class=\"hed-foot\">Connect</h3>\n                    <ul class=\"list-foot-social\">\n                        <li><a class=\"has-icon icon-rss\" href=\"/rss/\">RSS</a></li>\n                        <li><a class=\"has-icon icon-twitter\" href=\"https://twitter.com/source\">@source</a></li>\n                        <li><a class=\"has-icon icon-email\" href=\"http://eepurl.com/czSVTL\">Get our biweekly roundup email</a></li>\n                    </ul><!-- /end .list-foot-social -->\n                </div><!-- /end .foot-aside -->\n            </div><!-- /end .foot-main.foot-source -->\n\n            <div class=\"foot-main foot-opennews\">\n                <div class=\"foot-content\">\n                    <h2 class=\"foot-logo\">\n                        <a href=\"https://opennews.org\">\n                            <picture>\n                                <source srcset=\"/static/base/_v2/svg/logo-opennews.svg\" type=\"image/svg+xml\" />\n                                <img src=\"/static/base/_v2/dist/svg/png/logo-opennews.png\" alt=\"Knight-Mozilla OpenNews\" />\n                            </picture>\n                        </a>\n                    </h2>\n\n                    <p><a href=\"https://opennews.org\">OpenNews</a> connects a network of developers, designers, journalists, and editors to collaborate on open technologies and processes within journalism. OpenNews believes that a community of peers working, learning, and solving problems together can create a stronger, more responsive journalism ecosystem. Incubated at the <a href=\"https://www.mozilla.org/en-US/foundation/\">Mozilla Foundation</a> from 2011-2016, OpenNews is now a project of <a href=\"http://communitypartners.org/\">Community Partners</a>.</p>\n                </div><!-- /end .foot-content -->\n            </div><!-- /end .foot-main.foot-opennews -->\n\n        </div><!-- /end .page-footer -->\n    </footer>\n\n</div><!-- /end .page -->\n\n<!-- Anchors used by `aria-describedby` states -->\n<div id=\"wayfinding\" class=\"squelch\">\n    <span id=\"current-page\">Current page</span>\n</div>\n\n\n\n\n<!-- Page generated: 2023-04-24 09:11:22.453193 -->\n</body>\n</html>","oembed":false,"readabilityObject":{"title":"I tested how well ChatGPT can pull data out of messy PDFs (and here's a script so you can too)","content":"<div id=\"readability-page-1\" class=\"page\"><div>\n                <p>I convert a ton of text documents like PDFs to spreadsheets. It’s tedious and expensive work. So every time a new iteration of <span>AI</span> technology arrives, I wonder if it’s capable of doing what so many people ask for: to hand off a <span>PDF</span>, ask for a spreadsheet, and get one back. After throwing a couple programming problems at OpenAI’s ChatGPT and getting a viable result, I wondered if we were finally&nbsp;there.</p>\n\n<p>Back when OpenAI’s <span>GPT</span>-3 was the hot new thing, I saw Montreal journalist Roberto Rocha <a href=\"https://robertorocha.info/getting-tabular-data-from-unstructured-text-with-gpt-3-an-ongoing-experiment/\">attempt a similar test</a>. The results were lackluster, but ChatGPT, OpenAI’s newest model, has several improvements that make it better suited to extraction: It’s 10x larger than <span>GPT</span>-3 and is generally more coherent as a result, it’s been trained <a href=\"https://openai.com/blog/instruction-following/\">to explicitly follow instructions</a>, and it understands programming&nbsp;languages.</p>\n\n<p>To test how well ChatGPT could extract structured data from PDFs, I wrote a Python script (which I’ll share at the end!) to convert two document sets to&nbsp;spreadsheets:</p>\n\n<ul>\n\t<li>A 7,000-page <span>PDF</span> of New York data breach notification forms. There were five different forms, bad <span>OCR</span>, and some freeform letters mixed&nbsp;in.</li>\n\t<li>1,400 memos from internal police investigations. These were completely unstructured and contained emails and document scans. Super&nbsp;messy.</li>\n</ul>\n\n<p>My overall strategy was the&nbsp;following:</p>\n\n<ol>\n\t<li>Redo the <span>OCR</span>, using the <a href=\"https://github.com/freedmand/textra\">highest quality tools possible</a>. This was critically important because ChatGPT refused to work with poorly <span>OCR</span>’d&nbsp;text.</li>\n\t<li>Clean the data as well as I could, maintaining physical layout and removing garbage characters and boilerplate&nbsp;text.</li>\n\t<li>Break the documents into individual&nbsp;records.</li>\n\t<li>Ask ChatGPT to turn each record into <span>JSON</span>.</li>\n</ol>\n\n<p>I spent about a week getting familiarized with both datasets and doing all this preprocessing. Once it’s done, getting ChatGPT to convert a piece of text into <span>JSON</span> is really easy. You can paste in a record and say <em>“return a <span>JSON</span> representation of this”</em> and it will do it. But doing this for multiple records is a bad idea because ChatGPT will invent its own schema, using randomly chosen field names from the text. It will also decide on its own way to parse values. Addresses, for example, will sometimes end up as a string and sometimes as a <span>JSON</span> object or an array, with the constituent parts of an address split&nbsp;up.</p>\n\n<p><a href=\"https://github.com/dair-ai/Prompt-Engineering-Guide/blob/main/guides/prompts-intro.md\">Prompt design</a> is the most important factor in getting consistent results, and your language choices make a huge difference. One tip: Figure out what wording ChatGPT uses when referring to a task and mimic that. (If you don’t know, you can always ask: <em>“Explain how you’d _____ using _______.”</em>)</p>\n\n<p>Because ChatGPT understands code, I designed my prompt around asking for <span>JSON</span> that conforms to a given <a href=\"https://json-schema.org/\"><span>JSON</span> schema</a>. This was my&nbsp;prompt:</p>\n\n<pre>```\nText document goes here, truncated if longer than 4000 chars\n```\n\nFor the given text, can you provide a JSON representation that strictly follows this schema:\n\n```\n{\n      \"type\": \"object\",\n      \"additionalProperties\": false,\n      \"properties\": {\n        \"descriptive name of field here\": { \"type\": \"data type here\" },\n        ...\n      }\n}\n```\n</pre>\n\n<p>I tried to extract a <span>JSON</span> object from every response and run some validation checks against it. Two checks were particularly important: 1) making sure the <span>JSON</span> was complete, not truncated or broken, and 2) making sure the keys and values matched the schema. I retried if the validation check failed, and usually I’d get valid <span>JSON</span> back on the second or third attempts. If it continued to fail, I’d make a note of it and skip the record. Some records ChatGPT just doesn’t&nbsp;like.</p>\n\n<h2>Results</h2>\n\n<p>Impressively, ChatGPT built a <em>mostly</em> usable dataset. At first glance, I even thought I had a perfectly extracted dataset. But once I went through the pages and compared values, I started to notice errors. Some names were misspelled. Some were missing entirely. Some numbers were&nbsp;wrong.</p>\n\n<div>\n    <iframe width=\"100%\" src=\"https://www.youtube-nocookie.com/embed/wsSqRv-y1r4\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen=\"\"></iframe>\n    <p><em>Here’s a video demo of the data extraction I tried for this&nbsp;article.</em></p>\n</div>\n\n<p>The errors, although subtle and relatively infrequent, were enough to prevent me from doing the basic analyses that most data journalists want to do. Averages, histograms, mins and maxes were&nbsp;out.</p>\n\n<p>But for my projects, the mistakes were tolerable. I wanted to find big players in the breach database, so I didn’t care if some of the names were wrong or if some numeric values were off by a zero. For the police data, I was basically looking for a summary to identify certain incidents and the individuals involved. If I missed something, it would be <span>OK</span>.</p>\n\n<p>Overall, these are the types of errors ChatGPT&nbsp;introduced:</p>\n\n<ul>\n\t<li><strong>ChatGPT <a href=\"https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence)\">hallucinated</a> data, meaning it made things up.</strong> Often in subtle and hard-to-detect ways. For example, it turned “2222 Colony Road, <strong><em>Moor</em></strong>croft” (note the “r”) into “2222 Colony Road, <strong><em>Moon</em></strong>croft”. The word “Mooncroft” (with an “n”) doesn’t appear anywhere in the text. ChatGPT seemed to be making a connection between the words <em>colony</em> and <em>moon</em>. How&nbsp;quaint.</li>\n\t<li><strong>It stumbled on people’s names and assumed gender.</strong> Some forms had a “salutation” field, which seemed to cause ChatGPT to add salutations (“Miss”, “Mr”) when inappropriate and omit them even when given (“Dr” and “Prof”). It also failed to use the correct name when multiple names appeared in a record, preferring whichever came&nbsp;last.</li>\n\t<li><strong>ChatGPT remembered previous prompts, causing mixups.</strong> Occasionally it would use a name or a business entity from an earlier record, despite a perfectly valid one appearing in the current record’s text. For example, in one record it used the names of a lawyer and law firm last seen 150 and 30 pages earlier, respectively. This problem forced me to make sure names and entities actually existed in the current&nbsp;record.</li>\n\t<li><strong>Words it thought were typos got “corrected.”</strong> Usually this was helpful, but sometimes it introduced an error. This was particularly problematic with email&nbsp;addresses.</li>\n\t<li><strong>Errors were scattered seemingly randomly throughout the data.</strong> While certain columns contained more errors than others, all columns had error rates ranging from 1% to upwards of 6%. The errors were scattered across rows, too. Combined, this meant that I’d basically need to compare every row with every record to get a fully valid dataset—the very work I was trying to avoid in the first&nbsp;place.</li>\n</ul>\n\n<p>Problems with large language models have been <a href=\"https://medium.com/fair-bytes/how-biased-is-gpt-3-5b2b91f1177\">well</a> <a href=\"https://interaktiv.br.de/ai-generated-fact-boxes/\">documented</a> by now. Even with the great advances in ChatGPT, some of them reared their head in my experiments. Attempts to ignore these problems and shovel ChatGPT-derived work directly to readers will inevitably <a href=\"https://gizmodo.com/cnet-ai-chatgpt-news-robot-1849996151\">lead to disastrous failures</a>.</p>\n\n\n<div>\n    <p><img src=\"https://media.opennews.org/img/uploads/article_images/chatgpt_experiment.png\" alt=\"\"></p><p><em>Sometimes ChatGPT simply refuses to work with a document and gives a boilerplate response. It responded with concerns about “sensitive information” on several documents in both the police memos and the <span>NY</span> data breach datasets, despite them both being public&nbsp;documents.</em></p>\n</div>\n\n<h2>Will ChatGPT revolutionize data&nbsp;journalism?</h2>\n\n<p>I don’t think so, for three&nbsp;reasons:</p>\n\n<ol>\n\t<li><strong>No, for technical reasons:</strong> Working with ChatGPT via OpenAI’s <span>API</span> is painfully slow. It took nearly three weeks to extract approximately 2,500 records from the data breach <span>PDF</span> alone. This is even more significant considering I started this project before ChatGPT hit the mainstream and was able to use it for two weeks before rate limiting was imposed. The <span>API</span> is also unreliable and exhibits frequent downtime and interruptions, although <a href=\"https://openai.com/blog/chatgpt-plus/\">this may improve</a> in the&nbsp;future.</li>\n\t<li><strong>No, for economic reasons:</strong> With ChatGPT I’m convinced we’re trading one form of manual labor for another. We’re trading programming and transcription for cleaning, fact-checking and validation. Because any row can potentially be incorrect, every field must be checked in order to build confidence. In the end, I’m not convinced we save much&nbsp;work.</li>\n\t<li><strong>No, for editorial reasons:</strong> The problems with data hallucination and other mixups restrict this approach to internal or journalist-facing uses, in my opinion. It’s a better tip generator than story generator. Putting ChatGPT at the end of a journalistic workflow risks exchanging more speed and quantity for less&nbsp;credibility.</li>\n</ol>\n\n<p>The totality of these problems make most uses of ChatGPT editorially impractical, especially at scale. But I think it still has a place. For small, under-resourced newsrooms that need to turn a small <span>PDF</span> into a table, this could be workable (<em>Hey ChatGPT, can you turn this text into an array of <span>JSON</span> objects?</em>).</p>\n\n<p>Some PDFs are also just so messy and non-uniform that writing an extraction script is too time consuming. I’ve had countless projects die due to problems like that. ChatGPT extraction has the potential to breathe life into such&nbsp;projects.</p>\n\n<p>ChatGPT extraction could also serve well as an exploratory tool or a lead generator, in use cases where mistakes and missing values are tolerable, or speculative situations where you want to get a taste of the data before sinking weeks into a real cleanup and&nbsp;analysis.</p>\n\n<h2>Try it&nbsp;yourself</h2>\n\n<p>I made my ChatGPT extractor script <a href=\"https://github.com/brandonrobertz/chatgpt-document-extraction\">available on GitHub</a>. Maybe you have a troublesome data project and want to try this for yourself. Or maybe you want to see the possibilities and limitations face-to-face. I’m secretly hoping someone will finally crack the <a href=\"https://publicfiles.fcc.gov/\"><span>FCC</span> <span>TV</span> and cable political ad disclosure</a> dataset, closing the chapter <a href=\"https://wandb.ai/deepform/political-ad-extraction/benchmark\">left open</a> since <a href=\"https://projects.propublica.org/free-the-files/\">ProPublica’s Free The Files</a>&nbsp;project.</p>\n\n<p>Either way, I have a feeling we’ll be reporting on and using this technology for some time to come. And the best way to get acquainted with any technology is to use&nbsp;it.</p>\n                \n                \n\n                <!-- /end .links-article-social -->\n            </div></div>","textContent":"\n                I convert a ton of text documents like PDFs to spreadsheets. It’s tedious and expensive work. So every time a new iteration of AI technology arrives, I wonder if it’s capable of doing what so many people ask for: to hand off a PDF, ask for a spreadsheet, and get one back. After throwing a couple programming problems at OpenAI’s ChatGPT and getting a viable result, I wondered if we were finally there.\n\nBack when OpenAI’s GPT-3 was the hot new thing, I saw Montreal journalist Roberto Rocha attempt a similar test. The results were lackluster, but ChatGPT, OpenAI’s newest model, has several improvements that make it better suited to extraction: It’s 10x larger than GPT-3 and is generally more coherent as a result, it’s been trained to explicitly follow instructions, and it understands programming languages.\n\nTo test how well ChatGPT could extract structured data from PDFs, I wrote a Python script (which I’ll share at the end!) to convert two document sets to spreadsheets:\n\n\n\tA 7,000-page PDF of New York data breach notification forms. There were five different forms, bad OCR, and some freeform letters mixed in.\n\t1,400 memos from internal police investigations. These were completely unstructured and contained emails and document scans. Super messy.\n\n\nMy overall strategy was the following:\n\n\n\tRedo the OCR, using the highest quality tools possible. This was critically important because ChatGPT refused to work with poorly OCR’d text.\n\tClean the data as well as I could, maintaining physical layout and removing garbage characters and boilerplate text.\n\tBreak the documents into individual records.\n\tAsk ChatGPT to turn each record into JSON.\n\n\nI spent about a week getting familiarized with both datasets and doing all this preprocessing. Once it’s done, getting ChatGPT to convert a piece of text into JSON is really easy. You can paste in a record and say “return a JSON representation of this” and it will do it. But doing this for multiple records is a bad idea because ChatGPT will invent its own schema, using randomly chosen field names from the text. It will also decide on its own way to parse values. Addresses, for example, will sometimes end up as a string and sometimes as a JSON object or an array, with the constituent parts of an address split up.\n\nPrompt design is the most important factor in getting consistent results, and your language choices make a huge difference. One tip: Figure out what wording ChatGPT uses when referring to a task and mimic that. (If you don’t know, you can always ask: “Explain how you’d _____ using _______.”)\n\nBecause ChatGPT understands code, I designed my prompt around asking for JSON that conforms to a given JSON schema. This was my prompt:\n\n```\nText document goes here, truncated if longer than 4000 chars\n```\n\nFor the given text, can you provide a JSON representation that strictly follows this schema:\n\n```\n{\n      \"type\": \"object\",\n      \"additionalProperties\": false,\n      \"properties\": {\n        \"descriptive name of field here\": { \"type\": \"data type here\" },\n        ...\n      }\n}\n```\n\n\nI tried to extract a JSON object from every response and run some validation checks against it. Two checks were particularly important: 1) making sure the JSON was complete, not truncated or broken, and 2) making sure the keys and values matched the schema. I retried if the validation check failed, and usually I’d get valid JSON back on the second or third attempts. If it continued to fail, I’d make a note of it and skip the record. Some records ChatGPT just doesn’t like.\n\nResults\n\nImpressively, ChatGPT built a mostly usable dataset. At first glance, I even thought I had a perfectly extracted dataset. But once I went through the pages and compared values, I started to notice errors. Some names were misspelled. Some were missing entirely. Some numbers were wrong.\n\n\n    \n    Here’s a video demo of the data extraction I tried for this article.\n\n\nThe errors, although subtle and relatively infrequent, were enough to prevent me from doing the basic analyses that most data journalists want to do. Averages, histograms, mins and maxes were out.\n\nBut for my projects, the mistakes were tolerable. I wanted to find big players in the breach database, so I didn’t care if some of the names were wrong or if some numeric values were off by a zero. For the police data, I was basically looking for a summary to identify certain incidents and the individuals involved. If I missed something, it would be OK.\n\nOverall, these are the types of errors ChatGPT introduced:\n\n\n\tChatGPT hallucinated data, meaning it made things up. Often in subtle and hard-to-detect ways. For example, it turned “2222 Colony Road, Moorcroft” (note the “r”) into “2222 Colony Road, Mooncroft”. The word “Mooncroft” (with an “n”) doesn’t appear anywhere in the text. ChatGPT seemed to be making a connection between the words colony and moon. How quaint.\n\tIt stumbled on people’s names and assumed gender. Some forms had a “salutation” field, which seemed to cause ChatGPT to add salutations (“Miss”, “Mr”) when inappropriate and omit them even when given (“Dr” and “Prof”). It also failed to use the correct name when multiple names appeared in a record, preferring whichever came last.\n\tChatGPT remembered previous prompts, causing mixups. Occasionally it would use a name or a business entity from an earlier record, despite a perfectly valid one appearing in the current record’s text. For example, in one record it used the names of a lawyer and law firm last seen 150 and 30 pages earlier, respectively. This problem forced me to make sure names and entities actually existed in the current record.\n\tWords it thought were typos got “corrected.” Usually this was helpful, but sometimes it introduced an error. This was particularly problematic with email addresses.\n\tErrors were scattered seemingly randomly throughout the data. While certain columns contained more errors than others, all columns had error rates ranging from 1% to upwards of 6%. The errors were scattered across rows, too. Combined, this meant that I’d basically need to compare every row with every record to get a fully valid dataset—the very work I was trying to avoid in the first place.\n\n\nProblems with large language models have been well documented by now. Even with the great advances in ChatGPT, some of them reared their head in my experiments. Attempts to ignore these problems and shovel ChatGPT-derived work directly to readers will inevitably lead to disastrous failures.\n\n\n\n    Sometimes ChatGPT simply refuses to work with a document and gives a boilerplate response. It responded with concerns about “sensitive information” on several documents in both the police memos and the NY data breach datasets, despite them both being public documents.\n\n\nWill ChatGPT revolutionize data journalism?\n\nI don’t think so, for three reasons:\n\n\n\tNo, for technical reasons: Working with ChatGPT via OpenAI’s API is painfully slow. It took nearly three weeks to extract approximately 2,500 records from the data breach PDF alone. This is even more significant considering I started this project before ChatGPT hit the mainstream and was able to use it for two weeks before rate limiting was imposed. The API is also unreliable and exhibits frequent downtime and interruptions, although this may improve in the future.\n\tNo, for economic reasons: With ChatGPT I’m convinced we’re trading one form of manual labor for another. We’re trading programming and transcription for cleaning, fact-checking and validation. Because any row can potentially be incorrect, every field must be checked in order to build confidence. In the end, I’m not convinced we save much work.\n\tNo, for editorial reasons: The problems with data hallucination and other mixups restrict this approach to internal or journalist-facing uses, in my opinion. It’s a better tip generator than story generator. Putting ChatGPT at the end of a journalistic workflow risks exchanging more speed and quantity for less credibility.\n\n\nThe totality of these problems make most uses of ChatGPT editorially impractical, especially at scale. But I think it still has a place. For small, under-resourced newsrooms that need to turn a small PDF into a table, this could be workable (Hey ChatGPT, can you turn this text into an array of JSON objects?).\n\nSome PDFs are also just so messy and non-uniform that writing an extraction script is too time consuming. I’ve had countless projects die due to problems like that. ChatGPT extraction has the potential to breathe life into such projects.\n\nChatGPT extraction could also serve well as an exploratory tool or a lead generator, in use cases where mistakes and missing values are tolerable, or speculative situations where you want to get a taste of the data before sinking weeks into a real cleanup and analysis.\n\nTry it yourself\n\nI made my ChatGPT extractor script available on GitHub. Maybe you have a troublesome data project and want to try this for yourself. Or maybe you want to see the possibilities and limitations face-to-face. I’m secretly hoping someone will finally crack the FCC TV and cable political ad disclosure dataset, closing the chapter left open since ProPublica’s Free The Files project.\n\nEither way, I have a feeling we’ll be reporting on and using this technology for some time to come. And the best way to get acquainted with any technology is to use it.\n                \n                \n\n                \n            ","length":9479,"excerpt":"Scattered errors and hallucinated data make it an exploratory tool, not a shortcut to analysis","byline":"By Brandon Roberts","dir":null,"siteName":null,"lang":"en"},"finalizedMeta":{"title":"I tested how well ChatGPT can pull data out of messy PDFs (and here's a script so you can too)","description":"Scattered errors and hallucinated data make it an exploratory tool, not a shortcut to analysis","author":false,"creator":"","publisher":false,"date":"2023-04-24T14:13:30.444Z","topics":[]},"jsonLd":{"@type":false,"headline":false,"description":false,"image":[],"mainEntityOfPage":{"@type":false,"@id":false},"datePublished":false,"dateModified":false,"isAccessibleForFree":false,"isPartOf":{"@type":[],"name":false,"productID":false},"discussionUrl":false,"license":false,"author":{"@type":false,"name":false,"description":false,"sameAs":false,"image":{"@type":false,"url":false},"givenName":false,"familyName":false,"alternateName":false,"publishingPrinciples":false},"publisher":{"@type":false,"name":false,"description":false,"sameAs":false,"logo":{"@type":false,"url":false},"publishingPrinciples":false},"editor":{"@type":false,"name":false,"description":false,"sameAs":false,"image":{"@type":false,"url":false},"givenName":false,"familyName":false,"alternateName":false,"publishingPrinciples":false}},"twitterObj":false,"status":200,"metadata":{"author":false,"title":"I tested how well ChatGPT can pull data out of messy PDFs (and here's a script so you can too) - Features - Source: An OpenNews project","description":false,"canonical":"https://source.opennews.org/articles/testing-pdf-data-extraction-chatgpt/","keywords":[],"image":"/static/base/_v2/dist/svg/png/logo-source.png","firstParagraph":"Features:"},"dublinCore":{},"opengraph":{"title":"I tested how well ChatGPT can pull data out of messy PDFs (and here's a script so you can too)","description":"Scattered errors and hallucinated data make it an exploratory tool, not a shortcut to analysis","url":"https://source.opennews.org/articles/testing-pdf-data-extraction-chatgpt/","site_name":false,"locale":false,"type":"article","typeObject":{"published_time":false,"modified_time":false,"author":false,"publisher":false,"section":false,"tag":[]},"image":"https://media.opennews.org/cache/55/72/5572c19d70123378f22bc4917cbc0552.jpg"},"twitter":{"site":"","description":"","card":"summary_large_image","creator":false,"title":"","image":"https://media.opennews.org/cache/1b/59/1b59eb4d2a88f06e1c9b5d23c7ed7029.jpg","domain":"","image:alt":"<a href=\"https://www.youtube.com/watch?v=wsSqRv-y1r4\">A video demo</a> of the data extraction process for this experiment.","url":""},"archivedData":{"link":false,"wayback":false}}}