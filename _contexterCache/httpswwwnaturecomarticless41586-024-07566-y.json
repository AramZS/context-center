{"initialLink":"https://www.nature.com/articles/s41586-024-07566-y","sanitizedLink":"https://www.nature.com/articles/s41586-024-07566-y","finalLink":"https://www.nature.com/articles/s41586-024-07566-y","htmlEmbed":"<script>window.contexterSetup=window.contexterSetup||function(){window.contexterSetupComplete=!0;class ContexterLink extends HTMLAnchorElement{constructor(){super()}connectedCallback(){this.setAttribute(\"target\",\"_blank\")}}customElements.define(\"contexter-link\",ContexterLink,{extends:\"a\"}),customElements.define(\"contexter-inner\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__inner\"}}),customElements.define(\"contexter-thumbnail\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__thumbnail\"}}),customElements.define(\"contexter-byline\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__byline\"}}),customElements.define(\"contexter-keywordset\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__keywordset\"}}),customElements.define(\"contexter-linkset\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__linkset\"}}),customElements.define(\"contexter-meta\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__meta\"}}),customElements.define(\"contexter-summary\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"p-summary entry-summary\"}}),customElements.define(\"contexter-box-head\",class extends HTMLElement{constructor(){super()}connectedCallback(){this.className=\"contexter-box__head\"}}),customElements.define(\"contexter-box-inner\",class extends HTMLElement{constructor(){super()}connectedCallback(){}});class ContexterBox extends HTMLElement{constructor(){super(),this.first=!0,this.shadow=this.attachShadow({mode:\"open\"})}connectedCallback(){if(this.first){this.first=!1;var style=document.createElement(\"style\"),lightDomStyle=(style.innerHTML=`:host {--background: #f5f6f7;--border: darkblue;--blue: #0000ee;--font-color: black;--inner-border: black;font-family: Franklin,Arial,Helvetica,sans-serif;font-size: 14px;background: var(--background);width: 600px;color: var(--font-color);min-height: 90px;display: block;padding: 8px;border: 1px solid var(--border);cursor: pointer;box-sizing: border-box;margin: 6px;contain: content;margin: 6px auto;}// can only select top-level nodes with slotted::slotted(*) {max-width: 100%;display:block;}::slotted([slot=thumbnail]) {max-width: 100%;display:block;}::slotted([slot=header]) {width: 100%;font-size: 1.25rem;font-weight: bold;display:block;margin-bottom: 6px;}::slotted([slot=author]) {max-width: 50%;font-size: 12px;display:inline-block;float: left;}::slotted([slot=time]) {max-width: 50%;font-size: 12px;display:inline-block;float: right;}::slotted([slot=summary]) {width: 100%;margin-top: 6px;padding: 10px 2px;border-top: 1px solid var(--inner-border);font-size: 15px;display:inline-block;margin-bottom: 6px;}contexter-meta {height: auto;margin-bottom: 4px;width: 100%;display: grid;position: relative;min-height: 16px;grid-template-columns: repeat(2, 1fr);}::slotted([slot=keywords]) {width: 80%;padding: 2px 4px;border-top: 1px solid var(--inner-border);font-size: 11px;display: block;float: right;font-style: italic;text-align: right;grid-column: 2/2;grid-row: 1;align-self: end;justify-self: end;}::slotted([slot=keywords]):empty {border-top: 0px solid var(--inner-border);}::slotted([slot=archive-link]) {font-size: 1em;display: inline;}::slotted([slot=archive-link])::after {content: \"|\";display: inline;color: var(--font-color);text-decoration: none;margin: 0 .5em;}::slotted([slot=read-link]) {font-size: 1em;display: inline;}contexter-linkset {width: 80%;padding: 2px 4px;font-size: 13px;float: left;font-weight: bold;grid-row: 1;grid-column: 1/2;align-self: end;justify-self: start;}/* Extra small devices (phones, 600px and down) */@media only screen and (max-width: 600px) {:host {width: 310px;}}/* Small devices (portrait tablets and large phones, 600px and up) */@media only screen and (min-width: 600px) {...}/* Medium devices (landscape tablets, 768px and up) */@media only screen and (min-width: 768px) {...}/* Large devices (laptops/desktops, 992px and up) */@media only screen and (min-width: 992px) {...}/* Extra large devices (large laptops and desktops, 1200px and up) */@media only screen and (min-width: 1200px) {...}@media (prefers-color-scheme: dark){:host {--background: #354150;--border: #1f2b37;--blue: #55b0ff;--font-color: #ffffff;--inner-border: #787a7c;background: var(--background);border: 1px solid var(--border)}}`,document.createElement(\"style\"));lightDomStyle.innerHTML=`contexter-box {contain: content;}contexter-box .read-link {font-weight: bold;}contexter-box a {color: #0000ee;}contexter-box img {width: 100%;border: 0;padding: 0;margin: 0;}/* Extra small devices (phones, 600px and down) */@media only screen and (max-width: 600px) {...}/* Small devices (portrait tablets and large phones, 600px and up) */@media only screen and (min-width: 600px) {...}/* Medium devices (landscape tablets, 768px and up) */@media only screen and (min-width: 768px) {...}/* Large devices (laptops/desktops, 992px and up) */@media only screen and (min-width: 992px) {...}/* Extra large devices (large laptops and desktops, 1200px and up) */@media only screen and (min-width: 1200px) {...}@media (prefers-color-scheme: dark){contexter-box a {color: #55b0ff;}}`,this.appendChild(lightDomStyle),this.shadow.appendChild(style);const innerContainer=document.createElement(\"contexter-box-inner\"),innerSlotThumbnail=(this.shadow.appendChild(innerContainer),document.createElement(\"slot\")),innerSlotHeader=(innerSlotThumbnail.name=\"thumbnail\",innerContainer.appendChild(innerSlotThumbnail),document.createElement(\"slot\")),innerSlotAuthor=(innerSlotHeader.name=\"header\",innerContainer.appendChild(innerSlotHeader),document.createElement(\"slot\")),innerSlotTime=(innerSlotAuthor.name=\"author\",innerContainer.appendChild(innerSlotAuthor),document.createElement(\"slot\")),innerSlotSummary=(innerSlotTime.name=\"time\",innerContainer.appendChild(innerSlotTime),document.createElement(\"slot\")),metaContainer=(innerSlotSummary.name=\"summary\",innerContainer.appendChild(innerSlotSummary),document.createElement(\"contexter-meta\")),innerSlotInfo=(innerContainer.appendChild(metaContainer),document.createElement(\"slot\")),linkContainer=(innerSlotInfo.name=\"keywords\",metaContainer.appendChild(innerSlotInfo),document.createElement(\"contexter-linkset\")),innerSlotArchiveLink=(metaContainer.appendChild(linkContainer),document.createElement(\"slot\")),innerSlotReadLink=(innerSlotArchiveLink.name=\"archive-link\",linkContainer.appendChild(innerSlotArchiveLink),document.createElement(\"slot\"));innerSlotReadLink.name=\"read-link\",linkContainer.appendChild(innerSlotReadLink),this.className=\"contexter-box\",this.onclick=e=>{if(!e.target.className.includes(\"read-link\")&&!e.target.className.includes(\"title-link\")){const mainLinks=this.querySelectorAll(\"a.main-link\");mainLinks[0].click()}}}}}customElements.define(\"contexter-box\",ContexterBox)},window.contexterSetupComplete||window.contexterSetup();</script><contexter-box class=\"link-card h-entry hentry\" itemscope=\"\" itemtype=\"https://schema.org/CreativeWork\"><contexter-thumbnail class=\"thumbnail\" slot=\"thumbnail\"></contexter-thumbnail><contexter-box-head slot=\"header\" class=\"p-name entry-title\" itemprop=\"headline\"><contexter-box-head slot=\"header\" class=\"p-name entry-title\" itemprop=\"headline\"><a is=\"contexter-link\" href=\"https://www.nature.com/articles/s41586-024-07566-y\" itemprop=\"url\">AI models collapse when trained on recursively generated data - Nature</a></contexter-box-head></contexter-box-head><time class=\"dt-published published\" slot=\"time\" itemprop=\"datePublished\" datetime=\"2024-10-09T18:55:14.863Z\">10/9/2024</time><contexter-summary class=\"p-summary entry-summary\" itemprop=\"abstract\" slot=\"summary\"><p>&nbsp;Analysis shows that indiscriminately training generative artificial intelligence on real and generated content, usually done by scraping data from&nbsp;the Internet, can lead to a collapse in the ability of the models to generate diverse high-quality output.</p></contexter-summary><contexter-keywordset itemprop=\"keywords\" slot=\"keywords\"></contexter-keywordset><a is=\"contexter-link\" href=\"https://www.nature.com/articles/s41586-024-07566-y\" class=\"read-link main-link\" itemprop=\"sameAs\" slot=\"read-link\">Read</a></contexter-box>","linkId":"cc8942718b61c4fe579da957e579080edd54d02c","data":{"originalLink":"https://www.nature.com/articles/s41586-024-07566-y","sanitizedLink":"https://www.nature.com/articles/s41586-024-07566-y","canonical":"https://www.nature.com/articles/s41586-024-07566-y","htmlText":"<!DOCTYPE html>\n<html lang=\"en\" class=\"grade-c\">\n<head>\n    <title>AI models collapse when trained on recursively generated data | Nature</title>\n    \n        \n<link rel=\"alternate\" type=\"application/rss+xml\" href=\"https://www.nature.com/nature.rss\"/>\n\n\n    \n        \n\n        <script id=\"save-data-connection-testing\">\n            function hasConnection() {\n                return navigator.connection || navigator.mozConnection || navigator.webkitConnection || navigator.msConnection;\n            }\n\n            function createLink(src) {\n                var preloadLink = document.createElement(\"link\");\n                preloadLink.rel = \"preload\";\n                preloadLink.href = src;\n                preloadLink.as = \"font\";\n                preloadLink.type = \"font/woff2\";\n                preloadLink.crossOrigin = \"\";\n                document.head.insertBefore(preloadLink, document.head.firstChild);\n            }\n\n            var connectionDetail = {\n                saveDataEnabled: false,\n                slowConnection: false\n            };\n\n            var connection = hasConnection();\n            if (connection) {\n                connectionDetail.saveDataEnabled = connection.saveData;\n                if (/\\slow-2g|2g/.test(connection.effectiveType)) {\n                    connectionDetail.slowConnection = true;\n                }\n            }\n\n            if (!(connectionDetail.saveDataEnabled || connectionDetail.slowConnection)) {\n                createLink(\"/static/fonts/HardingText-Regular-Web-cecd90984f.woff2\");\n            } else {\n                document.documentElement.classList.add('save-data');\n            }\n        </script>\n    \n\n<link rel=\"preconnect\" href=\"https://cmp.nature.com\" crossorigin>\n\n<meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n<meta name=\"applicable-device\" content=\"pc,mobile\">\n<meta name=\"viewport\" content=\"width=device-width,initial-scale=1.0,maximum-scale=5,user-scalable=yes\">\n<meta name=\"360-site-verification\" content=\"5a2dc4ab3fcb9b0393241ffbbb490480\" />\n\n<script data-test=\"dataLayer\">\n    window.dataLayer = [{\"content\":{\"category\":{\"contentType\":\"article\",\"legacy\":{\"webtrendsPrimaryArticleType\":\"research\",\"webtrendsSubjectTerms\":\"computational-science;computer-science\",\"webtrendsContentCategory\":null,\"webtrendsContentCollection\":null,\"webtrendsContentGroup\":\"Nature\",\"webtrendsContentGroupType\":null,\"webtrendsContentSubGroup\":\"Article\",\"status\":null}},\"article\":{\"doi\":\"10.1038/s41586-024-07566-y\"},\"attributes\":{\"cms\":null,\"deliveryPlatform\":\"oscar\",\"copyright\":{\"open\":true,\"legacy\":{\"webtrendsLicenceType\":\"http://creativecommons.org/licenses/by/4.0/\"}}},\"contentInfo\":{\"authors\":[\"Ilia Shumailov\",\"Zakhar Shumaylov\",\"Yiren Zhao\",\"Nicolas Papernot\",\"Ross Anderson\",\"Yarin Gal\"],\"publishedAt\":1721779200,\"publishedAtString\":\"2024-07-24\",\"title\":\"AI models collapse when trained on recursively generated data\",\"legacy\":null,\"publishedAtTime\":null,\"documentType\":\"aplusplus\",\"subjects\":\"Computational science,Computer science\"},\"journal\":{\"pcode\":\"nature\",\"title\":\"nature\",\"volume\":\"631\",\"issue\":\"8022\",\"id\":41586,\"publishingModel\":\"Hybrid Access\"},\"authorization\":{\"status\":true},\"features\":[{\"name\":\"furtherReadingSection\",\"present\":true}],\"collection\":null},\"page\":{\"category\":{\"pageType\":\"article\"},\"attributes\":{\"template\":\"mosaic\",\"featureFlags\":[{\"name\":\"nature-onwards-journey\",\"active\":false}],\"testGroup\":null},\"search\":null},\"privacy\":{},\"version\":\"1.0.0\",\"product\":null,\"session\":null,\"user\":null,\"backHalfContent\":true,\"country\":\"US\",\"hasBody\":true,\"uneditedManuscript\":false,\"twitterId\":[\"o3xnx\",\"o43y9\",\"o3ef7\"],\"baiduId\":\"d38bce82bcb44717ccc29a90c4b781ea\",\"japan\":false}];\n    window.dataLayer.push({\n        ga4MeasurementId: 'G-ERRNTNZ807',\n        ga360TrackingId: 'UA-71668177-1',\n        twitterId: ['3xnx', 'o43y9', 'o3ef7'],\n        baiduId: 'd38bce82bcb44717ccc29a90c4b781ea',\n        ga4ServerUrl: 'https://collect.nature.com',\n        imprint: 'nature'\n    });\n</script>\n\n<script>\n    (function(w, d) {\n        w.config = w.config || {};\n        w.config.mustardcut = false;\n\n        \n        if (w.matchMedia && w.matchMedia('only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)').matches) {\n            w.config.mustardcut = true;\n            d.classList.add('js');\n            d.classList.remove('grade-c');\n            d.classList.remove('no-js');\n        }\n    })(window, document.documentElement);\n</script>\n \n\n\n\n     \n    \n    \n        \n    \n    <style>@media only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark) {  .c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card--major .c-card__title,.c-card__title,.u-h2,.u-h3,h2,h3{-webkit-font-smoothing:antialiased;font-family:Harding,Palatino,serif;font-weight:700;letter-spacing:-.0117156rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card__title,.u-h3,h3{font-size:1.25rem;line-height:1.4rem}.c-reading-companion__figure-title,.u-h4,h4{-webkit-font-smoothing:antialiased;font-weight:700;line-height:1.4rem}html{text-size-adjust:100%;box-sizing:border-box;font-size:100%;height:100%;line-height:1.15;overflow-y:scroll}body{background:#eee;color:#222;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;line-height:1.76;margin:0;min-height:100%}details,main{display:block}h1{font-size:2em;margin:.67em 0}a,sup{vertical-align:baseline}a{background-color:transparent;color:#069;overflow-wrap:break-word;text-decoration:underline;text-decoration-skip-ink:auto;word-break:break-word}b{font-weight:bolder}sup{font-size:75%;line-height:0;position:relative;top:-.5em}img{border:0;height:auto;max-width:100%;vertical-align:middle}button,input,select{font-family:inherit;font-size:100%;line-height:1.15;margin:0}button,input{overflow:visible}button,select{text-transform:none}[type=submit],button{-webkit-appearance:button}[type=checkbox]{box-sizing:border-box;padding:0}summary{display:list-item}[hidden]{display:none}button{border-radius:0;cursor:pointer;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}h1{-webkit-font-smoothing:antialiased;font-family:Harding,Palatino,serif;font-size:2rem;font-weight:700;letter-spacing:-.0390625rem;line-height:2.25rem}.c-card--major .c-card__title,.u-h2,.u-h3,h2{font-family:Harding,Palatino,serif;letter-spacing:-.0117156rem}.c-card--major .c-card__title,.u-h2,h2{-webkit-font-smoothing:antialiased;font-size:1.5rem;font-weight:700;line-height:1.6rem}.u-h3{font-size:1.25rem}.c-card__title,.c-reading-companion__figure-title,.u-h3,.u-h4,h4,h5,h6{-webkit-font-smoothing:antialiased;font-weight:700;line-height:1.4rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,.c-card__title,h3{font-family:Harding,Palatino,serif;font-size:1.25rem}.c-article-editorial-summary__container .c-article-editorial-summary__article-title,h3{-webkit-font-smoothing:antialiased;font-weight:700;letter-spacing:-.0117156rem;line-height:1.4rem}.c-reading-companion__figure-title,.u-h4,h4{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.125rem;letter-spacing:-.0117156rem}button:focus{outline:3px solid #fece3e;will-change:transform}input+label{padding-left:.5em}nav ol,nav ul{list-style:none none}p:empty{display:none}.sans-serif{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.article-page{background:#fff}.c-article-header{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;margin-bottom:40px}.c-article-identifiers{color:#6f6f6f;display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3;list-style:none;margin:0 0 8px;padding:0}.c-article-identifiers__item{border-right:1px solid #6f6f6f;list-style:none;margin-right:8px;padding-right:8px}.c-article-identifiers__item:last-child{border-right:0;margin-right:0;padding-right:0}.c-article-title{font-size:1.5rem;line-height:1.25;margin:0 0 16px}@media only screen and (min-width:768px){.c-article-title{font-size:1.875rem;line-height:1.2}}.c-article-author-list{display:inline;font-size:1rem;list-style:none;margin:0 8px 0 0;padding:0;width:100%}.c-article-author-list__item{display:inline;padding-right:0}.c-article-author-list svg{margin-left:4px}.c-article-author-list__show-more{display:none;margin-right:4px}.c-article-author-list__button,.js .c-article-author-list__item--hide,.js .c-article-author-list__show-more{display:none}.js .c-article-author-list--long .c-article-author-list__show-more,.js .c-article-author-list--long+.c-article-author-list__button{display:inline}@media only screen and (max-width:539px){.js .c-article-author-list__item--hide-small-screen{display:none}.js .c-article-author-list--short .c-article-author-list__show-more,.js .c-article-author-list--short+.c-article-author-list__button{display:inline}}#uptodate-client,.js .c-article-author-list--expanded .c-article-author-list__show-more{display:none!important}.js .c-article-author-list--expanded .c-article-author-list__item--hide-small-screen{display:inline!important}.c-article-author-list__button,.c-button-author-list{background:#ebf1f5;border:4px solid #ebf1f5;border-radius:20px;color:#666;font-size:.875rem;line-height:1.4;padding:2px 11px 2px 8px;text-decoration:none}.c-article-author-list__button svg,.c-button-author-list svg{margin:1px 4px 0 0}.c-article-author-list__button:hover,.c-button-author-list:hover{background:#069;border-color:transparent;color:#fff}.c-article-info-details{font-size:1rem;margin-bottom:8px;margin-top:16px}.c-article-info-details__cite-as{border-left:1px solid #6f6f6f;margin-left:8px;padding-left:8px}.c-article-metrics-bar{display:flex;flex-wrap:wrap;font-size:1rem;line-height:1.3}.c-article-metrics-bar__wrapper{margin:16px 0}.c-article-metrics-bar__item{align-items:baseline;border-right:1px solid #6f6f6f;margin-right:8px}.c-article-metrics-bar__item:last-child{border-right:0}.c-article-metrics-bar__count{font-weight:700;margin:0}.c-article-metrics-bar__label{color:#626262;font-style:normal;font-weight:400;margin:0 10px 0 5px}.c-article-metrics-bar__details{margin:0}.c-article-main-column{font-family:Harding,Palatino,serif;margin-right:8.6%;width:60.2%}@media only screen and (max-width:1023px){.c-article-main-column{margin-right:0;width:100%}}.c-article-extras{float:left;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;width:31.2%}@media only screen and (max-width:1023px){.c-article-extras{display:none}}.c-article-associated-content__container .c-article-associated-content__title,.c-article-section__title{border-bottom:2px solid #d5d5d5;font-size:1.25rem;margin:0;padding-bottom:8px}@media only screen and (min-width:768px){.c-article-associated-content__container .c-article-associated-content__title,.c-article-section__title{font-size:1.5rem;line-height:1.24}}.c-article-associated-content__container .c-article-associated-content__title{margin-bottom:8px}.c-article-body p{margin-bottom:24px;margin-top:0}.c-article-section{clear:both}.c-article-section__content{margin-bottom:40px;padding-top:8px}@media only screen and (max-width:1023px){.c-article-section__content{padding-left:0}}.c-article-authors-search{margin-bottom:24px;margin-top:0}.c-article-authors-search__item,.c-article-authors-search__title{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.c-article-authors-search__title{color:#626262;font-size:1.05rem;font-weight:700;margin:0;padding:0}.c-article-authors-search__item{font-size:1rem}.c-article-authors-search__text{margin:0}.c-article-license__badge,c-card__section{margin-top:8px}.c-code-block{border:1px solid #eee;font-family:monospace;margin:0 0 24px;padding:20px}.c-code-block__heading{font-weight:400;margin-bottom:16px}.c-code-block__line{display:block;overflow-wrap:break-word;white-space:pre-wrap}.c-article-share-box__no-sharelink-info{font-size:.813rem;font-weight:700;margin-bottom:24px;padding-top:4px}.c-article-share-box__only-read-input{border:1px solid #d5d5d5;box-sizing:content-box;display:inline-block;font-size:.875rem;font-weight:700;height:24px;margin-bottom:8px;padding:8px 10px}.c-article-share-box__button--link-like{background-color:transparent;border:0;color:#069;cursor:pointer;font-size:.875rem;margin-bottom:8px;margin-left:10px}.c-article-editorial-summary__container{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem}.c-article-editorial-summary__container .c-article-editorial-summary__content p:last-child{margin-bottom:0}.c-article-editorial-summary__container .c-article-editorial-summary__content--less{max-height:9.5rem;overflow:hidden}.c-article-editorial-summary__container .c-article-editorial-summary__button{background-color:#fff;border:0;color:#069;font-size:.875rem;margin-bottom:16px}.c-article-editorial-summary__container .c-article-editorial-summary__button.active,.c-article-editorial-summary__container .c-article-editorial-summary__button.hover,.c-article-editorial-summary__container .c-article-editorial-summary__button:active,.c-article-editorial-summary__container .c-article-editorial-summary__button:hover{text-decoration:underline;text-decoration-skip-ink:auto}.c-article-associated-content__container .c-article-associated-content__collection-label{font-size:.875rem;line-height:1.4}.c-article-associated-content__container .c-article-associated-content__collection-title{line-height:1.3}.c-context-bar{box-shadow:0 0 10px 0 rgba(51,51,51,.2);position:relative;width:100%}.c-context-bar__title{display:none}.c-reading-companion{clear:both;min-height:389px}.c-reading-companion__sticky{max-width:389px}.c-reading-companion__scroll-pane{margin:0;min-height:200px;overflow:hidden auto}.c-reading-companion__tabs{display:flex;flex-flow:row nowrap;font-size:1rem;list-style:none;margin:0 0 8px;padding:0}.c-reading-companion__tabs>li{flex-grow:1}.c-reading-companion__tab{background-color:#eee;border:1px solid #d5d5d5;border-image:initial;border-left-width:0;color:#069;font-size:1rem;padding:8px 8px 8px 15px;text-align:left;width:100%}.c-reading-companion__tabs li:first-child .c-reading-companion__tab{border-left-width:1px}.c-reading-companion__tab--active{background-color:#fff;border-bottom:1px solid #fff;color:#222;font-weight:700}.c-reading-companion__sections-list{list-style:none;padding:0}.c-reading-companion__figures-list,.c-reading-companion__references-list{list-style:none;min-height:389px;padding:0}.c-reading-companion__references-list--numeric{list-style:decimal inside}.c-reading-companion__sections-list{margin:0 0 8px;min-height:50px}.c-reading-companion__section-item{font-size:1rem;padding:0}.c-reading-companion__section-item a{display:block;line-height:1.5;overflow:hidden;padding:8px 0 8px 16px;text-overflow:ellipsis;white-space:nowrap}.c-reading-companion__figure-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:16px 8px 16px 0}.c-reading-companion__figure-item:first-child{border-top:none;padding-top:8px}.c-reading-companion__reference-item{border-top:1px solid #d5d5d5;font-size:1rem;padding:8px 8px 8px 16px}.c-reading-companion__reference-item:first-child{border-top:none}.c-reading-companion__reference-item a{word-break:break-word}.c-reading-companion__reference-citation{display:inline}.c-reading-companion__reference-links{font-size:.813rem;font-weight:700;list-style:none;margin:8px 0 0;padding:0;text-align:right}.c-reading-companion__reference-links>a{display:inline-block;padding-left:8px}.c-reading-companion__reference-links>a:first-child{display:inline-block;padding-left:0}.c-reading-companion__figure-title{display:block;margin:0 0 8px}.c-reading-companion__figure-links{display:flex;justify-content:space-between;margin:8px 0 0}.c-reading-companion__figure-links>a{align-items:center;display:flex}.c-reading-companion__figure-full-link svg{height:.8em;margin-left:2px}.c-reading-companion__panel{border-top:none;display:none;margin-top:0;padding-top:0}.c-cod,.c-reading-companion__panel--active{display:block}.c-cod{font-size:1rem;width:100%}.c-cod__form{background:#ebf0f3}.c-cod__prompt{font-size:1.125rem;line-height:1.3;margin:0 0 24px}.c-cod__label{display:block;margin:0 0 4px}.c-cod__row{display:flex;margin:0 0 16px}.c-cod__row:last-child{margin:0}.c-cod__input{border:1px solid #d5d5d5;border-radius:2px;flex-basis:75%;flex-shrink:0;margin:0;padding:13px}.c-cod__input--submit{background-color:#069;border:1px solid #069;color:#fff;flex-shrink:1;margin-left:8px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-cod__input--submit-single{flex-basis:100%;flex-shrink:0;margin:0}.c-cod__input--submit:focus,.c-cod__input--submit:hover{background-color:#fff;color:#069}.c-pdf-download__link .u-icon{padding-top:2px}.c-pdf-download{display:flex;margin-bottom:16px;max-height:48px}@media only screen and (min-width:540px){.c-pdf-download{max-height:none}}@media only screen and (min-width:1024px){.c-pdf-download{max-height:48px}}.c-pdf-download__link{display:flex;flex:1 1 0%}.c-pdf-download__link:hover{text-decoration:none}.c-pdf-download__text{padding-right:4px}@media only screen and (max-width:539px){.c-pdf-download__text{text-transform:capitalize}}@media only screen and (min-width:540px){.c-pdf-download__text{padding-right:8px}}.c-context-bar--sticky .c-pdf-download{display:block;margin-bottom:0;white-space:nowrap}@media only screen and (max-width:539px){.c-pdf-download .u-sticky-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}}.c-pdf-container{display:flex;justify-content:flex-end}@media only screen and (max-width:539px){.c-pdf-container .c-pdf-download{display:flex;flex-basis:100%}}.c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:16px}.c-article-extras .c-pdf-container .c-pdf-download{width:100%}.c-article-extras .c-pdf-container .c-pdf-download+.c-pdf-download{margin-left:0}@media only screen and (min-width:540px){.c-context-bar--sticky .c-pdf-download__link{align-items:center;flex:1 1 183px}}@media only screen and (max-width:320px){.c-context-bar--sticky .c-pdf-download__link{padding:16px}}.article-page--commercial .c-article-main-column .c-pdf-button__container .c-pdf-download{display:none}@media only screen and (max-width:1023px){.article-page--commercial .c-article-main-column .c-pdf-button__container .c-pdf-download{display:block}}.c-status-message--success{border-bottom:2px solid #00b8b0;justify-content:center;margin-bottom:16px;padding-bottom:8px}.c-recommendations-list__item .c-card{flex-basis:100%}.c-recommendations-list__item .c-card__image{align-items:baseline;flex:1 1 40%;margin:0 0 0 16px;max-width:150px}.c-recommendations-list__item .c-card__image img{border:1px solid #cedbe0;height:auto;min-height:0;position:static}@media only screen and (max-width:1023px){.c-recommendations-list__item .c-card__image{display:none}}.c-card__layout{display:flex;flex:1 1 auto;justify-content:space-between}.c-card__title-recommendation{-webkit-box-orient:vertical;-webkit-line-clamp:4;display:-webkit-box;font-size:1rem;font-weight:700;line-height:1.4;margin:0 0 8px;max-height:5.6em;overflow:hidden!important;text-overflow:ellipsis}.c-card__title-recommendation .c-card__link{color:inherit}.c-card__title-recommendation .c-card__link:hover{text-decoration:underline}.c-card__title-recommendation .MathJax_Display{display:inline!important}.c-card__link:not(.c-card__link--no-block-link):before{z-index:1}.c-article-metrics__heading a,.c-article-metrics__posts .c-card__title a,.c-article-recommendations-card__link{color:inherit}.c-recommendations-column-switch .c-meta{margin-top:auto}.c-article-recommendations-card__meta-type,.c-meta .c-meta__item:first-child{font-weight:700}.c-article-body .c-article-recommendations-card__authors{display:none;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.5;margin:0 0 8px}@media only screen and (max-width:539px){.c-article-body .c-article-recommendations-card__authors{display:block;margin:0}}.c-article-metrics__posts .c-card__title{font-size:1.05rem}.c-article-metrics__posts .c-card__title+span{color:#6f6f6f;font-size:1rem}p{overflow-wrap:break-word;word-break:break-word}.c-ad{text-align:center}@media only screen and (min-width:320px){.c-ad{padding:8px}}.c-ad--728x90{background-color:#ccc;display:none}.c-ad--728x90 .c-ad__inner{min-height:calc(1.5em + 94px)}@media only screen and (min-width:768px){.js .c-ad--728x90{display:none}}.c-ad__label{color:#333;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;font-weight:400;line-height:1.5;margin-bottom:4px}.c-author-list{color:#6f6f6f;font-family:inherit;font-size:1rem;line-height:inherit;list-style:none;margin:0;padding:0}.c-author-list>li,.c-breadcrumbs>li,.c-footer__links>li,.js .c-author-list,.u-list-comma-separated>li,.u-list-inline>li{display:inline}.c-author-list>li:not(:first-child):not(:last-child):before{content:\", \"}.c-author-list>li:not(:only-child):last-child:before{content:\" & \"}.c-author-list--compact{font-size:.875rem;line-height:1.4}.c-author-list--truncated>li:not(:only-child):last-child:before{content:\" ... \"}.js .c-author-list__hide{display:none;visibility:hidden}.js .c-author-list__hide:first-child+*{margin-block-start:0}.c-meta{color:inherit;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.4;list-style:none;margin:0;padding:0}.c-meta--large{font-size:1rem}.c-meta--large .c-meta__item{margin-bottom:8px}.c-meta__item{display:inline-block;margin-bottom:4px}.c-meta__item:not(:last-child){border-right:1px solid #d5d5d5;margin-right:4px;padding-right:4px}@media only screen and (max-width:539px){.c-meta__item--block-sm-max{display:block}.c-meta__item--block-sm-max:not(:last-child){border-right:none;margin-right:0;padding-right:0}}@media only screen and (min-width:1024px){.c-meta__item--block-at-lg{display:block}.c-meta__item--block-at-lg:not(:last-child){border-right:none;margin-right:0;padding-right:0}}.c-meta__type{font-weight:700;text-transform:none}.c-skip-link{background:#069;bottom:auto;color:#fff;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;padding:8px;position:absolute;text-align:center;transform:translateY(-100%);z-index:9999}@media (prefers-reduced-motion:reduce){.c-skip-link{transition:top .3s ease-in-out 0s}}@media print{.c-skip-link{display:none}}.c-skip-link:link{color:#fff}.c-status-message{align-items:center;box-sizing:border-box;display:flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;position:relative;width:100%}.c-card__summary>p:last-child,.c-status-message :last-child{margin-bottom:0}.c-status-message--boxed{background-color:#fff;border:1px solid #eee;border-radius:2px;line-height:1.4;padding:16px}.c-status-message__heading{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;font-weight:700}.c-status-message__icon{fill:currentcolor;display:inline-block;flex:0 0 auto;height:1.5em;margin-right:8px;transform:translate(0);vertical-align:text-top;width:1.5em}.c-status-message__icon--top{align-self:flex-start}.c-status-message--info .c-status-message__icon{color:#003f8d}.c-status-message--boxed.c-status-message--info{border-bottom:4px solid #003f8d}.c-status-message--error .c-status-message__icon{color:#c40606}.c-status-message--boxed.c-status-message--error{border-bottom:4px solid #c40606}.c-status-message--success .c-status-message__icon{color:#00b8b0}.c-status-message--boxed.c-status-message--success{border-bottom:4px solid #00b8b0}.c-status-message--warning .c-status-message__icon{color:#edbc53}.c-status-message--boxed.c-status-message--warning{border-bottom:4px solid #edbc53}.c-breadcrumbs{color:#000;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1rem;list-style:none;margin:0;padding:0}.c-breadcrumbs__link{color:#666}svg.c-breadcrumbs__chevron{fill:#888;height:10px;margin:4px 4px 0;width:10px}@media only screen and (max-width:539px){.c-breadcrumbs .c-breadcrumbs__item{display:none}.c-breadcrumbs .c-breadcrumbs__item:last-child,.c-breadcrumbs .c-breadcrumbs__item:nth-last-child(2){display:inline}}.c-card{background-color:transparent;border:0;box-shadow:none;display:flex;flex-direction:column;font-size:14px;min-width:0;overflow:hidden;padding:0;position:relative}.c-card--no-shape{background:0 0;border:0;box-shadow:none}.c-card__image{display:flex;justify-content:center;overflow:hidden;padding-bottom:56.25%;position:relative}@supports (aspect-ratio:1/1){.c-card__image{padding-bottom:0}}.c-card__image img{left:0;min-height:100%;min-width:100%;position:absolute}@supports ((-o-object-fit:cover) or (object-fit:cover)){.c-card__image img{height:100%;object-fit:cover;width:100%}}.c-card__body{flex:1 1 auto;padding:16px}.c-card--no-shape .c-card__body{padding:0}.c-card--no-shape .c-card__body:not(:first-child){padding-top:16px}.c-card__title{letter-spacing:-.01875rem;margin-bottom:8px;margin-top:0}[lang=de] .c-card__title{hyphens:auto}.c-card__summary{line-height:1.4}.c-card__summary>p{margin-bottom:5px}.c-card__summary a{text-decoration:underline}.c-card__link:not(.c-card__link--no-block-link):before{bottom:0;content:\"\";left:0;position:absolute;right:0;top:0}.c-card--flush .c-card__body{padding:0}.c-card--major{font-size:1rem}.c-card--dark{background-color:#29303c;border-width:0;color:#e3e4e5}.c-card--dark .c-card__title{color:#fff}.c-card--dark .c-card__link,.c-card--dark .c-card__summary a{color:inherit}.c-header{background-color:#fff;border-bottom:5px solid #000;font-size:1rem;line-height:1.4;margin-bottom:16px}.c-header__row{padding:0;position:relative}.c-header__row:not(:last-child){border-bottom:1px solid #eee}.c-header__split{align-items:center;display:flex;justify-content:space-between}.c-header__logo-container{flex:1 1 0px;line-height:0;margin:8px 24px 8px 0}.c-header__logo{transform:translateZ(0)}.c-header__logo img{max-height:32px}.c-header__container{margin:0 auto;max-width:1280px}.c-header__menu{align-items:center;display:flex;flex:0 1 auto;flex-wrap:wrap;font-weight:700;gap:8px 8px;line-height:1.4;list-style:none;margin:0 -8px;padding:0}@media print{.c-header__menu{display:none}}@media only screen and (max-width:1023px){.c-header__menu--hide-lg-max{display:none;visibility:hidden}}.c-header__menu--global{font-weight:400;justify-content:flex-end}.c-header__menu--global svg{display:none;visibility:hidden}.c-header__menu--global svg:first-child+*{margin-block-start:0}@media only screen and (min-width:540px){.c-header__menu--global svg{display:block;visibility:visible}}.c-header__menu--journal{font-size:.875rem;margin:8px 0 8px -8px}@media only screen and (min-width:540px){.c-header__menu--journal{flex-wrap:nowrap;font-size:1rem}}.c-header__item{padding-bottom:0;padding-top:0;position:static}.c-header__item--pipe{border-left:2px solid #eee;padding-left:8px}.c-header__item--padding{padding-bottom:8px;padding-top:8px}@media only screen and (min-width:540px){.c-header__item--dropdown-menu{position:relative}}@media only screen and (min-width:1024px){.c-header__item--hide-lg{display:none;visibility:hidden}}@media only screen and (max-width:767px){.c-header__item--hide-md-max{display:none;visibility:hidden}.c-header__item--hide-md-max:first-child+*{margin-block-start:0}}.c-header__link{align-items:center;color:inherit;display:inline-flex;gap:4px 4px;padding:8px;white-space:nowrap}.c-header__link svg{transition-duration:.2s}.c-header__show-text{display:none;visibility:hidden}.has-tethered .c-header__heading--js-hide:first-child+*{margin-block-start:0}@media only screen and (min-width:540px){.c-header__show-text{display:inline;visibility:visible}}.c-header__dropdown{background-color:#000;border-bottom:1px solid #2f2f2f;color:#eee;font-size:.875rem;line-height:1.2;padding:16px 0}@media print{.c-header__dropdown{display:none}}.c-header__heading{display:inline-block;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:1.25rem;font-weight:400;line-height:1.4;margin-bottom:8px}.c-header__heading--keyline{border-top:1px solid;border-color:#2f2f2f;margin-top:16px;padding-top:16px;width:100%}.c-header__list{display:flex;flex-wrap:wrap;gap:0 16px;list-style:none;margin:0 -8px}.c-header__flush{margin:0 -8px}.c-header__visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}.c-header__search-form{margin-bottom:8px}.c-header__search-layout{display:flex;flex-wrap:wrap;gap:16px 16px}.c-header__search-layout>:first-child{flex:999 1 auto}.c-header__search-layout>*{flex:1 1 auto}.c-header__search-layout--max-width{max-width:720px}.c-header__search-button{align-items:center;background-color:transparent;background-image:none;border:1px solid #fff;border-radius:2px;color:#fff;cursor:pointer;display:flex;font-family:sans-serif;font-size:1rem;justify-content:center;line-height:1.15;margin:0;padding:8px 16px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:100%}.u-button svg,.u-button--primary svg{fill:currentcolor}.c-header__input,.c-header__select{border:1px solid;border-radius:3px;box-sizing:border-box;font-size:1rem;padding:8px 16px;width:100%}.c-header__select{-webkit-appearance:none;background-image:url(\"data:image/svg+xml,%3Csvg height='16' viewBox='0 0 16 16' width='16' xmlns='http://www.w3.org/2000/svg'%3E%3Cpath d='m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z' fill='%23333' fill-rule='evenodd' transform='matrix(0 1 -1 0 11 3)'/%3E%3C/svg%3E\");background-position:right .7em top 50%;background-repeat:no-repeat;background-size:1em;box-shadow:0 1px 0 1px rgba(0,0,0,.04);display:block;margin:0;max-width:100%;min-width:150px}@media only screen and (min-width:540px){.c-header__menu--journal .c-header__item--dropdown-menu:last-child .c-header__dropdown.has-tethered{left:auto;right:0}}@media only screen and (min-width:768px){.c-header__menu--journal .c-header__item--dropdown-menu:last-child .c-header__dropdown.has-tethered{left:0;right:auto}}.c-header__dropdown.has-tethered{border-bottom:0;border-radius:0 0 2px 2px;left:0;position:absolute;top:100%;transform:translateY(5px);width:100%;z-index:1}@media only screen and (min-width:540px){.c-header__dropdown.has-tethered{transform:translateY(8px);width:auto}}@media only screen and (min-width:768px){.c-header__dropdown.has-tethered{min-width:225px}}.c-header__dropdown--full-width.has-tethered{padding:32px 0 24px;transform:none;width:100%}.has-tethered .c-header__heading--js-hide{display:none;visibility:hidden}.has-tethered .c-header__list--js-stack{flex-direction:column}.has-tethered .c-header__item--keyline,.has-tethered .c-header__list~.c-header__list .c-header__item:first-child{border-top:1px solid #d5d5d5;margin-top:8px;padding-top:8px}.c-header__item--snid-account-widget{display:flex}.c-header__container{padding:0 4px}.c-header__list{padding:0 12px}.c-header__menu .c-header__link{font-size:14px}.c-header__item--snid-account-widget .c-header__link{padding:8px}.c-header__menu--journal{margin-left:0}@media only screen and (min-width:540px){.c-header__container{padding:0 16px}.c-header__menu--journal{margin-left:-8px}.c-header__menu .c-header__link{font-size:16px}.c-header__link--search{gap:13px 13px}}.u-button{align-items:center;background-color:transparent;background-image:none;border:1px solid #069;border-radius:2px;color:#069;cursor:pointer;display:inline-flex;font-family:sans-serif;font-size:1rem;justify-content:center;line-height:1.3;margin:0;padding:8px;position:relative;text-decoration:none;transition:all .25s ease 0s,color .25s ease 0s,border-color .25s ease 0s;width:auto}.u-button--primary{background-color:#069;background-image:none;border:1px solid #069;color:#fff}.u-button--full-width{display:flex;width:100%}.u-display-none{display:none}.js .u-js-hide,.u-hide{display:none;visibility:hidden}.u-hide:first-child+*{margin-block-start:0}.u-visually-hidden{clip:rect(0,0,0,0);border:0;height:1px;margin:-100%;overflow:hidden;padding:0;position:absolute!important;width:1px}@media print{.u-hide-print{display:none}}@media only screen and (min-width:1024px){.u-hide-at-lg{display:none;visibility:hidden}.u-hide-at-lg:first-child+*{margin-block-start:0}}.u-clearfix:after,.u-clearfix:before{content:\"\";display:table}.u-clearfix:after{clear:both}.u-color-open-access{color:#b74616}.u-float-left{float:left}.u-icon{fill:currentcolor;display:inline-block;height:1em;transform:translate(0);vertical-align:text-top;width:1em}.u-full-height{height:100%}.u-list-reset{list-style:none;margin:0;padding:0}.u-sans-serif{font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif}.u-container{margin:0 auto;max-width:1280px;padding:0 16px}.u-justify-content-space-between{justify-content:space-between}.u-mt-32{margin-top:32px}.u-mb-8{margin-bottom:8px}.u-mb-16{margin-bottom:16px}.u-mb-24{margin-bottom:24px}.u-mb-32{margin-bottom:32px}.c-nature-box svg+.c-article__button-text,.u-ml-8{margin-left:8px}.u-pa-16{padding:16px}html *,html :after,html :before{box-sizing:inherit}.c-article-section__title,.c-article-title{font-weight:700}.c-card__title{line-height:1.4em}.c-article__button{background-color:#069;border:1px solid #069;border-radius:2px;color:#fff;display:flex;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Oxygen-Sans,Ubuntu,Cantarell,Helvetica Neue,sans-serif;font-size:.875rem;line-height:1.4;margin-bottom:16px;padding:13px;transition:background-color .2s ease-out 0s,color .2s ease-out 0s}.c-article__button,.c-article__button:hover{text-decoration:none}.c-article__button--inverted,.c-article__button:hover{background-color:#fff;color:#069}.c-article__button--inverted:hover{background-color:#069;color:#fff}.c-header__link{text-decoration:inherit}.grade-c-hide{display:block}.u-lazy-ad-wrapper{background-color:#ccc;display:none;min-height:137px}@media only screen and (min-width:768px){.u-lazy-ad-wrapper{display:block}}.c-nature-box{background-color:#fff;border:1px solid #d5d5d5;border-radius:2px;box-shadow:0 0 5px 0 rgba(51,51,51,.1);line-height:1.3;margin-bottom:24px;padding:16px 16px 3px}.c-nature-box__text{font-size:1rem;margin-bottom:16px}.c-nature-box .c-pdf-download{margin-bottom:16px!important}.c-nature-box--version{background-color:#eee}.c-nature-box__wrapper{transform:translateZ(0)}.c-nature-box__wrapper--placeholder{min-height:165px}.c-pdf-download__link{padding:13px 24px} } </style>\n\n\n\n\n    \n        <link data-test=\"critical-css-handler\" data-inline-css-source=\"critical-css\" rel=\"stylesheet\" href=\"/static/css/enhanced-article-nature-branded-68c4876c28.css\" media=\"print\" onload=\"this.media='only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)';this.onload=null\">\n    \n    <noscript>\n        <link rel=\"stylesheet\" type=\"text/css\" href=\"/static/css/enhanced-article-nature-branded-68c4876c28.css\" media=\"only print, only all and (prefers-color-scheme: no-preference), only all and (prefers-color-scheme: light), only all and (prefers-color-scheme: dark)\">\n    </noscript>\n\n<link rel=\"stylesheet\" type=\"text/css\" href=\"/static/css/article-print-122346e276.css\" media=\"print\">\n    \n\n\n\n<link rel=\"apple-touch-icon\" sizes=\"180x180\" href=/static/images/favicons/nature/apple-touch-icon-f39cb19454.png>\n<link rel=\"icon\" type=\"image/png\" sizes=\"48x48\" href=/static/images/favicons/nature/favicon-48x48-b52890008c.png>\n<link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=/static/images/favicons/nature/favicon-32x32-3fe59ece92.png>\n<link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=/static/images/favicons/nature/favicon-16x16-951651ab72.png>\n<link rel=\"manifest\" href=/static/manifest.json crossorigin=\"use-credentials\">\n<link rel=\"mask-icon\" href=/static/images/favicons/nature/safari-pinned-tab-69bff48fe6.svg color=\"#000000\">\n<link rel=\"shortcut icon\" href=/static/images/favicons/nature/favicon.ico>\n<meta name=\"msapplication-TileColor\" content=\"#000000\">\n<meta name=\"msapplication-config\" content=/static/browserconfig.xml>\n<meta name=\"theme-color\" content=\"#000000\">\n<meta name=\"application-name\" content=\"Nature\">\n\n\n<script>\n    (function () {\n        if ( typeof window.CustomEvent === \"function\" ) return false;\n        function CustomEvent ( event, params ) {\n            params = params || { bubbles: false, cancelable: false, detail: null };\n            var evt = document.createEvent( 'CustomEvent' );\n            evt.initCustomEvent( event, params.bubbles, params.cancelable, params.detail );\n            return evt;\n        }\n\n        CustomEvent.prototype = window.Event.prototype;\n\n        window.CustomEvent = CustomEvent;\n    })();\n</script>\n\n\n\n<!-- Google Tag Manager -->\n<script data-test=\"gtm-head\">\n    window.initGTM = function() {\n        if (window.config.mustardcut) {\n            (function (w, d, s, l, i) {\n                w[l] = w[l] || [];\n                w[l].push({'gtm.start': new Date().getTime(), event: 'gtm.js'});\n                var f = d.getElementsByTagName(s)[0],\n                        j = d.createElement(s),\n                        dl = l != 'dataLayer' ? '&l=' + l : '';\n                j.async = true;\n                j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;\n                f.parentNode.insertBefore(j, f);\n            })(window, document, 'script', 'dataLayer', 'GTM-MRVXSHQ');\n        }\n    }\n</script>\n<!-- End Google Tag Manager -->\n\n    <script>\n    (function(w,d,t) {\n        function cc() {\n            var h = w.location.hostname;\n            if (h.indexOf('preview-www.nature.com') > -1) return;\n\n            var e = d.createElement(t),\n                    s = d.getElementsByTagName(t)[0];\n\n            if (h.indexOf('nature.com') > -1) {\n                if (h.indexOf('test-www.nature.com') > -1) {\n                    e.src = 'https://cmp.nature.com/production_live/en/consent-bundle-8-68.js';\n                    e.setAttribute('onload', \"initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')\");\n                } else {\n                    e.src = 'https://cmp.nature.com/production_live/en/consent-bundle-8-68.js';\n                    e.setAttribute('onload', \"initGTM(window,document,'script','dataLayer','GTM-MRVXSHQ')\");\n                }\n            } else {\n                e.src = '/static/js/cookie-consent-es5-bundle-cb57c2c98a.js';\n                e.setAttribute('data-consent', h);\n            }\n            s.insertAdjacentElement('afterend', e);\n        }\n\n        cc();\n    })(window,document,'script');\n</script>\n\n\n<script id=\"js-position0\">\n    (function(w, d) {\n        w.idpVerifyPrefix = 'https://verify.nature.com';\n        w.ra21Host = 'https://wayf.springernature.com';\n        var moduleSupport = (function() {\n            return 'noModule' in d.createElement('script');\n        })();\n\n        if (w.config.mustardcut === true) {\n            w.loader = {\n                index: 0,\n                registered: [],\n                scripts: [\n                    \n                        {src: '/static/js/global-article-es6-bundle-c8a573ca90.js', test: 'global-article-js', module: true},\n                        {src: '/static/js/global-article-es5-bundle-d17603b9e9.js', test: 'global-article-js', nomodule: true},\n                        {src: '/static/js/shared-es6-bundle-86971cab8b.js', test: 'shared-js', module: true},\n                        {src: '/static/js/shared-es5-bundle-19a08afafc.js', test: 'shared-js', nomodule: true},\n                        {src: '/static/js/header-150-es6-bundle-5bb959eaa1.js', test: 'header-150-js', module: true},\n                        {src: '/static/js/header-150-es5-bundle-994fde5b1d.js', test: 'header-150-js', nomodule: true}\n                    \n                ].filter(function (s) {\n                    if (s.src === null) return false;\n                    if (moduleSupport && s.nomodule) return false;\n                    return !(!moduleSupport && s.module);\n                }),\n\n                register: function (value) {\n                    this.registered.push(value);\n                },\n\n                ready: function () {\n                    if (this.registered.length === this.scripts.length) {\n                        this.registered.forEach(function (fn) {\n                            if (typeof fn === 'function') {\n                                setTimeout(fn, 0); \n                            }\n                        });\n                        this.ready = function () {};\n                    }\n                },\n\n                insert: function (s) {\n                    var t = d.getElementById('js-position' + this.index);\n                    if (t && t.insertAdjacentElement) {\n                        t.insertAdjacentElement('afterend', s);\n                    } else {\n                        d.head.appendChild(s);\n                    }\n                    ++this.index;\n                },\n\n                createScript: function (script, beforeLoad) {\n                    var s = d.createElement('script');\n                    s.id = 'js-position' + (this.index + 1);\n                    s.setAttribute('data-test', script.test);\n                    if (beforeLoad) {\n                        s.defer = 'defer';\n                        s.onload = function () {\n                            if (script.noinit) {\n                                loader.register(true);\n                            }\n                            if (d.readyState === 'interactive' || d.readyState === 'complete') {\n                                loader.ready();\n                            }\n                        };\n                    } else {\n                        s.async = 'async';\n                    }\n                    s.src = script.src;\n                    return s;\n                },\n\n                init: function () {\n                    this.scripts.forEach(function (s) {\n                        loader.insert(loader.createScript(s, true));\n                    });\n\n                    d.addEventListener('DOMContentLoaded', function () {\n                        loader.ready();\n                        var conditionalScripts;\n                        \n                            conditionalScripts = [\n                                {match: 'div[data-pan-container]', src: '/static/js/pan-zoom-es6-bundle-464a2af269.js', test: 'pan-zoom-js',  module: true },\n                                {match: 'div[data-pan-container]', src: '/static/js/pan-zoom-es5-bundle-98fb9b653b.js', test: 'pan-zoom-js',  nomodule: true },\n                                {match: 'math,span.mathjax-tex', src: '/static/js/math-es6-bundle-23597ae350.js', test: 'math-js', module: true},\n                                {match: 'math,span.mathjax-tex', src: '/static/js/math-es5-bundle-6532c6f78b.js', test: 'math-js', nomodule: true}\n                            ];\n                        \n\n                        if (conditionalScripts) {\n                            conditionalScripts.filter(function (script) {\n                                return !!document.querySelector(script.match) && !((moduleSupport && script.nomodule) || (!moduleSupport && script.module));\n                            }).forEach(function (script) {\n                                loader.insert(loader.createScript(script));\n                            });\n                        }\n                    }, false);\n                }\n            };\n            loader.init();\n        }\n    })(window, document);\n</script>\n\n\n\n\n\n\n\n\n\n\n<meta name=\"robots\" content=\"noarchive\">\n<meta name=\"access\" content=\"Yes\">\n\n\n<link rel=\"search\" href=\"https://www.nature.com/search\">\n<link rel=\"search\" href=\"https://www.nature.com/opensearch/opensearch.xml\" type=\"application/opensearchdescription+xml\" title=\"nature.com\">\n<link rel=\"search\" href=\"https://www.nature.com/opensearch/request\" type=\"application/sru+xml\" title=\"nature.com\">\n\n\n\n\n\n    \n    <script type=\"application/ld+json\">{\"mainEntity\":{\"headline\":\"AI models collapse when trained on recursively generated data\",\"description\":\"Stable diffusion revolutionized image creation from descriptive text. GPT-2 (ref. 1), GPT-3(.5) (ref. 2) and GPT-4 (ref. 3) demonstrated high performance across a variety of language tasks. ChatGPT introduced such language models to the public. It is now clear that generative artificial intelligence (AI) such as large language models (LLMs) is here to stay and will substantially change the ecosystem of online text and images. Here we consider what may happen to GPT-{n} once LLMs contribute much of the text found online. We find that indiscriminate use of model-generated content in training causes irreversible defects in the resulting models, in which tails of the original content distribution disappear. We refer to this effect as ‘model collapse’ and show that it can occur in LLMs as well as in variational autoencoders (VAEs) and Gaussian mixture models (GMMs). We build theoretical intuition behind the phenomenon and portray its ubiquity among all learned generative models. We demonstrate that it must be taken seriously if we are to sustain the benefits of training from large-scale data scraped from the web. Indeed, the value of data collected about genuine human interactions with systems will be increasingly valuable in the presence of LLM-generated content in data crawled from the Internet.  Analysis shows that indiscriminately training generative artificial intelligence on real and generated content, usually done by scraping data from the Internet, can lead to a collapse in the ability of the models to generate diverse high-quality output.\",\"datePublished\":\"2024-07-24T00:00:00Z\",\"dateModified\":\"2024-07-24T00:00:00Z\",\"pageStart\":\"755\",\"pageEnd\":\"759\",\"license\":\"http://creativecommons.org/licenses/by/4.0/\",\"sameAs\":\"https://doi.org/10.1038/s41586-024-07566-y\",\"keywords\":[\"Computational science\",\"Computer science\",\"Science\",\"Humanities and Social Sciences\",\"multidisciplinary\"],\"image\":[\"https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41586-024-07566-y/MediaObjects/41586_2024_7566_Fig1_HTML.png\"],\"isPartOf\":{\"name\":\"Nature\",\"issn\":[\"1476-4687\",\"0028-0836\"],\"volumeNumber\":\"631\",\"@type\":[\"Periodical\",\"PublicationVolume\"]},\"publisher\":{\"name\":\"Nature Publishing Group UK\",\"logo\":{\"url\":\"https://www.springernature.com/app-sn/public/images/logo-springernature.png\",\"@type\":\"ImageObject\"},\"@type\":\"Organization\"},\"author\":[{\"name\":\"Ilia Shumailov\",\"affiliation\":[{\"name\":\"University of Oxford\",\"address\":{\"name\":\"OATML, Department of Computer Science, University of Oxford, Oxford, UK\",\"@type\":\"PostalAddress\"},\"@type\":\"Organization\"}],\"email\":\"ilia.shumailov@chch.ox.ac.uk\",\"@type\":\"Person\"},{\"name\":\"Zakhar Shumaylov\",\"affiliation\":[{\"name\":\"University of Cambridge\",\"address\":{\"name\":\"Department of Applied Mathematics and Theoretical Physics, University of Cambridge, Cambridge, UK\",\"@type\":\"PostalAddress\"},\"@type\":\"Organization\"}],\"email\":\"zs334@cam.ac.uk\",\"@type\":\"Person\"},{\"name\":\"Yiren Zhao\",\"url\":\"http://orcid.org/0000-0002-3727-7463\",\"affiliation\":[{\"name\":\"Imperial College London\",\"address\":{\"name\":\"Department of Electrical and Electronic Engineering, Imperial College London, London, UK\",\"@type\":\"PostalAddress\"},\"@type\":\"Organization\"}],\"@type\":\"Person\"},{\"name\":\"Nicolas Papernot\",\"affiliation\":[{\"name\":\"University of Toronto\",\"address\":{\"name\":\"University of Toronto, Toronto, Canada\",\"@type\":\"PostalAddress\"},\"@type\":\"Organization\"},{\"name\":\"Vector Institute\",\"address\":{\"name\":\"Vector Institute, Toronto, Canada\",\"@type\":\"PostalAddress\"},\"@type\":\"Organization\"}],\"@type\":\"Person\"},{\"name\":\"Ross Anderson\",\"url\":\"http://orcid.org/0000-0001-8697-5682\",\"affiliation\":[{\"name\":\"University of Cambridge\",\"address\":{\"name\":\"Department of Computer Science and Technology, University of Cambridge, Cambridge, UK\",\"@type\":\"PostalAddress\"},\"@type\":\"Organization\"},{\"name\":\"University of Edinburgh\",\"address\":{\"name\":\"School of Informatics, University of Edinburgh, Edinburgh, UK\",\"@type\":\"PostalAddress\"},\"@type\":\"Organization\"}],\"@type\":\"Person\"},{\"name\":\"Yarin Gal\",\"url\":\"http://orcid.org/0000-0002-2733-2078\",\"affiliation\":[{\"name\":\"University of Oxford\",\"address\":{\"name\":\"OATML, Department of Computer Science, University of Oxford, Oxford, UK\",\"@type\":\"PostalAddress\"},\"@type\":\"Organization\"}],\"email\":\"yarin@cs.ox.ac.uk\",\"@type\":\"Person\"}],\"isAccessibleForFree\":true,\"@type\":\"ScholarlyArticle\"},\"@context\":\"https://schema.org\",\"@type\":\"WebPage\"}</script>\n\n\n\n\n    \n    \n    \n\n\n    \n    <link rel=\"canonical\" href=\"https://www.nature.com/articles/s41586-024-07566-y\">\n    \n    \n    <meta name=\"journal_id\" content=\"41586\"/>\n    <meta name=\"dc.title\" content=\"AI models collapse when trained on recursively generated data\"/>\n    <meta name=\"dc.source\" content=\"Nature 2024 631:8022\"/>\n    <meta name=\"dc.format\" content=\"text/html\"/>\n    <meta name=\"dc.publisher\" content=\"Nature Publishing Group\"/>\n    <meta name=\"dc.date\" content=\"2024-07-24\"/>\n    <meta name=\"dc.type\" content=\"OriginalPaper\"/>\n    <meta name=\"dc.language\" content=\"En\"/>\n    <meta name=\"dc.copyright\" content=\"2024 The Author(s)\"/>\n    <meta name=\"dc.rights\" content=\"2024 The Author(s)\"/>\n    <meta name=\"dc.rightsAgent\" content=\"journalpermissions@springernature.com\"/>\n    <meta name=\"dc.description\" content=\"Stable diffusion revolutionized image creation from descriptive text. GPT-2 (ref.&#8201;1), GPT-3(.5) (ref.&#8201;2) and GPT-4 (ref.&#8201;3) demonstrated high performance across a variety of language tasks. ChatGPT introduced such language models to the public. It is now clear that generative artificial intelligence (AI) such as large language models (LLMs) is here to stay and will substantially change the ecosystem of online text and images. Here we consider what may happen to GPT-{n} once LLMs contribute much of the text found online. We find that indiscriminate use of model-generated content in training causes irreversible defects in the resulting models, in which tails of the original content distribution disappear. We refer to this effect as &#8216;model collapse&#8217; and show that it can occur in LLMs as well as in variational autoencoders (VAEs) and Gaussian mixture models (GMMs). We build theoretical intuition behind the phenomenon and portray its ubiquity among all learned generative models. We demonstrate that it must be taken seriously if we are to sustain the benefits of training from large-scale data scraped from the web. Indeed, the value of data collected about genuine human interactions with systems will be increasingly valuable in the presence of LLM-generated content in data crawled from the Internet. &amp;nbsp;Analysis shows that indiscriminately training generative artificial intelligence on real and generated content, usually done by scraping data from&amp;nbsp;the Internet, can lead to a collapse in the ability of the models to generate diverse high-quality output.\"/>\n    <meta name=\"prism.issn\" content=\"1476-4687\"/>\n    <meta name=\"prism.publicationName\" content=\"Nature\"/>\n    <meta name=\"prism.publicationDate\" content=\"2024-07-24\"/>\n    <meta name=\"prism.volume\" content=\"631\"/>\n    <meta name=\"prism.number\" content=\"8022\"/>\n    <meta name=\"prism.section\" content=\"OriginalPaper\"/>\n    <meta name=\"prism.startingPage\" content=\"755\"/>\n    <meta name=\"prism.endingPage\" content=\"759\"/>\n    <meta name=\"prism.copyright\" content=\"2024 The Author(s)\"/>\n    <meta name=\"prism.rightsAgent\" content=\"journalpermissions@springernature.com\"/>\n    <meta name=\"prism.url\" content=\"https://www.nature.com/articles/s41586-024-07566-y\"/>\n    <meta name=\"prism.doi\" content=\"doi:10.1038/s41586-024-07566-y\"/>\n    <meta name=\"citation_pdf_url\" content=\"https://www.nature.com/articles/s41586-024-07566-y.pdf\"/>\n    <meta name=\"citation_fulltext_html_url\" content=\"https://www.nature.com/articles/s41586-024-07566-y\"/>\n    <meta name=\"citation_journal_title\" content=\"Nature\"/>\n    <meta name=\"citation_journal_abbrev\" content=\"Nature\"/>\n    <meta name=\"citation_publisher\" content=\"Nature Publishing Group\"/>\n    <meta name=\"citation_issn\" content=\"1476-4687\"/>\n    <meta name=\"citation_title\" content=\"AI models collapse when trained on recursively generated data\"/>\n    <meta name=\"citation_volume\" content=\"631\"/>\n    <meta name=\"citation_issue\" content=\"8022\"/>\n    <meta name=\"citation_publication_date\" content=\"2024/07\"/>\n    <meta name=\"citation_online_date\" content=\"2024/07/24\"/>\n    <meta name=\"citation_firstpage\" content=\"755\"/>\n    <meta name=\"citation_lastpage\" content=\"759\"/>\n    <meta name=\"citation_article_type\" content=\"Article\"/>\n    <meta name=\"citation_fulltext_world_readable\" content=\"\"/>\n    <meta name=\"citation_language\" content=\"en\"/>\n    <meta name=\"dc.identifier\" content=\"doi:10.1038/s41586-024-07566-y\"/>\n    <meta name=\"DOI\" content=\"10.1038/s41586-024-07566-y\"/>\n    <meta name=\"size\" content=\"93999\"/>\n    <meta name=\"citation_doi\" content=\"10.1038/s41586-024-07566-y\"/>\n    <meta name=\"citation_springer_api_url\" content=\"http://api.springer.com/xmldata/jats?q=doi:10.1038/s41586-024-07566-y&amp;api_key=\"/>\n    <meta name=\"description\" content=\"Stable diffusion revolutionized image creation from descriptive text. GPT-2 (ref.&#8201;1), GPT-3(.5) (ref.&#8201;2) and GPT-4 (ref.&#8201;3) demonstrated high performance across a variety of language tasks. ChatGPT introduced such language models to the public. It is now clear that generative artificial intelligence (AI) such as large language models (LLMs) is here to stay and will substantially change the ecosystem of online text and images. Here we consider what may happen to GPT-{n} once LLMs contribute much of the text found online. We find that indiscriminate use of model-generated content in training causes irreversible defects in the resulting models, in which tails of the original content distribution disappear. We refer to this effect as &#8216;model collapse&#8217; and show that it can occur in LLMs as well as in variational autoencoders (VAEs) and Gaussian mixture models (GMMs). We build theoretical intuition behind the phenomenon and portray its ubiquity among all learned generative models. We demonstrate that it must be taken seriously if we are to sustain the benefits of training from large-scale data scraped from the web. Indeed, the value of data collected about genuine human interactions with systems will be increasingly valuable in the presence of LLM-generated content in data crawled from the Internet. &amp;nbsp;Analysis shows that indiscriminately training generative artificial intelligence on real and generated content, usually done by scraping data from&amp;nbsp;the Internet, can lead to a collapse in the ability of the models to generate diverse high-quality output.\"/>\n    <meta name=\"dc.creator\" content=\"Shumailov, Ilia\"/>\n    <meta name=\"dc.creator\" content=\"Shumaylov, Zakhar\"/>\n    <meta name=\"dc.creator\" content=\"Zhao, Yiren\"/>\n    <meta name=\"dc.creator\" content=\"Papernot, Nicolas\"/>\n    <meta name=\"dc.creator\" content=\"Anderson, Ross\"/>\n    <meta name=\"dc.creator\" content=\"Gal, Yarin\"/>\n    <meta name=\"dc.subject\" content=\"Computational science\"/>\n    <meta name=\"dc.subject\" content=\"Computer science\"/>\n    <meta name=\"citation_reference\" content=\"citation_journal_title=OpenAI blog; citation_title=Language models are unsupervised multitask learners; citation_author=A Radford; citation_volume=1; citation_publication_date=2019; citation_pages=9; citation_id=CR1\"/>\n    <meta name=\"citation_reference\" content=\"citation_journal_title=Adv. Neural Inf. Process. Syst.; citation_title=Language models are few-shot learners; citation_author=T Brown; citation_volume=33; citation_publication_date=2020; citation_pages=1877-1901; citation_id=CR2\"/>\n    <meta name=\"citation_reference\" content=\"OpenAI. GPT-4 Technical Report. \n                  https://cdn.openai.com/papers/gpt-4.pdf\n                  \n                 (2023).\"/>\n    <meta name=\"citation_reference\" content=\"Devlin, J., Chang, M.-W., Lee, K. &amp; Toutanova, K. in Proc. 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) (eds Burstein, J., Doran, C. &amp; Solorio, T.) 4171&#8211;4186 (Association for Computational Linguistics, 2019).\"/>\n    <meta name=\"citation_reference\" content=\"Liu, Y. et al. RoBERTa: a Robustly Optimized BERT Pretraining Approach. Preprint at \n                  https://arxiv.org/abs/1907.11692\n                  \n                 (2019).\"/>\n    <meta name=\"citation_reference\" content=\"Zhang, S. et al. Opt: open pre-trained transformer language models. Preprint at \n                  https://arxiv.org/abs/2205.01068\n                  \n                 (2022).\"/>\n    <meta name=\"citation_reference\" content=\"Aljundi, R., Kelchtermans, K. &amp; Tuytelaars, T. Task-free continual learning. in: Proc. 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 11254&#8211;11263 (IEEE, 2019).\"/>\n    <meta name=\"citation_reference\" content=\"Carlini, N. &amp; Terzis, A. in Proc. Tenth International Conference on Learning Representations (ICLR, 2022).\"/>\n    <meta name=\"citation_reference\" content=\"Carlini, N. et al. in Proc. 2024 IEEE Symposium on Security and Privacy (SP) 179 (IEEE, 2024).\"/>\n    <meta name=\"citation_reference\" content=\"Mousavi-Hosseini, A., Park, S., Girotti, M., Mitliagkas, I. &amp; Erdogdu, M. A. in Proc. Eleventh International Conference on Learning Representations (ICLR, 2023).\"/>\n    <meta name=\"citation_reference\" content=\"citation_journal_title=J. Mach. Learn. Res.; citation_title=The implicit bias of gradient descent on separable data; citation_author=D Soudry, E Hoffer, MS Nacson, S Gunasekar, N Srebro; citation_volume=19; citation_publication_date=2018; citation_pages=1-57; citation_id=CR11\"/>\n    <meta name=\"citation_reference\" content=\"Gu, Y., Dong, L., Wei, F. &amp; Huang, M. in Proc. Twelfth International Conference on Learning Representations (ICLR, 2024).\"/>\n    <meta name=\"citation_reference\" content=\"Shumailov, I. &amp; Shumaylov, Z. Public code for Model Collapse (0.1). Zenodo \n                  https://doi.org/10.5281/zenodo.10866595\n                  \n                 (2024).\"/>\n    <meta name=\"citation_reference\" content=\"Bommasani, R. et al. On the opportunities and risks of foundation models. Preprint at \n                  https://arxiv.org/abs/2108.07258\n                  \n                 (2022).\"/>\n    <meta name=\"citation_reference\" content=\"Strubell, E., Ganesh, A. &amp; McCallum, A. in Proc. 57th Annual Meeting of the Association for Computational Linguistics (eds Korhonen, A., Traum, D. &amp; M&#224;rquez, L.) 3645&#8211;3650 (Association for Computational Linguistics, 2019).\"/>\n    <meta name=\"citation_reference\" content=\"Merity, S., Xiong, C., Bradbury, J. &amp; Socher, R. in Proc. 5th International Conference on Learning Representations (ICLR, 2017).\"/>\n    <meta name=\"citation_reference\" content=\"Keskar, N. S., McCann, B., Varshney, L. R., Xiong, C. &amp; Socher, R. CTRL: a conditional transformer language model for controllable generation. Preprint at \n                  https://arxiv.org/abs/1909.05858\n                  \n                 (2019).\"/>\n    <meta name=\"citation_reference\" content=\"Shumailov, I. et al. in Proc. 2021 IEEE European Symposium on Security and Privacy (EuroS&amp;P) 212&#8211;231 (IEEE, 2021).\"/>\n    <meta name=\"citation_reference\" content=\"Google. Finding more high-quality sites in search. Google \n                  https://googleblog.blogspot.com/2011/02/finding-more-high-quality-sites-in.html\n                  \n                 (2011).\"/>\n    <meta name=\"citation_reference\" content=\"Mims, C. The search engine backlash against &#8216;content mills&#8217;. MIT Technology Review \n                  https://www.technologyreview.com/2010/07/26/26327/the-search-engine-backlash-against-content-mills/\n                  \n                 (2010).\"/>\n    <meta name=\"citation_reference\" content=\"citation_journal_title=Am. Stat.; citation_title=Black swans and the domains of statistics; citation_author=NN Taleb; citation_volume=61; citation_publication_date=2007; citation_pages=198-200; citation_doi=10.1198/000313007X219996; citation_id=CR21\"/>\n    <meta name=\"citation_reference\" content=\"LeCun, Y., Cortes, C. &amp; Burges, C. J. C. The MNIST database of handwritten digits. \n                  http://yann.lecun.com/exdb/mnist/\n                  \n                 (1998).\"/>\n    <meta name=\"citation_author\" content=\"Shumailov, Ilia\"/>\n    <meta name=\"citation_author_institution\" content=\"OATML, Department of Computer Science, University of Oxford, Oxford, UK\"/>\n    <meta name=\"citation_author\" content=\"Shumaylov, Zakhar\"/>\n    <meta name=\"citation_author_institution\" content=\"Department of Applied Mathematics and Theoretical Physics, University of Cambridge, Cambridge, UK\"/>\n    <meta name=\"citation_author\" content=\"Zhao, Yiren\"/>\n    <meta name=\"citation_author_institution\" content=\"Department of Electrical and Electronic Engineering, Imperial College London, London, UK\"/>\n    <meta name=\"citation_author\" content=\"Papernot, Nicolas\"/>\n    <meta name=\"citation_author_institution\" content=\"University of Toronto, Toronto, Canada\"/>\n    <meta name=\"citation_author_institution\" content=\"Vector Institute, Toronto, Canada\"/>\n    <meta name=\"citation_author\" content=\"Anderson, Ross\"/>\n    <meta name=\"citation_author_institution\" content=\"Department of Computer Science and Technology, University of Cambridge, Cambridge, UK\"/>\n    <meta name=\"citation_author_institution\" content=\"School of Informatics, University of Edinburgh, Edinburgh, UK\"/>\n    <meta name=\"citation_author\" content=\"Gal, Yarin\"/>\n    <meta name=\"citation_author_institution\" content=\"OATML, Department of Computer Science, University of Oxford, Oxford, UK\"/>\n    <meta name=\"access_endpoint\" content=\"https://www.nature.com/platform/readcube-access\"/>\n    <meta name=\"twitter:site\" content=\"@nature\"/>\n    <meta name=\"twitter:card\" content=\"summary_large_image\"/>\n    <meta name=\"twitter:image:alt\" content=\"Content cover image\"/>\n    <meta name=\"twitter:title\" content=\"AI models collapse when trained on recursively generated data\"/>\n    <meta name=\"twitter:description\" content=\"Nature - Analysis shows that indiscriminately training generative artificial intelligence on real and generated content, usually done by scraping data from the Internet, can lead to a collapse in...\"/>\n    <meta name=\"twitter:image\" content=\"https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41586-024-07566-y/MediaObjects/41586_2024_7566_Fig1_HTML.png\"/>\n    \n\n    \n    \n    <meta property=\"og:url\" content=\"https://www.nature.com/articles/s41586-024-07566-y\"/>\n    <meta property=\"og:type\" content=\"article\"/>\n    <meta property=\"og:site_name\" content=\"Nature\"/>\n    <meta property=\"og:title\" content=\"AI models collapse when trained on recursively generated data - Nature\"/>\n    <meta property=\"og:description\" content=\"&amp;nbsp;Analysis shows that indiscriminately training generative artificial intelligence on real and generated content, usually done by scraping data from&amp;nbsp;the Internet, can lead to a collapse in the ability of the models to generate diverse high-quality output.\"/>\n    <meta property=\"og:image\" content=\"https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs41586-024-07566-y/MediaObjects/41586_2024_7566_Fig1_HTML.png\"/>\n    \n\n    <script>\n        window.eligibleForRa21 = 'false'; \n    </script>\n</head>\n<body class=\"article-page\">\n\n<noscript><iframe src=\"https://www.googletagmanager.com/ns.html?id=GTM-MRVXSHQ\"\n                  height=\"0\" width=\"0\" style=\"display:none;visibility:hidden\"></iframe></noscript>\n\n\n\n<div class=\"position-relative cleared z-index-50 background-white\" data-test=\"top-containers\">\n    <a class=\"c-skip-link\" href=\"#content\">Skip to main content</a>\n\n\n\n<div class=\"c-grade-c-banner u-hide\">\n    <div class=\"c-grade-c-banner__container\">\n        \n        <p>Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain\n            the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in\n            Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles\n            and JavaScript.</p>\n\n    </div>\n</div>\n\n    \n\n    <div class=\"u-lazy-ad-wrapper u-mbs-0\">\n            <div class=\"deferred-placeholder\" data-replace=\"true\"\n                 data-placeholder=\"/placeholder/v1/institutionalBanner?bpids=[bpids] #institutional-banner-container\"></div>\n            <aside class=\"c-ad c-ad--728x90\">\n                <div class=\"c-ad__inner\" data-container-type=\"banner-advert\">\n                    <p class=\"c-ad__label\">Advertisement</p>\n                    \n        \n            \n    <div id=\"div-gpt-ad-top-1\"\n         class=\"div-gpt-ad advert leaderboard js-ad text-center hide-print grade-c-hide\"\n         data-ad-type=\"top\"\n         data-test=\"top-ad\"\n         data-pa11y-ignore\n         data-gpt\n         data-gpt-unitpath=\"/285/nature.com/article\"\n         data-gpt-sizes=\"728x90\"\n         data-gpt-targeting=\"type=article;pos=top;artid=s41586-024-07566-y;doi=10.1038/s41586-024-07566-y;techmeta=119,123,129,141;subjmeta=1042,117,639,705;kwrd=Computational+science,Computer+science\">\n        <noscript>\n            <a href=\"//pubads.g.doubleclick.net/gampad/jump?iu=/285/nature.com/article&amp;sz=728x90&amp;c=1638430036&amp;t=pos%3Dtop%26type%3Darticle%26artid%3Ds41586-024-07566-y%26doi%3D10.1038/s41586-024-07566-y%26techmeta%3D119,123,129,141%26subjmeta%3D1042,117,639,705%26kwrd%3DComputational+science,Computer+science\">\n                <img data-test=\"gpt-advert-fallback-img\"\n                     src=\"//pubads.g.doubleclick.net/gampad/ad?iu=/285/nature.com/article&amp;sz=728x90&amp;c=1638430036&amp;t=pos%3Dtop%26type%3Darticle%26artid%3Ds41586-024-07566-y%26doi%3D10.1038/s41586-024-07566-y%26techmeta%3D119,123,129,141%26subjmeta%3D1042,117,639,705%26kwrd%3DComputational+science,Computer+science\"\n                     alt=\"Advertisement\"\n                     width=\"728\"\n                     height=\"90\"></a>\n        </noscript>\n    </div>\n\n        \n    \n                </div>\n            </aside>\n        </div>\n    <header class=\"c-header\" id=\"header\" data-header data-track-component=\"nature-150-split-header\" style=\"border-color:#000\">\n        <div class=\"c-header__row\">\n            <div class=\"c-header__container\">\n                <div class=\"c-header__split\">\n                    \n                    \n                    <div class=\"c-header__logo-container\">\n                        \n                        <a href=\"/\"\n                           data-track=\"click\" data-track-action=\"home\" data-track-label=\"image\">\n                            <picture class=\"c-header__logo\">\n                                <source srcset=\"https://media.springernature.com/full/nature-cms/uploads/product/nature/header-86f1267ea01eccd46b530284be10585e.svg\" media=\"(min-width: 875px)\">\n                                <img src=\"https://media.springernature.com/full/nature-cms/uploads/product/nature/header-86f1267ea01eccd46b530284be10585e.svg\" height=\"32\" alt=\"Nature\">\n                            </picture>\n                        </a>\n                    \n                    </div>\n                    \n                    <ul class=\"c-header__menu c-header__menu--global\">\n                        <li class=\"c-header__item c-header__item--padding c-header__item--hide-md-max\">\n                            <a class=\"c-header__link\" href=\"https://www.nature.com/siteindex\" data-test=\"siteindex-link\"\n                               data-track=\"click\" data-track-action=\"open nature research index\" data-track-label=\"link\">\n                                <span>View all journals</span>\n                            </a>\n                        </li>\n                        <li class=\"c-header__item c-header__item--padding c-header__item--pipe\">\n                            <a class=\"c-header__link c-header__link--search\"\n                                href=\"#search-menu\"\n                                data-header-expander\n                                data-test=\"search-link\" data-track=\"click\" data-track-action=\"open search tray\" data-track-label=\"button\">\n                                <svg role=\"img\" aria-hidden=\"true\" focusable=\"false\" height=\"22\" width=\"22\" viewBox=\"0 0 18 18\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M16.48 15.455c.283.282.29.749.007 1.032a.738.738 0 01-1.032-.007l-3.045-3.044a7 7 0 111.026-1.026zM8 14A6 6 0 108 2a6 6 0 000 12z\"/></svg><span>Search</span>\n                            </a>\n                        </li>\n                        <li class=\"c-header__item c-header__item--padding c-header__item--snid-account-widget c-header__item--pipe\">\n                            \n                                <a class=\"c-header__link eds-c-header__link\" id=\"identity-account-widget\" href='https://idp.nature.com/auth/personal/springernature?redirect_uri=https://www.nature.com/articles/s41586-024-07566-y?error=cookies_not_supported&code=a5f1884f-5da9-4500-ae99-e8edb6f84971'><span class=\"eds-c-header__widget-fragment-title\">Log in</span></a>\n                            \n                        </li>\n                    </ul>\n                </div>\n            </div>\n        </div>\n        \n            <div class=\"c-header__row\">\n                <div class=\"c-header__container\" data-test=\"navigation-row\">\n                    <div class=\"c-header__split\">\n                        <ul class=\"c-header__menu c-header__menu--journal\">\n                            \n                                <li class=\"c-header__item c-header__item--dropdown-menu\" data-test=\"explore-content-button\">\n                                    <a href=\"#explore\"\n                                       class=\"c-header__link\"\n                                       data-header-expander\n                                       data-test=\"menu-button--explore\"\n                                       data-track=\"click\" data-track-action=\"open explore expander\" data-track-label=\"button\">\n                                        <span><span class=\"c-header__show-text\">Explore</span> content</span><svg role=\"img\" aria-hidden=\"true\" focusable=\"false\" height=\"16\" viewBox=\"0 0 16 16\" width=\"16\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z\" transform=\"matrix(0 1 -1 0 11 3)\"/></svg>\n                                    </a>\n                                </li>\n                            \n                            \n                                <li class=\"c-header__item c-header__item--dropdown-menu\">\n                                    <a href=\"#about-the-journal\"\n                                       class=\"c-header__link\"\n                                       data-header-expander\n                                       data-test=\"menu-button--about-the-journal\"\n                                       data-track=\"click\" data-track-action=\"open about the journal expander\" data-track-label=\"button\">\n                                        <span>About <span class=\"c-header__show-text\">the journal</span></span><svg role=\"img\" aria-hidden=\"true\" focusable=\"false\" height=\"16\" viewBox=\"0 0 16 16\" width=\"16\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z\" transform=\"matrix(0 1 -1 0 11 3)\"/></svg>\n                                    </a>\n                                </li>\n                                \n                                    <li class=\"c-header__item c-header__item--dropdown-menu\" data-test=\"publish-with-us-button\">\n                                        <a href=\"#publish-with-us\"\n                                           class=\"c-header__link c-header__link--dropdown-menu\"\n                                           data-header-expander\n                                           data-test=\"menu-button--publish\"\n                                           data-track=\"click\" data-track-action=\"open publish with us expander\" data-track-label=\"button\">\n                                            <span>Publish <span class=\"c-header__show-text\">with us</span></span><svg role=\"img\" aria-hidden=\"true\" focusable=\"false\" height=\"16\" viewBox=\"0 0 16 16\" width=\"16\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z\" transform=\"matrix(0 1 -1 0 11 3)\"/></svg>\n                                        </a>\n                                    </li>\n                                \n                            \n                            \n                        </ul>\n                        <ul class=\"c-header__menu c-header__menu--hide-lg-max\">\n                            \n                                <li class=\"c-header__item\">\n                                    <a class=\"c-header__link\"\n                                       href=\"https://idp.nature.com/auth/personal/springernature?redirect_uri&#x3D;https%3A%2F%2Fwww.nature.com%2Fmy-account%2Falerts%2Fsubscribe-journal%3Flist-id%3D1%26journal-link%3Dhttps%253A%252F%252Fwww.nature.com%252Fnature%252F\"\n                                       rel=\"nofollow\"\n                                       data-track=\"click\"\n                                       data-track-action=\"Sign up for alerts\"\n                                       data-track-label=\"link (desktop site header)\"\n                                       data-track-external>\n                                        <span>Sign up for alerts</span><svg role=\"img\" aria-hidden=\"true\" focusable=\"false\" height=\"18\" viewBox=\"0 0 18 18\" width=\"18\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z\" fill=\"#222\"/></svg>\n                                    </a>\n                                </li>\n                            \n                            \n                                <li class=\"c-header__item c-header__item--pipe\">\n                                    <a class=\"c-header__link\"\n                                       href=\"https://www.nature.com/nature.rss\"\n                                       data-track=\"click\"\n                                       data-track-action=\"rss feed\"\n                                       data-track-label=\"link\">\n                                            <span>RSS feed</span>\n                                    </a>\n                                </li>\n                            \n                        </ul>\n                    </div>\n                </div>\n            </div>\n        \n    </header>\n\n\n    \n    \n        <nav class=\"u-mb-16\" aria-label=\"breadcrumbs\">\n            <div class=\"u-container\">\n                <ol class=\"c-breadcrumbs\" itemscope itemtype=\"https://schema.org/BreadcrumbList\">\n                    <li class=\"c-breadcrumbs__item\" id=\"breadcrumb0\" itemprop=\"itemListElement\" itemscope itemtype=\"https://schema.org/ListItem\"><a class=\"c-breadcrumbs__link\"\n                               href=\"/\" itemprop=\"item\"\n                               data-track=\"click\" data-track-action=\"breadcrumb\" data-track-category=\"header\" data-track-label=\"link:nature\"><span itemprop=\"name\">nature</span></a><meta itemprop=\"position\" content=\"1\">\n                                    <svg class=\"c-breadcrumbs__chevron\" role=\"img\" aria-hidden=\"true\" focusable=\"false\" height=\"10\" viewBox=\"0 0 10 10\" width=\"10\"\n                                         xmlns=\"http://www.w3.org/2000/svg\">\n                                        <path d=\"m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z\"\n                                              fill=\"#666\" fill-rule=\"evenodd\" transform=\"matrix(0 -1 1 0 0 10)\"/>\n                                    </svg>\n                                </li><li class=\"c-breadcrumbs__item\" id=\"breadcrumb1\" itemprop=\"itemListElement\" itemscope itemtype=\"https://schema.org/ListItem\"><a class=\"c-breadcrumbs__link\"\n                               href=\"/nature/articles?type&#x3D;article\" itemprop=\"item\"\n                               data-track=\"click\" data-track-action=\"breadcrumb\" data-track-category=\"header\" data-track-label=\"link:articles\"><span itemprop=\"name\">articles</span></a><meta itemprop=\"position\" content=\"2\">\n                                    <svg class=\"c-breadcrumbs__chevron\" role=\"img\" aria-hidden=\"true\" focusable=\"false\" height=\"10\" viewBox=\"0 0 10 10\" width=\"10\"\n                                         xmlns=\"http://www.w3.org/2000/svg\">\n                                        <path d=\"m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z\"\n                                              fill=\"#666\" fill-rule=\"evenodd\" transform=\"matrix(0 -1 1 0 0 10)\"/>\n                                    </svg>\n                                </li><li class=\"c-breadcrumbs__item\" id=\"breadcrumb2\" itemprop=\"itemListElement\" itemscope itemtype=\"https://schema.org/ListItem\">\n                                    <span itemprop=\"name\">article</span><meta itemprop=\"position\" content=\"3\"></li>\n                </ol>\n            </div>\n        </nav>\n    \n\n\n\n    \n\n</div>\n\n\n<div class=\"u-container u-mt-32 u-mb-32 u-clearfix\" id=\"content\" data-component=\"article-container\"  data-container-type=\"article\">\n    <main class=\"c-article-main-column u-float-left js-main-column\" data-track-component=\"article body\">\n        \n            <div class=\"c-context-bar u-hide\"\n                 data-test=\"context-bar\"\n                 data-context-bar\n                 aria-hidden=\"true\">\n                <div class=\"c-context-bar__container u-container\" data-track-context=\"sticky banner\">\n                    <div class=\"c-context-bar__title\">\n                        AI models collapse when trained on recursively generated data\n                    </div>\n                    \n    \n        <div class=\"c-pdf-download u-clear-both js-pdf-download\">\n            <a href=\"/articles/s41586-024-07566-y.pdf\" class=\"u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link\" data-article-pdf=\"true\" data-readcube-pdf-url=\"true\" data-test=\"download-pdf\" data-draft-ignore=\"true\" data-track=\"content_download\" data-track-type=\"article pdf download\" data-track-action=\"download pdf\" data-track-label=\"link\" data-track-external download>\n                <span class=\"c-pdf-download__text\">Download PDF</span>\n                <svg aria-hidden=\"true\" focusable=\"false\" width=\"16\" height=\"16\" class=\"u-icon\"><use xlink:href=\"#icon-download\"/></svg>\n            </a>\n        </div>\n    \n\n                </div>\n            </div>\n        \n        <article lang=\"en\">\n            \n                <div class=\"c-pdf-button__container u-mb-16 u-hide-at-lg js-context-bar-sticky-point-mobile\">\n                    <div class=\"c-pdf-container\" data-track-context=\"article body\">\n                        \n                            \n    \n        <div class=\"c-pdf-download u-clear-both js-pdf-download\">\n            <a href=\"/articles/s41586-024-07566-y.pdf\" class=\"u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link\" data-article-pdf=\"true\" data-readcube-pdf-url=\"true\" data-test=\"download-pdf\" data-draft-ignore=\"true\" data-track=\"content_download\" data-track-type=\"article pdf download\" data-track-action=\"download pdf\" data-track-label=\"link\" data-track-external download>\n                <span class=\"c-pdf-download__text\">Download PDF</span>\n                <svg aria-hidden=\"true\" focusable=\"false\" width=\"16\" height=\"16\" class=\"u-icon\"><use xlink:href=\"#icon-download\"/></svg>\n            </a>\n        </div>\n    \n\n                        \n                    </div>\n                </div>\n            \n            <div class=\"c-article-header\">\n                <header>\n                    <ul class=\"c-article-identifiers\" data-test=\"article-identifier\">\n                        \n        <li class=\"c-article-identifiers__item\" data-test=\"article-category\">Article</li>\n    \n        <li class=\"c-article-identifiers__item\">\n            <a href=\"https://www.springernature.com/gp/open-research/about/the-fundamentals-of-open-access-and-open-research\" data-track=\"click\" data-track-action=\"open access\" data-track-label=\"link\" class=\"u-color-open-access\" data-test=\"open-access\">Open access</a>\n        </li>\n    \n    \n\n                        <li class=\"c-article-identifiers__item\">Published: <time datetime=\"2024-07-24\">24 July 2024</time></li>\n                    </ul>\n\n                    <h1 class=\"c-article-title\" data-test=\"article-title\" data-article-title=\"\">AI models collapse when trained on recursively generated data</h1>\n                    <ul class=\"c-article-author-list c-article-author-list--short\" data-test=\"authors-list\" data-component-authors-activator=\"authors-list\"><li class=\"c-article-author-list__item\"><a data-test=\"author-name\" data-track=\"click\" data-track-action=\"open author\" data-track-label=\"link\" href=\"#auth-Ilia-Shumailov-Aff1\" data-author-popup=\"auth-Ilia-Shumailov-Aff1\" data-author-search=\"Shumailov, Ilia\" data-corresp-id=\"c1\">Ilia Shumailov<svg width=\"16\" height=\"16\" focusable=\"false\" role=\"img\" aria-hidden=\"true\" class=\"u-icon\"><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#icon-eds-i-mail-medium\"></use></svg></a><sup class=\"u-js-hide\"><a href=\"#Aff1\">1</a></sup><sup class=\"u-js-hide\"> <a href=\"#na1\">na1</a></sup>, </li><li class=\"c-article-author-list__item\"><a data-test=\"author-name\" data-track=\"click\" data-track-action=\"open author\" data-track-label=\"link\" href=\"#auth-Zakhar-Shumaylov-Aff2\" data-author-popup=\"auth-Zakhar-Shumaylov-Aff2\" data-author-search=\"Shumaylov, Zakhar\" data-corresp-id=\"c2\">Zakhar Shumaylov<svg width=\"16\" height=\"16\" focusable=\"false\" role=\"img\" aria-hidden=\"true\" class=\"u-icon\"><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#icon-eds-i-mail-medium\"></use></svg></a><sup class=\"u-js-hide\"><a href=\"#Aff2\">2</a></sup><sup class=\"u-js-hide\"> <a href=\"#na1\">na1</a></sup>, </li><li class=\"c-article-author-list__item c-article-author-list__item--hide-small-screen\"><a data-test=\"author-name\" data-track=\"click\" data-track-action=\"open author\" data-track-label=\"link\" href=\"#auth-Yiren-Zhao-Aff3\" data-author-popup=\"auth-Yiren-Zhao-Aff3\" data-author-search=\"Zhao, Yiren\">Yiren Zhao</a><span class=\"u-js-hide\"> \n            <a class=\"js-orcid\" href=\"http://orcid.org/0000-0002-3727-7463\"><span class=\"u-visually-hidden\">ORCID: </span>orcid.org/0000-0002-3727-7463</a></span><sup class=\"u-js-hide\"><a href=\"#Aff3\">3</a></sup>, </li><li class=\"c-article-author-list__item c-article-author-list__item--hide-small-screen\"><a data-test=\"author-name\" data-track=\"click\" data-track-action=\"open author\" data-track-label=\"link\" href=\"#auth-Nicolas-Papernot-Aff4-Aff5\" data-author-popup=\"auth-Nicolas-Papernot-Aff4-Aff5\" data-author-search=\"Papernot, Nicolas\">Nicolas Papernot</a><sup class=\"u-js-hide\"><a href=\"#Aff4\">4</a>,<a href=\"#Aff5\">5</a></sup>, </li><li class=\"c-article-author-list__item c-article-author-list__item--hide-small-screen\"><a data-test=\"author-name\" data-track=\"click\" data-track-action=\"open author\" data-track-label=\"link\" href=\"#auth-Ross-Anderson-Aff6-Aff7\" data-author-popup=\"auth-Ross-Anderson-Aff6-Aff7\" data-author-search=\"Anderson, Ross\">Ross Anderson</a><span class=\"u-js-hide\"> \n            <a class=\"js-orcid\" href=\"http://orcid.org/0000-0001-8697-5682\"><span class=\"u-visually-hidden\">ORCID: </span>orcid.org/0000-0001-8697-5682</a></span><sup class=\"u-js-hide\"><a href=\"#Aff6\">6</a>,<a href=\"#Aff7\">7</a></sup><sup class=\"u-js-hide\"> <a href=\"#na2\">na2</a></sup> &amp; </li><li class=\"c-article-author-list__show-more\" aria-label=\"Show all 6 authors for this article\" title=\"Show all 6 authors for this article\">…</li><li class=\"c-article-author-list__item\"><a data-test=\"author-name\" data-track=\"click\" data-track-action=\"open author\" data-track-label=\"link\" href=\"#auth-Yarin-Gal-Aff1\" data-author-popup=\"auth-Yarin-Gal-Aff1\" data-author-search=\"Gal, Yarin\" data-corresp-id=\"c3\">Yarin Gal<svg width=\"16\" height=\"16\" focusable=\"false\" role=\"img\" aria-hidden=\"true\" class=\"u-icon\"><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#icon-eds-i-mail-medium\"></use></svg></a><span class=\"u-js-hide\"> \n            <a class=\"js-orcid\" href=\"http://orcid.org/0000-0002-2733-2078\"><span class=\"u-visually-hidden\">ORCID: </span>orcid.org/0000-0002-2733-2078</a></span><sup class=\"u-js-hide\"><a href=\"#Aff1\">1</a></sup> </li></ul><button aria-expanded=\"false\" class=\"c-article-author-list__button\"><svg width=\"16\" height=\"16\" focusable=\"false\" role=\"img\" aria-hidden=\"true\" class=\"u-icon\"><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#icon-eds-i-chevron-down-medium\"></use></svg><span>Show authors</span></button>\n\n                    \n\n                    <p class=\"c-article-info-details\" data-container-section=\"info\">\n                        \n    <a data-test=\"journal-link\" href=\"/\" data-track=\"click\" data-track-action=\"journal homepage\" data-track-category=\"article body\" data-track-label=\"link\"><i data-test=\"journal-title\">Nature</i></a>\n\n                        <b data-test=\"journal-volume\"><span class=\"u-visually-hidden\">volume</span> 631</b>, <span class=\"u-visually-hidden\">pages </span>755–759 (<span data-test=\"article-publication-year\">2024</span>)<a href=\"#citeas\" class=\"c-article-info-details__cite-as u-hide-print\" data-track=\"click\" data-track-action=\"cite this article\" data-track-label=\"link\">Cite this article</a>\n                    </p>\n                    \n        <div class=\"c-article-metrics-bar__wrapper u-clear-both\">\n            <ul class=\"c-article-metrics-bar u-list-reset\">\n                \n                    <li class=\" c-article-metrics-bar__item\" data-test=\"access-count\">\n                        <p class=\"c-article-metrics-bar__count\">299k <span class=\"c-article-metrics-bar__label\">Accesses</span></p>\n                    </li>\n                \n                \n                    <li class=\"c-article-metrics-bar__item\" data-test=\"citation-count\">\n                        <p class=\"c-article-metrics-bar__count\">8 <span class=\"c-article-metrics-bar__label\">Citations</span></p>\n                    </li>\n                \n                \n                    \n                        <li class=\"c-article-metrics-bar__item\" data-test=\"altmetric-score\">\n                            <p class=\"c-article-metrics-bar__count\">2773 <span class=\"c-article-metrics-bar__label\">Altmetric</span></p>\n                        </li>\n                    \n                \n                <li class=\"c-article-metrics-bar__item\">\n                    <p class=\"c-article-metrics-bar__details\"><a href=\"/articles/s41586-024-07566-y/metrics\" data-track=\"click\" data-track-action=\"view metrics\" data-track-label=\"link\" rel=\"nofollow\">Metrics <span class=\"u-visually-hidden\">details</span></a></p>\n                </li>\n            </ul>\n        </div>\n    \n                    \n                </header>\n\n                \n    <div class=\"u-js-hide\" data-component=\"article-subject-links\">\n        <h3 class=\"c-article__sub-heading\">Subjects</h3>\n        <ul class=\"c-article-subject-list\">\n            <li class=\"c-article-subject-list__subject\"><a href=\"/subjects/computational-science\" data-track=\"click\" data-track-action=\"view subject\" data-track-label=\"link\">Computational science</a></li><li class=\"c-article-subject-list__subject\"><a href=\"/subjects/computer-science\" data-track=\"click\" data-track-action=\"view subject\" data-track-label=\"link\">Computer science</a></li>\n        </ul>\n    </div>\n\n                \n    \n    \n\n    \n    \n\n                \n            </div>\n\n        <div class=\"c-article-body\">\n            <section aria-labelledby=\"Abs1\" data-title=\"Abstract\" lang=\"en\"><div class=\"c-article-section\" id=\"Abs1-section\"><h2 class=\"c-article-section__title js-section-title js-c-reading-companion-sections-item\" id=\"Abs1\">Abstract</h2><div class=\"c-article-section__content\" id=\"Abs1-content\"><p>Stable diffusion revolutionized image creation from descriptive text. GPT-2 (ref. <sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 1\" title=\"Radford, A. et al. Language models are unsupervised multitask learners. OpenAI blog 1, 9 (2019).\" href=\"/articles/s41586-024-07566-y#ref-CR1\" id=\"ref-link-section-d34320735e541\">1</a></sup>), GPT-3(.5) (ref. <sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 2\" title=\"Brown, T. et al. Language models are few-shot learners. Adv. Neural Inf. Process. Syst. 33, 1877–1901 (2020).\" href=\"/articles/s41586-024-07566-y#ref-CR2\" id=\"ref-link-section-d34320735e545\">2</a></sup>) and GPT-4 (ref. <sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 3\" title=\"OpenAI. GPT-4 Technical Report. &#xA;                  https://cdn.openai.com/papers/gpt-4.pdf&#xA;                  &#xA;                 (2023).\" href=\"/articles/s41586-024-07566-y#ref-CR3\" id=\"ref-link-section-d34320735e549\">3</a></sup>) demonstrated high performance across a variety of language tasks. ChatGPT introduced such language models to the public. It is now clear that generative artificial intelligence (AI) such as large language models (LLMs) is here to stay and will substantially change the ecosystem of online text and images. Here we consider what may happen to GPT-{<i>n</i>} once LLMs contribute much of the text found online. We find that indiscriminate use of model-generated content in training causes irreversible defects in the resulting models, in which tails of the original content distribution disappear. We refer to this effect as ‘model collapse’ and show that it can occur in LLMs as well as in variational autoencoders (VAEs) and Gaussian mixture models (GMMs). We build theoretical intuition behind the phenomenon and portray its ubiquity among all learned generative models. We demonstrate that it must be taken seriously if we are to sustain the benefits of training from large-scale data scraped from the web. Indeed, the value of data collected about genuine human interactions with systems will be increasingly valuable in the presence of LLM-generated content in data crawled from the Internet.</p></div></div></section>\n\n            <noscript>\n                \n            </noscript>\n\n            \n\n            \n                \n                    \n        \n            <section aria-labelledby=\"inline-recommendations\" data-title=\"Inline Recommendations\" class=\"c-article-recommendations\" data-track-component=\"inline-recommendations\">\n                <h3 class=\"c-article-recommendations-title\" id=\"inline-recommendations\">Similar content being viewed by others</h3>\n                <div class=\"c-article-recommendations-list\">\n                    \n                        <div class=\"c-article-recommendations-list__item\">\n                            <article class=\"c-article-recommendations-card\" itemscope itemtype=\"http://schema.org/ScholarlyArticle\">\n                                \n                                    <div class=\"c-article-recommendations-card__img\"><img src=\"https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41598-024-55686-2/MediaObjects/41598_2024_55686_Fig1_HTML.png\" loading=\"lazy\" alt=\"\"></div>\n                                \n                                <div class=\"c-article-recommendations-card__main\">\n                                    <h3 class=\"c-article-recommendations-card__heading\" itemprop=\"name headline\">\n                                        <a class=\"c-article-recommendations-card__link\"\n                                           itemprop=\"url\"\n                                           href=\"https://www.nature.com/articles/s41598-024-55686-2?fromPaywallRec=false\"\n                                           data-track=\"select_recommendations_1\"\n                                           data-track-context=\"inline recommendations\"\n                                           data-track-action=\"click recommendations inline - 1\"\n                                           data-track-label=\"10.1038/s41598-024-55686-2\">Bias of AI-generated content: an examination of news produced by large language models\n                                        </a>\n                                    </h3>\n                                    <div class=\"c-article-meta-recommendations\" data-test=\"recommendation-info\">\n                                        <span class=\"c-article-meta-recommendations__item-type\">Article</span>\n                                         <span class=\"c-article-meta-recommendations__access-type\">Open access</span>\n                                         <span class=\"c-article-meta-recommendations__date\">04 March 2024</span>\n                                    </div>\n                                </div>\n                            </article>\n                        </div>\n                    \n                        <div class=\"c-article-recommendations-list__item\">\n                            <article class=\"c-article-recommendations-card\" itemscope itemtype=\"http://schema.org/ScholarlyArticle\">\n                                \n                                    <div class=\"c-article-recommendations-card__img\"><img src=\"https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41467-023-43713-1/MediaObjects/41467_2023_43713_Fig1_HTML.png\" loading=\"lazy\" alt=\"\"></div>\n                                \n                                <div class=\"c-article-recommendations-card__main\">\n                                    <h3 class=\"c-article-recommendations-card__heading\" itemprop=\"name headline\">\n                                        <a class=\"c-article-recommendations-card__link\"\n                                           itemprop=\"url\"\n                                           href=\"https://www.nature.com/articles/s41467-023-43713-1?fromPaywallRec=false\"\n                                           data-track=\"select_recommendations_2\"\n                                           data-track-context=\"inline recommendations\"\n                                           data-track-action=\"click recommendations inline - 2\"\n                                           data-track-label=\"10.1038/s41467-023-43713-1\">Augmenting interpretable models with large language models during training\n                                        </a>\n                                    </h3>\n                                    <div class=\"c-article-meta-recommendations\" data-test=\"recommendation-info\">\n                                        <span class=\"c-article-meta-recommendations__item-type\">Article</span>\n                                         <span class=\"c-article-meta-recommendations__access-type\">Open access</span>\n                                         <span class=\"c-article-meta-recommendations__date\">30 November 2023</span>\n                                    </div>\n                                </div>\n                            </article>\n                        </div>\n                    \n                        <div class=\"c-article-recommendations-list__item\">\n                            <article class=\"c-article-recommendations-card\" itemscope itemtype=\"http://schema.org/ScholarlyArticle\">\n                                \n                                    <div class=\"c-article-recommendations-card__img\"><img src=\"https://media.springernature.com/w215h120/springer-static/image/art%3A10.1038%2Fs41467-022-29632-7/MediaObjects/41467_2022_29632_Fig1_HTML.png\" loading=\"lazy\" alt=\"\"></div>\n                                \n                                <div class=\"c-article-recommendations-card__main\">\n                                    <h3 class=\"c-article-recommendations-card__heading\" itemprop=\"name headline\">\n                                        <a class=\"c-article-recommendations-card__link\"\n                                           itemprop=\"url\"\n                                           href=\"https://www.nature.com/articles/s41467-022-29632-7?fromPaywallRec=false\"\n                                           data-track=\"select_recommendations_3\"\n                                           data-track-context=\"inline recommendations\"\n                                           data-track-action=\"click recommendations inline - 3\"\n                                           data-track-label=\"10.1038/s41467-022-29632-7\">The neural coding framework for learning generative models\n                                        </a>\n                                    </h3>\n                                    <div class=\"c-article-meta-recommendations\" data-test=\"recommendation-info\">\n                                        <span class=\"c-article-meta-recommendations__item-type\">Article</span>\n                                         <span class=\"c-article-meta-recommendations__access-type\">Open access</span>\n                                         <span class=\"c-article-meta-recommendations__date\">19 April 2022</span>\n                                    </div>\n                                </div>\n                            </article>\n                        </div>\n                    \n                </div>\n            </section>\n        \n            <script>\n                window.dataLayer = window.dataLayer || [];\n                window.dataLayer.push({\n                    recommendations: {\n                        recommender: 'semantic',\n                        model: 'specter',\n                        policy_id: 'NA',\n                        timestamp: 1728497468,\n                        embedded_user: 'null'\n                    }\n                });\n            </script>\n        \n    \n                \n                \n                <div class=\"main-content\">\n                    <section data-title=\"Main\"><div class=\"c-article-section\" id=\"Sec1-section\"><h2 class=\"c-article-section__title js-section-title js-c-reading-companion-sections-item\" id=\"Sec1\">Main</h2><div class=\"c-article-section__content\" id=\"Sec1-content\"><p>The development of LLMs is very involved and requires large quantities of training data. Yet, although current LLMs<sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 2\" title=\"Brown, T. et al. Language models are few-shot learners. Adv. Neural Inf. Process. Syst. 33, 1877–1901 (2020).\" href=\"/articles/s41586-024-07566-y#ref-CR2\" id=\"ref-link-section-d34320735e583\">2</a>,<a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" title=\"Devlin, J., Chang, M.-W., Lee, K. &amp; Toutanova, K. in Proc. 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) (eds Burstein, J., Doran, C. &amp; Solorio, T.) 4171–4186 (Association for Computational Linguistics, 2019).\" href=\"#ref-CR4\" id=\"ref-link-section-d34320735e586\">4</a>,<a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" title=\"Liu, Y. et al. RoBERTa: a Robustly Optimized BERT Pretraining Approach. Preprint at \n                  https://arxiv.org/abs/1907.11692\n                  \n                 (2019).\" href=\"#ref-CR5\" id=\"ref-link-section-d34320735e586_1\">5</a>,<a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 6\" title=\"Zhang, S. et al. Opt: open pre-trained transformer language models. Preprint at \n                  https://arxiv.org/abs/2205.01068\n                  \n                 (2022).\" href=\"/articles/s41586-024-07566-y#ref-CR6\" id=\"ref-link-section-d34320735e589\">6</a></sup>, including GPT-3, were trained on predominantly human-generated text, this may change. If the training data of most future models are also scraped from the web, then they will inevitably train on data produced by their predecessors. In this paper, we investigate what happens when text produced by, for example, a version of GPT forms most of the training dataset of following models. What happens to GPT generations GPT-{<i>n</i>} as <i>n</i> increases? We discover that indiscriminately learning from data produced by other models causes ‘model collapse’—a degenerative process whereby, over time, models forget the true underlying data distribution, even in the absence of a shift in the distribution over time. We give examples of model collapse for GMMs, VAEs and LLMs. We show that, over time, models start losing information about the true distribution, which first starts with tails disappearing, and learned behaviours converge over the generations to a point estimate with very small variance. Furthermore, we show that this process is inevitable, even for cases with almost ideal conditions for long-term learning, that is, no function estimation error. We also briefly mention two close concepts to model collapse from the existing literature: catastrophic forgetting arising in the framework of task-free continual learning<sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 7\" title=\"Aljundi, R., Kelchtermans, K. &amp; Tuytelaars, T. Task-free continual learning. in: Proc. 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 11254–11263 (IEEE, 2019).\" href=\"/articles/s41586-024-07566-y#ref-CR7\" id=\"ref-link-section-d34320735e599\">7</a></sup> and data poisoning<sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 8\" title=\"Carlini, N. &amp; Terzis, A. in Proc. Tenth International Conference on Learning Representations (ICLR, 2022).\" href=\"/articles/s41586-024-07566-y#ref-CR8\" id=\"ref-link-section-d34320735e603\">8</a>,<a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 9\" title=\"Carlini, N. et al. in Proc. 2024 IEEE Symposium on Security and Privacy (SP) 179 (IEEE, 2024).\" href=\"/articles/s41586-024-07566-y#ref-CR9\" id=\"ref-link-section-d34320735e606\">9</a></sup> maliciously leading to unintended behaviour. Neither is able to explain the phenomenon of model collapse fully, as the setting is fundamentally different, but they provide another perspective on the observed phenomenon and are discussed in more depth in the&nbsp;<a data-track=\"click\" data-track-label=\"link\" data-track-action=\"supplementary material anchor\" href=\"/articles/s41586-024-07566-y#MOESM1\">Supplementary Materials</a>. Finally, we discuss the broader implications of model collapse. We note that access to the original data distribution is crucial: in learning tasks in which the tails of the underlying distribution matter, one needs access to real human-produced data. In other words, the use of LLMs at scale to publish content on the Internet will pollute the collection of data to train their successors: data about human interactions with LLMs will be increasingly valuable.</p></div></div></section><section data-title=\"What is model collapse?\"><div class=\"c-article-section\" id=\"Sec2-section\"><h2 class=\"c-article-section__title js-section-title js-c-reading-companion-sections-item\" id=\"Sec2\">What is model collapse?</h2><div class=\"c-article-section__content\" id=\"Sec2-content\">\n                <h3 class=\"c-article__sub-heading\" id=\"FPar1\">Definition 2.1 (model collapse)</h3>\n                <p>Model collapse is a degenerative process affecting generations of learned generative models, in which the data they generate end up polluting the training set of the next generation. Being trained on polluted data, they then mis-perceive reality. The process is depicted in Fig. <a data-track=\"click\" data-track-label=\"link\" data-track-action=\"figure anchor\" href=\"/articles/s41586-024-07566-y#Fig1\">1a</a>. We separate two special cases: early model collapse and late model collapse. In early model collapse, the model begins losing information about the tails of the distribution; in late model collapse, the model converges to a distribution that carries little resemblance to the original one, often with substantially reduced variance.</p>\n              <p>This process occurs owing to three specific sources of error compounding over generations and causing deviation from the original model:</p><ul class=\"u-list-style-bullet\">\n                <li>\n                  <p><b>Statistical approximation error.</b> This is the primary type of error, which arises owing to the number of samples being finite, and disappears as the number of samples tends to infinity. This occurs because of a non-zero probability that information can get lost at every step of resampling.</p>\n                </li>\n                <li>\n                  <p><b>Functional expressivity error.</b> This is a secondary type of error, arising owing to limited function approximator expressiveness. In particular, neural networks are only universal approximators as their size goes to infinity. As a result, a neural network can introduce non-zero likelihood outside the support of the original distribution or zero likelihood inside the support of the original distribution. A simple example of the expressivity error is if we tried fitting a mixture of two Gaussians with a single Gaussian. Even if we have perfect information about the data distribution (that is, infinite number of samples), model errors will be inevitable. However, in the absence of the other two types of error, this can only occur at the first generation.</p>\n                </li>\n                <li>\n                  <p><b>Functional approximation error.</b> This is a secondary type of error, arising primarily from the limitations of learning procedures, for example, structural bias of stochastic gradient descent<sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 10\" title=\"Mousavi-Hosseini, A., Park, S., Girotti, M., Mitliagkas, I. &amp; Erdogdu, M. A. in Proc. Eleventh International Conference on Learning Representations (ICLR, 2023).\" href=\"/articles/s41586-024-07566-y#ref-CR10\" id=\"ref-link-section-d34320735e657\">10</a>,<a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 11\" title=\"Soudry, D., Hoffer, E., Nacson, M. S., Gunasekar, S. &amp; Srebro, N. The implicit bias of gradient descent on separable data. J. Mach. Learn. Res. 19, 1–57 (2018).\" href=\"/articles/s41586-024-07566-y#ref-CR11\" id=\"ref-link-section-d34320735e660\">11</a></sup> or choice of objective<sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 12\" title=\"Gu, Y., Dong, L., Wei, F. &amp; Huang, M. in Proc. Twelfth International Conference on Learning Representations (ICLR, 2024).\" href=\"/articles/s41586-024-07566-y#ref-CR12\" id=\"ref-link-section-d34320735e664\">12</a></sup>. This error can be viewed as one arising in the limit of infinite data and perfect expressivity at each generation.</p>\n                </li>\n              </ul><p>Each of the above can cause model collapse to get worse or better. More approximation power can even be a double-edged sword—better expressiveness may counteract statistical noise, resulting in a good approximation of the true distribution, but it can equally compound the noise. More often than not, we get a cascading effect, in which individual inaccuracies combine to cause the overall error to grow. For example, overfitting the density model causes the model to extrapolate incorrectly and assigns high-density regions to low-density regions not covered in the training set support; these will then be sampled with arbitrary frequency. It is worth noting that other types of error exist. For example, computers have limited precision in practice. We now turn to mathematical intuition to explain how the above give rise to the errors observed, how different sources can compound and how we can quantify the average model divergence.</p></div></div></section><section data-title=\"Theoretical intuition\"><div class=\"c-article-section\" id=\"Sec3-section\"><h2 class=\"c-article-section__title js-section-title js-c-reading-companion-sections-item\" id=\"Sec3\">Theoretical intuition</h2><div class=\"c-article-section__content\" id=\"Sec3-content\"><p>Here we provide a theoretical intuition for the phenomenon of model collapse. We argue that the process of model collapse is universal among generative models that recursively train on data generated by previous generations. We quantify the sources of errors discussed in the previous section by examining two mathematical models, which prove to be simple enough to provide analytical expressions for quantities of interest, but also portray the phenomenon of model collapse: a discrete distribution in the absence of functional expressivity and approximation errors, and a multidimensional Gaussian approximation, portraying joint functional expressivity and statistical errors. We further illustrate the impact of all three jointly for a more complex setting of density estimation in Hilbert spaces in the <a data-track=\"click\" data-track-label=\"link\" data-track-action=\"supplementary material anchor\" href=\"/articles/s41586-024-07566-y#MOESM1\">Supplementary Materials</a>.</p><p>The overall stochastic process we consider, which we call learning with generational data, is the following. The dataset at generation <i>i</i> is <span class=\"mathjax-tex\">\\({{\\mathcal{D}}}_{i}\\)</span>, comprising independent and identically distributed random variables <span class=\"mathjax-tex\">\\({X}_{j}^{i}\\)</span> with distribution <i>p</i><sub><i>i</i></sub>, <i>j</i> <span class=\"stix\">∈</span> {1,…, <i>M</i><sub><i>i</i></sub>} denotes the size of the dataset. Going from generation <i>i</i> to generation <i>i</i> + 1, we aim to estimate the distribution of samples in <span class=\"mathjax-tex\">\\({{\\mathcal{D}}}_{i}\\)</span>, with an approximation <span class=\"mathjax-tex\">\\({p}_{{\\theta }_{i+1}}\\)</span>. This step is what we refer to as functional approximation, <span class=\"mathjax-tex\">\\({p}_{{\\theta }_{i+1}}={{\\mathcal{F}}}_{\\theta }({p}_{i})\\)</span>. The dataset <span class=\"mathjax-tex\">\\({{\\mathcal{D}}}_{i+1}\\)</span> is then generated by sampling from <span class=\"mathjax-tex\">\\({p}_{i+1}={\\alpha }_{i}{p}_{{\\theta }_{i+1}}+{\\beta }_{i}{p}_{i}+{\\gamma }_{i}{p}_{0}\\)</span>, with non-negative parameters <i>α</i><sub><i>i</i></sub>, <i>β</i><sub><i>i</i></sub>, <i>γ</i><sub><i>i</i></sub> summing to 1, that is, they represent proportions of data used from different generations. This corresponds to a mixing of data coming from the original distribution (<i>γ</i><sub><i>i</i></sub>), data used by the previous generation (<i>β</i><sub><i>i</i></sub>) and data generated by the new model (<i>α</i><sub><i>i</i></sub>). We refer to this as the sampling step. For the mathematical models to come, we consider <i>α</i><sub><i>i</i></sub> = <i>γ</i><sub><i>i</i></sub> = 0, that is, data only from a single step are used, whereas numerical experiments are performed on more realistic choices of parameters.</p><h3 class=\"c-article__sub-heading\" id=\"Sec4\">Discrete distributions with exact approximation</h3><p>In this subsection, we consider a discrete probability distribution in absence of functional approximation and expressivity errors, that is, <span class=\"mathjax-tex\">\\({\\mathcal{F}}(p)=p\\)</span>. In this case, model collapse arises only because of statistical errors from the sampling step. At first, the tails (low-probability events) begin to disappear as a result of the low probability of sampling them and, over time, support of&nbsp;the distribution shrinks. Denoting the sample size as <i>M</i>, if we consider state <i>i</i> with probability <span class=\"mathjax-tex\">\\(q\\le \\frac{1}{M}\\)</span>, the expected number of samples with value <i>i</i> coming from those events will be less than 1. In practice, this would mean that we lose information about them. Considering more generally some state <i>i</i> with probability <i>q</i>, using standard conditional probability, we can show that the probability of losing information (that is, sampling no data at some generation) is equal to 1 − <i>q</i>, implying that the distribution must converge to a delta function positioned at some state, with the probability of ending up at a certain state equal to the probability of sampling said state from the original distribution.</p><p>This can be shown directly by considering the process <span class=\"mathjax-tex\">\\({{\\bf{X}}}^{i}\\to {\\mathcal{F}}\\,\\to \\)</span><span class=\"mathjax-tex\">\\({p}_{i+1}\\to {{\\bf{X}}}^{i+1}\\)</span> as a Markov chain, as <b>X</b><sup><i>i</i>+1</sup> only depends on <b>X</b><sup><i>i</i></sup>. Furthermore, if all the <span class=\"mathjax-tex\">\\({X}_{j}^{i}\\)</span> have the same value, then at the next generation, the approximated distribution will be exactly a delta function and therefore all of <span class=\"mathjax-tex\">\\({X}_{j}^{i+1}\\)</span> will also have the same value. This implies that the Markov chain contains at least one absorbing state and therefore, with probability 1, it will converge to one of the absorbing states. This is a well-known fact, of which a proof is provided in the <a data-track=\"click\" data-track-label=\"link\" data-track-action=\"supplementary material anchor\" href=\"/articles/s41586-024-07566-y#MOESM1\">Supplementary Materials</a>. For this chain, the only absorbing states are those corresponding to delta functions. As a result, as we follow the progress of model collapse, we are guaranteed to end up in a constant state, having lost all the information of the original distribution when the chain is absorbed. This argument also works in general owing to floating-point representations being discrete, making the Markov chain over the parameters of the model discrete. Thus, as long as the model parameterization allows for delta functions, we will get to it, because—owing to sampling errors—the only possible absorbing states are delta functions. On the basis of the discussion above, we see how both early model collapse, in which only the low-probability events get cut off, and late stage model collapse, in which the process begins to collapse into a single mode, must arise in the case of discrete distributions with perfect functional approximation.</p><h3 class=\"c-article__sub-heading\" id=\"Sec5\">Multidimensional Gaussian</h3><p>Following the discussion about discrete distributions, we now present a more generic result, which can be shown in the Gaussian approximation setting, in which each generation is approximated using the unbiased estimates of the mean and the variance. A similar result holds more generally, which we detail in the&nbsp;<a data-track=\"click\" data-track-label=\"link\" data-track-action=\"supplementary material anchor\" href=\"/articles/s41586-024-07566-y#MOESM1\">Supplementary Materials</a>.</p>\n                  <h3 class=\"c-article__sub-heading\" id=\"FPar2\">Theorem 3.1 (Gaussian model collapse)</h3>\n                  <p>Assume the original data are sampled from distribution <span class=\"mathjax-tex\">\\({{\\mathcal{D}}}_{0}\\)</span> (not necessarily Gaussian), with non-zero sample variance. Assume <i>X</i><sup><i>n</i></sup> are fit recursively using the unbiased sample mean and variance estimators from the previous generation, <span class=\"mathjax-tex\">\\({X}_{j}^{n}| {\\mu }_{n},{\\Sigma }_{n} \\sim {\\mathcal{N}}({\\mu }_{n},{\\Sigma }_{n})\\)</span>, with a fixed sample size. Then,</p><div id=\"Equa\" class=\"c-article-equation\"><div class=\"c-article-equation__content\"><span class=\"mathjax-tex\">$${\\mathbb{E}}[{{\\mathbb{W}}}_{2}^{2}({\\mathcal{N}}({\\mu }_{n},{\\Sigma }_{n}),{{\\mathcal{D}}}_{0})]\\to \\infty ;\\,{\\Sigma }_{n}\\,\\mathop{\\to }\\limits^{{\\rm{a}}.{\\rm{s}}.}\\,0\\,\\,{\\rm{a}}{\\rm{s}}\\,\\,n\\to \\infty ,$$</span></div></div><p>in which <span class=\"mathjax-tex\">\\({{\\mathbb{W}}}_{2}\\)</span> denotes the Wasserstein-2 distance between the true distribution and its approximation at generation <i>n</i>.</p>\n                <p>In words, this implies that not only does the <i>n</i>th generation approximation diverge arbitrarily far from the original one but it also collapses to be zero variance as the number of generations increases, with probability 1. The results are very analogous to that seen in the discrete case, with this theorem illustrating the effect of late stage model collapse, in which the process begins to collapse to be zero variance. The early stage model collapse can also be seen and the interested reader is referred to the&nbsp;<a data-track=\"click\" data-track-label=\"link\" data-track-action=\"supplementary material anchor\" href=\"/articles/s41586-024-07566-y#MOESM1\">Supplementary Materials</a> for a more in-depth discussion.</p></div></div></section><section data-title=\"Model collapse in language models\"><div class=\"c-article-section\" id=\"Sec6-section\"><h2 class=\"c-article-section__title js-section-title js-c-reading-companion-sections-item\" id=\"Sec6\">Model collapse in language models</h2><div class=\"c-article-section__content\" id=\"Sec6-content\"><p>In this section, we evaluate the effect of model collapse on language models. We cover more interpretable machine learning models—VAEs and GMMs—in the&nbsp;<a data-track=\"click\" data-track-label=\"link\" data-track-action=\"supplementary material anchor\" href=\"/articles/s41586-024-07566-y#MOESM1\">Supplementary Materials</a>. Code is publically available in ref. <sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 13\" title=\"Shumailov, I. &amp; Shumaylov, Z. Public code for Model Collapse (0.1). Zenodo \n                  https://doi.org/10.5281/zenodo.10866595\n                  \n                 (2024).\" href=\"/articles/s41586-024-07566-y#ref-CR13\" id=\"ref-link-section-d34320735e1881\">13</a></sup>.</p><p>Model collapse is universal across various families of machine learning models. Yet, if small models such as GMMs and VAEs are normally trained from scratch, LLMs are different. They are so expensive to retrain from scratch that they are typically initialized with pre-trained models such as BERT<sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 4\" title=\"Devlin, J., Chang, M.-W., Lee, K. &amp; Toutanova, K. in Proc. 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) (eds Burstein, J., Doran, C. &amp; Solorio, T.) 4171–4186 (Association for Computational Linguistics, 2019).\" href=\"/articles/s41586-024-07566-y#ref-CR4\" id=\"ref-link-section-d34320735e1888\">4</a></sup>, RoBERTa<sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 5\" title=\"Liu, Y. et al. RoBERTa: a Robustly Optimized BERT Pretraining Approach. Preprint at \n                  https://arxiv.org/abs/1907.11692\n                  \n                 (2019).\" href=\"/articles/s41586-024-07566-y#ref-CR5\" id=\"ref-link-section-d34320735e1892\">5</a></sup> or GPT-2 (ref. <sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 2\" title=\"Brown, T. et al. Language models are few-shot learners. Adv. Neural Inf. Process. Syst. 33, 1877–1901 (2020).\" href=\"/articles/s41586-024-07566-y#ref-CR2\" id=\"ref-link-section-d34320735e1896\">2</a></sup>), which are trained on large text corpora. They are then fine-tuned to various downstream&nbsp;tasks<sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 14\" title=\"Bommasani, R. et al. On the opportunities and risks of foundation models. Preprint at \n                  https://arxiv.org/abs/2108.07258\n                  \n                 (2022).\" href=\"/articles/s41586-024-07566-y#ref-CR14\" id=\"ref-link-section-d34320735e1900\">14</a></sup>.</p><p>Here we explore what happens with language models when they are sequentially fine-tuned with data generated by other models. We can easily replicate all experiments covered in this paper with larger language models in non-fine-tuning settings to demonstrate model collapse. Given that training a single moderately large model produces twice the American lifetime’s worth of CO<sub>2</sub> (ref. <sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 15\" title=\"Strubell, E., Ganesh, A. &amp; McCallum, A. in Proc. 57th Annual Meeting of the Association for Computational Linguistics (eds Korhonen, A., Traum, D. &amp; Màrquez, L.) 3645–3650 (Association for Computational Linguistics, 2019).\" href=\"/articles/s41586-024-07566-y#ref-CR15\" id=\"ref-link-section-d34320735e1909\">15</a></sup>), we opted to not run such an experiment and instead focus on a more realistic setting for a proof of concept. Note that even the language experiments described in this paper took weeks to run. We evaluate the most common setting of training a language model—a fine-tuning setting for which each of the training cycles starts from a pre-trained model with recent data. The data here come from another fine-tuned pre-trained model. Because training is restricted to produce models that are close to the original pre-trained model, and data points generated by the models will generally produce very small gradients, the expectation here may be that the model should only change moderately after fine-tuning. We fine-tune the OPT-125m causal language model made available by Meta through Hugging Face<sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 6\" title=\"Zhang, S. et al. Opt: open pre-trained transformer language models. Preprint at \n                  https://arxiv.org/abs/2205.01068\n                  \n                 (2022).\" href=\"/articles/s41586-024-07566-y#ref-CR6\" id=\"ref-link-section-d34320735e1913\">6</a></sup>.</p><p>We fine-tune it on the wikitext2 dataset<sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 16\" title=\"Merity, S., Xiong, C., Bradbury, J. &amp; Socher, R. in Proc. 5th International Conference on Learning Representations (ICLR, 2017).\" href=\"/articles/s41586-024-07566-y#ref-CR16\" id=\"ref-link-section-d34320735e1920\">16</a></sup>. For data generation from the trained models, we use a five-way beam search. We block training sequences to be 64 tokens long; then, for each token sequence in the training set, we ask the model to predict the next 64 tokens. We go through all of the original training dataset and produce an artificial dataset of the same size. Because we go through all of the original dataset and predict all of the blocks, if the model had 0 error, it would produce the original wikitext2 dataset. Training for each generation starts with generation from the original training data. Each experiment is run five times and the results are shown as five separate runs with different randomness seeds. The original model fine-tuned with real wikitext2 data obtains 34 mean perplexity, from the zero-shot baseline of 115, that is, it successfully learns the task. Finally, to be as realistic as possible, we use the best-performing model on the original task, evaluated using the original wikitext2 validation set, as the base model for the subsequent generations, meaning that—in practice—observed model collapse can be even more pronounced. Here we consider two different settings:</p><ul class=\"u-list-style-bullet\">\n                <li>\n                  <p>Five epochs, no original training data. Here the model is trained for five epochs starting on the original dataset but with no original data retained for subsequent runs. The overall original task performance is presented in Fig. <a data-track=\"click\" data-track-label=\"link\" data-track-action=\"figure anchor\" href=\"/articles/s41586-024-07566-y#Fig1\">1b</a>. We find that training with generated data allows us to adapt to the underlying task, losing some performance, from 20 to 28 perplexity points.</p>\n                </li>\n                <li>\n                  <p>Ten epochs, 10% of original training data preserved. Here the model is trained for ten epochs on the original dataset and with every new generation of training, a random 10% of the original data points is sampled. The overall original task performance is presented in Fig. <a data-track=\"click\" data-track-label=\"link\" data-track-action=\"figure anchor\" href=\"/articles/s41586-024-07566-y#Fig1\">1c</a>. We find that preservation of the original data allows for better model fine-tuning and leads to only minor degradation of performance.</p>\n                </li>\n              </ul><p>Both training regimes lead to degraded performance in our models, yet we do find that learning with generated data is possible and models can successfully learn (some of) the underlying task. In particular, from Fig. <a data-track=\"click\" data-track-label=\"link\" data-track-action=\"figure anchor\" href=\"/articles/s41586-024-07566-y#Fig1\">1</a> and their 3D versions in the&nbsp;<a data-track=\"click\" data-track-label=\"link\" data-track-action=\"supplementary material anchor\" href=\"/articles/s41586-024-07566-y#MOESM1\">Supplementary Materials</a>, we see that model collapse occurs, as the density of samples with low perplexity begins to accumulate over the generations. This in turn makes it likely that, over the generations, the sampled data will similarly collapse to a delta function.</p><div class=\"c-article-section__figure js-c-reading-companion-figures-item\" data-test=\"figure\" data-container-section=\"figure\" id=\"figure-1\" data-title=\"The high-level description of the feedback mechanism in the learning process.\"><figure><figcaption><b id=\"Fig1\" class=\"c-article-section__figure-caption\" data-test=\"figure-caption-text\">Fig. 1: The high-level description of the feedback mechanism in the learning process.</b></figcaption><div class=\"c-article-section__figure-content\"><div class=\"c-article-section__figure-item\"><a class=\"c-article-section__figure-link\" data-test=\"img-link\" data-track=\"click\" data-track-label=\"image\" data-track-action=\"view figure\" href=\"/articles/s41586-024-07566-y/figures/1\" rel=\"nofollow\"><picture><source type=\"image/webp\" srcset=\"//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41586-024-07566-y/MediaObjects/41586_2024_7566_Fig1_HTML.png?as=webp\"><img aria-describedby=\"Fig1\" src=\"//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41586-024-07566-y/MediaObjects/41586_2024_7566_Fig1_HTML.png\" alt=\"figure 1\" loading=\"lazy\" width=\"685\" height=\"739\"></picture></a></div><div class=\"c-article-section__figure-description\" data-test=\"bottom-caption\" id=\"figure-1-desc\"><p><b>a</b>, Model collapse refers to a degenerative learning process in which models start forgetting improbable events over time, as the model becomes poisoned with its own projection of reality. Here data are assumed to be human-curated and start off clean; then model 0 is trained and data are sampled from it; at step <i>n</i>, data are added to the overall data from step <i>n</i> − 1 and this combination is used to train model <i>n</i>. Data obtained with Monte Carlo sampling should ideally be statistically close to the original, provided that fitting and sampling procedures are perfect. This process depicts what happens in real life with the Internet: model-generated data become pervasive. <b>b</b>,<b>c</b>, Performance of OPT-125m models of different generations evaluated using the original wikitext2 test dataset. Shown on the left are the histograms of perplexities of each individual data training sequence produced by different generations as evaluated by the very first model trained with the real data. Over the generations, models tend to produce samples that the original model trained with real data is more likely to produce. At the same time, a much longer tail appears for later generations. Later generations start producing samples that would never be produced by the original model, that is, they start misperceiving reality based on errors introduced by their ancestors. The same plots are shown in 3D in the <a data-track=\"click\" data-track-label=\"link\" data-track-action=\"supplementary material anchor\" href=\"/articles/s41586-024-07566-y#MOESM1\">Supplementary Materials</a>. On the right, average perplexity and its standard deviation are shown for each independent run. The <i>x</i> axis refers to the generation of the model. ‘Real’ refers to the ‘model 0’ trained on the original wikitext2 dataset; model 1 was trained on the data produced by model 0, model 2 was trained on data produced by model 1 and so on, with all generated datasets equal in size. We find that models trained on generated data are able to learn some of the original task, but with errors, as seen from the increase in perplexity.</p></div></div><div class=\"u-text-right u-hide-print\"><a class=\"c-article__pill-button\" data-test=\"article-link\" data-track=\"click\" data-track-label=\"button\" data-track-action=\"view figure\" href=\"/articles/s41586-024-07566-y/figures/1\" data-track-dest=\"link:Figure1 Full size image\" aria-label=\"Full size image figure 1\" rel=\"nofollow\"><span>Full size image</span><svg width=\"16\" height=\"16\" focusable=\"false\" role=\"img\" aria-hidden=\"true\" class=\"u-icon\"><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#icon-eds-i-chevron-right-small\"></use></svg></a></div></figure></div><p>It is important to note here that the observed behaviour is in line with the general intuition established in the section ‘Theoretical intuition’. To be precise, in all experiments, generational learning is only performed on a finite (usually small) number of generations, whereas claims of the section ‘Theoretical intuition’ are mostly presented in the limit of generations going to infinity. However, as seen from experiments on VAEs and GMMs in the&nbsp;<a data-track=\"click\" data-track-label=\"link\" data-track-action=\"supplementary material anchor\" href=\"/articles/s41586-024-07566-y#MOESM1\">Supplementary Materials</a>, convergence to delta functions and specific rates of such convergence are highly related to the specifics of the problem considered, and complete collapse may or may not occur, even after a small number of steps. This is further illustrated theoretically in the&nbsp;<a data-track=\"click\" data-track-label=\"link\" data-track-action=\"supplementary material anchor\" href=\"/articles/s41586-024-07566-y#MOESM1\">Supplementary Materials</a>, in which potentially notable divergence from the original model can occur even after a few generations.</p><p>Figure <a data-track=\"click\" data-track-label=\"link\" data-track-action=\"figure anchor\" href=\"/articles/s41586-024-07566-y#Fig1\">1b,c</a> on the left shows histograms of individual data-point perplexities generated by the models of different generations as is evaluated by the first model developed with real wikitext2 training data. Here, over the generations, models tend to produce more sequences that the original model would produce with the higher likelihood. The observed effect is similar to that described for VAEs and GMMs in the&nbsp;<a data-track=\"click\" data-track-label=\"link\" data-track-action=\"supplementary material anchor\" href=\"/articles/s41586-024-07566-y#MOESM1\">Supplementary Materials</a>, in which—over the generations—models started to produce samples that would be produced with higher probabilities by the original model. At the same time, we discover that generated data have much longer tails, suggesting that some of the data would never be produced by the original model—these are the errors that accumulate because of the learning with generational data.</p>\n                <h3 class=\"c-article__sub-heading\" id=\"FPar3\">Example 1</h3>\n                <p>Example of text outputs of an OPT-125m model affected by model collapse—models degrade over generations, for which each new generation is trained on data produced by the previous generation.</p><ul class=\"u-list-style-bullet\">\n                  <li>\n                    <p><b>Input:</b> some started before 1360 — was typically accomplished by a master mason and a small team of itinerant masons, supplemented by local parish labourers, according to Poyntz Wright. But other authors reject this model, suggesting instead that leading architects designed the parish church towers based on early examples of Perpendicular.</p>\n                  </li>\n                  <li>\n                    <p><b>Outputs:</b></p>\n                  </li>\n                  <li>\n                    <p><b>Gen 0:</b> Revival architecture such as St. John’s Cathedral in London. The earliest surviving example of Perpendicular Revival architecture is found in the 18th @-@ century Church of Our Lady of Guernsey, which dates from the late 19th century. There are two types of perpendicular churches : those.</p>\n                  </li>\n                  <li>\n                    <p><b>Gen 1:</b> architecture such as St. Peter’s Basilica in Rome or St. Peter’s Basilica in Buenos Aires. There is no evidence that any of these buildings were built during the reign of Pope Innocent III, but it is possible that they may have been built during the reign of his successor, Pope Innocent.</p>\n                  </li>\n                  <li>\n                    <p><b>Gen 5:</b> ism, which had been translated into more than 100 languages including English, French, German, Italian, Spanish, Portuguese, Dutch, Swedish, Norwegian, Polish, Hungarian, Slovak, Lithuanian, Estonian, Finnish, Romanian, Bulgarian, Turkish, Croatian, Serbian, Ukrainian, Russian, Kazakh, Kyrgyz.</p>\n                  </li>\n                  <li>\n                    <p><b>Gen 9:</b> architecture. In addition to being home to some of the world’s largest populations of black @-@ tailed jackrabbits, white @-@ tailed jackrabbits, blue @-@ tailed jackrabbits, red @-@ tailed jackrabbits, yellow @-.</p>\n                  </li>\n                </ul>\n              <h3 class=\"c-article__sub-heading\" id=\"Sec7\">Ablation: Repetitions</h3><p>We find that data generated by language models in our experiments end up containing a large number of repeating phrases, as in Example 1. The repeating problem has been observed in nearly all text-generation models<sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 17\" title=\"Keskar, N. S., McCann, B., Varshney, L. R., Xiong, C. &amp; Socher, R. CTRL: a conditional transformer language model for controllable generation. Preprint at \n                  https://arxiv.org/abs/1909.05858\n                  \n                 (2019).\" href=\"/articles/s41586-024-07566-y#ref-CR17\" id=\"ref-link-section-d34320735e2081\">17</a>,<a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 18\" title=\"Shumailov, I. et al. in Proc. 2021 IEEE European Symposium on Security and Privacy (EuroS&amp;P) 212–231 (IEEE, 2021).\" href=\"/articles/s41586-024-07566-y#ref-CR18\" id=\"ref-link-section-d34320735e2084\">18</a></sup> and, to rule this out as the cause of model collapse, we further provide numerical experiments when models are explicitly encouraged to produce non-repeating sequences with a repeating penalty of 2.0. We find that this causes the models to produce lower score continuations to avoid using repeats, which—as a result—causes the consequent models to perform even worse. Model perplexities shift across the generations towards more probable token sequences, as measured using the model trained on the original real data distribution. Further illustrations are provided in the&nbsp;<a data-track=\"click\" data-track-label=\"link\" data-track-action=\"supplementary material anchor\" href=\"/articles/s41586-024-07566-y#MOESM1\">Supplementary Materials</a>. In particular, enforcing this for the LLM experiments causes the perplexity to double compared with the original. Models remain as susceptible to model collapse, if not more.</p><p>The described process demonstrates that fine-tuning of language models does not curb the effects of model collapse and models that are being fine-tuned are also vulnerable. We find that, over the generations, models tend to produce more probable sequences from the original data and start introducing their own improbable sequences, that is, errors.</p></div></div></section><section data-title=\"Discussion\"><div class=\"c-article-section\" id=\"Sec8-section\"><h2 class=\"c-article-section__title js-section-title js-c-reading-companion-sections-item\" id=\"Sec8\">Discussion</h2><div class=\"c-article-section__content\" id=\"Sec8-content\"><p>We now discuss the implications of model collapse on the underlying learning dynamics of LLMs. Long-term poisoning attacks on language models are not new. For example, we saw the creation of click, content and troll farms, a form of human ‘language models’, whose job is to misguide social networks and search algorithms. The negative effect that these poisoning attacks had on search results led to changes in search algorithms. For example, Google downgraded farmed articles<sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 19\" title=\"Google. Finding more high-quality sites in search. Google \n                  https://googleblog.blogspot.com/2011/02/finding-more-high-quality-sites-in.html\n                  \n                 (2011).\" href=\"/articles/s41586-024-07566-y#ref-CR19\" id=\"ref-link-section-d34320735e2103\">19</a></sup>, putting more emphasis on content produced by trustworthy sources, such as education domains, whereas DuckDuckGo removed them altogether<sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 20\" title=\"Mims, C. The search engine backlash against ‘content mills’. MIT Technology Review \n                  https://www.technologyreview.com/2010/07/26/26327/the-search-engine-backlash-against-content-mills/\n                  \n                 (2010).\" href=\"/articles/s41586-024-07566-y#ref-CR20\" id=\"ref-link-section-d34320735e2107\">20</a></sup>. What is different with the arrival of LLMs is the scale at which such poisoning can happen once it is automated. Preserving the ability of LLMs to model low-probability events is essential to the fairness of their predictions: such events are often relevant to marginalized groups. Low-probability events are also vital to understand complex systems<sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 21\" title=\"Taleb, N. N. Black swans and the domains of statistics. Am. Stat. 61, 198–200 (2007).\" href=\"/articles/s41586-024-07566-y#ref-CR21\" id=\"ref-link-section-d34320735e2111\">21</a></sup>.</p><p>Our evaluation suggests a ‘first mover advantage’ when it comes to training models such as LLMs. In our work, we demonstrate that training on samples from another generative model can induce a distribution shift, which—over time—causes model collapse. This in turn causes the model to mis-perceive the underlying learning task. To sustain learning over a long period of time, we need to make sure that access to the original data source is preserved and that further data not generated by LLMs remain available over time. The need to distinguish data generated by LLMs from other data raises questions about the provenance of content that is crawled from the Internet: it is unclear how content generated by LLMs can be tracked at scale. One option is community-wide coordination to ensure that different parties involved in LLM creation and deployment share the information needed to resolve questions of provenance. Otherwise, it may become increasingly difficult to train newer versions of LLMs without access to data that were crawled from the Internet before the mass adoption of the technology or direct access to data generated by humans at scale.</p></div></div></section>\n                </div>\n            \n\n            <div>\n                <section data-title=\"Data availability\"><div class=\"c-article-section\" id=\"data-availability-section\"><h2 class=\"c-article-section__title js-section-title js-c-reading-companion-sections-item\" id=\"data-availability\">Data availability</h2><div class=\"c-article-section__content\" id=\"data-availability-content\">\n              \n              <p>Data generation code for GMM experiments is available in ref. <sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 13\" title=\"Shumailov, I. &amp; Shumaylov, Z. Public code for Model Collapse (0.1). Zenodo &#xA;                  https://doi.org/10.5281/zenodo.10866595&#xA;                  &#xA;                 (2024).\" href=\"/articles/s41586-024-07566-y#ref-CR13\" id=\"ref-link-section-d34320735e2200\">13</a></sup>. Data used for VAE experiments are available in ref. <sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 22\" title=\"LeCun, Y., Cortes, C. &amp; Burges, C. J. C. The MNIST database of handwritten digits. &#xA;                  http://yann.lecun.com/exdb/mnist/&#xA;                  &#xA;                 (1998).\" href=\"/articles/s41586-024-07566-y#ref-CR22\" id=\"ref-link-section-d34320735e2204\">22</a></sup>. Data used for LLM experiments are available in ref. <sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 16\" title=\"Merity, S., Xiong, C., Bradbury, J. &amp; Socher, R. in Proc. 5th International Conference on Learning Representations (ICLR, 2017).\" href=\"/articles/s41586-024-07566-y#ref-CR16\" id=\"ref-link-section-d34320735e2208\">16</a></sup>.</p>\n            </div></div></section><section data-title=\"Code availability\"><div class=\"c-article-section\" id=\"code-availability-section\"><h2 class=\"c-article-section__title js-section-title js-c-reading-companion-sections-item\" id=\"code-availability\">Code availability</h2><div class=\"c-article-section__content\" id=\"code-availability-content\">\n              \n              <p>Code for all experiments is publically available in ref. <sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 13\" title=\"Shumailov, I. &amp; Shumaylov, Z. Public code for Model Collapse (0.1). Zenodo &#xA;                  https://doi.org/10.5281/zenodo.10866595&#xA;                  &#xA;                 (2024).\" href=\"/articles/s41586-024-07566-y#ref-CR13\" id=\"ref-link-section-d34320735e2220\">13</a></sup>.</p>\n            </div></div></section><div id=\"MagazineFulltextArticleBodySuffix\"><section aria-labelledby=\"Bib1\" data-title=\"References\"><div class=\"c-article-section\" id=\"Bib1-section\"><h2 class=\"c-article-section__title js-section-title js-c-reading-companion-sections-item\" id=\"Bib1\">References</h2><div class=\"c-article-section__content\" id=\"Bib1-content\"><div data-container-section=\"references\"><ol class=\"c-article-references\" data-track-component=\"outbound reference\" data-track-context=\"references section\"><li class=\"c-article-references__item js-c-reading-companion-references-item\" data-counter=\"1.\"><p class=\"c-article-references__text\" id=\"ref-CR1\">Radford, A. et al. Language models are unsupervised multitask learners. <i>OpenAI blog</i> <b>1</b>, 9 (2019).</p><p class=\"c-article-references__links u-hide-print\"><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 1\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Language%20models%20are%20unsupervised%20multitask%20learners&amp;journal=OpenAI%20blog&amp;volume=1&amp;publication_year=2019&amp;author=Radford%2CA\">\n                    Google Scholar</a> \n                </p></li><li class=\"c-article-references__item js-c-reading-companion-references-item\" data-counter=\"2.\"><p class=\"c-article-references__text\" id=\"ref-CR2\">Brown, T. et al. Language models are few-shot learners. <i>Adv. Neural Inf. Process. Syst.</i> <b>33</b>, 1877–1901 (2020).</p><p class=\"c-article-references__links u-hide-print\"><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 2\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Language%20models%20are%20few-shot%20learners&amp;journal=Adv.%20Neural%20Inf.%20Process.%20Syst.&amp;volume=33&amp;pages=1877-1901&amp;publication_year=2020&amp;author=Brown%2CT\">\n                    Google Scholar</a> \n                </p></li><li class=\"c-article-references__item js-c-reading-companion-references-item\" data-counter=\"3.\"><p class=\"c-article-references__text\" id=\"ref-CR3\">OpenAI. GPT-4 Technical Report. <a href=\"https://cdn.openai.com/papers/gpt-4.pdf\" data-track=\"click_references\" data-track-action=\"external reference\" data-track-value=\"external reference\" data-track-label=\"https://cdn.openai.com/papers/gpt-4.pdf\">https://cdn.openai.com/papers/gpt-4.pdf</a> (2023).</p></li><li class=\"c-article-references__item js-c-reading-companion-references-item\" data-counter=\"4.\"><p class=\"c-article-references__text\" id=\"ref-CR4\">Devlin, J., Chang, M.-W., Lee, K. &amp; Toutanova, K. in <i>Proc. 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</i> (eds Burstein, J., Doran, C. &amp; Solorio, T.) 4171–4186 (Association for Computational Linguistics, 2019).</p></li><li class=\"c-article-references__item js-c-reading-companion-references-item\" data-counter=\"5.\"><p class=\"c-article-references__text\" id=\"ref-CR5\">Liu, Y. et al. RoBERTa: a Robustly Optimized BERT Pretraining Approach. Preprint at <a href=\"https://arxiv.org/abs/1907.11692\" data-track=\"click_references\" data-track-action=\"external reference\" data-track-value=\"external reference\" data-track-label=\"https://arxiv.org/abs/1907.11692\">https://arxiv.org/abs/1907.11692</a> (2019).</p></li><li class=\"c-article-references__item js-c-reading-companion-references-item\" data-counter=\"6.\"><p class=\"c-article-references__text\" id=\"ref-CR6\">Zhang, S. et al. Opt: open pre-trained transformer language models. Preprint at <a href=\"https://arxiv.org/abs/2205.01068\" data-track=\"click_references\" data-track-action=\"external reference\" data-track-value=\"external reference\" data-track-label=\"https://arxiv.org/abs/2205.01068\">https://arxiv.org/abs/2205.01068</a> (2022).</p></li><li class=\"c-article-references__item js-c-reading-companion-references-item\" data-counter=\"7.\"><p class=\"c-article-references__text\" id=\"ref-CR7\">Aljundi, R., Kelchtermans, K. &amp; Tuytelaars, T. Task-free continual learning. in: <i>Proc. 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</i> 11254–11263 (IEEE, 2019).</p></li><li class=\"c-article-references__item js-c-reading-companion-references-item\" data-counter=\"8.\"><p class=\"c-article-references__text\" id=\"ref-CR8\">Carlini, N. &amp; Terzis, A. in <i>Proc. Tenth International Conference on Learning Representations</i> (ICLR, 2022).</p></li><li class=\"c-article-references__item js-c-reading-companion-references-item\" data-counter=\"9.\"><p class=\"c-article-references__text\" id=\"ref-CR9\">Carlini, N. et al. in <i>Proc. 2024 IEEE Symposium on Security and Privacy (SP)</i> 179 (IEEE, 2024).</p></li><li class=\"c-article-references__item js-c-reading-companion-references-item\" data-counter=\"10.\"><p class=\"c-article-references__text\" id=\"ref-CR10\">Mousavi-Hosseini, A., Park, S., Girotti, M., Mitliagkas, I. &amp; Erdogdu, M. A. in <i>Proc. Eleventh International Conference on Learning Representations</i> (ICLR, 2023).</p></li><li class=\"c-article-references__item js-c-reading-companion-references-item\" data-counter=\"11.\"><p class=\"c-article-references__text\" id=\"ref-CR11\">Soudry, D., Hoffer, E., Nacson, M. S., Gunasekar, S. &amp; Srebro, N. The implicit bias of gradient descent on separable data. <i>J. Mach. Learn. Res.</i> <b>19</b>, 1–57 (2018).</p><p class=\"c-article-references__links u-hide-print\"><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"mathscinet reference\" data-track-action=\"mathscinet reference\" href=\"http://www.ams.org/mathscinet-getitem?mr=3899772\" aria-label=\"MathSciNet reference 11\">MathSciNet</a> \n    <a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 11\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=The%20implicit%20bias%20of%20gradient%20descent%20on%20separable%20data&amp;journal=J.%20Mach.%20Learn.%20Res.&amp;volume=19&amp;pages=1-57&amp;publication_year=2018&amp;author=Soudry%2CD&amp;author=Hoffer%2CE&amp;author=Nacson%2CMS&amp;author=Gunasekar%2CS&amp;author=Srebro%2CN\">\n                    Google Scholar</a> \n                </p></li><li class=\"c-article-references__item js-c-reading-companion-references-item\" data-counter=\"12.\"><p class=\"c-article-references__text\" id=\"ref-CR12\">Gu, Y., Dong, L., Wei, F. &amp; Huang, M. in <i>Proc. Twelfth International Conference on Learning Representations</i> (ICLR, 2024).</p></li><li class=\"c-article-references__item js-c-reading-companion-references-item\" data-counter=\"13.\"><p class=\"c-article-references__text\" id=\"ref-CR13\">Shumailov, I. &amp; Shumaylov, Z. Public code for Model Collapse (0.1). <i>Zenodo</i> <a href=\"https://doi.org/10.5281/zenodo.10866595\" data-track=\"click_references\" data-track-action=\"external reference\" data-track-value=\"external reference\" data-track-label=\"10.5281/zenodo.10866595\">https://doi.org/10.5281/zenodo.10866595</a> (2024).</p></li><li class=\"c-article-references__item js-c-reading-companion-references-item\" data-counter=\"14.\"><p class=\"c-article-references__text\" id=\"ref-CR14\">Bommasani, R. et al. On the opportunities and risks of foundation models. Preprint at <a href=\"https://arxiv.org/abs/2108.07258\" data-track=\"click_references\" data-track-action=\"external reference\" data-track-value=\"external reference\" data-track-label=\"https://arxiv.org/abs/2108.07258\">https://arxiv.org/abs/2108.07258</a> (2022).</p></li><li class=\"c-article-references__item js-c-reading-companion-references-item\" data-counter=\"15.\"><p class=\"c-article-references__text\" id=\"ref-CR15\">Strubell, E., Ganesh, A. &amp; McCallum, A. in <i>Proc. 57th Annual Meeting of the Association for Computational Linguistics</i> (eds Korhonen, A., Traum, D. &amp; Màrquez, L.) 3645–3650 (Association for Computational Linguistics, 2019).</p></li><li class=\"c-article-references__item js-c-reading-companion-references-item\" data-counter=\"16.\"><p class=\"c-article-references__text\" id=\"ref-CR16\">Merity, S., Xiong, C., Bradbury, J. &amp; Socher, R. in <i>Proc. 5th International Conference on Learning Representations</i> (ICLR, 2017).</p></li><li class=\"c-article-references__item js-c-reading-companion-references-item\" data-counter=\"17.\"><p class=\"c-article-references__text\" id=\"ref-CR17\">Keskar, N. S., McCann, B., Varshney, L. R., Xiong, C. &amp; Socher, R. CTRL: a conditional transformer language model for controllable generation. Preprint at <a href=\"https://arxiv.org/abs/1909.05858\" data-track=\"click_references\" data-track-action=\"external reference\" data-track-value=\"external reference\" data-track-label=\"https://arxiv.org/abs/1909.05858\">https://arxiv.org/abs/1909.05858</a> (2019).</p></li><li class=\"c-article-references__item js-c-reading-companion-references-item\" data-counter=\"18.\"><p class=\"c-article-references__text\" id=\"ref-CR18\">Shumailov, I. et al. in <i>Proc. 2021 IEEE European Symposium on Security and Privacy (EuroS&amp;P)</i> 212–231 (IEEE, 2021).</p></li><li class=\"c-article-references__item js-c-reading-companion-references-item\" data-counter=\"19.\"><p class=\"c-article-references__text\" id=\"ref-CR19\">Google. Finding more high-quality sites in search. <i>Google</i> <a href=\"https://googleblog.blogspot.com/2011/02/finding-more-high-quality-sites-in.html\" data-track=\"click_references\" data-track-action=\"external reference\" data-track-value=\"external reference\" data-track-label=\"https://googleblog.blogspot.com/2011/02/finding-more-high-quality-sites-in.html\">https://googleblog.blogspot.com/2011/02/finding-more-high-quality-sites-in.html</a> (2011).</p></li><li class=\"c-article-references__item js-c-reading-companion-references-item\" data-counter=\"20.\"><p class=\"c-article-references__text\" id=\"ref-CR20\">Mims, C. The search engine backlash against ‘content mills’. <i>MIT Technology Review</i> <a href=\"https://www.technologyreview.com/2010/07/26/26327/the-search-engine-backlash-against-content-mills/\" data-track=\"click_references\" data-track-action=\"external reference\" data-track-value=\"external reference\" data-track-label=\"https://www.technologyreview.com/2010/07/26/26327/the-search-engine-backlash-against-content-mills/\">https://www.technologyreview.com/2010/07/26/26327/the-search-engine-backlash-against-content-mills/</a> (2010).</p></li><li class=\"c-article-references__item js-c-reading-companion-references-item\" data-counter=\"21.\"><p class=\"c-article-references__text\" id=\"ref-CR21\">Taleb, N. N. Black swans and the domains of statistics. <i>Am. Stat.</i> <b>61</b>, 198–200 (2007).</p><p class=\"c-article-references__links u-hide-print\"><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1198/000313007X219996\" data-track-item_id=\"10.1198/000313007X219996\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1198%2F000313007X219996\" aria-label=\"Article reference 21\" data-doi=\"10.1198/000313007X219996\">Article</a> \n    <a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"mathscinet reference\" data-track-action=\"mathscinet reference\" href=\"http://www.ams.org/mathscinet-getitem?mr=2393721\" aria-label=\"MathSciNet reference 21\">MathSciNet</a> \n    <a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 21\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Black%20swans%20and%20the%20domains%20of%20statistics&amp;journal=Am.%20Stat.&amp;doi=10.1198%2F000313007X219996&amp;volume=61&amp;pages=198-200&amp;publication_year=2007&amp;author=Taleb%2CNN\">\n                    Google Scholar</a> \n                </p></li><li class=\"c-article-references__item js-c-reading-companion-references-item\" data-counter=\"22.\"><p class=\"c-article-references__text\" id=\"ref-CR22\">LeCun, Y., Cortes, C. &amp; Burges, C. J. C. The MNIST database of handwritten digits. <a href=\"http://yann.lecun.com/exdb/mnist/\" data-track=\"click_references\" data-track-action=\"external reference\" data-track-value=\"external reference\" data-track-label=\"http://yann.lecun.com/exdb/mnist/\">http://yann.lecun.com/exdb/mnist/</a> (1998).</p></li></ol><p class=\"c-article-references__download u-hide-print\"><a data-track=\"click\" data-track-action=\"download citation references\" data-track-label=\"link\" rel=\"nofollow\" href=\"https://citation-needed.springer.com/v2/references/10.1038/s41586-024-07566-y?format=refman&amp;flavour=references\">Download references<svg width=\"16\" height=\"16\" focusable=\"false\" role=\"img\" aria-hidden=\"true\" class=\"u-icon\"><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#icon-eds-i-download-medium\"></use></svg></a></p></div></div></div></section></div><section data-title=\"Acknowledgements\"><div class=\"c-article-section\" id=\"Ack1-section\"><h2 class=\"c-article-section__title js-section-title js-c-reading-companion-sections-item\" id=\"Ack1\">Acknowledgements</h2><div class=\"c-article-section__content\" id=\"Ack1-content\"><p>This paper is dedicated to the memory of Professor Ross J. Anderson, our colleague and friend, who contributed much to this and other works we have produced over the years. We thank A. Thudi, D. Glukhov, P. Zaika, and D. Barak for useful discussions and feedback.</p></div></div></section><section aria-labelledby=\"author-information\" data-title=\"Author information\"><div class=\"c-article-section\" id=\"author-information-section\"><h2 class=\"c-article-section__title js-section-title js-c-reading-companion-sections-item\" id=\"author-information\">Author information</h2><div class=\"c-article-section__content\" id=\"author-information-content\"><span class=\"c-article-author-information__subtitle u-visually-hidden\" id=\"author-notes\">Author notes</span><ol class=\"c-article-author-information__list\"><li class=\"c-article-author-information__item\" id=\"na1\"><p>These authors contributed equally: Ilia Shumailov, Zakhar Shumaylov</p></li><li class=\"c-article-author-information__item\" id=\"na2\"><p>Deceased: Ross Anderson</p></li></ol><h3 class=\"c-article__sub-heading\" id=\"affiliations\">Authors and Affiliations</h3><ol class=\"c-article-author-affiliation__list\"><li id=\"Aff1\"><p class=\"c-article-author-affiliation__address\">OATML, Department of Computer Science, University of Oxford, Oxford, UK</p><p class=\"c-article-author-affiliation__authors-list\">Ilia Shumailov &amp; Yarin Gal</p></li><li id=\"Aff2\"><p class=\"c-article-author-affiliation__address\">Department of Applied Mathematics and Theoretical Physics, University of Cambridge, Cambridge, UK</p><p class=\"c-article-author-affiliation__authors-list\">Zakhar Shumaylov</p></li><li id=\"Aff3\"><p class=\"c-article-author-affiliation__address\">Department of Electrical and Electronic Engineering, Imperial College London, London, UK</p><p class=\"c-article-author-affiliation__authors-list\">Yiren Zhao</p></li><li id=\"Aff4\"><p class=\"c-article-author-affiliation__address\">University of Toronto, Toronto, Ontario, Canada</p><p class=\"c-article-author-affiliation__authors-list\">Nicolas Papernot</p></li><li id=\"Aff5\"><p class=\"c-article-author-affiliation__address\">Vector Institute, Toronto, Ontario, Canada</p><p class=\"c-article-author-affiliation__authors-list\">Nicolas Papernot</p></li><li id=\"Aff6\"><p class=\"c-article-author-affiliation__address\">Department of Computer Science and Technology, University of Cambridge, Cambridge, UK</p><p class=\"c-article-author-affiliation__authors-list\">Ross Anderson</p></li><li id=\"Aff7\"><p class=\"c-article-author-affiliation__address\">School of Informatics, University of Edinburgh, Edinburgh, UK</p><p class=\"c-article-author-affiliation__authors-list\">Ross Anderson</p></li></ol><div class=\"u-js-hide u-hide-print\" data-test=\"author-info\"><span class=\"c-article__sub-heading\">Authors</span><ol class=\"c-article-authors-search u-list-reset\"><li id=\"auth-Ilia-Shumailov-Aff1\"><span class=\"c-article-authors-search__title u-h3 js-search-name\">Ilia Shumailov</span><div class=\"c-article-authors-search__list\"><div class=\"c-article-authors-search__item c-article-authors-search__list-item--left\"><a href=\"/search?author=Ilia%20Shumailov\" class=\"c-article-button\" data-track=\"click\" data-track-action=\"author link - publication\" data-track-label=\"link\" rel=\"nofollow\">View author publications</a></div><div class=\"c-article-authors-search__item c-article-authors-search__list-item--right\"><p class=\"search-in-title-js c-article-authors-search__text\">You can also search for this author in\n                        <span class=\"c-article-identifiers\"><a class=\"c-article-identifiers__item\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Ilia%20Shumailov\" data-track=\"click\" data-track-action=\"author link - pubmed\" data-track-label=\"link\" rel=\"nofollow\">PubMed</a><span class=\"u-hide\"> </span><a class=\"c-article-identifiers__item\" href=\"http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Ilia%20Shumailov%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en\" data-track=\"click\" data-track-action=\"author link - scholar\" data-track-label=\"link\" rel=\"nofollow\">Google Scholar</a></span></p></div></div></li><li id=\"auth-Zakhar-Shumaylov-Aff2\"><span class=\"c-article-authors-search__title u-h3 js-search-name\">Zakhar Shumaylov</span><div class=\"c-article-authors-search__list\"><div class=\"c-article-authors-search__item c-article-authors-search__list-item--left\"><a href=\"/search?author=Zakhar%20Shumaylov\" class=\"c-article-button\" data-track=\"click\" data-track-action=\"author link - publication\" data-track-label=\"link\" rel=\"nofollow\">View author publications</a></div><div class=\"c-article-authors-search__item c-article-authors-search__list-item--right\"><p class=\"search-in-title-js c-article-authors-search__text\">You can also search for this author in\n                        <span class=\"c-article-identifiers\"><a class=\"c-article-identifiers__item\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Zakhar%20Shumaylov\" data-track=\"click\" data-track-action=\"author link - pubmed\" data-track-label=\"link\" rel=\"nofollow\">PubMed</a><span class=\"u-hide\"> </span><a class=\"c-article-identifiers__item\" href=\"http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Zakhar%20Shumaylov%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en\" data-track=\"click\" data-track-action=\"author link - scholar\" data-track-label=\"link\" rel=\"nofollow\">Google Scholar</a></span></p></div></div></li><li id=\"auth-Yiren-Zhao-Aff3\"><span class=\"c-article-authors-search__title u-h3 js-search-name\">Yiren Zhao</span><div class=\"c-article-authors-search__list\"><div class=\"c-article-authors-search__item c-article-authors-search__list-item--left\"><a href=\"/search?author=Yiren%20Zhao\" class=\"c-article-button\" data-track=\"click\" data-track-action=\"author link - publication\" data-track-label=\"link\" rel=\"nofollow\">View author publications</a></div><div class=\"c-article-authors-search__item c-article-authors-search__list-item--right\"><p class=\"search-in-title-js c-article-authors-search__text\">You can also search for this author in\n                        <span class=\"c-article-identifiers\"><a class=\"c-article-identifiers__item\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Yiren%20Zhao\" data-track=\"click\" data-track-action=\"author link - pubmed\" data-track-label=\"link\" rel=\"nofollow\">PubMed</a><span class=\"u-hide\"> </span><a class=\"c-article-identifiers__item\" href=\"http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Yiren%20Zhao%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en\" data-track=\"click\" data-track-action=\"author link - scholar\" data-track-label=\"link\" rel=\"nofollow\">Google Scholar</a></span></p></div></div></li><li id=\"auth-Nicolas-Papernot-Aff4-Aff5\"><span class=\"c-article-authors-search__title u-h3 js-search-name\">Nicolas Papernot</span><div class=\"c-article-authors-search__list\"><div class=\"c-article-authors-search__item c-article-authors-search__list-item--left\"><a href=\"/search?author=Nicolas%20Papernot\" class=\"c-article-button\" data-track=\"click\" data-track-action=\"author link - publication\" data-track-label=\"link\" rel=\"nofollow\">View author publications</a></div><div class=\"c-article-authors-search__item c-article-authors-search__list-item--right\"><p class=\"search-in-title-js c-article-authors-search__text\">You can also search for this author in\n                        <span class=\"c-article-identifiers\"><a class=\"c-article-identifiers__item\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Nicolas%20Papernot\" data-track=\"click\" data-track-action=\"author link - pubmed\" data-track-label=\"link\" rel=\"nofollow\">PubMed</a><span class=\"u-hide\"> </span><a class=\"c-article-identifiers__item\" href=\"http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Nicolas%20Papernot%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en\" data-track=\"click\" data-track-action=\"author link - scholar\" data-track-label=\"link\" rel=\"nofollow\">Google Scholar</a></span></p></div></div></li><li id=\"auth-Ross-Anderson-Aff6-Aff7\"><span class=\"c-article-authors-search__title u-h3 js-search-name\">Ross Anderson</span><div class=\"c-article-authors-search__list\"><div class=\"c-article-authors-search__item c-article-authors-search__list-item--left\"><a href=\"/search?author=Ross%20Anderson\" class=\"c-article-button\" data-track=\"click\" data-track-action=\"author link - publication\" data-track-label=\"link\" rel=\"nofollow\">View author publications</a></div><div class=\"c-article-authors-search__item c-article-authors-search__list-item--right\"><p class=\"search-in-title-js c-article-authors-search__text\">You can also search for this author in\n                        <span class=\"c-article-identifiers\"><a class=\"c-article-identifiers__item\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Ross%20Anderson\" data-track=\"click\" data-track-action=\"author link - pubmed\" data-track-label=\"link\" rel=\"nofollow\">PubMed</a><span class=\"u-hide\"> </span><a class=\"c-article-identifiers__item\" href=\"http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Ross%20Anderson%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en\" data-track=\"click\" data-track-action=\"author link - scholar\" data-track-label=\"link\" rel=\"nofollow\">Google Scholar</a></span></p></div></div></li><li id=\"auth-Yarin-Gal-Aff1\"><span class=\"c-article-authors-search__title u-h3 js-search-name\">Yarin Gal</span><div class=\"c-article-authors-search__list\"><div class=\"c-article-authors-search__item c-article-authors-search__list-item--left\"><a href=\"/search?author=Yarin%20Gal\" class=\"c-article-button\" data-track=\"click\" data-track-action=\"author link - publication\" data-track-label=\"link\" rel=\"nofollow\">View author publications</a></div><div class=\"c-article-authors-search__item c-article-authors-search__list-item--right\"><p class=\"search-in-title-js c-article-authors-search__text\">You can also search for this author in\n                        <span class=\"c-article-identifiers\"><a class=\"c-article-identifiers__item\" href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Yarin%20Gal\" data-track=\"click\" data-track-action=\"author link - pubmed\" data-track-label=\"link\" rel=\"nofollow\">PubMed</a><span class=\"u-hide\"> </span><a class=\"c-article-identifiers__item\" href=\"http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Yarin%20Gal%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en\" data-track=\"click\" data-track-action=\"author link - scholar\" data-track-label=\"link\" rel=\"nofollow\">Google Scholar</a></span></p></div></div></li></ol></div><h3 class=\"c-article__sub-heading\" id=\"contributions\">Contributions</h3><p>I.S. and Z.S. proposed and developed the idea, led the research and mathematical modelling and developed the GMM and VAE experiments. I.S. and Y.Z. developed the language-model experiments. N.P., Y.G. and R.A. supervised and guided the project. All authors contributed to writing of the manuscript. Y.G. is supported by a Turing AI Fellowship financed by the UK government’s Office for Artificial Intelligence, through UK Research and Innovation (grant reference EP/V030302/1) and delivered by the Alan Turing Institute.</p><h3 class=\"c-article__sub-heading\" id=\"corresponding-author\">Corresponding authors</h3><p id=\"corresponding-author-list\">Correspondence to\n                <a id=\"corresp-c1\" href=\"mailto:ilia.shumailov@chch.ox.ac.uk\">Ilia Shumailov</a>, <a id=\"corresp-c2\" href=\"mailto:zs334@cam.ac.uk\">Zakhar Shumaylov</a> or <a id=\"corresp-c3\" href=\"mailto:yarin@cs.ox.ac.uk\">Yarin Gal</a>.</p></div></div></section><section data-title=\"Ethics declarations\"><div class=\"c-article-section\" id=\"ethics-section\"><h2 class=\"c-article-section__title js-section-title js-c-reading-companion-sections-item\" id=\"ethics\">Ethics declarations</h2><div class=\"c-article-section__content\" id=\"ethics-content\">\n              \n                <h3 class=\"c-article__sub-heading\" id=\"FPar5\">Competing interests</h3>\n                <p>The authors declare no competing interests.</p>\n              \n            </div></div></section><section data-title=\"Peer review\"><div class=\"c-article-section\" id=\"peer-review-section\"><h2 class=\"c-article-section__title js-section-title js-c-reading-companion-sections-item\" id=\"peer-review\">Peer review</h2><div class=\"c-article-section__content\" id=\"peer-review-content\">\n              \n              \n                <h3 class=\"c-article__sub-heading\" id=\"FPar4\">Peer review information</h3>\n                <p><i>Nature</i> thanks the anonymous reviewers for their contribution to the peer review of this work.</p>\n              \n            </div></div></section><section data-title=\"Additional information\"><div class=\"c-article-section\" id=\"additional-information-section\"><h2 class=\"c-article-section__title js-section-title js-c-reading-companion-sections-item\" id=\"additional-information\">Additional information</h2><div class=\"c-article-section__content\" id=\"additional-information-content\"><p><b>Publisher’s note</b> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div></div></section><section data-title=\"Supplementary information\"><div class=\"c-article-section\" id=\"Sec10-section\"><h2 class=\"c-article-section__title js-section-title js-c-reading-companion-sections-item\" id=\"Sec10\">Supplementary information</h2><div class=\"c-article-section__content\" id=\"Sec10-content\"><div data-test=\"supplementary-info\"><div id=\"figshareContainer\" class=\"c-article-figshare-container\" data-test=\"figshare-container\"></div><div class=\"c-article-supplementary__item\" data-test=\"supp-item\" id=\"MOESM1\"><h3 class=\"c-article-supplementary__title u-h3\"><a class=\"print-link\" data-track=\"click\" data-track-action=\"view supplementary info\" data-test=\"supp-info-link\" data-track-label=\"supplementary information\" href=\"https://static-content.springer.com/esm/art%3A10.1038%2Fs41586-024-07566-y/MediaObjects/41586_2024_7566_MOESM1_ESM.pdf\" data-supp-info-image=\"\">Supplementary Information</a></h3></div><div class=\"c-article-supplementary__item\" data-test=\"supp-item\" id=\"MOESM2\"><h3 class=\"c-article-supplementary__title u-h3\"><a class=\"print-link\" data-track=\"click\" data-track-action=\"view supplementary info\" data-test=\"supp-info-link\" data-track-label=\"supplementary data\" href=\"https://static-content.springer.com/esm/art%3A10.1038%2Fs41586-024-07566-y/MediaObjects/41586_2024_7566_MOESM2_ESM.zip\" data-supp-info-image=\"\">Supplementary Data</a></h3></div></div></div></div></section><section data-title=\"Rights and permissions\"><div class=\"c-article-section\" id=\"rightslink-section\"><h2 class=\"c-article-section__title js-section-title js-c-reading-companion-sections-item\" id=\"rightslink\">Rights and permissions</h2><div class=\"c-article-section__content\" id=\"rightslink-content\">\n                <p><b>Open Access</b>  This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <a href=\"http://creativecommons.org/licenses/by/4.0/\" rel=\"license\">http://creativecommons.org/licenses/by/4.0/</a>.</p>\n              <p class=\"c-article-rights\"><a data-track=\"click\" data-track-action=\"view rights and permissions\" data-track-label=\"link\" href=\"https://s100.copyright.com/AppDispatchServlet?title=AI%20models%20collapse%20when%20trained%20on%20recursively%20generated%20data&amp;author=Ilia%20Shumailov%20et%20al&amp;contentID=10.1038%2Fs41586-024-07566-y&amp;copyright=The%20Author%28s%29&amp;publication=0028-0836&amp;publicationDate=2024-07-24&amp;publisherName=SpringerNature&amp;orderBeanReset=true&amp;oa=CC%20BY\">Reprints and permissions</a></p></div></div></section><section aria-labelledby=\"article-info\" data-title=\"About this article\"><div class=\"c-article-section\" id=\"article-info-section\"><h2 class=\"c-article-section__title js-section-title js-c-reading-companion-sections-item\" id=\"article-info\">About this article</h2><div class=\"c-article-section__content\" id=\"article-info-content\"><div class=\"c-bibliographic-information\"><div class=\"u-hide-print c-bibliographic-information__column c-bibliographic-information__column--border\"><a data-crossmark=\"10.1038/s41586-024-07566-y\" target=\"_blank\" rel=\"noopener\" href=\"https://crossmark.crossref.org/dialog/?doi=10.1038/s41586-024-07566-y\" data-track=\"click\" data-track-action=\"Click Crossmark\" data-track-label=\"link\" data-test=\"crossmark\"><img loading=\"lazy\" width=\"57\" height=\"81\" alt=\"Check for updates. Verify currency and authenticity via CrossMark\" src=\"data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>\"></a></div><div class=\"c-bibliographic-information__column\"><h3 class=\"c-article__sub-heading\" id=\"citeas\">Cite this article</h3><p class=\"c-bibliographic-information__citation\">Shumailov, I., Shumaylov, Z., Zhao, Y. <i>et al.</i> AI models collapse when trained on recursively generated data.\n                    <i>Nature</i> <b>631</b>, 755–759 (2024). https://doi.org/10.1038/s41586-024-07566-y</p><p class=\"c-bibliographic-information__download-citation u-hide-print\"><a data-test=\"citation-link\" data-track=\"click\" data-track-action=\"download article citation\" data-track-label=\"link\" data-track-external=\"\" rel=\"nofollow\" href=\"https://citation-needed.springer.com/v2/references/10.1038/s41586-024-07566-y?format=refman&amp;flavour=citation\">Download citation<svg width=\"16\" height=\"16\" focusable=\"false\" role=\"img\" aria-hidden=\"true\" class=\"u-icon\"><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#icon-eds-i-download-medium\"></use></svg></a></p><ul class=\"c-bibliographic-information__list\" data-test=\"publication-history\"><li class=\"c-bibliographic-information__list-item\"><p>Received<span class=\"u-hide\">: </span><span class=\"c-bibliographic-information__value\"><time datetime=\"2023-10-20\">20 October 2023</time></span></p></li><li class=\"c-bibliographic-information__list-item\"><p>Accepted<span class=\"u-hide\">: </span><span class=\"c-bibliographic-information__value\"><time datetime=\"2024-05-14\">14 May 2024</time></span></p></li><li class=\"c-bibliographic-information__list-item\"><p>Published<span class=\"u-hide\">: </span><span class=\"c-bibliographic-information__value\"><time datetime=\"2024-07-24\">24 July 2024</time></span></p></li><li class=\"c-bibliographic-information__list-item\"><p>Issue Date<span class=\"u-hide\">: </span><span class=\"c-bibliographic-information__value\"><time datetime=\"2024-07-25\">25 July 2024</time></span></p></li><li class=\"c-bibliographic-information__list-item c-bibliographic-information__list-item--full-width\"><p><abbr title=\"Digital Object Identifier\">DOI</abbr><span class=\"u-hide\">: </span><span class=\"c-bibliographic-information__value\">https://doi.org/10.1038/s41586-024-07566-y</span></p></li></ul><div data-component=\"share-box\"><div class=\"c-article-share-box u-display-none\" hidden=\"\"><h3 class=\"c-article__sub-heading\">Share this article</h3><p class=\"c-article-share-box__description\">Anyone you share the following link with will be able to read this content:</p><button class=\"js-get-share-url c-article-share-box__button\" type=\"button\" id=\"get-share-url\" data-track=\"click\" data-track-label=\"button\" data-track-external=\"\" data-track-action=\"get shareable link\">Get shareable link</button><div class=\"js-no-share-url-container u-display-none\" hidden=\"\"><p class=\"js-c-article-share-box__no-sharelink-info c-article-share-box__no-sharelink-info\">Sorry, a shareable link is not currently available for this article.</p></div><div class=\"js-share-url-container u-display-none\" hidden=\"\"><p class=\"js-share-url c-article-share-box__only-read-input\" id=\"share-url\" data-track=\"click\" data-track-label=\"button\" data-track-action=\"select share url\"></p><button class=\"js-copy-share-url c-article-share-box__button--link-like\" type=\"button\" id=\"copy-share-url\" data-track=\"click\" data-track-label=\"button\" data-track-action=\"copy share url\" data-track-external=\"\">Copy to clipboard</button></div><p class=\"js-c-article-share-box__additional-info c-article-share-box__additional-info\">\n                            Provided by the Springer Nature SharedIt content-sharing initiative\n                        </p></div></div><div data-component=\"article-info-list\"></div></div></div></div></div></section>\n            </div>\n\n            \n        <section>\n            <div class=\"c-article-section js-article-section\" id=\"further-reading-section\" data-test=\"further-reading-section\">\n                <h2 class=\"c-article-section__title js-section-title js-c-reading-companion-sections-item\" id=\"further-reading\">This article is cited by</h2>\n                <div class=\"c-article-section__content js-collapsible-section\" id=\"further-reading-content\">\n                    <ul class=\"c-article-further-reading__list\" id=\"further-reading-list\">\n                        \n                            <li class=\"c-article-further-reading__item js-ref-item\">\n                            \n                                <h3 class=\"c-article-further-reading__title\" data-test=\"article-title\">\n                                    <a class=\"print-link\" data-track=\"click\" data-track-action=\"view further reading article\"\n                                       data-track-label=\"link:AI models fed AI-generated data quickly spew nonsense\" href=\"https://doi.org/10.1038/d41586-024-02420-7\">\n                                        AI models fed AI-generated data quickly spew nonsense\n                                    </a>\n                                </h3>\n                            \n                                \n                                    <ul data-test=\"author-list\" class=\"c-author-list c-author-list--compact u-sans-serif u-mb-4 u-mt-auto\">\n                                        <li>Elizabeth Gibney</li>\n                                    </ul>\n                                \n                                <p class=\"c-article-further-reading__journal-title\"><i>Nature</i> (2024)</p>\n                            </li>\n                        \n                            <li class=\"c-article-further-reading__item js-ref-item\">\n                            \n                                <h3 class=\"c-article-further-reading__title\" data-test=\"article-title\">\n                                    <a class=\"print-link\" data-track=\"click\" data-track-action=\"view further reading article\"\n                                       data-track-label=\"link:Stochastic contingency machines feeding on meaning: on the computational determination of social reality in machine learning\" href=\"https://doi.org/10.1007/s00146-024-02079-8\">\n                                        Stochastic contingency machines feeding on meaning: on the computational determination of social reality in machine learning\n                                    </a>\n                                </h3>\n                            \n                                \n                                    <ul data-test=\"author-list\" class=\"c-author-list c-author-list--compact u-sans-serif u-mb-4 u-mt-auto\">\n                                        <li>Richard Groß</li>\n                                    </ul>\n                                \n                                <p class=\"c-article-further-reading__journal-title\"><i>AI &amp; SOCIETY</i> (2024)</p>\n                            </li>\n                        \n                    </ul>\n                </div>\n            </div>\n        </section>\n    \n\n        </div>\n</article>\n</main>\n\n<aside class=\"c-article-extras u-hide-print\" aria-label=\"Article navigation\" data-component-reading-companion data-container-type=\"reading-companion\" data-track-component=\"reading companion\">\n    <div class=\"js-context-bar-sticky-point-desktop\" data-track-context=\"reading companion\">\n        \n\n        \n            \n                \n    \n        <div class=\"c-pdf-download u-clear-both js-pdf-download\">\n            <a href=\"/articles/s41586-024-07566-y.pdf\" class=\"u-button u-button--full-width u-button--primary u-justify-content-space-between c-pdf-download__link\" data-article-pdf=\"true\" data-readcube-pdf-url=\"true\" data-test=\"download-pdf\" data-draft-ignore=\"true\" data-track=\"content_download\" data-track-type=\"article pdf download\" data-track-action=\"download pdf\" data-track-label=\"link\" data-track-external download>\n                <span class=\"c-pdf-download__text\">Download PDF</span>\n                <svg aria-hidden=\"true\" focusable=\"false\" width=\"16\" height=\"16\" class=\"u-icon\"><use xlink:href=\"#icon-download\"/></svg>\n            </a>\n        </div>\n    \n\n            \n        \n    </div>\n\n    \n        \n    \n\n    \n    \n        <div class=\"c-article-associated-content__container\">\n            <section>\n                <h2 class=\"c-article-associated-content__title u-mb-24\">Associated content</h2>\n                \n                    \n                    \n                        <div class=\"u-full-height u-mb-24\">\n                            \n    <article class=\"u-full-height c-card c-card--flush\">\n        <div class=\"c-card__layout u-full-height\">\n            <div class=\"c-card__body\">\n                <h3 class=\"c-card__title\">\n                    <a href=\"https://www.nature.com/articles/d41586-024-02355-z\"\n                       class=\"c-card__link u-link-inherit\"\n                       data-track=\"click\"\n                       data-track-action=\"view article\"\n                       data-track-category=\"associated content\"\n                       \n                       data-track-label=\"news_and_views\">AI produces gibberish when trained on too much AI-generated data</a>\n                </h3>\n                \n<ul data-test=\"author-list\" class=\"c-author-list c-author-list--compact\">\n    <li>Emily Wenger</li>\n</ul>\n\n                \n    <div class=\"c-card__section c-meta\">\n        \n            <span class=\"c-meta__item\">Nature</span>\n        \n        <span class=\"c-meta__item\" data-test=\"article.type\"><span class=\"c-meta__type\">News &amp; Views</span></span>\n        \n        \n            <time class=\"c-meta__item\" datetime=\"2024-07-24\">24 Jul 2024</time>\n        \n    </div>\n\n            </div>\n        </div>\n    </article>\n\n\n                        </div>\n                    \n                \n            </section>\n        </div>\n        <script>\n            window.dataLayer = window.dataLayer || [];\n            window.dataLayer[0] = window.dataLayer[0] || {};\n            window.dataLayer[0].content = window.dataLayer[0].content || {};\n            window.dataLayer[0].content.associatedContentTypes = \"news_and_views\";\n        </script>\n    \n\n    \n\n    <div class=\"c-reading-companion\">\n        <div class=\"c-reading-companion__sticky\" data-component=\"reading-companion-sticky\" data-test=\"reading-companion-sticky\">\n            <div class=\"c-reading-companion__panel c-reading-companion__sections c-reading-companion__panel--active\" id=\"tabpanel-sections\">\n                <div class=\"u-lazy-ad-wrapper u-mt-16 u-hide\" data-component-mpu>\n                    <div class=\"c-ad c-ad--300x250\">\n                        <div class=\"c-ad__inner\">\n                            <p class=\"c-ad__label\">Advertisement</p>\n                            \n    <div id=\"div-gpt-ad-right-2\"\n         class=\"div-gpt-ad advert medium-rectangle js-ad text-center hide-print grade-c-hide\"\n         data-ad-type=\"right\"\n         data-test=\"right-ad\"\n         data-pa11y-ignore\n         data-gpt\n         data-gpt-unitpath=\"/285/nature.com/article\"\n         data-gpt-sizes=\"300x250\"\n         data-gpt-targeting=\"type=article;pos=right;artid=s41586-024-07566-y;doi=10.1038/s41586-024-07566-y;techmeta=119,123,129,141;subjmeta=1042,117,639,705;kwrd=Computational+science,Computer+science\">\n        <noscript>\n            <a href=\"//pubads.g.doubleclick.net/gampad/jump?iu=/285/nature.com/article&amp;sz=300x250&amp;c=171857631&amp;t=pos%3Dright%26type%3Darticle%26artid%3Ds41586-024-07566-y%26doi%3D10.1038/s41586-024-07566-y%26techmeta%3D119,123,129,141%26subjmeta%3D1042,117,639,705%26kwrd%3DComputational+science,Computer+science\">\n                <img data-test=\"gpt-advert-fallback-img\"\n                     src=\"//pubads.g.doubleclick.net/gampad/ad?iu=/285/nature.com/article&amp;sz=300x250&amp;c=171857631&amp;t=pos%3Dright%26type%3Darticle%26artid%3Ds41586-024-07566-y%26doi%3D10.1038/s41586-024-07566-y%26techmeta%3D119,123,129,141%26subjmeta%3D1042,117,639,705%26kwrd%3DComputational+science,Computer+science\"\n                     alt=\"Advertisement\"\n                     width=\"300\"\n                     height=\"250\"></a>\n        </noscript>\n    </div>\n\n                        </div>\n                    </div>\n                </div>\n            </div>\n            <div class=\"c-reading-companion__panel c-reading-companion__figures c-reading-companion__panel--full-width\" id=\"tabpanel-figures\"></div>\n            <div class=\"c-reading-companion__panel c-reading-companion__references c-reading-companion__panel--full-width\" id=\"tabpanel-references\"></div>\n        </div>\n    </div>\n</aside>\n</div>\n\n\n    \n        <nav class=\"c-header__dropdown\" aria-labelledby=\"Explore-content\" data-test=\"Explore-content\" id=\"explore\" data-track-component=\"nature-150-split-header\">\n            <div class=\"c-header__container\">\n                <h2 id=\"Explore-content\" class=\"c-header__heading c-header__heading--js-hide\">Explore content</h2>\n                <ul class=\"c-header__list c-header__list--js-stack\">\n                    \n                        \n                            <li class=\"c-header__item\">\n                                <a class=\"c-header__link\"\n                                   href=\"/nature/research-articles\"\n                                   data-track=\"click\"\n                                   data-track-action=\"research articles\"\n                                   data-track-label=\"link\"\n                                   data-test=\"explore-nav-item\">\n                                    Research articles\n                                </a>\n                            </li>\n                        \n                            <li class=\"c-header__item\">\n                                <a class=\"c-header__link\"\n                                   href=\"/news\"\n                                   data-track=\"click\"\n                                   data-track-action=\"news\"\n                                   data-track-label=\"link\"\n                                   data-test=\"explore-nav-item\">\n                                    News\n                                </a>\n                            </li>\n                        \n                            <li class=\"c-header__item\">\n                                <a class=\"c-header__link\"\n                                   href=\"/opinion\"\n                                   data-track=\"click\"\n                                   data-track-action=\"opinion\"\n                                   data-track-label=\"link\"\n                                   data-test=\"explore-nav-item\">\n                                    Opinion\n                                </a>\n                            </li>\n                        \n                            <li class=\"c-header__item\">\n                                <a class=\"c-header__link\"\n                                   href=\"/research-analysis\"\n                                   data-track=\"click\"\n                                   data-track-action=\"research analysis\"\n                                   data-track-label=\"link\"\n                                   data-test=\"explore-nav-item\">\n                                    Research Analysis\n                                </a>\n                            </li>\n                        \n                            <li class=\"c-header__item\">\n                                <a class=\"c-header__link\"\n                                   href=\"/careers\"\n                                   data-track=\"click\"\n                                   data-track-action=\"careers\"\n                                   data-track-label=\"link\"\n                                   data-test=\"explore-nav-item\">\n                                    Careers\n                                </a>\n                            </li>\n                        \n                            <li class=\"c-header__item\">\n                                <a class=\"c-header__link\"\n                                   href=\"/books-culture\"\n                                   data-track=\"click\"\n                                   data-track-action=\"books &amp; culture\"\n                                   data-track-label=\"link\"\n                                   data-test=\"explore-nav-item\">\n                                    Books &amp; Culture\n                                </a>\n                            </li>\n                        \n                            <li class=\"c-header__item\">\n                                <a class=\"c-header__link\"\n                                   href=\"/nature/podcasts\"\n                                   data-track=\"click\"\n                                   data-track-action=\"podcasts\"\n                                   data-track-label=\"link\"\n                                   data-test=\"explore-nav-item\">\n                                    Podcasts\n                                </a>\n                            </li>\n                        \n                            <li class=\"c-header__item\">\n                                <a class=\"c-header__link\"\n                                   href=\"/nature/videos\"\n                                   data-track=\"click\"\n                                   data-track-action=\"videos\"\n                                   data-track-label=\"link\"\n                                   data-test=\"explore-nav-item\">\n                                    Videos\n                                </a>\n                            </li>\n                        \n                            <li class=\"c-header__item\">\n                                <a class=\"c-header__link\"\n                                   href=\"/nature/current-issue\"\n                                   data-track=\"click\"\n                                   data-track-action=\"current issue\"\n                                   data-track-label=\"link\"\n                                   data-test=\"explore-nav-item\">\n                                    Current issue\n                                </a>\n                            </li>\n                        \n                            <li class=\"c-header__item\">\n                                <a class=\"c-header__link\"\n                                   href=\"/nature/browse-issues\"\n                                   data-track=\"click\"\n                                   data-track-action=\"browse issues\"\n                                   data-track-label=\"link\"\n                                   data-test=\"explore-nav-item\">\n                                    Browse issues\n                                </a>\n                            </li>\n                        \n                            <li class=\"c-header__item\">\n                                <a class=\"c-header__link\"\n                                   href=\"/nature/collections\"\n                                   data-track=\"click\"\n                                   data-track-action=\"collections\"\n                                   data-track-label=\"link\"\n                                   data-test=\"explore-nav-item\">\n                                    Collections\n                                </a>\n                            </li>\n                        \n                            <li class=\"c-header__item\">\n                                <a class=\"c-header__link\"\n                                   href=\"/nature/browse-subjects\"\n                                   data-track=\"click\"\n                                   data-track-action=\"subjects\"\n                                   data-track-label=\"link\"\n                                   data-test=\"explore-nav-item\">\n                                    Subjects\n                                </a>\n                            </li>\n                        \n                    \n                </ul>\n                <ul class=\"c-header__list c-header__list--js-stack\">\n                    \n                        <li class=\"c-header__item\">\n                            <a class=\"c-header__link\"\n                               href=\"https://www.facebook.com/Nature\"\n                               data-track=\"click\"\n                               data-track-action=\"facebook\"\n                               data-track-label=\"link\">Follow us on Facebook\n                            </a>\n                        </li>\n                    \n                    \n                        <li class=\"c-header__item\">\n                            <a class=\"c-header__link\"\n                               href=\"https://twitter.com/nature\"\n                               data-track=\"click\"\n                               data-track-action=\"twitter\"\n                               data-track-label=\"link\">Follow us on Twitter\n                            </a>\n                        </li>\n                    \n                    \n                    \n                        <li class=\"c-header__item c-header__item--hide-lg\">\n                            <a class=\"c-header__link\"\n                               href=\"https://www.nature.com/my-account/alerts/subscribe-journal?list-id&#x3D;1\"\n                               rel=\"nofollow\"\n                               data-track=\"click\"\n                               data-track-action=\"Sign up for alerts\"\n                               data-track-external\n                               data-track-label=\"link (mobile dropdown)\">Sign up for alerts<svg role=\"img\" aria-hidden=\"true\" focusable=\"false\" height=\"18\" viewBox=\"0 0 18 18\" width=\"18\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z\" fill=\"#fff\"/></svg>\n                            </a>\n                        </li>\n                    \n                    \n                        <li class=\"c-header__item c-header__item--hide-lg\">\n                            <a class=\"c-header__link\"\n                               href=\"https://www.nature.com/nature.rss\"\n                               data-track=\"click\"\n                               data-track-action=\"rss feed\"\n                               data-track-label=\"link\">\n                                <span>RSS feed</span>\n                            </a>\n                        </li>\n                    \n                </ul>\n            </div>\n        </nav>\n    \n    \n        \n            <nav class=\"c-header__dropdown\" aria-labelledby=\"About-the-journal\" id=\"about-the-journal\" data-test=\"about-the-journal\" data-track-component=\"nature-150-split-header\">\n                <div class=\"c-header__container\">\n                    <h2 id=\"About-the-journal\" class=\"c-header__heading c-header__heading--js-hide\">About the journal</h2>\n                    <ul class=\"c-header__list c-header__list--js-stack\">\n                        \n                            <li class=\"c-header__item\">\n                                <a class=\"c-header__link\"\n                                   href=\"/nature/journal-staff\"\n                                   data-track=\"click\"\n                                   data-track-action=\"journal staff\"\n                                   data-track-label=\"link\">\n                                    Journal Staff\n                                </a>\n                            </li>\n                        \n                            <li class=\"c-header__item\">\n                                <a class=\"c-header__link\"\n                                   href=\"/nature/editors\"\n                                   data-track=\"click\"\n                                   data-track-action=\"about the editors\"\n                                   data-track-label=\"link\">\n                                    About the Editors\n                                </a>\n                            </li>\n                        \n                            <li class=\"c-header__item\">\n                                <a class=\"c-header__link\"\n                                   href=\"/nature/journal-information\"\n                                   data-track=\"click\"\n                                   data-track-action=\"journal information\"\n                                   data-track-label=\"link\">\n                                    Journal Information\n                                </a>\n                            </li>\n                        \n                            <li class=\"c-header__item\">\n                                <a class=\"c-header__link\"\n                                   href=\"/nature/our-publishing-models\"\n                                   data-track=\"click\"\n                                   data-track-action=\"our publishing models\"\n                                   data-track-label=\"link\">\n                                    Our publishing models\n                                </a>\n                            </li>\n                        \n                            <li class=\"c-header__item\">\n                                <a class=\"c-header__link\"\n                                   href=\"/nature/editorial-values-statement\"\n                                   data-track=\"click\"\n                                   data-track-action=\"editorial values statement\"\n                                   data-track-label=\"link\">\n                                    Editorial Values Statement\n                                </a>\n                            </li>\n                        \n                            <li class=\"c-header__item\">\n                                <a class=\"c-header__link\"\n                                   href=\"/nature/journal-impact\"\n                                   data-track=\"click\"\n                                   data-track-action=\"journal metrics\"\n                                   data-track-label=\"link\">\n                                    Journal Metrics\n                                </a>\n                            </li>\n                        \n                            <li class=\"c-header__item\">\n                                <a class=\"c-header__link\"\n                                   href=\"/nature/awards\"\n                                   data-track=\"click\"\n                                   data-track-action=\"awards\"\n                                   data-track-label=\"link\">\n                                    Awards\n                                </a>\n                            </li>\n                        \n                            <li class=\"c-header__item\">\n                                <a class=\"c-header__link\"\n                                   href=\"/nature/contact\"\n                                   data-track=\"click\"\n                                   data-track-action=\"contact\"\n                                   data-track-label=\"link\">\n                                    Contact\n                                </a>\n                            </li>\n                        \n                            <li class=\"c-header__item\">\n                                <a class=\"c-header__link\"\n                                   href=\"/nature/editorial-policies\"\n                                   data-track=\"click\"\n                                   data-track-action=\"editorial policies\"\n                                   data-track-label=\"link\">\n                                    Editorial policies\n                                </a>\n                            </li>\n                        \n                            <li class=\"c-header__item\">\n                                <a class=\"c-header__link\"\n                                   href=\"/nature/history-of-nature\"\n                                   data-track=\"click\"\n                                   data-track-action=\"history of nature\"\n                                   data-track-label=\"link\">\n                                    History of Nature\n                                </a>\n                            </li>\n                        \n                            <li class=\"c-header__item\">\n                                <a class=\"c-header__link\"\n                                   href=\"/nature/send-a-news-tip\"\n                                   data-track=\"click\"\n                                   data-track-action=\"send a news tip\"\n                                   data-track-label=\"link\">\n                                    Send a news tip\n                                </a>\n                            </li>\n                        \n                    </ul>\n                </div>\n            </nav>\n        \n\n        \n            <nav class=\"c-header__dropdown\" aria-labelledby=\"Publish-with-us-label\" id=\"publish-with-us\" data-test=\"publish-with-us\" data-track-component=\"nature-150-split-header\">\n                <div class=\"c-header__container\">\n                    <h2 id=\"Publish-with-us-label\" class=\"c-header__heading c-header__heading--js-hide\">Publish with us</h2>\n                    <ul class=\"c-header__list c-header__list--js-stack\">\n                        \n                            <li class=\"c-header__item\">\n                                <a class=\"c-header__link\"\n                                   href=\"/nature/for-authors\"\n                                   data-track=\"click\"\n                                   data-track-action=\"for authors\"\n                                   data-track-label=\"link\">\n                                    For Authors\n                                </a>\n                            </li>\n                        \n                            <li class=\"c-header__item\">\n                                <a class=\"c-header__link\"\n                                   href=\"/nature/for-referees\"\n                                   data-track=\"click\"\n                                   data-track-action=\"for referees\"\n                                   data-track-label=\"link\">\n                                    For Referees\n                                </a>\n                            </li>\n                        \n                        \n                            <li class=\"c-header__item\">\n                                <a class=\"c-header__link\" data-test=\"nature-author-services\"\n                                   data-track=\"nav_language_services\"\n                                   data-track-context=\"header publish with us dropdown menu\"\n                                   data-track-action=\"manuscript author services\"\n                                   data-track-label=\"link manuscript author services\"\n                                   href=\"https://authorservices.springernature.com/go/sn/?utm_source=For+Authors&utm_medium=Website_Nature&utm_campaign=Platform+Experimentation+2022&utm_id=PE2022\">\n                                    Language editing services\n                                </a>\n                            </li>\n                        \n                        \n                            <li class=\"c-header__item c-header__item--keyline\">\n                                <a class=\"c-header__link\"\n                                   href=\"https://mts-nature.nature.com/\"\n                                   data-track=\"click||click_submit_manuscript\"\n                                   data-track-context=\"submit link in Nature header dropdown menu\"\n                                   data-track-action=\"submit manuscript\"\n                                   data-track-label=\"link (publish with us dropdown menu)\"\n                                   data-track-external>Submit manuscript<svg role=\"img\" aria-hidden=\"true\" focusable=\"false\" height=\"18\" viewBox=\"0 0 18 18\" width=\"18\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"m15 0c1.1045695 0 2 .8954305 2 2v5.5c0 .27614237-.2238576.5-.5.5s-.5-.22385763-.5-.5v-5.5c0-.51283584-.3860402-.93550716-.8833789-.99327227l-.1166211-.00672773h-9v3c0 1.1045695-.8954305 2-2 2h-3v10c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h7.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-7.5c-1.1045695 0-2-.8954305-2-2v-10.17157288c0-.53043297.21071368-1.0391408.58578644-1.41421356l3.82842712-3.82842712c.37507276-.37507276.88378059-.58578644 1.41421356-.58578644zm-.5442863 8.18867991 3.3545404 3.35454039c.2508994.2508994.2538696.6596433.0035959.909917-.2429543.2429542-.6561449.2462671-.9065387-.0089489l-2.2609825-2.3045251.0010427 7.2231989c0 .3569916-.2898381.6371378-.6473715.6371378-.3470771 0-.6473715-.2852563-.6473715-.6371378l-.0010428-7.2231995-2.2611222 2.3046654c-.2531661.2580415-.6562868.2592444-.9065605.0089707-.24295423-.2429542-.24865597-.6576651.0036132-.9099343l3.3546673-3.35466731c.2509089-.25090888.6612706-.25227691.9135302-.00001728zm-.9557137-3.18867991c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm-8.5-3.587-3.587 3.587h2.587c.55228475 0 1-.44771525 1-1zm8.5 1.587c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z\" fill=\"#fff\"/></svg>\n                                </a>\n                            </li>\n                        \n                    </ul>\n                </div>\n            </nav>\n        \n    \n\n\n<div id=\"search-menu\" class=\"c-header__dropdown c-header__dropdown--full-width\" data-track-component=\"nature-150-split-header\">\n    <div class=\"c-header__container\">\n        <h2 class=\"c-header__visually-hidden\">Search</h2>\n        <form class=\"c-header__search-form\" action=\"/search\" method=\"get\" role=\"search\" autocomplete=\"off\" data-test=\"inline-search\">\n            <label class=\"c-header__heading\" for=\"keywords\">Search articles by subject, keyword or author</label>\n            <div class=\"c-header__search-layout c-header__search-layout--max-width\">\n                <div>\n                    <input type=\"text\" required=\"\" class=\"c-header__input\" id=\"keywords\" name=\"q\" value=\"\">\n                </div>\n                <div class=\"c-header__search-layout\">\n                    <div>\n                        <label for=\"results-from\" class=\"c-header__visually-hidden\">Show results from</label>\n                        <select id=\"results-from\" name=\"journal\" class=\"c-header__select\">\n                            \n                                \n                                    <option value=\"\" selected>All journals</option>\n                                    <option value=\"nature\">This journal</option>\n                                \n                            \n                        </select>\n                    </div>\n                    <div>\n                        <button type=\"submit\" class=\"c-header__search-button\">Search</button>\n                    </div>\n                </div>\n\n            </div>\n        </form>\n\n        <div class=\"c-header__flush\">\n            <a class=\"c-header__link\" href=\"/search/advanced\"\n               data-track=\"click\" data-track-action=\"advanced search\" data-track-label=\"link\">\n                Advanced search\n            </a>\n        </div>\n\n        <h3 class=\"c-header__heading c-header__heading--keyline\">Quick links</h3>\n        <ul class=\"c-header__list\">\n            <li><a class=\"c-header__link\" href=\"/subjects\" data-track=\"click\" data-track-action=\"explore articles by subject\" data-track-label=\"link\">Explore articles by subject</a></li>\n            <li><a class=\"c-header__link\" href=\"/naturecareers\" data-track=\"click\" data-track-action=\"find a job\" data-track-label=\"link\">Find a job</a></li>\n            <li><a class=\"c-header__link\" href=\"/authors/index.html\" data-track=\"click\" data-track-action=\"guide to authors\" data-track-label=\"link\">Guide to authors</a></li>\n            <li><a class=\"c-header__link\" href=\"/authors/editorial_policies/\" data-track=\"click\" data-track-action=\"editorial policies\" data-track-label=\"link\">Editorial policies</a></li>\n        </ul>\n    </div>\n</div>\n\n<footer class=\"composite-layer\" itemscope itemtype=\"http://schema.org/Periodical\">\n        <meta itemprop=\"publisher\" content=\"Springer Nature\">\n        \n\n        <div class=\"u-mt-16 u-mb-16\">\n    <div class=\"u-container\">\n        <div class=\"u-display-flex u-flex-wrap u-justify-content-space-between\">\n            \n\n            <p class=\"c-meta u-ma-0 u-flex-shrink\">\n                <span class=\"c-meta__item\">\n                    Nature (<i>Nature</i>)\n                </span>\n                \n    \n    <span class=\"c-meta__item\">\n        <abbr title=\"International Standard Serial Number\">ISSN</abbr> <span itemprop=\"onlineIssn\">1476-4687</span> (online)\n    </span>\n    \n\n\n                \n    \n    <span class=\"c-meta__item\">\n        <abbr title=\"International Standard Serial Number\">ISSN</abbr> <span itemprop=\"printIssn\">0028-0836</span> (print)\n    </span>\n    \n\n            </p>\n        </div>\n    </div>\n</div>\n\n    <div class=\"c-footer\">\n        <div class=\"u-hide-print\" data-track-component=\"footer\">\n    <h2 class=\"u-visually-hidden\">nature.com sitemap</h2>\n    <div class=\"c-footer__container\">\n        <div class=\"c-footer__grid c-footer__group--separator\">\n            <div class=\"c-footer__group\">\n                <h3 class=\"c-footer__heading u-mt-0\">About Nature Portfolio</h3>\n                <ul class=\"c-footer__list\">\n                    <li class=\"c-footer__item\"><a class=\"c-footer__link\"\n                                                  href=\"https://www.nature.com/npg_/company_info/index.html\"\n                                                  data-track=\"click\" data-track-action=\"about us\"\n                                                  data-track-label=\"link\">About us</a></li>\n                    <li class=\"c-footer__item\"><a class=\"c-footer__link\"\n                                                  href=\"https://www.nature.com/npg_/press_room/press_releases.html\"\n                                                  data-track=\"click\" data-track-action=\"press releases\"\n                                                  data-track-label=\"link\">Press releases</a></li>\n                    <li class=\"c-footer__item\"><a class=\"c-footer__link\" href=\"https://press.nature.com/\"\n                                                  data-track=\"click\" data-track-action=\"press office\"\n                                                  data-track-label=\"link\">Press office</a></li>\n                    <li class=\"c-footer__item\"><a class=\"c-footer__link\" href=\"https://support.nature.com/support/home\"\n                                                  data-track=\"click\" data-track-action=\"contact us\"\n                                                  data-track-label=\"link\">Contact us</a></li>\n                </ul>\n            </div>\n\n            <div class=\"c-footer__group\">\n                <h3 class=\"c-footer__heading u-mt-0\">Discover content</h3>\n                <ul class=\"c-footer__list\">\n                    <li class=\"c-footer__item\"><a class=\"c-footer__link\" href=\"https://www.nature.com/siteindex\"\n                                                  data-track=\"click\" data-track-action=\"journals a-z\"\n                                                  data-track-label=\"link\">Journals A-Z</a></li>\n                    <li class=\"c-footer__item\"><a class=\"c-footer__link\" href=\"https://www.nature.com/subjects\"\n                                                  data-track=\"click\" data-track-action=\"article by subject\"\n                                                  data-track-label=\"link\">Articles by subject</a></li>\n                    <li class=\"c-footer__item\"><a class=\"c-footer__link\" href=\"https://www.protocols.io/\"\n                                                  data-track=\"click\" data-track-action=\"protocols.io\"\n                                                  data-track-label=\"link\">protocols.io</a></li>\n                    <li class=\"c-footer__item\"><a class=\"c-footer__link\" href=\"https://www.natureindex.com/\"\n                                                  data-track=\"click\" data-track-action=\"nature index\"\n                                                  data-track-label=\"link\">Nature Index</a></li>\n                </ul>\n            </div>\n\n            <div class=\"c-footer__group\">\n                <h3 class=\"c-footer__heading u-mt-0\">Publishing policies</h3>\n                <ul class=\"c-footer__list\">\n                    <li class=\"c-footer__item\"><a class=\"c-footer__link\"\n                                                  href=\"https://www.nature.com/authors/editorial_policies\"\n                                                  data-track=\"click\" data-track-action=\"Nature portfolio policies\"\n                                                  data-track-label=\"link\">Nature portfolio policies</a></li>\n                    <li class=\"c-footer__item\"><a class=\"c-footer__link\"\n                                                  href=\"https://www.nature.com/nature-research/open-access\"\n                                                  data-track=\"click\" data-track-action=\"open access\"\n                                                  data-track-label=\"link\">Open access</a></li>\n                </ul>\n            </div>\n\n            <div class=\"c-footer__group\">\n                <h3 class=\"c-footer__heading u-mt-0\">Author &amp; Researcher services</h3>\n                <ul class=\"c-footer__list\">\n                    <li class=\"c-footer__item\"><a class=\"c-footer__link\" href=\"https://www.nature.com/reprints\"\n                                                  data-track=\"click\" data-track-action=\"reprints and permissions\"\n                                                  data-track-label=\"link\">Reprints &amp; permissions</a></li>\n                    <li class=\"c-footer__item\"><a class=\"c-footer__link\"\n                                                  href=\"https://www.springernature.com/gp/authors/research-data\"\n                                                  data-track=\"click\" data-track-action=\"data research service\"\n                                                  data-track-label=\"link\">Research data</a></li>\n                    <li class=\"c-footer__item\"><a class=\"c-footer__link\"\n                                                  href=\"https://authorservices.springernature.com/language-editing/\"\n                                                  data-track=\"click\" data-track-action=\"language editing\"\n                                                  data-track-label=\"link\">Language editing</a></li>\n                    <li class=\"c-footer__item\"><a class=\"c-footer__link\"\n                                                  href=\"https://authorservices.springernature.com/scientific-editing/\"\n                                                  data-track=\"click\" data-track-action=\"scientific editing\"\n                                                  data-track-label=\"link\">Scientific editing</a></li>\n                    <li class=\"c-footer__item\"><a class=\"c-footer__link\" href=\"https://masterclasses.nature.com/\"\n                                                  data-track=\"click\" data-track-action=\"nature masterclasses\"\n                                                  data-track-label=\"link\">Nature Masterclasses</a></li>\n                    <li class=\"c-footer__item\"><a class=\"c-footer__link\" href=\"https://solutions.springernature.com/\"\n                                                  data-track=\"click\" data-track-action=\"research solutions\"\n                                                  data-track-label=\"link\">Research Solutions</a></li>\n                </ul>\n            </div>\n\n            <div class=\"c-footer__group\">\n                <h3 class=\"c-footer__heading u-mt-0\">Libraries &amp; institutions</h3>\n                <ul class=\"c-footer__list\">\n                    <li class=\"c-footer__item\"><a class=\"c-footer__link\"\n                                                  href=\"https://www.springernature.com/gp/librarians/tools-services\"\n                                                  data-track=\"click\" data-track-action=\"librarian service and tools\"\n                                                  data-track-label=\"link\">Librarian service &amp; tools</a></li>\n                    <li class=\"c-footer__item\"><a class=\"c-footer__link\"\n                                                  href=\"https://www.springernature.com/gp/librarians/manage-your-account/librarianportal\"\n                                                  data-track=\"click\" data-track-action=\"librarian portal\"\n                                                  data-track-label=\"link\">Librarian portal</a></li>\n                    <li class=\"c-footer__item\"><a class=\"c-footer__link\"\n                                                  href=\"https://www.nature.com/openresearch/about-open-access/information-for-institutions\"\n                                                  data-track=\"click\" data-track-action=\"open research\"\n                                                  data-track-label=\"link\">Open research</a></li>\n                    <li class=\"c-footer__item\"><a class=\"c-footer__link\"\n                                                  href=\"https://www.springernature.com/gp/librarians/recommend-to-your-library\"\n                                                  data-track=\"click\" data-track-action=\"Recommend to library\"\n                                                  data-track-label=\"link\">Recommend to library</a></li>\n                </ul>\n            </div>\n\n            <div class=\"c-footer__group\">\n                <h3 class=\"c-footer__heading u-mt-0\">Advertising &amp; partnerships</h3>\n                <ul class=\"c-footer__list\">\n                    <li class=\"c-footer__item\"><a class=\"c-footer__link\"\n                                                  href=\"https://partnerships.nature.com/product/digital-advertising/\"\n                                                  data-track=\"click\" data-track-action=\"advertising\"\n                                                  data-track-label=\"link\">Advertising</a></li>\n                    <li class=\"c-footer__item\"><a class=\"c-footer__link\" href=\"https://partnerships.nature.com/\"\n                                                  data-track=\"click\" data-track-action=\"partnerships and services\"\n                                                  data-track-label=\"link\">Partnerships &amp; Services</a></li>\n                    <li class=\"c-footer__item\"><a class=\"c-footer__link\"\n                                                  href=\"https://partnerships.nature.com/media-kits/\" data-track=\"click\"\n                                                  data-track-action=\"media kits\" data-track-label=\"link\">Media kits</a>\n                    </li>\n                    <li class=\"c-footer__item\"><a class=\"c-footer__link\"\n                                                  href=\"https://partnerships.nature.com/product/branded-content-native-advertising/\"\n                                                  data-track-action=\"branded content\" data-track-label=\"link\">Branded\n                        content</a></li>\n                </ul>\n            </div>\n\n            <div class=\"c-footer__group\">\n                <h3 class=\"c-footer__heading u-mt-0\">Professional development</h3>\n                <ul class=\"c-footer__list\">\n                    <li class=\"c-footer__item\"><a class=\"c-footer__link\" href=\"https://www.nature.com/naturecareers/\"\n                                                  data-track=\"click\" data-track-action=\"nature careers\"\n                                                  data-track-label=\"link\">Nature Careers</a></li>\n                    <li class=\"c-footer__item\"><a class=\"c-footer__link\" href=\"https://conferences.nature.com\"\n                                                  data-track=\"click\" data-track-action=\"nature conferences\"\n                                                  data-track-label=\"link\">Nature<span class=\"u-visually-hidden\"> </span>\n                        Conferences</a></li>\n                </ul>\n            </div>\n\n            <div class=\"c-footer__group\">\n                <h3 class=\"c-footer__heading u-mt-0\">Regional websites</h3>\n                <ul class=\"c-footer__list\">\n                    <li class=\"c-footer__item\"><a class=\"c-footer__link\" href=\"https://www.nature.com/natafrica\"\n                                                  data-track=\"click\" data-track-action=\"nature africa\"\n                                                  data-track-label=\"link\">Nature Africa</a></li>\n                    <li class=\"c-footer__item\"><a class=\"c-footer__link\" href=\"http://www.naturechina.com\"\n                                                  data-track=\"click\" data-track-action=\"nature china\"\n                                                  data-track-label=\"link\">Nature China</a></li>\n                    <li class=\"c-footer__item\"><a class=\"c-footer__link\" href=\"https://www.nature.com/nindia\"\n                                                  data-track=\"click\" data-track-action=\"nature india\"\n                                                  data-track-label=\"link\">Nature India</a></li>\n                    <li class=\"c-footer__item\"><a class=\"c-footer__link\" href=\"https://www.nature.com/natitaly\"\n                                                  data-track=\"click\" data-track-action=\"nature Italy\"\n                                                  data-track-label=\"link\">Nature Italy</a></li>\n                    <li class=\"c-footer__item\"><a class=\"c-footer__link\" href=\"https://www.natureasia.com/ja-jp\"\n                                                  data-track=\"click\" data-track-action=\"nature japan\"\n                                                  data-track-label=\"link\">Nature Japan</a></li>\n                    <li class=\"c-footer__item\"><a class=\"c-footer__link\" href=\"https://www.nature.com/nmiddleeast\"\n                                                  data-track=\"click\" data-track-action=\"nature middle east\"\n                                                  data-track-label=\"link\">Nature Middle East</a></li>\n                </ul>\n            </div>\n\n        </div>\n    </div>\n    <div class=\"c-footer__container\">\n        <ul class=\"c-footer__links\">\n            <li class=\"c-footer__item\"><a class=\"c-footer__link\" href=\"https://www.nature.com/info/privacy\"\n                                          data-track=\"click\" data-track-action=\"privacy policy\" data-track-label=\"link\">Privacy\n                Policy</a></li>\n            <li class=\"c-footer__item\"><a class=\"c-footer__link\" href=\"https://www.nature.com/info/cookies\"\n                                          data-track=\"click\" data-track-action=\"use of cookies\" data-track-label=\"link\">Use\n                of cookies</a></li>\n            <li class=\"c-footer__item\">\n                <button class=\"optanon-toggle-display c-footer__link\" onclick=\"javascript:;\"\n                        data-cc-action=\"preferences\" data-track=\"click\" data-track-action=\"manage cookies\"\n                        data-track-label=\"link\">Your privacy choices/Manage cookies\n                </button>\n            </li>\n            <li class=\"c-footer__item\"><a class=\"c-footer__link\" href=\"https://www.nature.com/info/legal-notice\"\n                                          data-track=\"click\" data-track-action=\"legal notice\" data-track-label=\"link\">Legal\n                notice</a></li>\n            <li class=\"c-footer__item\"><a class=\"c-footer__link\"\n                                          href=\"https://www.nature.com/info/accessibility-statement\" data-track=\"click\"\n                                          data-track-action=\"accessibility statement\" data-track-label=\"link\">Accessibility\n                statement</a></li>\n            <li class=\"c-footer__item\"><a class=\"c-footer__link\" href=\"https://www.nature.com/info/terms-and-conditions\"\n                                          data-track=\"click\" data-track-action=\"terms and conditions\"\n                                          data-track-label=\"link\">Terms &amp; Conditions</a></li>\n            <li class=\"c-footer__item\"><a class=\"c-footer__link\" href=\"https://www.springernature.com/ccpa\"\n                                          data-track=\"click\" data-track-action=\"california privacy statement\"\n                                          data-track-label=\"link\">Your US state privacy rights</a></li>\n            \n        </ul>\n    </div>\n</div>\n\n\n        <div class=\"c-footer__container\">\n    <a href=\"https://www.springernature.com/\" class=\"c-footer__link\">\n        <img src=\"/static/images/logos/sn-logo-white-ea63208b81.svg\" alt=\"Springer Nature\" loading=\"lazy\" width=\"200\" height=\"20\"/>\n    </a>\n    <p class=\"c-footer__legal\" data-test=\"copyright\">&copy; 2024 Springer Nature Limited</p>\n</div>\n\n    </div>\n    <div class=\"u-visually-hidden\" aria-hidden=\"true\">\n    \n    <?xml version=\"1.0\" encoding=\"UTF-8\"?><!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\" \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs><path id=\"a\" d=\"M0 .74h56.72v55.24H0z\"/></defs><symbol id=\"icon-access\" viewBox=\"0 0 18 18\"><path d=\"m14 8c.5522847 0 1 .44771525 1 1v7h2.5c.2761424 0 .5.2238576.5.5v1.5h-18v-1.5c0-.2761424.22385763-.5.5-.5h2.5v-7c0-.55228475.44771525-1 1-1s1 .44771525 1 1v6.9996556h8v-6.9996556c0-.55228475.4477153-1 1-1zm-8 0 2 1v5l-2 1zm6 0v7l-2-1v-5zm-2.42653766-7.59857636 7.03554716 4.92488299c.4162533.29137735.5174853.86502537.226108 1.28127873-.1721584.24594054-.4534847.39241464-.7536934.39241464h-14.16284822c-.50810197 0-.92-.41189803-.92-.92 0-.30020869.1464741-.58153499.39241464-.75369337l7.03554714-4.92488299c.34432015-.2410241.80260453-.2410241 1.14692468 0zm-.57346234 2.03988748-3.65526982 2.55868888h7.31053962z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-account\" viewBox=\"0 0 18 18\"><path d=\"m10.2379028 16.9048051c1.3083556-.2032362 2.5118471-.7235183 3.5294683-1.4798399-.8731327-2.5141501-2.0638925-3.935978-3.7673711-4.3188248v-1.27684611c1.1651924-.41183641 2-1.52307546 2-2.82929429 0-1.65685425-1.3431458-3-3-3-1.65685425 0-3 1.34314575-3 3 0 1.30621883.83480763 2.41745788 2 2.82929429v1.27684611c-1.70347856.3828468-2.89423845 1.8046747-3.76737114 4.3188248 1.01762123.7563216 2.22111275 1.2766037 3.52946833 1.4798399.40563808.0629726.81921174.0951949 1.23790281.0951949s.83226473-.0322223 1.2379028-.0951949zm4.3421782-2.1721994c1.4927655-1.4532925 2.419919-3.484675 2.419919-5.7326057 0-4.418278-3.581722-8-8-8s-8 3.581722-8 8c0 2.2479307.92715352 4.2793132 2.41991895 5.7326057.75688473-2.0164459 1.83949951-3.6071894 3.48926591-4.3218837-1.14534283-.70360829-1.90918486-1.96796271-1.90918486-3.410722 0-2.209139 1.790861-4 4-4s4 1.790861 4 4c0 1.44275929-.763842 2.70711371-1.9091849 3.410722 1.6497664.7146943 2.7323812 2.3054378 3.4892659 4.3218837zm-5.580081 3.2673943c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-alert\" viewBox=\"0 0 18 18\"><path d=\"m4 10h2.5c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-3.08578644l-1.12132034 1.1213203c-.18753638.1875364-.29289322.4418903-.29289322.7071068v.1715729h14v-.1715729c0-.2652165-.1053568-.5195704-.2928932-.7071068l-1.7071068-1.7071067v-3.4142136c0-2.76142375-2.2385763-5-5-5-2.76142375 0-5 2.23857625-5 5zm3 4c0 1.1045695.8954305 2 2 2s2-.8954305 2-2zm-5 0c-.55228475 0-1-.4477153-1-1v-.1715729c0-.530433.21071368-1.0391408.58578644-1.4142135l1.41421356-1.4142136v-3c0-3.3137085 2.6862915-6 6-6s6 2.6862915 6 6v3l1.4142136 1.4142136c.3750727.3750727.5857864.8837805.5857864 1.4142135v.1715729c0 .5522847-.4477153 1-1 1h-4c0 1.6568542-1.3431458 3-3 3-1.65685425 0-3-1.3431458-3-3z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-arrow-broad\" viewBox=\"0 0 16 16\"><path d=\"m6.10307866 2.97190702v7.69043288l2.44965196-2.44676915c.38776071-.38730439 1.0088052-.39493524 1.38498697-.01919617.38609051.38563612.38643641 1.01053024-.00013864 1.39665039l-4.12239817 4.11754683c-.38616704.3857126-1.01187344.3861062-1.39846576-.0000311l-4.12258206-4.11773056c-.38618426-.38572979-.39254614-1.00476697-.01636437-1.38050605.38609047-.38563611 1.01018509-.38751562 1.4012233.00306241l2.44985644 2.4469734v-8.67638639c0-.54139983.43698413-.98042709.98493125-.98159081l7.89910522-.0043627c.5451687 0 .9871152.44142642.9871152.98595351s-.4419465.98595351-.9871152.98595351z\" fill-rule=\"evenodd\" transform=\"matrix(-1 0 0 -1 14 15)\"/></symbol><symbol id=\"icon-arrow-down\" viewBox=\"0 0 16 16\"><path d=\"m3.28337502 11.5302405 4.03074001 4.176208c.37758093.3912076.98937525.3916069 1.367372-.0000316l4.03091977-4.1763942c.3775978-.3912252.3838182-1.0190815.0160006-1.4001736-.3775061-.39113013-.9877245-.39303641-1.3700683.003106l-2.39538585 2.4818345v-11.6147896l-.00649339-.11662112c-.055753-.49733869-.46370161-.88337888-.95867408-.88337888-.49497246 0-.90292107.38604019-.95867408.88337888l-.00649338.11662112v11.6147896l-2.39518594-2.4816273c-.37913917-.39282218-.98637524-.40056175-1.35419292-.0194697-.37750607.3911302-.37784433 1.0249269.00013556 1.4165479z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-arrow-left\" viewBox=\"0 0 16 16\"><path d=\"m4.46975946 3.28337502-4.17620792 4.03074001c-.39120768.37758093-.39160691.98937525.0000316 1.367372l4.1763942 4.03091977c.39122514.3775978 1.01908149.3838182 1.40017357.0160006.39113012-.3775061.3930364-.9877245-.00310603-1.3700683l-2.48183446-2.39538585h11.61478958l.1166211-.00649339c.4973387-.055753.8833789-.46370161.8833789-.95867408 0-.49497246-.3860402-.90292107-.8833789-.95867408l-.1166211-.00649338h-11.61478958l2.4816273-2.39518594c.39282216-.37913917.40056173-.98637524.01946965-1.35419292-.39113012-.37750607-1.02492687-.37784433-1.41654791.00013556z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-arrow-right\" viewBox=\"0 0 16 16\"><path d=\"m11.5302405 12.716625 4.176208-4.03074003c.3912076-.37758093.3916069-.98937525-.0000316-1.367372l-4.1763942-4.03091981c-.3912252-.37759778-1.0190815-.38381821-1.4001736-.01600053-.39113013.37750607-.39303641.98772445.003106 1.37006824l2.4818345 2.39538588h-11.6147896l-.11662112.00649339c-.49733869.055753-.88337888.46370161-.88337888.95867408 0 .49497246.38604019.90292107.88337888.95867408l.11662112.00649338h11.6147896l-2.4816273 2.39518592c-.39282218.3791392-.40056175.9863753-.0194697 1.3541929.3911302.3775061 1.0249269.3778444 1.4165479-.0001355z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-arrow-sub\" viewBox=\"0 0 16 16\"><path d=\"m7.89692134 4.97190702v7.69043288l-2.44965196-2.4467692c-.38776071-.38730434-1.0088052-.39493519-1.38498697-.0191961-.38609047.3856361-.38643643 1.0105302.00013864 1.3966504l4.12239817 4.1175468c.38616704.3857126 1.01187344.3861062 1.39846576-.0000311l4.12258202-4.1177306c.3861843-.3857298.3925462-1.0047669.0163644-1.380506-.3860905-.38563612-1.0101851-.38751563-1.4012233.0030624l-2.44985643 2.4469734v-8.67638639c0-.54139983-.43698413-.98042709-.98493125-.98159081l-7.89910525-.0043627c-.54516866 0-.98711517.44142642-.98711517.98595351s.44194651.98595351.98711517.98595351z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-arrow-up\" viewBox=\"0 0 16 16\"><path d=\"m12.716625 4.46975946-4.03074003-4.17620792c-.37758093-.39120768-.98937525-.39160691-1.367372.0000316l-4.03091981 4.1763942c-.37759778.39122514-.38381821 1.01908149-.01600053 1.40017357.37750607.39113012.98772445.3930364 1.37006824-.00310603l2.39538588-2.48183446v11.61478958l.00649339.1166211c.055753.4973387.46370161.8833789.95867408.8833789.49497246 0 .90292107-.3860402.95867408-.8833789l.00649338-.1166211v-11.61478958l2.39518592 2.4816273c.3791392.39282216.9863753.40056173 1.3541929.01946965.3775061-.39113012.3778444-1.02492687-.0001355-1.41654791z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-article\" viewBox=\"0 0 18 18\"><path d=\"m13 15v-12.9906311c0-.0073595-.0019884-.0093689.0014977-.0093689l-11.00158888.00087166v13.00506804c0 .5482678.44615281.9940603.99415146.9940603h10.27350412c-.1701701-.2941734-.2675644-.6357129-.2675644-1zm-12 .0059397v-13.00506804c0-.5562408.44704472-1.00087166.99850233-1.00087166h11.00299537c.5510129 0 .9985023.45190985.9985023 1.0093689v2.9906311h3v9.9914698c0 1.1065798-.8927712 2.0085302-1.9940603 2.0085302h-12.01187942c-1.09954652 0-1.99406028-.8927712-1.99406028-1.9940603zm13-9.0059397v9c0 .5522847.4477153 1 1 1s1-.4477153 1-1v-9zm-10-2h7v4h-7zm1 1v2h5v-2zm-1 4h7v1h-7zm0 2h7v1h-7zm0 2h7v1h-7z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-audio\" viewBox=\"0 0 18 18\"><path d=\"m13.0957477 13.5588459c-.195279.1937043-.5119137.193729-.7072234.0000551-.1953098-.193674-.1953346-.5077061-.0000556-.7014104 1.0251004-1.0168342 1.6108711-2.3905226 1.6108711-3.85745208 0-1.46604976-.5850634-2.83898246-1.6090736-3.85566829-.1951894-.19379323-.1950192-.50782531.0003802-.70141028.1953993-.19358497.512034-.19341614.7072234.00037709 1.2094886 1.20083761 1.901635 2.8250555 1.901635 4.55670148 0 1.73268608-.6929822 3.35779608-1.9037571 4.55880738zm2.1233994 2.1025159c-.195234.193749-.5118687.1938462-.7072235.0002171-.1953548-.1936292-.1954528-.5076613-.0002189-.7014104 1.5832215-1.5711805 2.4881302-3.6939808 2.4881302-5.96012998 0-2.26581266-.9046382-4.3883241-2.487443-5.95944795-.1952117-.19377107-.1950777-.50780316.0002993-.70141031s.5120117-.19347426.7072234.00029682c1.7683321 1.75528196 2.7800854 4.12911258 2.7800854 6.66056144 0 2.53182498-1.0120556 4.90597838-2.7808529 6.66132328zm-14.21898205-3.6854911c-.5523759 0-1.00016505-.4441085-1.00016505-.991944v-3.96777631c0-.54783558.44778915-.99194407 1.00016505-.99194407h2.0003301l5.41965617-3.8393633c.44948677-.31842296 1.07413994-.21516983 1.39520191.23062232.12116339.16823446.18629727.36981184.18629727.57655577v12.01603479c0 .5478356-.44778914.9919441-1.00016505.9919441-.20845738 0-.41170538-.0645985-.58133413-.184766l-5.41965617-3.8393633zm0-.991944h2.32084805l5.68047235 4.0241292v-12.01603479l-5.68047235 4.02412928h-2.32084805z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-block\" viewBox=\"0 0 24 24\"><path d=\"m0 0h24v24h-24z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-book\" viewBox=\"0 0 18 18\"><path d=\"m4 13v-11h1v11h11v-11h-13c-.55228475 0-1 .44771525-1 1v10.2675644c.29417337-.1701701.63571286-.2675644 1-.2675644zm12 1h-13c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1h13zm0 3h-13c-1.1045695 0-2-.8954305-2-2v-12c0-1.1045695.8954305-2 2-2h13c.5522847 0 1 .44771525 1 1v14c0 .5522847-.4477153 1-1 1zm-8.5-13h6c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-6c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm1 2h4c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-4c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-broad\" viewBox=\"0 0 24 24\"><path d=\"m9.18274226 7.81v7.7999954l2.48162734-2.4816273c.3928221-.3928221 1.0219731-.4005617 1.4030652-.0194696.3911301.3911301.3914806 1.0249268-.0001404 1.4165479l-4.17620796 4.1762079c-.39120769.3912077-1.02508144.3916069-1.41671995-.0000316l-4.1763942-4.1763942c-.39122514-.3912251-.39767006-1.0190815-.01657798-1.4001736.39113012-.3911301 1.02337106-.3930364 1.41951349.0031061l2.48183446 2.4818344v-8.7999954c0-.54911294.4426881-.99439484.99778758-.99557515l8.00221246-.00442485c.5522847 0 1 .44771525 1 1s-.4477153 1-1 1z\" fill-rule=\"evenodd\" transform=\"matrix(-1 0 0 -1 20.182742 24.805206)\"/></symbol><symbol id=\"icon-calendar\" viewBox=\"0 0 18 18\"><path d=\"m12.5 0c.2761424 0 .5.21505737.5.49047852v.50952148h2c1.1072288 0 2 .89451376 2 2v12c0 1.1072288-.8945138 2-2 2h-12c-1.1072288 0-2-.8945138-2-2v-12c0-1.1072288.89451376-2 2-2h1v1h-1c-.55393837 0-1 .44579254-1 1v3h14v-3c0-.55393837-.4457925-1-1-1h-2v1.50952148c0 .27088381-.2319336.49047852-.5.49047852-.2761424 0-.5-.21505737-.5-.49047852v-3.01904296c0-.27088381.2319336-.49047852.5-.49047852zm3.5 7h-14v8c0 .5539384.44579254 1 1 1h12c.5539384 0 1-.4457925 1-1zm-11 6v1h-1v-1zm3 0v1h-1v-1zm3 0v1h-1v-1zm-6-2v1h-1v-1zm3 0v1h-1v-1zm6 0v1h-1v-1zm-3 0v1h-1v-1zm-3-2v1h-1v-1zm6 0v1h-1v-1zm-3 0v1h-1v-1zm-5.5-9c.27614237 0 .5.21505737.5.49047852v.50952148h5v1h-5v1.50952148c0 .27088381-.23193359.49047852-.5.49047852-.27614237 0-.5-.21505737-.5-.49047852v-3.01904296c0-.27088381.23193359-.49047852.5-.49047852z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-cart\" viewBox=\"0 0 18 18\"><path d=\"m5 14c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm10 0c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm-10 1c-.55228475 0-1 .4477153-1 1s.44771525 1 1 1 1-.4477153 1-1-.44771525-1-1-1zm10 0c-.5522847 0-1 .4477153-1 1s.4477153 1 1 1 1-.4477153 1-1-.4477153-1-1-1zm-12.82032249-15c.47691417 0 .88746157.33678127.98070211.80449199l.23823144 1.19501025 13.36277974.00045554c.5522847.00001882.9999659.44774934.9999659 1.00004222 0 .07084994-.0075361.14150708-.022474.2107727l-1.2908094 5.98534344c-.1007861.46742419-.5432548.80388386-1.0571651.80388386h-10.24805106c-.59173366 0-1.07142857.4477153-1.07142857 1 0 .5128358.41361449.9355072.94647737.9932723l.1249512.0067277h10.35933776c.2749512 0 .4979349.2228539.4979349.4978051 0 .2749417-.2227336.4978951-.4976753.4980063l-10.35959736.0041886c-1.18346732 0-2.14285714-.8954305-2.14285714-2 0-.6625717.34520317-1.24989198.87690425-1.61383592l-1.63768102-8.19004794c-.01312273-.06561364-.01950005-.131011-.0196107-.19547395l-1.71961253-.00064219c-.27614237 0-.5-.22385762-.5-.5 0-.27614237.22385763-.5.5-.5zm14.53193359 2.99950224h-13.11300004l1.20580469 6.02530174c.11024034-.0163252.22327998-.02480398.33844139-.02480398h10.27064786z\"/></symbol><symbol id=\"icon-chevron-less\" viewBox=\"0 0 10 10\"><path d=\"m5.58578644 4-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z\" fill-rule=\"evenodd\" transform=\"matrix(0 -1 -1 0 9 9)\"/></symbol><symbol id=\"icon-chevron-more\" viewBox=\"0 0 10 10\"><path d=\"m5.58578644 6-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4.00000002c-.39052429.3905243-1.02368927.3905243-1.41421356 0s-.39052429-1.02368929 0-1.41421358z\" fill-rule=\"evenodd\" transform=\"matrix(0 1 -1 0 11 1)\"/></symbol><symbol id=\"icon-chevron-right\" viewBox=\"0 0 10 10\"><path d=\"m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z\" fill-rule=\"evenodd\" transform=\"matrix(0 -1 1 0 0 10)\"/></symbol><symbol id=\"icon-circle-fill\" viewBox=\"0 0 16 16\"><path d=\"m8 14c-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6 6 2.6862915 6 6-2.6862915 6-6 6z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-circle\" viewBox=\"0 0 16 16\"><path d=\"m8 12c2.209139 0 4-1.790861 4-4s-1.790861-4-4-4-4 1.790861-4 4 1.790861 4 4 4zm0 2c-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6 6 2.6862915 6 6-2.6862915 6-6 6z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-citation\" viewBox=\"0 0 18 18\"><path d=\"m8.63593473 5.99995183c2.20913897 0 3.99999997 1.79084375 3.99999997 3.99996146 0 1.40730761-.7267788 2.64486871-1.8254829 3.35783281 1.6240224.6764218 2.8754442 2.0093871 3.4610603 3.6412466l-1.0763845.000006c-.5310008-1.2078237-1.5108121-2.1940153-2.7691712-2.7181346l-.79002167-.329052v-1.023992l.63016577-.4089232c.8482885-.5504661 1.3698342-1.4895187 1.3698342-2.51898361 0-1.65683828-1.3431457-2.99996146-2.99999997-2.99996146-1.65685425 0-3 1.34312318-3 2.99996146 0 1.02946491.52154569 1.96851751 1.36983419 2.51898361l.63016581.4089232v1.023992l-.79002171.329052c-1.25835905.5241193-2.23817037 1.5103109-2.76917113 2.7181346l-1.07638453-.000006c.58561612-1.6318595 1.8370379-2.9648248 3.46106024-3.6412466-1.09870405-.7129641-1.82548287-1.9505252-1.82548287-3.35783281 0-2.20911771 1.790861-3.99996146 4-3.99996146zm7.36897597-4.99995183c1.1018574 0 1.9950893.89353404 1.9950893 2.00274083v5.994422c0 1.10608317-.8926228 2.00274087-1.9950893 2.00274087l-3.0049107-.0009037v-1l3.0049107.00091329c.5490631 0 .9950893-.44783123.9950893-1.00275046v-5.994422c0-.55646537-.4450595-1.00275046-.9950893-1.00275046h-14.00982141c-.54906309 0-.99508929.44783123-.99508929 1.00275046v5.9971821c0 .66666024.33333333.99999036 1 .99999036l2-.00091329v1l-2 .0009037c-1 0-2-.99999041-2-1.99998077v-5.9971821c0-1.10608322.8926228-2.00274083 1.99508929-2.00274083zm-8.5049107 2.9999711c.27614237 0 .5.22385547.5.5 0 .2761349-.22385763.5-.5.5h-4c-.27614237 0-.5-.2238651-.5-.5 0-.27614453.22385763-.5.5-.5zm3 0c.2761424 0 .5.22385547.5.5 0 .2761349-.2238576.5-.5.5h-1c-.27614237 0-.5-.2238651-.5-.5 0-.27614453.22385763-.5.5-.5zm4 0c.2761424 0 .5.22385547.5.5 0 .2761349-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238651-.5-.5 0-.27614453.2238576-.5.5-.5z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-close\" viewBox=\"0 0 16 16\"><path d=\"m2.29679575 12.2772478c-.39658757.3965876-.39438847 1.0328109-.00062148 1.4265779.39651227.3965123 1.03246768.3934888 1.42657791-.0006214l4.27724782-4.27724787 4.2772478 4.27724787c.3965876.3965875 1.0328109.3943884 1.4265779.0006214.3965123-.3965122.3934888-1.0324677-.0006214-1.4265779l-4.27724787-4.2772478 4.27724787-4.27724782c.3965875-.39658757.3943884-1.03281091.0006214-1.42657791-.3965122-.39651226-1.0324677-.39348875-1.4265779.00062148l-4.2772478 4.27724782-4.27724782-4.27724782c-.39658757-.39658757-1.03281091-.39438847-1.42657791-.00062148-.39651226.39651227-.39348875 1.03246768.00062148 1.42657791l4.27724782 4.27724782z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-collections\" viewBox=\"0 0 18 18\"><path d=\"m15 4c1.1045695 0 2 .8954305 2 2v9c0 1.1045695-.8954305 2-2 2h-8c-1.1045695 0-2-.8954305-2-2h1c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h8c.5128358 0 .9355072-.3860402.9932723-.8833789l.0067277-.1166211v-9c0-.51283584-.3860402-.93550716-.8833789-.99327227l-.1166211-.00672773h-1v-1zm-4-3c1.1045695 0 2 .8954305 2 2v9c0 1.1045695-.8954305 2-2 2h-8c-1.1045695 0-2-.8954305-2-2v-9c0-1.1045695.8954305-2 2-2zm0 1h-8c-.51283584 0-.93550716.38604019-.99327227.88337887l-.00672773.11662113v9c0 .5128358.38604019.9355072.88337887.9932723l.11662113.0067277h8c.5128358 0 .9355072-.3860402.9932723-.8833789l.0067277-.1166211v-9c0-.51283584-.3860402-.93550716-.8833789-.99327227zm-1.5 7c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm0-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm0-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-5c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-compare\" viewBox=\"0 0 18 18\"><path d=\"m12 3c3.3137085 0 6 2.6862915 6 6s-2.6862915 6-6 6c-1.0928452 0-2.11744941-.2921742-2.99996061-.8026704-.88181407.5102749-1.90678042.8026704-3.00003939.8026704-3.3137085 0-6-2.6862915-6-6s2.6862915-6 6-6c1.09325897 0 2.11822532.29239547 3.00096303.80325037.88158756-.51107621 1.90619177-.80325037 2.99903697-.80325037zm-6 1c-2.76142375 0-5 2.23857625-5 5 0 2.7614237 2.23857625 5 5 5 .74397391 0 1.44999672-.162488 2.08451611-.4539116-1.27652344-1.1000812-2.08451611-2.7287264-2.08451611-4.5460884s.80799267-3.44600721 2.08434391-4.5463015c-.63434719-.29121054-1.34037-.4536985-2.08434391-.4536985zm6 0c-.7439739 0-1.4499967.16248796-2.08451611.45391156 1.27652341 1.10008123 2.08451611 2.72872644 2.08451611 4.54608844s-.8079927 3.4460072-2.08434391 4.5463015c.63434721.2912105 1.34037001.4536985 2.08434391.4536985 2.7614237 0 5-2.2385763 5-5 0-2.76142375-2.2385763-5-5-5zm-1.4162763 7.0005324h-3.16744736c.15614659.3572676.35283837.6927622.58425872 1.0006671h1.99892988c.23142036-.3079049.42811216-.6433995.58425876-1.0006671zm.4162763-2.0005324h-4c0 .34288501.0345146.67770871.10025909 1.0011864h3.79948181c.0657445-.32347769.1002591-.65830139.1002591-1.0011864zm-.4158423-1.99953894h-3.16831543c-.13859957.31730812-.24521946.651783-.31578599.99935097h3.79988742c-.0705665-.34756797-.1771864-.68204285-.315786-.99935097zm-1.58295822-1.999926-.08316107.06199199c-.34550042.27081213-.65446126.58611297-.91825862.93727862h2.00044041c-.28418626-.37830727-.6207872-.71499149-.99902072-.99927061z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-download-file\" viewBox=\"0 0 18 18\"><path d=\"m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm0 1h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v14.00982141c0 .5500396.44491393.9950893.99406028.9950893h12.01187942c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717zm-1.5046024 4c.27614237 0 .5.21637201.5.49209595v6.14827645l1.7462789-1.77990922c.1933927-.1971171.5125222-.19455839.7001689-.0069117.1932998.19329992.1910058.50899492-.0027774.70277812l-2.59089271 2.5908927c-.19483374.1948337-.51177825.1937771-.70556873-.0000133l-2.59099079-2.5909908c-.19484111-.1948411-.19043735-.5151448-.00279066-.70279146.19329987-.19329987.50465175-.19237083.70018565.00692852l1.74638684 1.78001764v-6.14827695c0-.27177709.23193359-.49209595.5-.49209595z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-download\" viewBox=\"0 0 16 16\"><path d=\"m12.9975267 12.999368c.5467123 0 1.0024733.4478567 1.0024733 1.000316 0 .5563109-.4488226 1.000316-1.0024733 1.000316h-9.99505341c-.54671233 0-1.00247329-.4478567-1.00247329-1.000316 0-.5563109.44882258-1.000316 1.00247329-1.000316zm-4.9975267-11.999368c.55228475 0 1 .44497754 1 .99589209v6.80214418l2.4816273-2.48241149c.3928222-.39294628 1.0219732-.4006883 1.4030652-.01947579.3911302.39125371.3914806 1.02525073-.0001404 1.41699553l-4.17620792 4.17752758c-.39120769.3913313-1.02508144.3917306-1.41671995-.0000316l-4.17639421-4.17771394c-.39122513-.39134876-.39767006-1.01940351-.01657797-1.40061601.39113012-.39125372 1.02337105-.3931606 1.41951349.00310701l2.48183446 2.48261871v-6.80214418c0-.55001601.44386482-.99589209 1-.99589209z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-editors\" viewBox=\"0 0 18 18\"><path d=\"m8.72592184 2.54588137c-.48811714-.34391207-1.08343326-.54588137-1.72592184-.54588137-1.65685425 0-3 1.34314575-3 3 0 1.02947485.5215457 1.96853646 1.3698342 2.51900785l.6301658.40892721v1.02400182l-.79002171.32905522c-1.93395773.8055207-3.20997829 2.7024791-3.20997829 4.8180274v.9009805h-1v-.9009805c0-2.5479714 1.54557359-4.79153984 3.82548288-5.7411543-1.09870406-.71297106-1.82548288-1.95054399-1.82548288-3.3578652 0-2.209139 1.790861-4 4-4 1.09079823 0 2.07961816.43662103 2.80122451 1.1446278-.37707584.09278571-.7373238.22835063-1.07530267.40125357zm-2.72592184 14.45411863h-1v-.9009805c0-2.5479714 1.54557359-4.7915398 3.82548288-5.7411543-1.09870406-.71297106-1.82548288-1.95054399-1.82548288-3.3578652 0-2.209139 1.790861-4 4-4s4 1.790861 4 4c0 1.40732121-.7267788 2.64489414-1.8254829 3.3578652 2.2799093.9496145 3.8254829 3.1931829 3.8254829 5.7411543v.9009805h-1v-.9009805c0-2.1155483-1.2760206-4.0125067-3.2099783-4.8180274l-.7900217-.3290552v-1.02400184l.6301658-.40892721c.8482885-.55047139 1.3698342-1.489533 1.3698342-2.51900785 0-1.65685425-1.3431458-3-3-3-1.65685425 0-3 1.34314575-3 3 0 1.02947485.5215457 1.96853646 1.3698342 2.51900785l.6301658.40892721v1.02400184l-.79002171.3290552c-1.93395773.8055207-3.20997829 2.7024791-3.20997829 4.8180274z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-email\" viewBox=\"0 0 18 18\"><path d=\"m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587h-14.00982141c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm0 1h-14.00982141c-.54871518 0-.99508929.44887827-.99508929 1.00585866v9.98828264c0 .5572961.44630695 1.0058587.99508929 1.0058587h14.00982141c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-.0049107 2.55749512v1.44250488l-7 4-7-4v-1.44250488l7 4z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-error\" viewBox=\"0 0 18 18\"><path d=\"m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm2.8630343 4.71100931-2.8630343 2.86303426-2.86303426-2.86303426c-.39658757-.39658757-1.03281091-.39438847-1.4265779-.00062147-.39651227.39651226-.39348876 1.03246767.00062147 1.4265779l2.86303426 2.86303426-2.86303426 2.8630343c-.39658757.3965875-.39438847 1.0328109-.00062147 1.4265779.39651226.3965122 1.03246767.3934887 1.4265779-.0006215l2.86303426-2.8630343 2.8630343 2.8630343c.3965875.3965876 1.0328109.3943885 1.4265779.0006215.3965122-.3965123.3934887-1.0324677-.0006215-1.4265779l-2.8630343-2.8630343 2.8630343-2.86303426c.3965876-.39658757.3943885-1.03281091.0006215-1.4265779-.3965123-.39651227-1.0324677-.39348876-1.4265779.00062147z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-ethics\" viewBox=\"0 0 18 18\"><path d=\"m6.76384967 1.41421356.83301651-.8330165c.77492941-.77492941 2.03133823-.77492941 2.80626762 0l.8330165.8330165c.3750728.37507276.8837806.58578644 1.4142136.58578644h1.3496361c1.1045695 0 2 .8954305 2 2v1.34963611c0 .53043298.2107137 1.03914081.5857864 1.41421356l.8330165.83301651c.7749295.77492941.7749295 2.03133823 0 2.80626762l-.8330165.8330165c-.3750727.3750728-.5857864.8837806-.5857864 1.4142136v1.3496361c0 1.1045695-.8954305 2-2 2h-1.3496361c-.530433 0-1.0391408.2107137-1.4142136.5857864l-.8330165.8330165c-.77492939.7749295-2.03133821.7749295-2.80626762 0l-.83301651-.8330165c-.37507275-.3750727-.88378058-.5857864-1.41421356-.5857864h-1.34963611c-1.1045695 0-2-.8954305-2-2v-1.3496361c0-.530433-.21071368-1.0391408-.58578644-1.4142136l-.8330165-.8330165c-.77492941-.77492939-.77492941-2.03133821 0-2.80626762l.8330165-.83301651c.37507276-.37507275.58578644-.88378058.58578644-1.41421356v-1.34963611c0-1.1045695.8954305-2 2-2h1.34963611c.53043298 0 1.03914081-.21071368 1.41421356-.58578644zm-1.41421356 1.58578644h-1.34963611c-.55228475 0-1 .44771525-1 1v1.34963611c0 .79564947-.31607052 1.55871121-.87867966 2.12132034l-.8330165.83301651c-.38440512.38440512-.38440512 1.00764896 0 1.39205408l.8330165.83301646c.56260914.5626092.87867966 1.3256709.87867966 2.1213204v1.3496361c0 .5522847.44771525 1 1 1h1.34963611c.79564947 0 1.55871121.3160705 2.12132034.8786797l.83301651.8330165c.38440512.3844051 1.00764896.3844051 1.39205408 0l.83301646-.8330165c.5626092-.5626092 1.3256709-.8786797 2.1213204-.8786797h1.3496361c.5522847 0 1-.4477153 1-1v-1.3496361c0-.7956495.3160705-1.5587112.8786797-2.1213204l.8330165-.83301646c.3844051-.38440512.3844051-1.00764896 0-1.39205408l-.8330165-.83301651c-.5626092-.56260913-.8786797-1.32567087-.8786797-2.12132034v-1.34963611c0-.55228475-.4477153-1-1-1h-1.3496361c-.7956495 0-1.5587112-.31607052-2.1213204-.87867966l-.83301646-.8330165c-.38440512-.38440512-1.00764896-.38440512-1.39205408 0l-.83301651.8330165c-.56260913.56260914-1.32567087.87867966-2.12132034.87867966zm3.58698944 11.4960218c-.02081224.002155-.04199226.0030286-.06345763.002542-.98766446-.0223875-1.93408568-.3063547-2.75885125-.8155622-.23496767-.1450683-.30784554-.4531483-.16277726-.688116.14506827-.2349677.45314827-.3078455.68811595-.1627773.67447084.4164161 1.44758575.6483839 2.25617384.6667123.01759529.0003988.03495764.0017019.05204365.0038639.01713363-.0017748.03452416-.0026845.05212715-.0026845 2.4852814 0 4.5-2.0147186 4.5-4.5 0-1.04888973-.3593547-2.04134635-1.0074477-2.83787157-.1742817-.21419731-.1419238-.5291218.0722736-.70340353.2141973-.17428173.5291218-.14192375.7034035.07227357.7919032.97327203 1.2317706 2.18808682 1.2317706 3.46900153 0 3.0375661-2.4624339 5.5-5.5 5.5-.02146768 0-.04261937-.0013529-.06337445-.0039782zm1.57975095-10.78419583c.2654788.07599731.419084.35281842.3430867.61829728-.0759973.26547885-.3528185.419084-.6182973.3430867-.37560116-.10752146-.76586237-.16587951-1.15568824-.17249193-2.5587807-.00064534-4.58547766 2.00216524-4.58547766 4.49928198 0 .62691557.12797645 1.23496.37274865 1.7964426.11035133.2531347-.0053975.5477984-.25853224.6581497-.25313473.1103514-.54779841-.0053975-.65814974-.2585322-.29947131-.6869568-.45606667-1.43097603-.45606667-2.1960601 0-3.05211432 2.47714695-5.50006595 5.59399617-5.49921198.48576182.00815502.96289603.0795037 1.42238033.21103795zm-1.9766658 6.41091303 2.69835-2.94655317c.1788432-.21040373.4943901-.23598862.7047939-.05714545.2104037.17884318.2359886.49439014.0571454.70479387l-3.01637681 3.34277395c-.18039088.1999106-.48669547.2210637-.69285412.0478478l-1.93095347-1.62240047c-.21213845-.17678204-.24080048-.49206439-.06401844-.70420284.17678204-.21213844.49206439-.24080048.70420284-.06401844z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-expand\"><path d=\"M7.498 11.918a.997.997 0 0 0-.003-1.411.995.995 0 0 0-1.412-.003l-4.102 4.102v-3.51A1 1 0 0 0 .98 10.09.992.992 0 0 0 0 11.092V17c0 .554.448 1.002 1.002 1.002h5.907c.554 0 1.002-.45 1.002-1.003 0-.539-.45-.978-1.006-.978h-3.51zm3.005-5.835a.997.997 0 0 0 .003 1.412.995.995 0 0 0 1.411.003l4.103-4.103v3.51a1 1 0 0 0 1.001 1.006A.992.992 0 0 0 18 6.91V1.002A1 1 0 0 0 17 0h-5.907a1.003 1.003 0 0 0-1.002 1.003c0 .539.45.978 1.006.978h3.51z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-explore\" viewBox=\"0 0 18 18\"><path d=\"m9 17c4.418278 0 8-3.581722 8-8s-3.581722-8-8-8-8 3.581722-8 8 3.581722 8 8 8zm0 1c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9zm0-2.5c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5c2.969509 0 5.400504-2.3575119 5.497023-5.31714844.0090007-.27599565.2400359-.49243782.5160315-.48343711.2759957.0090007.4924378.2400359.4834371.51603155-.114093 3.4985237-2.9869632 6.284554-6.4964916 6.284554zm-.29090657-12.99359748c.27587424-.01216621.50937715.20161139.52154336.47748563.01216621.27587423-.20161139.50937715-.47748563.52154336-2.93195733.12930094-5.25315116 2.54886451-5.25315116 5.49456849 0 .27614237-.22385763.5-.5.5s-.5-.22385763-.5-.5c0-3.48142406 2.74307146-6.34074398 6.20909343-6.49359748zm1.13784138 8.04763908-1.2004882-1.20048821c-.19526215-.19526215-.19526215-.51184463 0-.70710678s.51184463-.19526215.70710678 0l1.20048821 1.2004882 1.6006509-4.00162734-4.50670359 1.80268144-1.80268144 4.50670359zm4.10281269-6.50378907-2.6692597 6.67314927c-.1016411.2541026-.3029834.4554449-.557086.557086l-6.67314927 2.6692597 2.66925969-6.67314926c.10164107-.25410266.30298336-.45544495.55708602-.55708602z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-filter\" viewBox=\"0 0 16 16\"><path d=\"m14.9738641 0c.5667192 0 1.0261359.4477136 1.0261359 1 0 .24221858-.0902161.47620768-.2538899.65849851l-5.6938314 6.34147206v5.49997973c0 .3147562-.1520673.6111434-.4104543.7999971l-2.05227171 1.4999945c-.45337535.3313696-1.09655869.2418269-1.4365902-.1999993-.13321514-.1730955-.20522717-.3836284-.20522717-.5999978v-6.99997423l-5.69383133-6.34147206c-.3731872-.41563511-.32996891-1.0473954.09653074-1.41107611.18705584-.15950448.42716133-.2474224.67571519-.2474224zm-5.9218641 8.5h-2.105v6.491l.01238459.0070843.02053271.0015705.01955278-.0070558 2.0532976-1.4990996zm-8.02585008-7.5-.01564945.00240169 5.83249953 6.49759831h2.313l5.836-6.499z\"/></symbol><symbol id=\"icon-home\" viewBox=\"0 0 18 18\"><path d=\"m9 5-6 6v5h4v-4h4v4h4v-5zm7 6.5857864v4.4142136c0 .5522847-.4477153 1-1 1h-5v-4h-2v4h-5c-.55228475 0-1-.4477153-1-1v-4.4142136c-.25592232 0-.51184464-.097631-.70710678-.2928932l-.58578644-.5857864c-.39052429-.3905243-.39052429-1.02368929 0-1.41421358l8.29289322-8.29289322 8.2928932 8.29289322c.3905243.39052429.3905243 1.02368928 0 1.41421358l-.5857864.5857864c-.1952622.1952622-.4511845.2928932-.7071068.2928932zm-7-9.17157284-7.58578644 7.58578644.58578644.5857864 7-6.99999996 7 6.99999996.5857864-.5857864z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-image\" viewBox=\"0 0 18 18\"><path d=\"m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm-3.49645283 10.1752453-3.89407257 6.7495552c.11705545.048464.24538859.0751995.37998328.0751995h10.60290092l-2.4329715-4.2154691-1.57494129 2.7288098zm8.49779013 6.8247547c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v13.98991071l4.50814957-7.81026689 3.08089884 5.33809539 1.57494129-2.7288097 3.5875735 6.2159812zm-3.0059397-11c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2-2-.8954305-2-2 .8954305-2 2-2zm0 1c-.5522847 0-1 .44771525-1 1s.4477153 1 1 1 1-.44771525 1-1-.4477153-1-1-1z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-info\" viewBox=\"0 0 18 18\"><path d=\"m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm0 7h-1.5l-.11662113.00672773c-.49733868.05776511-.88337887.48043643-.88337887.99327227 0 .47338693.32893365.86994729.77070917.97358929l.1126697.01968298.11662113.00672773h.5v3h-.5l-.11662113.0067277c-.42082504.0488782-.76196299.3590206-.85696816.7639815l-.01968298.1126697-.00672773.1166211.00672773.1166211c.04887817.4208251.35902055.761963.76398144.8569682l.1126697.019683.11662113.0067277h3l.1166211-.0067277c.4973387-.0577651.8833789-.4804365.8833789-.9932723 0-.4733869-.3289337-.8699473-.7707092-.9735893l-.1126697-.019683-.1166211-.0067277h-.5v-4l-.00672773-.11662113c-.04887817-.42082504-.35902055-.76196299-.76398144-.85696816l-.1126697-.01968298zm0-3.25c-.69035594 0-1.25.55964406-1.25 1.25s.55964406 1.25 1.25 1.25 1.25-.55964406 1.25-1.25-.55964406-1.25-1.25-1.25z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-institution\" viewBox=\"0 0 18 18\"><path d=\"m7 16.9998189v-2.0003623h4v2.0003623h2v-3.0005434h-8v3.0005434zm-3-10.00181122h-1.52632364c-.27614237 0-.5-.22389817-.5-.50009056 0-.13995446.05863589-.27350497.16166338-.36820841l1.23156713-1.13206327h-2.36690687v12.00217346h3v-2.0003623h-3v-1.0001811h3v-1.0001811h1v-4.00072448h-1zm10 0v2.00036224h-1v4.00072448h1v1.0001811h3v1.0001811h-3v2.0003623h3v-12.00217346h-2.3695309l1.2315671 1.13206327c.2033191.186892.2166633.50325042.0298051.70660631-.0946863.10304615-.2282126.16169266-.3681417.16169266zm3-3.00054336c.5522847 0 1 .44779634 1 1.00018112v13.00235456h-18v-13.00235456c0-.55238478.44771525-1.00018112 1-1.00018112h3.45499992l4.20535144-3.86558216c.19129876-.17584288.48537447-.17584288.67667324 0l4.2053514 3.86558216zm-4 3.00054336h-8v1.00018112h8zm-2 6.00108672h1v-4.00072448h-1zm-1 0v-4.00072448h-2v4.00072448zm-3 0v-4.00072448h-1v4.00072448zm8-4.00072448c.5522847 0 1 .44779634 1 1.00018112v2.00036226h-2v-2.00036226c0-.55238478.4477153-1.00018112 1-1.00018112zm-12 0c.55228475 0 1 .44779634 1 1.00018112v2.00036226h-2v-2.00036226c0-.55238478.44771525-1.00018112 1-1.00018112zm5.99868798-7.81907007-5.24205601 4.81852671h10.48411203zm.00131202 3.81834559c-.55228475 0-1-.44779634-1-1.00018112s.44771525-1.00018112 1-1.00018112 1 .44779634 1 1.00018112-.44771525 1.00018112-1 1.00018112zm-1 11.00199236v1.0001811h2v-1.0001811z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-location\" viewBox=\"0 0 18 18\"><path d=\"m9.39521328 16.2688008c.79596342-.7770119 1.59208152-1.6299956 2.33285652-2.5295081 1.4020032-1.7024324 2.4323601-3.3624519 2.9354918-4.871847.2228715-.66861448.3364384-1.29323246.3364384-1.8674457 0-3.3137085-2.6862915-6-6-6-3.36356866 0-6 2.60156856-6 6 0 .57421324.11356691 1.19883122.3364384 1.8674457.50313169 1.5093951 1.53348863 3.1694146 2.93549184 4.871847.74077492.8995125 1.53689309 1.7524962 2.33285648 2.5295081.13694479.1336842.26895677.2602648.39521328.3793207.12625651-.1190559.25826849-.2456365.39521328-.3793207zm-.39521328 1.7311992s-7-6-7-11c0-4 3.13400675-7 7-7 3.8659932 0 7 3.13400675 7 7 0 5-7 11-7 11zm0-8c-1.65685425 0-3-1.34314575-3-3s1.34314575-3 3-3c1.6568542 0 3 1.34314575 3 3s-1.3431458 3-3 3zm0-1c1.1045695 0 2-.8954305 2-2s-.8954305-2-2-2-2 .8954305-2 2 .8954305 2 2 2z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-minus\" viewBox=\"0 0 16 16\"><path d=\"m2.00087166 7h11.99825664c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-11.99825664c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-newsletter\" viewBox=\"0 0 18 18\"><path d=\"m9 11.8482489 2-1.1428571v-1.7053918h-4v1.7053918zm-3-1.7142857v-2.1339632h6v2.1339632l3-1.71428574v-6.41967746h-12v6.41967746zm10-5.3839632 1.5299989.95624934c.2923814.18273835.4700011.50320827.4700011.8479983v8.44575236c0 1.1045695-.8954305 2-2 2h-14c-1.1045695 0-2-.8954305-2-2v-8.44575236c0-.34479003.1776197-.66525995.47000106-.8479983l1.52999894-.95624934v-2.75c0-.55228475.44771525-1 1-1h12c.5522847 0 1 .44771525 1 1zm0 1.17924764v3.07075236l-7 4-7-4v-3.07075236l-1 .625v8.44575236c0 .5522847.44771525 1 1 1h14c.5522847 0 1-.4477153 1-1v-8.44575236zm-10-1.92924764h6v1h-6zm-1 2h8v1h-8z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-orcid\" viewBox=\"0 0 18 18\"><path d=\"m9 1c4.418278 0 8 3.581722 8 8s-3.581722 8-8 8-8-3.581722-8-8 3.581722-8 8-8zm-2.90107518 5.2732337h-1.41865256v7.1712107h1.41865256zm4.55867178.02508949h-2.99247027v7.14612121h2.91062487c.7673039 0 1.4476365-.1483432 2.0410182-.445034s1.0511995-.7152915 1.3734671-1.2558144c.3222677-.540523.4833991-1.1603247.4833991-1.85942385 0-.68545815-.1602789-1.30270225-.4808414-1.85175082-.3205625-.54904856-.7707074-.97532211-1.3504481-1.27883343-.5797408-.30351132-1.2413173-.45526471-1.9847495-.45526471zm-.1892674 1.07933542c.7877654 0 1.4143875.22336734 1.8798852.67010873.4654977.44674138.698243 1.05546001.698243 1.82617415 0 .74343221-.2310402 1.34447791-.6931277 1.80315511-.4620874.4586773-1.0750688.6880124-1.8389625.6880124h-1.46810075v-4.98745039zm-5.08652545-3.71099194c-.21825533 0-.410525.08444276-.57681478.25333081-.16628977.16888806-.24943341.36245684-.24943341.58071218 0 .22345188.08314364.41961891.24943341.58850696.16628978.16888806.35855945.25333082.57681478.25333082.233845 0 .43390938-.08314364.60019916-.24943342.16628978-.16628977.24943342-.36375592.24943342-.59240436 0-.233845-.08314364-.43131115-.24943342-.59240437s-.36635416-.24163862-.60019916-.24163862z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-plus\" viewBox=\"0 0 16 16\"><path d=\"m2.00087166 7h4.99912834v-4.99912834c0-.55276616.44386482-1.00087166 1-1.00087166.55228475 0 1 .44463086 1 1.00087166v4.99912834h4.9991283c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-4.9991283v4.9991283c0 .5527662-.44386482 1.0008717-1 1.0008717-.55228475 0-1-.4446309-1-1.0008717v-4.9991283h-4.99912834c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-print\" viewBox=\"0 0 18 18\"><path d=\"m16.0049107 5h-14.00982141c-.54941618 0-.99508929.4467783-.99508929.99961498v6.00077002c0 .5570958.44271433.999615.99508929.999615h1.00491071v-3h12v3h1.0049107c.5494162 0 .9950893-.4467783.9950893-.999615v-6.00077002c0-.55709576-.4427143-.99961498-.9950893-.99961498zm-2.0049107-1v-2.00208688c0-.54777062-.4519464-.99791312-1.0085302-.99791312h-7.9829396c-.55661731 0-1.0085302.44910695-1.0085302.99791312v2.00208688zm1 10v2.0018986c0 1.103521-.9019504 1.9981014-2.0085302 1.9981014h-7.9829396c-1.1092806 0-2.0085302-.8867064-2.0085302-1.9981014v-2.0018986h-1.00491071c-1.10185739 0-1.99508929-.8874333-1.99508929-1.999615v-6.00077002c0-1.10435686.8926228-1.99961498 1.99508929-1.99961498h1.00491071v-2.00208688c0-1.10341695.90195036-1.99791312 2.0085302-1.99791312h7.9829396c1.1092806 0 2.0085302.89826062 2.0085302 1.99791312v2.00208688h1.0049107c1.1018574 0 1.9950893.88743329 1.9950893 1.99961498v6.00077002c0 1.1043569-.8926228 1.999615-1.9950893 1.999615zm-1-3h-10v5.0018986c0 .5546075.44702548.9981014 1.0085302.9981014h7.9829396c.5565964 0 1.0085302-.4491701 1.0085302-.9981014zm-9 1h8v1h-8zm0 2h5v1h-5zm9-5c-.5522847 0-1-.44771525-1-1s.4477153-1 1-1 1 .44771525 1 1-.4477153 1-1 1z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-search\" viewBox=\"0 0 22 22\"><path d=\"M21.697 20.261a1.028 1.028 0 01.01 1.448 1.034 1.034 0 01-1.448-.01l-4.267-4.267A9.812 9.811 0 010 9.812a9.812 9.811 0 1117.43 6.182zM9.812 18.222A8.41 8.41 0 109.81 1.403a8.41 8.41 0 000 16.82z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-social-facebook\" viewBox=\"0 0 24 24\"><path d=\"m6.00368507 20c-1.10660471 0-2.00368507-.8945138-2.00368507-1.9940603v-12.01187942c0-1.10128908.89451376-1.99406028 1.99406028-1.99406028h12.01187942c1.1012891 0 1.9940603.89451376 1.9940603 1.99406028v12.01187942c0 1.1012891-.88679 1.9940603-2.0032184 1.9940603h-2.9570132v-6.1960818h2.0797387l.3114113-2.414723h-2.39115v-1.54164807c0-.69911803.1941355-1.1755439 1.1966615-1.1755439l1.2786739-.00055875v-2.15974763l-.2339477-.02492088c-.3441234-.03134957-.9500153-.07025255-1.6293054-.07025255-1.8435726 0-3.1057323 1.12531866-3.1057323 3.19187953v1.78079225h-2.0850778v2.414723h2.0850778v6.1960818z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-social-twitter\" viewBox=\"0 0 24 24\"><path d=\"m18.8767135 6.87445248c.7638174-.46908424 1.351611-1.21167363 1.6250764-2.09636345-.7135248.43394112-1.50406.74870123-2.3464594.91677702-.6695189-.73342162-1.6297913-1.19486605-2.6922204-1.19486605-2.0399895 0-3.6933555 1.69603749-3.6933555 3.78628909 0 .29642457.0314329.58673729.0942985.8617704-3.06469922-.15890802-5.78835241-1.66547825-7.60988389-3.9574208-.3174714.56076194-.49978171 1.21167363-.49978171 1.90536824 0 1.31404706.65223085 2.47224203 1.64236444 3.15218497-.60350999-.0198635-1.17401554-.1925232-1.67222562-.47366811v.04583885c0 1.83355406 1.27302891 3.36609966 2.96411421 3.71294696-.31118484.0886217-.63651445.1329326-.97441718.1329326-.2357461 0-.47149219-.0229194-.69466516-.0672303.47149219 1.5065703 1.83253297 2.6036468 3.44975116 2.632678-1.2651707 1.0160946-2.85724264 1.6196394-4.5891906 1.6196394-.29861172 0-.59093688-.0152796-.88011875-.0504227 1.63450624 1.0726291 3.57548241 1.6990934 5.66104951 1.6990934 6.79263079 0 10.50641749-5.7711113 10.50641749-10.7751859l-.0094298-.48894775c.7229547-.53478659 1.3516109-1.20250585 1.8419628-1.96190282-.6632323.30100846-1.3751855.50422736-2.1217148.59590507z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-social-youtube\" viewBox=\"0 0 24 24\"><path d=\"m10.1415 14.3973208-.0005625-5.19318431 4.863375 2.60554491zm9.963-7.92753362c-.6845625-.73643756-1.4518125-.73990314-1.803375-.7826454-2.518875-.18714178-6.2971875-.18714178-6.2971875-.18714178-.007875 0-3.7861875 0-6.3050625.18714178-.352125.04274226-1.1188125.04620784-1.8039375.7826454-.5394375.56084773-.7149375 1.8344515-.7149375 1.8344515s-.18 1.49597903-.18 2.99138042v1.4024082c0 1.495979.18 2.9913804.18 2.9913804s.1755 1.2736038.7149375 1.8344515c.685125.7364376 1.5845625.7133337 1.9850625.7901542 1.44.1420891 6.12.1859866 6.12.1859866s3.78225-.005776 6.301125-.1929178c.3515625-.0433198 1.1188125-.0467854 1.803375-.783223.5394375-.5608477.7155-1.8344515.7155-1.8344515s.18-1.4954014.18-2.9913804v-1.4024082c0-1.49540139-.18-2.99138042-.18-2.99138042s-.1760625-1.27360377-.7155-1.8344515z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-subject-medicine\" viewBox=\"0 0 18 18\"><path d=\"m12.5 8h-6.5c-1.65685425 0-3 1.34314575-3 3v1c0 1.6568542 1.34314575 3 3 3h1v-2h-.5c-.82842712 0-1.5-.6715729-1.5-1.5s.67157288-1.5 1.5-1.5h1.5 2 1 2c1.6568542 0 3-1.34314575 3-3v-1c0-1.65685425-1.3431458-3-3-3h-2v2h1.5c.8284271 0 1.5.67157288 1.5 1.5s-.6715729 1.5-1.5 1.5zm-5.5-1v-1h-3.5c-1.38071187 0-2.5-1.11928813-2.5-2.5s1.11928813-2.5 2.5-2.5h1.02786405c.46573528 0 .92507448.10843528 1.34164078.31671843l1.13382424.56691212c.06026365-1.05041141.93116291-1.88363055 1.99667093-1.88363055 1.1045695 0 2 .8954305 2 2h2c2.209139 0 4 1.790861 4 4v1c0 2.209139-1.790861 4-4 4h-2v1h2c1.1045695 0 2 .8954305 2 2s-.8954305 2-2 2h-2c0 1.1045695-.8954305 2-2 2s-2-.8954305-2-2h-1c-2.209139 0-4-1.790861-4-4v-1c0-2.209139 1.790861-4 4-4zm0-2v-2.05652691c-.14564246-.03538148-.28733393-.08714006-.42229124-.15461871l-1.15541752-.57770876c-.27771087-.13885544-.583937-.21114562-.89442719-.21114562h-1.02786405c-.82842712 0-1.5.67157288-1.5 1.5s.67157288 1.5 1.5 1.5zm4 1v1h1.5c.2761424 0 .5-.22385763.5-.5s-.2238576-.5-.5-.5zm-1 1v-5c0-.55228475-.44771525-1-1-1s-1 .44771525-1 1v5zm-2 4v5c0 .5522847.44771525 1 1 1s1-.4477153 1-1v-5zm3 2v2h2c.5522847 0 1-.4477153 1-1s-.4477153-1-1-1zm-4-1v-1h-.5c-.27614237 0-.5.2238576-.5.5s.22385763.5.5.5zm-3.5-9h1c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-success\" viewBox=\"0 0 18 18\"><path d=\"m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm3.4860198 4.98163161-4.71802968 5.50657859-2.62834168-2.02300024c-.42862421-.36730544-1.06564993-.30775346-1.42283677.13301307-.35718685.44076653-.29927542 1.0958383.12934879 1.46314377l3.40735508 2.7323063c.42215801.3385221 1.03700951.2798252 1.38749189-.1324571l5.38450527-6.33394549c.3613513-.43716226.3096573-1.09278382-.115462-1.46437175-.4251192-.37158792-1.0626796-.31842941-1.4240309.11873285z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-table\" viewBox=\"0 0 18 18\"><path d=\"m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587l-4.0059107-.001.001.001h-1l-.001-.001h-5l.001.001h-1l-.001-.001-3.00391071.001c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm-11.0059107 5h-3.999v6.9941413c0 .5572961.44630695 1.0058587.99508929 1.0058587h3.00391071zm6 0h-5v8h5zm5.0059107-4h-4.0059107v3h5.001v1h-5.001v7.999l4.0059107.001c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-12.5049107 9c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.2238576.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238576-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm-6-2c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.2238576.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.2238576-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.2238576.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.2238576-.5-.5s.22385763-.5.5-.5zm-6-2c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-1c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm12 0c.2761424 0 .5.22385763.5.5s-.2238576.5-.5.5h-2c-.2761424 0-.5-.22385763-.5-.5s.2238576-.5.5-.5zm-6 0c.27614237 0 .5.22385763.5.5s-.22385763.5-.5.5h-2c-.27614237 0-.5-.22385763-.5-.5s.22385763-.5.5-.5zm1.499-5h-5v3h5zm-6 0h-3.00391071c-.54871518 0-.99508929.44887827-.99508929 1.00585866v1.99414134h3.999z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-tick-circle\" viewBox=\"0 0 24 24\"><path d=\"m12 2c5.5228475 0 10 4.4771525 10 10s-4.4771525 10-10 10-10-4.4771525-10-10 4.4771525-10 10-10zm0 1c-4.97056275 0-9 4.02943725-9 9 0 4.9705627 4.02943725 9 9 9 4.9705627 0 9-4.0294373 9-9 0-4.97056275-4.0294373-9-9-9zm4.2199868 5.36606669c.3613514-.43716226.9989118-.49032077 1.424031-.11873285s.4768133 1.02720949.115462 1.46437175l-6.093335 6.94397871c-.3622945.4128716-.9897871.4562317-1.4054264.0971157l-3.89719065-3.3672071c-.42862421-.3673054-.48653564-1.0223772-.1293488-1.4631437s.99421256-.5003185 1.42283677-.1330131l3.11097438 2.6987741z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-tick\" viewBox=\"0 0 16 16\"><path d=\"m6.76799012 9.21106946-3.1109744-2.58349728c-.42862421-.35161617-1.06564993-.29460792-1.42283677.12733148s-.29927541 1.04903009.1293488 1.40064626l3.91576307 3.23873978c.41034319.3393961 1.01467563.2976897 1.37450571-.0948578l6.10568327-6.660841c.3613513-.41848908.3096572-1.04610608-.115462-1.4018218-.4251192-.35571573-1.0626796-.30482786-1.424031.11366122z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-update\" viewBox=\"0 0 18 18\"><path d=\"m1 13v1c0 .5522847.44771525 1 1 1h14c.5522847 0 1-.4477153 1-1v-1h-1v-10h-14v10zm16-1h1v2c0 1.1045695-.8954305 2-2 2h-14c-1.1045695 0-2-.8954305-2-2v-2h1v-9c0-.55228475.44771525-1 1-1h14c.5522847 0 1 .44771525 1 1zm-1 0v1h-4.5857864l-1 1h-2.82842716l-1-1h-4.58578644v-1h5l1 1h2l1-1zm-13-8h12v7h-12zm1 1v5h10v-5zm1 1h4v1h-4zm0 2h4v1h-4z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-upload\" viewBox=\"0 0 18 18\"><path d=\"m10.0046024 0c.5497429 0 1.3179837.32258606 1.707238.71184039l4.5763192 4.57631922c.3931386.39313859.7118404 1.16760135.7118404 1.71431368v8.98899651c0 1.1092806-.8945138 2.0085302-1.9940603 2.0085302h-12.01187942c-1.10128908 0-1.99406028-.8926228-1.99406028-1.9950893v-14.00982141c0-1.10185739.88743329-1.99508929 1.99961498-1.99508929zm0 1h-7.00498742c-.55709576 0-.99961498.44271433-.99961498.99508929v14.00982141c0 .5500396.44491393.9950893.99406028.9950893h12.01187942c.5463747 0 .9940603-.4506622.9940603-1.0085302v-8.98899651c0-.28393444-.2150684-.80332809-.4189472-1.0072069l-4.5763192-4.57631922c-.2038461-.20384606-.718603-.41894717-1.0001312-.41894717zm-1.85576936 4.14572769c.19483374-.19483375.51177826-.19377714.70556874.00001334l2.59099082 2.59099079c.1948411.19484112.1904373.51514474.0027906.70279143-.1932998.19329987-.5046517.19237083-.7001856-.00692852l-1.74638687-1.7800176v6.14827687c0 .2717771-.23193359.492096-.5.492096-.27614237 0-.5-.216372-.5-.492096v-6.14827641l-1.74627892 1.77990922c-.1933927.1971171-.51252214.19455839-.70016883.0069117-.19329987-.19329988-.19100584-.50899493.00277731-.70277808z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-video\" viewBox=\"0 0 18 18\"><path d=\"m16.0049107 2c1.1018574 0 1.9950893.89706013 1.9950893 2.00585866v9.98828264c0 1.1078052-.8926228 2.0058587-1.9950893 2.0058587h-14.00982141c-1.10185739 0-1.99508929-.8970601-1.99508929-2.0058587v-9.98828264c0-1.10780515.8926228-2.00585866 1.99508929-2.00585866zm0 1h-14.00982141c-.54871518 0-.99508929.44887827-.99508929 1.00585866v9.98828264c0 .5572961.44630695 1.0058587.99508929 1.0058587h14.00982141c.5487152 0 .9950893-.4488783.9950893-1.0058587v-9.98828264c0-.55729607-.446307-1.00585866-.9950893-1.00585866zm-8.30912922 2.24944486 4.60460462 2.73982242c.9365543.55726659.9290753 1.46522435 0 2.01804082l-4.60460462 2.7398224c-.93655425.5572666-1.69578148.1645632-1.69578148-.8937585v-5.71016863c0-1.05087579.76670616-1.446575 1.69578148-.89375851zm-.67492769.96085624v5.5750128c0 .2995102-.10753745.2442517.16578928.0847713l4.58452283-2.67497259c.3050619-.17799716.3051624-.21655446 0-.39461026l-4.58452283-2.67497264c-.26630747-.15538481-.16578928-.20699944-.16578928.08477139z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-warning\" viewBox=\"0 0 18 18\"><path d=\"m9 11.75c.69035594 0 1.25.5596441 1.25 1.25s-.55964406 1.25-1.25 1.25-1.25-.5596441-1.25-1.25.55964406-1.25 1.25-1.25zm.41320045-7.75c.55228475 0 1.00000005.44771525 1.00000005 1l-.0034543.08304548-.3333333 4c-.043191.51829212-.47645714.91695452-.99654578.91695452h-.15973424c-.52008864 0-.95335475-.3986624-.99654576-.91695452l-.33333333-4c-.04586475-.55037702.36312325-1.03372649.91350028-1.07959124l.04148683-.00259031zm-.41320045 14c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-checklist-banner\" viewBox=\"0 0 56.69 56.69\"><path style=\"fill:none\" d=\"M0 0h56.69v56.69H0z\"/><clipPath id=\"b\"><use xlink:href=\"#a\" style=\"overflow:visible\"/></clipPath><path d=\"M21.14 34.46c0-6.77 5.48-12.26 12.24-12.26s12.24 5.49 12.24 12.26-5.48 12.26-12.24 12.26c-6.76-.01-12.24-5.49-12.24-12.26zm19.33 10.66 10.23 9.22s1.21 1.09 2.3-.12l2.09-2.32s1.09-1.21-.12-2.3l-10.23-9.22m-19.29-5.92c0-4.38 3.55-7.94 7.93-7.94s7.93 3.55 7.93 7.94c0 4.38-3.55 7.94-7.93 7.94-4.38-.01-7.93-3.56-7.93-7.94zm17.58 12.99 4.14-4.81\" style=\"clip-path:url(#b);fill:none;stroke:#01324b;stroke-width:2;stroke-linecap:round\"/><path d=\"M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5m14.42-5.2V4.86s0-2.93-2.93-2.93H4.13s-2.93 0-2.93 2.93v37.57s0 2.93 2.93 2.93h15.01M8.26 9.75H28.6M8.26 15.98H28.6m-20.34 6.2h12.5\" style=\"clip-path:url(#b);fill:none;stroke:#01324b;stroke-width:2;stroke-linecap:round;stroke-linejoin:round\"/></symbol><symbol id=\"icon-chevron-down\" viewBox=\"0 0 16 16\"><path d=\"m5.58578644 3-3.29289322-3.29289322c-.39052429-.39052429-.39052429-1.02368927 0-1.41421356s1.02368927-.39052429 1.41421356 0l4 4c.39052429.39052429.39052429 1.02368927 0 1.41421356l-4 4c-.39052429.39052429-1.02368927.39052429-1.41421356 0s-.39052429-1.02368927 0-1.41421356z\" fill-rule=\"evenodd\" transform=\"matrix(0 1 -1 0 11 1)\"/></symbol><symbol id=\"icon-eds-i-arrow-right-medium\" viewBox=\"0 0 24 24\"><path d=\"m12.728 3.293 7.98 7.99a.996.996 0 0 1 .281.561l.011.157c0 .32-.15.605-.384.788l-7.908 7.918a1 1 0 0 1-1.416-1.414L17.576 13H4a1 1 0 0 1 0-2h13.598l-6.285-6.293a1 1 0 0 1-.082-1.32l.083-.095a1 1 0 0 1 1.414.001Z\"/></symbol><symbol id=\"icon-eds-i-chevron-down-medium\" viewBox=\"0 0 16 16\"><path d=\"m2.00087166 7h4.99912834v-4.99912834c0-.55276616.44386482-1.00087166 1-1.00087166.55228475 0 1 .44463086 1 1.00087166v4.99912834h4.9991283c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-4.9991283v4.9991283c0 .5527662-.44386482 1.0008717-1 1.0008717-.55228475 0-1-.4446309-1-1.0008717v-4.9991283h-4.99912834c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-eds-i-chevron-down-small\" viewBox=\"0 0 16 16\"><path d=\"M13.692 5.278a1 1 0 0 1 .03 1.414L9.103 11.51a1.491 1.491 0 0 1-2.188.019L2.278 6.692a1 1 0 0 1 1.444-1.384L8 9.771l4.278-4.463a1 1 0 0 1 1.318-.111l.096.081Z\"/></symbol><symbol id=\"icon-eds-i-chevron-right-medium\" viewBox=\"0 0 10 10\"><path d=\"m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z\" fill-rule=\"evenodd\" transform=\"matrix(0 -1 1 0 0 10)\"/></symbol><symbol id=\"icon-eds-i-chevron-right-small\" viewBox=\"0 0 10 10\"><path d=\"m5.96738168 4.70639573 2.39518594-2.41447274c.37913917-.38219212.98637524-.38972225 1.35419292-.01894278.37750606.38054586.37784436.99719163-.00013556 1.37821513l-4.03074001 4.06319683c-.37758093.38062133-.98937525.38100976-1.367372-.00003075l-4.03091981-4.06337806c-.37759778-.38063832-.38381821-.99150444-.01600053-1.3622839.37750607-.38054587.98772445-.38240057 1.37006824.00302197l2.39538588 2.4146743.96295325.98624457z\" fill-rule=\"evenodd\" transform=\"matrix(0 -1 1 0 0 10)\"/></symbol><symbol id=\"icon-eds-i-chevron-up-medium\" viewBox=\"0 0 16 16\"><path d=\"m2.00087166 7h11.99825664c.5527662 0 1.0008717.44386482 1.0008717 1 0 .55228475-.4446309 1-1.0008717 1h-11.99825664c-.55276616 0-1.00087166-.44386482-1.00087166-1 0-.55228475.44463086-1 1.00087166-1z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-eds-i-close-medium\" viewBox=\"0 0 16 16\"><path d=\"m2.29679575 12.2772478c-.39658757.3965876-.39438847 1.0328109-.00062148 1.4265779.39651227.3965123 1.03246768.3934888 1.42657791-.0006214l4.27724782-4.27724787 4.2772478 4.27724787c.3965876.3965875 1.0328109.3943884 1.4265779.0006214.3965123-.3965122.3934888-1.0324677-.0006214-1.4265779l-4.27724787-4.2772478 4.27724787-4.27724782c.3965875-.39658757.3943884-1.03281091.0006214-1.42657791-.3965122-.39651226-1.0324677-.39348875-1.4265779.00062148l-4.2772478 4.27724782-4.27724782-4.27724782c-.39658757-.39658757-1.03281091-.39438847-1.42657791-.00062148-.39651226.39651227-.39348875 1.03246768.00062148 1.42657791l4.27724782 4.27724782z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-eds-i-download-medium\" viewBox=\"0 0 16 16\"><path d=\"m12.9975267 12.999368c.5467123 0 1.0024733.4478567 1.0024733 1.000316 0 .5563109-.4488226 1.000316-1.0024733 1.000316h-9.99505341c-.54671233 0-1.00247329-.4478567-1.00247329-1.000316 0-.5563109.44882258-1.000316 1.00247329-1.000316zm-4.9975267-11.999368c.55228475 0 1 .44497754 1 .99589209v6.80214418l2.4816273-2.48241149c.3928222-.39294628 1.0219732-.4006883 1.4030652-.01947579.3911302.39125371.3914806 1.02525073-.0001404 1.41699553l-4.17620792 4.17752758c-.39120769.3913313-1.02508144.3917306-1.41671995-.0000316l-4.17639421-4.17771394c-.39122513-.39134876-.39767006-1.01940351-.01657797-1.40061601.39113012-.39125372 1.02337105-.3931606 1.41951349.00310701l2.48183446 2.48261871v-6.80214418c0-.55001601.44386482-.99589209 1-.99589209z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-eds-i-info-filled-medium\" viewBox=\"0 0 18 18\"><path d=\"m9 0c4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9zm0 7h-1.5l-.11662113.00672773c-.49733868.05776511-.88337887.48043643-.88337887.99327227 0 .47338693.32893365.86994729.77070917.97358929l.1126697.01968298.11662113.00672773h.5v3h-.5l-.11662113.0067277c-.42082504.0488782-.76196299.3590206-.85696816.7639815l-.01968298.1126697-.00672773.1166211.00672773.1166211c.04887817.4208251.35902055.761963.76398144.8569682l.1126697.019683.11662113.0067277h3l.1166211-.0067277c.4973387-.0577651.8833789-.4804365.8833789-.9932723 0-.4733869-.3289337-.8699473-.7707092-.9735893l-.1126697-.019683-.1166211-.0067277h-.5v-4l-.00672773-.11662113c-.04887817-.42082504-.35902055-.76196299-.76398144-.85696816l-.1126697-.01968298zm0-3.25c-.69035594 0-1.25.55964406-1.25 1.25s.55964406 1.25 1.25 1.25 1.25-.55964406 1.25-1.25-.55964406-1.25-1.25-1.25z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-eds-i-mail-medium\" viewBox=\"0 0 24 24\"><path d=\"m19.462 0c1.413 0 2.538 1.184 2.538 2.619v12.762c0 1.435-1.125 2.619-2.538 2.619h-16.924c-1.413 0-2.538-1.184-2.538-2.619v-12.762c0-1.435 1.125-2.619 2.538-2.619zm.538 5.158-7.378 6.258a2.549 2.549 0 0 1 -3.253-.008l-7.369-6.248v10.222c0 .353.253.619.538.619h16.924c.285 0 .538-.266.538-.619zm-.538-3.158h-16.924c-.264 0-.5.228-.534.542l8.65 7.334c.2.165.492.165.684.007l8.656-7.342-.001-.025c-.044-.3-.274-.516-.531-.516z\"/></symbol><symbol id=\"icon-eds-i-menu-medium\" viewBox=\"0 0 24 24\"><path d=\"M21 4a1 1 0 0 1 0 2H3a1 1 0 1 1 0-2h18Zm-4 7a1 1 0 0 1 0 2H3a1 1 0 0 1 0-2h14Zm4 7a1 1 0 0 1 0 2H3a1 1 0 0 1 0-2h18Z\"/></symbol><symbol id=\"icon-eds-i-search-medium\" viewBox=\"0 0 24 24\"><path d=\"M11 1c5.523 0 10 4.477 10 10 0 2.4-.846 4.604-2.256 6.328l3.963 3.965a1 1 0 0 1-1.414 1.414l-3.965-3.963A9.959 9.959 0 0 1 11 21C5.477 21 1 16.523 1 11S5.477 1 11 1Zm0 2a8 8 0 1 0 0 16 8 8 0 0 0 0-16Z\"/></symbol><symbol id=\"icon-eds-i-user-single-medium\" viewBox=\"0 0 24 24\"><path d=\"M12 1a5 5 0 1 1 0 10 5 5 0 0 1 0-10Zm0 2a3 3 0 1 0 0 6 3 3 0 0 0 0-6Zm-.406 9.008a8.965 8.965 0 0 1 6.596 2.494A9.161 9.161 0 0 1 21 21.025V22a1 1 0 0 1-1 1H4a1 1 0 0 1-1-1v-.985c.05-4.825 3.815-8.777 8.594-9.007Zm.39 1.992-.299.006c-3.63.175-6.518 3.127-6.678 6.775L5 21h13.998l-.009-.268a7.157 7.157 0 0 0-1.97-4.573l-.214-.213A6.967 6.967 0 0 0 11.984 14Z\"/></symbol><symbol id=\"icon-eds-i-warning-filled-medium\" viewBox=\"0 0 18 18\"><path d=\"m9 11.75c.69035594 0 1.25.5596441 1.25 1.25s-.55964406 1.25-1.25 1.25-1.25-.5596441-1.25-1.25.55964406-1.25 1.25-1.25zm.41320045-7.75c.55228475 0 1.00000005.44771525 1.00000005 1l-.0034543.08304548-.3333333 4c-.043191.51829212-.47645714.91695452-.99654578.91695452h-.15973424c-.52008864 0-.95335475-.3986624-.99654576-.91695452l-.33333333-4c-.04586475-.55037702.36312325-1.03372649.91350028-1.07959124l.04148683-.00259031zm-.41320045 14c-4.97056275 0-9-4.0294373-9-9 0-4.97056275 4.02943725-9 9-9 4.9705627 0 9 4.02943725 9 9 0 4.9705627-4.0294373 9-9 9z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-expand-image\" viewBox=\"0 0 18 18\"><path d=\"m7.49754099 11.9178212c.38955542-.3895554.38761957-1.0207846-.00290473-1.4113089-.39324695-.3932469-1.02238878-.3918247-1.41130883-.0029047l-4.10273549 4.1027355.00055454-3.5103985c.00008852-.5603185-.44832171-1.006032-1.00155062-1.0059446-.53903074.0000852-.97857527.4487442-.97866268 1.0021075l-.00093318 5.9072465c-.00008751.553948.44841131 1.001882 1.00174994 1.0017946l5.906983-.0009331c.5539233-.0000875 1.00197907-.4486389 1.00206646-1.0018679.00008515-.5390307-.45026621-.9784332-1.00588841-.9783454l-3.51010549.0005545zm3.00571741-5.83449376c-.3895554.38955541-.3876196 1.02078454.0029047 1.41130883.393247.39324696 1.0223888.39182478 1.4113089.00290473l4.1027355-4.10273549-.0005546 3.5103985c-.0000885.56031852.4483217 1.006032 1.0015506 1.00594461.5390308-.00008516.9785753-.44874418.9786627-1.00210749l.0009332-5.9072465c.0000875-.553948-.4484113-1.00188204-1.0017499-1.00179463l-5.906983.00093313c-.5539233.00008751-1.0019791.44863892-1.0020665 1.00186784-.0000852.53903074.4502662.97843325 1.0058884.97834547l3.5101055-.00055449z\" fill-rule=\"evenodd\"/></symbol><symbol id=\"icon-github\" viewBox=\"0 0 100 100\"><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M48.854 0C21.839 0 0 22 0 49.217c0 21.756 13.993 40.172 33.405 46.69 2.427.49 3.316-1.059 3.316-2.362 0-1.141-.08-5.052-.08-9.127-13.59 2.934-16.42-5.867-16.42-5.867-2.184-5.704-5.42-7.17-5.42-7.17-4.448-3.015.324-3.015.324-3.015 4.934.326 7.523 5.052 7.523 5.052 4.367 7.496 11.404 5.378 14.235 4.074.404-3.178 1.699-5.378 3.074-6.6-10.839-1.141-22.243-5.378-22.243-24.283 0-5.378 1.94-9.778 5.014-13.2-.485-1.222-2.184-6.275.486-13.038 0 0 4.125-1.304 13.426 5.052a46.97 46.97 0 0 1 12.214-1.63c4.125 0 8.33.571 12.213 1.63 9.302-6.356 13.427-5.052 13.427-5.052 2.67 6.763.97 11.816.485 13.038 3.155 3.422 5.015 7.822 5.015 13.2 0 18.905-11.404 23.06-22.324 24.283 1.78 1.548 3.316 4.481 3.316 9.126 0 6.6-.08 11.897-.08 13.526 0 1.304.89 2.853 3.316 2.364 19.412-6.52 33.405-24.935 33.405-46.691C97.707 22 75.788 0 48.854 0z\"/></symbol><symbol id=\"icon-springer-arrow-left\"><path d=\"M15 7a1 1 0 000-2H3.385l2.482-2.482a.994.994 0 00.02-1.403 1.001 1.001 0 00-1.417 0L.294 5.292a1.001 1.001 0 000 1.416l4.176 4.177a.991.991 0 001.4.016 1 1 0 00-.003-1.42L3.385 7H15z\"/></symbol><symbol id=\"icon-springer-arrow-right\"><path d=\"M1 7a1 1 0 010-2h11.615l-2.482-2.482a.994.994 0 01-.02-1.403 1.001 1.001 0 011.417 0l4.176 4.177a1.001 1.001 0 010 1.416l-4.176 4.177a.991.991 0 01-1.4.016 1 1 0 01.003-1.42L12.615 7H1z\"/></symbol><symbol id=\"icon-submit-open\" viewBox=\"0 0 16 17\"><path d=\"M12 0c1.10457 0 2 .895431 2 2v5c0 .276142-.223858.5-.5.5S13 7.276142 13 7V2c0-.512836-.38604-.935507-.883379-.993272L12 1H6v3c0 1.10457-.89543 2-2 2H1v8c0 .512836.38604.935507.883379.993272L2 15h6.5c.276142 0 .5.223858.5.5s-.223858.5-.5.5H2c-1.104569 0-2-.89543-2-2V5.828427c0-.530433.210714-1.039141.585786-1.414213L4.414214.585786C4.789286.210714 5.297994 0 5.828427 0H12Zm3.41 11.14c.250899.250899.250274.659726 0 .91-.242954.242954-.649606.245216-.9-.01l-1.863671-1.900337.001043 5.869492c0 .356992-.289839.637138-.647372.637138-.347077 0-.647371-.285256-.647371-.637138l-.001043-5.869492L9.5 12.04c-.253166.258042-.649726.260274-.9.01-.242954-.242954-.252269-.657731 0-.91l2.942184-2.951303c.250908-.250909.66127-.252277.91353-.000017L15.41 11.14ZM5 1.413 1.413 5H4c.552285 0 1-.447715 1-1V1.413ZM11 3c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Zm0 2c.276142 0 .5.223858.5.5s-.223858.5-.5.5H7.5c-.276142 0-.5-.223858-.5-.5s.223858-.5.5-.5H11Z\" fill-rule=\"nonzero\"/></symbol></svg>\n</div>\n</footer>\n\n\n\n\n    \n\n    \n\n<div class=\"c-site-messages message u-hide u-hide-print c-site-messages--nature-briefing c-site-messages--nature-briefing-email-variant c-site-messages--nature-briefing-redesign-2020 sans-serif \"\ndata-component-id=\"nature-briefing-banner\"\ndata-component-expirydays=\"30\"\ndata-component-trigger-scroll-percentage=\"15\"\ndata-track=\"in-view\"\ndata-track-action=\"in-view\"\ndata-track-category=\"nature briefing\"\ndata-track-label=\"Briefing banner visible: Flagship\">\n\n    \n    <div class=\"c-site-messages__banner-large\">\n\n        \n<div class=\"c-site-messages__close-container\">\n    <button class=\"c-site-messages__close\"\n        data-track=\"click\"\n        data-track-category=\"nature briefing\"\n        data-track-label=\"Briefing banner dismiss: Flagship\">\n        <svg width=\"25px\" height=\"25px\" focusable=\"false\" aria-hidden=\"true\" viewBox=\"0 0 25 25\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n            <title>Close banner</title>\n            <defs></defs>\n            <g stroke=\"none\" stroke-width=\"1\" fill=\"none\" fill-rule=\"evenodd\">\n                <rect opacity=\"0\" x=\"0\" y=\"0\" width=\"25\" height=\"25\"></rect>\n                <path d=\"M6.29679575,16.2772478 C5.90020818,16.6738354 5.90240728,17.3100587 6.29617427,17.7038257 C6.69268654,18.100338 7.32864195,18.0973145 7.72275218,17.7032043 L12,13.4259564 L16.2772478,17.7032043 C16.6738354,18.0997918 17.3100587,18.0975927 17.7038257,17.7038257 C18.100338,17.3073135 18.0973145,16.671358 17.7032043,16.2772478 L13.4259564,12 L17.7032043,7.72275218 C18.0997918,7.32616461 18.0975927,6.68994127 17.7038257,6.29617427 C17.3073135,5.89966201 16.671358,5.90268552 16.2772478,6.29679575 L12,10.5740436 L7.72275218,6.29679575 C7.32616461,5.90020818 6.68994127,5.90240728 6.29617427,6.29617427 C5.89966201,6.69268654 5.90268552,7.32864195 6.29679575,7.72275218 L10.5740436,12 L6.29679575,16.2772478 Z\" fill=\"#ffffff\"></path>\n            </g>\n        </svg>\n        <span class=\"visually-hidden\">Close</span>\n    </button>\n</div>\n\n\n        <div class=\"c-site-messages__form-container\">\n\n            <div class=\"grid grid-12 last\">\n                <div class=\"grid grid-4\">\n                    <img alt=\"Nature Briefing AI and Robotics\" src=\"/static/images/logos/nature-briefing-ai-and-robotics-logo-51b3cf6c52.svg\" width=\"400\" height=\"40\">\n                    <p class=\"c-site-messages--nature-briefing__strapline extra-tight-line-height\">Sign up for the <em>Nature Briefing: AI and Robotics</em> newsletter — what matters in AI and robotics research, free to your inbox weekly.</p>\n                </div>\n                <div class=\"grid grid-8 last\">\n                    <form action=\"https://www.nature.com/briefing/ai_and_robotics\" method=\"post\" data-location=\"banner\" data-track=\"submit||signup_nature_briefing_banner\" data-track-action=\"transmit-form\" data-track-category=\"nature briefing\" data-track-label=\"Briefing banner submit: Flagship\">\n                        <input id=\"briefing-banner-signup-form-input-track-originReferralPoint\" type=\"hidden\" name=\"track_originReferralPoint\" value=\"AIAndRoboticsBriefingBanner\">\n                        <input id=\"briefing-banner-signup-form-input-track-formType\" type=\"hidden\" name=\"track_formType\" value=\"DirectEmailBanner\">\n\n                        <input type=\"hidden\" value=\"false\" name=\"gdpr_tick\" id=\"gdpr_tick_banner\">\n                        <input type=\"hidden\" value=\"false\" name=\"marketing\" id=\"marketing_input_banner\">\n                        <input type=\"hidden\" value=\"false\" name=\"marketing_tick\" id=\"marketing_tick_banner\">\n                        <input type=\"hidden\" value=\"AIAndRoboticsBriefingBanner\" name=\"brieferEntryPoint\" id=\"brieferEntryPoint_banner\">\n\n                        <label class=\"nature-briefing-banner__email-label\" for=\"emailAddress\">Email address</label>\n\n                        <div class=\"nature-briefing-banner__email-wrapper\">\n                            <input class=\"nature-briefing-banner__email-input box-sizing text14\" type=\"email\" id=\"emailAddress\" name=\"emailAddress\" value=\"\" placeholder=\"e.g. jo.smith@university.ac.uk\" required data-test-element=\"briefing-emailbanner-email-input\">\n                            \n                            <input type=\"hidden\" value=\"true\" name=\"N:ai_and_robotics\" id=\"defaultNewsletter_banner\">\n                            <button type=\"submit\" class=\"nature-briefing-banner__submit-button box-sizing text14\" data-test-element=\"briefing-emailbanner-signup-button\">Sign up</button>\n                        </div>\n\n                        <div class=\"nature-briefing-banner__checkbox-wrapper grid grid-12 last\">\n                            <input class=\"nature-briefing-banner__checkbox-checkbox\" id=\"gdpr-briefing-banner-checkbox\" type=\"checkbox\" name=\"gdpr\" value=\"true\" data-test-element=\"briefing-emailbanner-gdpr-checkbox\" required>\n                            <label class=\"nature-briefing-banner__checkbox-label box-sizing text13 sans-serif block tighten-line-height\" for=\"gdpr-briefing-banner-checkbox\">I agree my information will be processed in accordance with the <em>Nature</em> and Springer Nature Limited <a href=\"https://www.nature.com/info/privacy\">Privacy Policy</a>.</label>\n                        </div>\n                    </form>\n                </div>\n            </div>\n\n        </div>\n\n    </div>\n\n    \n    <div class=\"c-site-messages__banner-small\">\n\n        \n<div class=\"c-site-messages__close-container\">\n    <button class=\"c-site-messages__close\"\n        data-track=\"click\"\n        data-track-category=\"nature briefing\"\n        data-track-label=\"Briefing banner dismiss: Flagship\">\n        <svg width=\"25px\" height=\"25px\" focusable=\"false\" aria-hidden=\"true\" viewBox=\"0 0 25 25\" version=\"1.1\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n            <title>Close banner</title>\n            <defs></defs>\n            <g stroke=\"none\" stroke-width=\"1\" fill=\"none\" fill-rule=\"evenodd\">\n                <rect opacity=\"0\" x=\"0\" y=\"0\" width=\"25\" height=\"25\"></rect>\n                <path d=\"M6.29679575,16.2772478 C5.90020818,16.6738354 5.90240728,17.3100587 6.29617427,17.7038257 C6.69268654,18.100338 7.32864195,18.0973145 7.72275218,17.7032043 L12,13.4259564 L16.2772478,17.7032043 C16.6738354,18.0997918 17.3100587,18.0975927 17.7038257,17.7038257 C18.100338,17.3073135 18.0973145,16.671358 17.7032043,16.2772478 L13.4259564,12 L17.7032043,7.72275218 C18.0997918,7.32616461 18.0975927,6.68994127 17.7038257,6.29617427 C17.3073135,5.89966201 16.671358,5.90268552 16.2772478,6.29679575 L12,10.5740436 L7.72275218,6.29679575 C7.32616461,5.90020818 6.68994127,5.90240728 6.29617427,6.29617427 C5.89966201,6.69268654 5.90268552,7.32864195 6.29679575,7.72275218 L10.5740436,12 L6.29679575,16.2772478 Z\" fill=\"#ffffff\"></path>\n            </g>\n        </svg>\n        <span class=\"visually-hidden\">Close</span>\n    </button>\n</div>\n\n\n        <div class=\"c-site-messages__content text14\">\n            <span class=\"c-site-messages--nature-briefing__strapline strong\">Get the most important science stories of the day, free in your inbox.</span>\n            <a class=\"nature-briefing__link text14 sans-serif\"\n                data-track=\"click\"\n                data-track-category=\"nature briefing\"\n                data-track-label=\"Small-screen banner CTA to site\"\n                data-test-element=\"briefing-banner-link\"\n                target=\"_blank\"\n                rel=\"noreferrer noopener\"\n                href=\"/briefing/ai-and-robotics/?brieferEntryPoint=AIAndRoboticsBriefingBanner\">Sign up for Nature Briefing: AI and Robotics\n            </a>\n        </div>\n\n    </div>\n\n</div>\n\n\n\n\n\n\n<noscript>\n    <img hidden src=\"https://verify.nature.com/verify/nature.png\" width=\"0\" height=\"0\" style=\"display: none\" alt=\"\">\n</noscript>\n\n\n\n\n<script src=\"//content.readcube.com/ping?doi=10.1038/s41586-024-07566-y&amp;format=js&amp;last_modified=2024-07-24\" async></script>\n\n<img src=\"/q1wioojh/article/s41586-024-07566-y\" width=\"1\" height=\"1\" alt=\"\" class=\"u-visually-hidden\" data-test=\"counter-pixel\">\n\n</body>\n</html>","oembed":false,"readabilityObject":{"title":"AI models collapse when trained on recursively generated data","content":"<div id=\"readability-page-1\" class=\"page\"><div>\n                    <div id=\"Sec1-section\" data-title=\"Main\"><h2 id=\"Sec1\">Main</h2><p>The development of LLMs is very involved and requires large quantities of training data. Yet, although current LLMs<sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 2\" title=\"Brown, T. et al. Language models are few-shot learners. Adv. Neural Inf. Process. Syst. 33, 1877–1901 (2020).\" href=\"about:/articles/s41586-024-07566-y#ref-CR2\" id=\"ref-link-section-d34320735e583\">2</a>,<a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" title=\"Devlin, J., Chang, M.-W., Lee, K. &amp; Toutanova, K. in Proc. 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) (eds Burstein, J., Doran, C. &amp; Solorio, T.) 4171–4186 (Association for Computational Linguistics, 2019).\" href=\"#ref-CR4\" id=\"ref-link-section-d34320735e586\">4</a>,<a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" title=\"Liu, Y. et al. RoBERTa: a Robustly Optimized BERT Pretraining Approach. Preprint at \n                  https://arxiv.org/abs/1907.11692\n                  \n                 (2019).\" href=\"#ref-CR5\" id=\"ref-link-section-d34320735e586_1\">5</a>,<a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 6\" title=\"Zhang, S. et al. Opt: open pre-trained transformer language models. Preprint at \n                  https://arxiv.org/abs/2205.01068\n                  \n                 (2022).\" href=\"about:/articles/s41586-024-07566-y#ref-CR6\" id=\"ref-link-section-d34320735e589\">6</a></sup>, including GPT-3, were trained on predominantly human-generated text, this may change. If the training data of most future models are also scraped from the web, then they will inevitably train on data produced by their predecessors. In this paper, we investigate what happens when text produced by, for example, a version of GPT forms most of the training dataset of following models. What happens to GPT generations GPT-{<i>n</i>} as <i>n</i> increases? We discover that indiscriminately learning from data produced by other models causes ‘model collapse’—a degenerative process whereby, over time, models forget the true underlying data distribution, even in the absence of a shift in the distribution over time. We give examples of model collapse for GMMs, VAEs and LLMs. We show that, over time, models start losing information about the true distribution, which first starts with tails disappearing, and learned behaviours converge over the generations to a point estimate with very small variance. Furthermore, we show that this process is inevitable, even for cases with almost ideal conditions for long-term learning, that is, no function estimation error. We also briefly mention two close concepts to model collapse from the existing literature: catastrophic forgetting arising in the framework of task-free continual learning<sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 7\" title=\"Aljundi, R., Kelchtermans, K. &amp; Tuytelaars, T. Task-free continual learning. in: Proc. 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 11254–11263 (IEEE, 2019).\" href=\"about:/articles/s41586-024-07566-y#ref-CR7\" id=\"ref-link-section-d34320735e599\">7</a></sup> and data poisoning<sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 8\" title=\"Carlini, N. &amp; Terzis, A. in Proc. Tenth International Conference on Learning Representations (ICLR, 2022).\" href=\"about:/articles/s41586-024-07566-y#ref-CR8\" id=\"ref-link-section-d34320735e603\">8</a>,<a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 9\" title=\"Carlini, N. et al. in Proc. 2024 IEEE Symposium on Security and Privacy (SP) 179 (IEEE, 2024).\" href=\"about:/articles/s41586-024-07566-y#ref-CR9\" id=\"ref-link-section-d34320735e606\">9</a></sup> maliciously leading to unintended behaviour. Neither is able to explain the phenomenon of model collapse fully, as the setting is fundamentally different, but they provide another perspective on the observed phenomenon and are discussed in more depth in the&nbsp;<a data-track=\"click\" data-track-label=\"link\" data-track-action=\"supplementary material anchor\" href=\"about:/articles/s41586-024-07566-y#MOESM1\">Supplementary Materials</a>. Finally, we discuss the broader implications of model collapse. We note that access to the original data distribution is crucial: in learning tasks in which the tails of the underlying distribution matter, one needs access to real human-produced data. In other words, the use of LLMs at scale to publish content on the Internet will pollute the collection of data to train their successors: data about human interactions with LLMs will be increasingly valuable.</p></div><div id=\"Sec2-section\" data-title=\"What is model collapse?\"><h2 id=\"Sec2\">What is model collapse?</h2><div id=\"Sec2-content\">\n                <h3 id=\"FPar1\">Definition 2.1 (model collapse)</h3>\n                <p>Model collapse is a degenerative process affecting generations of learned generative models, in which the data they generate end up polluting the training set of the next generation. Being trained on polluted data, they then mis-perceive reality. The process is depicted in Fig. <a data-track=\"click\" data-track-label=\"link\" data-track-action=\"figure anchor\" href=\"about:/articles/s41586-024-07566-y#Fig1\">1a</a>. We separate two special cases: early model collapse and late model collapse. In early model collapse, the model begins losing information about the tails of the distribution; in late model collapse, the model converges to a distribution that carries little resemblance to the original one, often with substantially reduced variance.</p>\n              <p>This process occurs owing to three specific sources of error compounding over generations and causing deviation from the original model:</p><ul>\n                <li>\n                  <p><b>Statistical approximation error.</b> This is the primary type of error, which arises owing to the number of samples being finite, and disappears as the number of samples tends to infinity. This occurs because of a non-zero probability that information can get lost at every step of resampling.</p>\n                </li>\n                <li>\n                  <p><b>Functional expressivity error.</b> This is a secondary type of error, arising owing to limited function approximator expressiveness. In particular, neural networks are only universal approximators as their size goes to infinity. As a result, a neural network can introduce non-zero likelihood outside the support of the original distribution or zero likelihood inside the support of the original distribution. A simple example of the expressivity error is if we tried fitting a mixture of two Gaussians with a single Gaussian. Even if we have perfect information about the data distribution (that is, infinite number of samples), model errors will be inevitable. However, in the absence of the other two types of error, this can only occur at the first generation.</p>\n                </li>\n                <li>\n                  <p><b>Functional approximation error.</b> This is a secondary type of error, arising primarily from the limitations of learning procedures, for example, structural bias of stochastic gradient descent<sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 10\" title=\"Mousavi-Hosseini, A., Park, S., Girotti, M., Mitliagkas, I. &amp; Erdogdu, M. A. in Proc. Eleventh International Conference on Learning Representations (ICLR, 2023).\" href=\"about:/articles/s41586-024-07566-y#ref-CR10\" id=\"ref-link-section-d34320735e657\">10</a>,<a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 11\" title=\"Soudry, D., Hoffer, E., Nacson, M. S., Gunasekar, S. &amp; Srebro, N. The implicit bias of gradient descent on separable data. J. Mach. Learn. Res. 19, 1–57 (2018).\" href=\"about:/articles/s41586-024-07566-y#ref-CR11\" id=\"ref-link-section-d34320735e660\">11</a></sup> or choice of objective<sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 12\" title=\"Gu, Y., Dong, L., Wei, F. &amp; Huang, M. in Proc. Twelfth International Conference on Learning Representations (ICLR, 2024).\" href=\"about:/articles/s41586-024-07566-y#ref-CR12\" id=\"ref-link-section-d34320735e664\">12</a></sup>. This error can be viewed as one arising in the limit of infinite data and perfect expressivity at each generation.</p>\n                </li>\n              </ul><p>Each of the above can cause model collapse to get worse or better. More approximation power can even be a double-edged sword—better expressiveness may counteract statistical noise, resulting in a good approximation of the true distribution, but it can equally compound the noise. More often than not, we get a cascading effect, in which individual inaccuracies combine to cause the overall error to grow. For example, overfitting the density model causes the model to extrapolate incorrectly and assigns high-density regions to low-density regions not covered in the training set support; these will then be sampled with arbitrary frequency. It is worth noting that other types of error exist. For example, computers have limited precision in practice. We now turn to mathematical intuition to explain how the above give rise to the errors observed, how different sources can compound and how we can quantify the average model divergence.</p></div></div><div id=\"Sec3-section\" data-title=\"Theoretical intuition\"><h2 id=\"Sec3\">Theoretical intuition</h2><div id=\"Sec3-content\"><p>Here we provide a theoretical intuition for the phenomenon of model collapse. We argue that the process of model collapse is universal among generative models that recursively train on data generated by previous generations. We quantify the sources of errors discussed in the previous section by examining two mathematical models, which prove to be simple enough to provide analytical expressions for quantities of interest, but also portray the phenomenon of model collapse: a discrete distribution in the absence of functional expressivity and approximation errors, and a multidimensional Gaussian approximation, portraying joint functional expressivity and statistical errors. We further illustrate the impact of all three jointly for a more complex setting of density estimation in Hilbert spaces in the <a data-track=\"click\" data-track-label=\"link\" data-track-action=\"supplementary material anchor\" href=\"about:/articles/s41586-024-07566-y#MOESM1\">Supplementary Materials</a>.</p><p>The overall stochastic process we consider, which we call learning with generational data, is the following. The dataset at generation <i>i</i> is <span>\\({{\\mathcal{D}}}_{i}\\)</span>, comprising independent and identically distributed random variables <span>\\({X}_{j}^{i}\\)</span> with distribution <i>p</i><sub><i>i</i></sub>, <i>j</i> <span>∈</span> {1,…, <i>M</i><sub><i>i</i></sub>} denotes the size of the dataset. Going from generation <i>i</i> to generation <i>i</i> + 1, we aim to estimate the distribution of samples in <span>\\({{\\mathcal{D}}}_{i}\\)</span>, with an approximation <span>\\({p}_{{\\theta }_{i+1}}\\)</span>. This step is what we refer to as functional approximation, <span>\\({p}_{{\\theta }_{i+1}}={{\\mathcal{F}}}_{\\theta }({p}_{i})\\)</span>. The dataset <span>\\({{\\mathcal{D}}}_{i+1}\\)</span> is then generated by sampling from <span>\\({p}_{i+1}={\\alpha }_{i}{p}_{{\\theta }_{i+1}}+{\\beta }_{i}{p}_{i}+{\\gamma }_{i}{p}_{0}\\)</span>, with non-negative parameters <i>α</i><sub><i>i</i></sub>, <i>β</i><sub><i>i</i></sub>, <i>γ</i><sub><i>i</i></sub> summing to 1, that is, they represent proportions of data used from different generations. This corresponds to a mixing of data coming from the original distribution (<i>γ</i><sub><i>i</i></sub>), data used by the previous generation (<i>β</i><sub><i>i</i></sub>) and data generated by the new model (<i>α</i><sub><i>i</i></sub>). We refer to this as the sampling step. For the mathematical models to come, we consider <i>α</i><sub><i>i</i></sub> = <i>γ</i><sub><i>i</i></sub> = 0, that is, data only from a single step are used, whereas numerical experiments are performed on more realistic choices of parameters.</p><h3 id=\"Sec4\">Discrete distributions with exact approximation</h3><p>In this subsection, we consider a discrete probability distribution in absence of functional approximation and expressivity errors, that is, <span>\\({\\mathcal{F}}(p)=p\\)</span>. In this case, model collapse arises only because of statistical errors from the sampling step. At first, the tails (low-probability events) begin to disappear as a result of the low probability of sampling them and, over time, support of&nbsp;the distribution shrinks. Denoting the sample size as <i>M</i>, if we consider state <i>i</i> with probability <span>\\(q\\le \\frac{1}{M}\\)</span>, the expected number of samples with value <i>i</i> coming from those events will be less than 1. In practice, this would mean that we lose information about them. Considering more generally some state <i>i</i> with probability <i>q</i>, using standard conditional probability, we can show that the probability of losing information (that is, sampling no data at some generation) is equal to 1 − <i>q</i>, implying that the distribution must converge to a delta function positioned at some state, with the probability of ending up at a certain state equal to the probability of sampling said state from the original distribution.</p><p>This can be shown directly by considering the process <span>\\({{\\bf{X}}}^{i}\\to {\\mathcal{F}}\\,\\to \\)</span><span>\\({p}_{i+1}\\to {{\\bf{X}}}^{i+1}\\)</span> as a Markov chain, as <b>X</b><sup><i>i</i>+1</sup> only depends on <b>X</b><sup><i>i</i></sup>. Furthermore, if all the <span>\\({X}_{j}^{i}\\)</span> have the same value, then at the next generation, the approximated distribution will be exactly a delta function and therefore all of <span>\\({X}_{j}^{i+1}\\)</span> will also have the same value. This implies that the Markov chain contains at least one absorbing state and therefore, with probability 1, it will converge to one of the absorbing states. This is a well-known fact, of which a proof is provided in the <a data-track=\"click\" data-track-label=\"link\" data-track-action=\"supplementary material anchor\" href=\"about:/articles/s41586-024-07566-y#MOESM1\">Supplementary Materials</a>. For this chain, the only absorbing states are those corresponding to delta functions. As a result, as we follow the progress of model collapse, we are guaranteed to end up in a constant state, having lost all the information of the original distribution when the chain is absorbed. This argument also works in general owing to floating-point representations being discrete, making the Markov chain over the parameters of the model discrete. Thus, as long as the model parameterization allows for delta functions, we will get to it, because—owing to sampling errors—the only possible absorbing states are delta functions. On the basis of the discussion above, we see how both early model collapse, in which only the low-probability events get cut off, and late stage model collapse, in which the process begins to collapse into a single mode, must arise in the case of discrete distributions with perfect functional approximation.</p><h3 id=\"Sec5\">Multidimensional Gaussian</h3><p>Following the discussion about discrete distributions, we now present a more generic result, which can be shown in the Gaussian approximation setting, in which each generation is approximated using the unbiased estimates of the mean and the variance. A similar result holds more generally, which we detail in the&nbsp;<a data-track=\"click\" data-track-label=\"link\" data-track-action=\"supplementary material anchor\" href=\"about:/articles/s41586-024-07566-y#MOESM1\">Supplementary Materials</a>.</p>\n                  <h3 id=\"FPar2\">Theorem 3.1 (Gaussian model collapse)</h3>\n                  <p>Assume the original data are sampled from distribution <span>\\({{\\mathcal{D}}}_{0}\\)</span> (not necessarily Gaussian), with non-zero sample variance. Assume <i>X</i><sup><i>n</i></sup> are fit recursively using the unbiased sample mean and variance estimators from the previous generation, <span>\\({X}_{j}^{n}| {\\mu }_{n},{\\Sigma }_{n} \\sim {\\mathcal{N}}({\\mu }_{n},{\\Sigma }_{n})\\)</span>, with a fixed sample size. Then,</p><div id=\"Equa\"><p><span>$${\\mathbb{E}}[{{\\mathbb{W}}}_{2}^{2}({\\mathcal{N}}({\\mu }_{n},{\\Sigma }_{n}),{{\\mathcal{D}}}_{0})]\\to \\infty ;\\,{\\Sigma }_{n}\\,\\mathop{\\to }\\limits^{{\\rm{a}}.{\\rm{s}}.}\\,0\\,\\,{\\rm{a}}{\\rm{s}}\\,\\,n\\to \\infty ,$$</span></p></div><p>in which <span>\\({{\\mathbb{W}}}_{2}\\)</span> denotes the Wasserstein-2 distance between the true distribution and its approximation at generation <i>n</i>.</p>\n                <p>In words, this implies that not only does the <i>n</i>th generation approximation diverge arbitrarily far from the original one but it also collapses to be zero variance as the number of generations increases, with probability 1. The results are very analogous to that seen in the discrete case, with this theorem illustrating the effect of late stage model collapse, in which the process begins to collapse to be zero variance. The early stage model collapse can also be seen and the interested reader is referred to the&nbsp;<a data-track=\"click\" data-track-label=\"link\" data-track-action=\"supplementary material anchor\" href=\"about:/articles/s41586-024-07566-y#MOESM1\">Supplementary Materials</a> for a more in-depth discussion.</p></div></div><div id=\"Sec6-section\" data-title=\"Model collapse in language models\"><h2 id=\"Sec6\">Model collapse in language models</h2><div id=\"Sec6-content\"><p>In this section, we evaluate the effect of model collapse on language models. We cover more interpretable machine learning models—VAEs and GMMs—in the&nbsp;<a data-track=\"click\" data-track-label=\"link\" data-track-action=\"supplementary material anchor\" href=\"about:/articles/s41586-024-07566-y#MOESM1\">Supplementary Materials</a>. Code is publically available in ref. <sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 13\" title=\"Shumailov, I. &amp; Shumaylov, Z. Public code for Model Collapse (0.1). Zenodo \n                  https://doi.org/10.5281/zenodo.10866595\n                  \n                 (2024).\" href=\"about:/articles/s41586-024-07566-y#ref-CR13\" id=\"ref-link-section-d34320735e1881\">13</a></sup>.</p><p>Model collapse is universal across various families of machine learning models. Yet, if small models such as GMMs and VAEs are normally trained from scratch, LLMs are different. They are so expensive to retrain from scratch that they are typically initialized with pre-trained models such as BERT<sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 4\" title=\"Devlin, J., Chang, M.-W., Lee, K. &amp; Toutanova, K. in Proc. 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) (eds Burstein, J., Doran, C. &amp; Solorio, T.) 4171–4186 (Association for Computational Linguistics, 2019).\" href=\"about:/articles/s41586-024-07566-y#ref-CR4\" id=\"ref-link-section-d34320735e1888\">4</a></sup>, RoBERTa<sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 5\" title=\"Liu, Y. et al. RoBERTa: a Robustly Optimized BERT Pretraining Approach. Preprint at \n                  https://arxiv.org/abs/1907.11692\n                  \n                 (2019).\" href=\"about:/articles/s41586-024-07566-y#ref-CR5\" id=\"ref-link-section-d34320735e1892\">5</a></sup> or GPT-2 (ref. <sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 2\" title=\"Brown, T. et al. Language models are few-shot learners. Adv. Neural Inf. Process. Syst. 33, 1877–1901 (2020).\" href=\"about:/articles/s41586-024-07566-y#ref-CR2\" id=\"ref-link-section-d34320735e1896\">2</a></sup>), which are trained on large text corpora. They are then fine-tuned to various downstream&nbsp;tasks<sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 14\" title=\"Bommasani, R. et al. On the opportunities and risks of foundation models. Preprint at \n                  https://arxiv.org/abs/2108.07258\n                  \n                 (2022).\" href=\"about:/articles/s41586-024-07566-y#ref-CR14\" id=\"ref-link-section-d34320735e1900\">14</a></sup>.</p><p>Here we explore what happens with language models when they are sequentially fine-tuned with data generated by other models. We can easily replicate all experiments covered in this paper with larger language models in non-fine-tuning settings to demonstrate model collapse. Given that training a single moderately large model produces twice the American lifetime’s worth of CO<sub>2</sub> (ref. <sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 15\" title=\"Strubell, E., Ganesh, A. &amp; McCallum, A. in Proc. 57th Annual Meeting of the Association for Computational Linguistics (eds Korhonen, A., Traum, D. &amp; Màrquez, L.) 3645–3650 (Association for Computational Linguistics, 2019).\" href=\"about:/articles/s41586-024-07566-y#ref-CR15\" id=\"ref-link-section-d34320735e1909\">15</a></sup>), we opted to not run such an experiment and instead focus on a more realistic setting for a proof of concept. Note that even the language experiments described in this paper took weeks to run. We evaluate the most common setting of training a language model—a fine-tuning setting for which each of the training cycles starts from a pre-trained model with recent data. The data here come from another fine-tuned pre-trained model. Because training is restricted to produce models that are close to the original pre-trained model, and data points generated by the models will generally produce very small gradients, the expectation here may be that the model should only change moderately after fine-tuning. We fine-tune the OPT-125m causal language model made available by Meta through Hugging Face<sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 6\" title=\"Zhang, S. et al. Opt: open pre-trained transformer language models. Preprint at \n                  https://arxiv.org/abs/2205.01068\n                  \n                 (2022).\" href=\"about:/articles/s41586-024-07566-y#ref-CR6\" id=\"ref-link-section-d34320735e1913\">6</a></sup>.</p><p>We fine-tune it on the wikitext2 dataset<sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 16\" title=\"Merity, S., Xiong, C., Bradbury, J. &amp; Socher, R. in Proc. 5th International Conference on Learning Representations (ICLR, 2017).\" href=\"about:/articles/s41586-024-07566-y#ref-CR16\" id=\"ref-link-section-d34320735e1920\">16</a></sup>. For data generation from the trained models, we use a five-way beam search. We block training sequences to be 64 tokens long; then, for each token sequence in the training set, we ask the model to predict the next 64 tokens. We go through all of the original training dataset and produce an artificial dataset of the same size. Because we go through all of the original dataset and predict all of the blocks, if the model had 0 error, it would produce the original wikitext2 dataset. Training for each generation starts with generation from the original training data. Each experiment is run five times and the results are shown as five separate runs with different randomness seeds. The original model fine-tuned with real wikitext2 data obtains 34 mean perplexity, from the zero-shot baseline of 115, that is, it successfully learns the task. Finally, to be as realistic as possible, we use the best-performing model on the original task, evaluated using the original wikitext2 validation set, as the base model for the subsequent generations, meaning that—in practice—observed model collapse can be even more pronounced. Here we consider two different settings:</p><ul>\n                <li>\n                  <p>Five epochs, no original training data. Here the model is trained for five epochs starting on the original dataset but with no original data retained for subsequent runs. The overall original task performance is presented in Fig. <a data-track=\"click\" data-track-label=\"link\" data-track-action=\"figure anchor\" href=\"about:/articles/s41586-024-07566-y#Fig1\">1b</a>. We find that training with generated data allows us to adapt to the underlying task, losing some performance, from 20 to 28 perplexity points.</p>\n                </li>\n                <li>\n                  <p>Ten epochs, 10% of original training data preserved. Here the model is trained for ten epochs on the original dataset and with every new generation of training, a random 10% of the original data points is sampled. The overall original task performance is presented in Fig. <a data-track=\"click\" data-track-label=\"link\" data-track-action=\"figure anchor\" href=\"about:/articles/s41586-024-07566-y#Fig1\">1c</a>. We find that preservation of the original data allows for better model fine-tuning and leads to only minor degradation of performance.</p>\n                </li>\n              </ul><p>Both training regimes lead to degraded performance in our models, yet we do find that learning with generated data is possible and models can successfully learn (some of) the underlying task. In particular, from Fig. <a data-track=\"click\" data-track-label=\"link\" data-track-action=\"figure anchor\" href=\"about:/articles/s41586-024-07566-y#Fig1\">1</a> and their 3D versions in the&nbsp;<a data-track=\"click\" data-track-label=\"link\" data-track-action=\"supplementary material anchor\" href=\"about:/articles/s41586-024-07566-y#MOESM1\">Supplementary Materials</a>, we see that model collapse occurs, as the density of samples with low perplexity begins to accumulate over the generations. This in turn makes it likely that, over the generations, the sampled data will similarly collapse to a delta function.</p><div data-test=\"figure\" data-container-section=\"figure\" id=\"figure-1\" data-title=\"The high-level description of the feedback mechanism in the learning process.\"><figure><figcaption><b id=\"Fig1\" data-test=\"figure-caption-text\">Fig. 1: The high-level description of the feedback mechanism in the learning process.</b></figcaption><div><div><a data-test=\"img-link\" data-track=\"click\" data-track-label=\"image\" data-track-action=\"view figure\" href=\"/articles/s41586-024-07566-y/figures/1\" rel=\"nofollow\"><picture><source type=\"image/webp\" srcset=\"//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41586-024-07566-y/MediaObjects/41586_2024_7566_Fig1_HTML.png?as=webp\"><img aria-describedby=\"Fig1\" src=\"//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41586-024-07566-y/MediaObjects/41586_2024_7566_Fig1_HTML.png\" alt=\"figure 1\" loading=\"lazy\" width=\"685\" height=\"739\"></picture></a></div><p><b>a</b>, Model collapse refers to a degenerative learning process in which models start forgetting improbable events over time, as the model becomes poisoned with its own projection of reality. Here data are assumed to be human-curated and start off clean; then model 0 is trained and data are sampled from it; at step <i>n</i>, data are added to the overall data from step <i>n</i> − 1 and this combination is used to train model <i>n</i>. Data obtained with Monte Carlo sampling should ideally be statistically close to the original, provided that fitting and sampling procedures are perfect. This process depicts what happens in real life with the Internet: model-generated data become pervasive. <b>b</b>,<b>c</b>, Performance of OPT-125m models of different generations evaluated using the original wikitext2 test dataset. Shown on the left are the histograms of perplexities of each individual data training sequence produced by different generations as evaluated by the very first model trained with the real data. Over the generations, models tend to produce samples that the original model trained with real data is more likely to produce. At the same time, a much longer tail appears for later generations. Later generations start producing samples that would never be produced by the original model, that is, they start misperceiving reality based on errors introduced by their ancestors. The same plots are shown in 3D in the <a data-track=\"click\" data-track-label=\"link\" data-track-action=\"supplementary material anchor\" href=\"about:/articles/s41586-024-07566-y#MOESM1\">Supplementary Materials</a>. On the right, average perplexity and its standard deviation are shown for each independent run. The <i>x</i> axis refers to the generation of the model. ‘Real’ refers to the ‘model 0’ trained on the original wikitext2 dataset; model 1 was trained on the data produced by model 0, model 2 was trained on data produced by model 1 and so on, with all generated datasets equal in size. We find that models trained on generated data are able to learn some of the original task, but with errors, as seen from the increase in perplexity.</p></div><p><a data-test=\"article-link\" data-track=\"click\" data-track-label=\"button\" data-track-action=\"view figure\" href=\"/articles/s41586-024-07566-y/figures/1\" data-track-dest=\"link:Figure1 Full size image\" aria-label=\"Full size image figure 1\" rel=\"nofollow\"><span>Full size image</span></a></p></figure></div><p>It is important to note here that the observed behaviour is in line with the general intuition established in the section ‘Theoretical intuition’. To be precise, in all experiments, generational learning is only performed on a finite (usually small) number of generations, whereas claims of the section ‘Theoretical intuition’ are mostly presented in the limit of generations going to infinity. However, as seen from experiments on VAEs and GMMs in the&nbsp;<a data-track=\"click\" data-track-label=\"link\" data-track-action=\"supplementary material anchor\" href=\"about:/articles/s41586-024-07566-y#MOESM1\">Supplementary Materials</a>, convergence to delta functions and specific rates of such convergence are highly related to the specifics of the problem considered, and complete collapse may or may not occur, even after a small number of steps. This is further illustrated theoretically in the&nbsp;<a data-track=\"click\" data-track-label=\"link\" data-track-action=\"supplementary material anchor\" href=\"about:/articles/s41586-024-07566-y#MOESM1\">Supplementary Materials</a>, in which potentially notable divergence from the original model can occur even after a few generations.</p><p>Figure <a data-track=\"click\" data-track-label=\"link\" data-track-action=\"figure anchor\" href=\"about:/articles/s41586-024-07566-y#Fig1\">1b,c</a> on the left shows histograms of individual data-point perplexities generated by the models of different generations as is evaluated by the first model developed with real wikitext2 training data. Here, over the generations, models tend to produce more sequences that the original model would produce with the higher likelihood. The observed effect is similar to that described for VAEs and GMMs in the&nbsp;<a data-track=\"click\" data-track-label=\"link\" data-track-action=\"supplementary material anchor\" href=\"about:/articles/s41586-024-07566-y#MOESM1\">Supplementary Materials</a>, in which—over the generations—models started to produce samples that would be produced with higher probabilities by the original model. At the same time, we discover that generated data have much longer tails, suggesting that some of the data would never be produced by the original model—these are the errors that accumulate because of the learning with generational data.</p>\n                <h3 id=\"FPar3\">Example 1</h3>\n                <p>Example of text outputs of an OPT-125m model affected by model collapse—models degrade over generations, for which each new generation is trained on data produced by the previous generation.</p><ul>\n                  <li>\n                    <p><b>Input:</b> some started before 1360 — was typically accomplished by a master mason and a small team of itinerant masons, supplemented by local parish labourers, according to Poyntz Wright. But other authors reject this model, suggesting instead that leading architects designed the parish church towers based on early examples of Perpendicular.</p>\n                  </li>\n                  <li>\n                    <p><b>Outputs:</b></p>\n                  </li>\n                  <li>\n                    <p><b>Gen 0:</b> Revival architecture such as St. John’s Cathedral in London. The earliest surviving example of Perpendicular Revival architecture is found in the 18th @-@ century Church of Our Lady of Guernsey, which dates from the late 19th century. There are two types of perpendicular churches : those.</p>\n                  </li>\n                  <li>\n                    <p><b>Gen 1:</b> architecture such as St. Peter’s Basilica in Rome or St. Peter’s Basilica in Buenos Aires. There is no evidence that any of these buildings were built during the reign of Pope Innocent III, but it is possible that they may have been built during the reign of his successor, Pope Innocent.</p>\n                  </li>\n                  <li>\n                    <p><b>Gen 5:</b> ism, which had been translated into more than 100 languages including English, French, German, Italian, Spanish, Portuguese, Dutch, Swedish, Norwegian, Polish, Hungarian, Slovak, Lithuanian, Estonian, Finnish, Romanian, Bulgarian, Turkish, Croatian, Serbian, Ukrainian, Russian, Kazakh, Kyrgyz.</p>\n                  </li>\n                  <li>\n                    <p><b>Gen 9:</b> architecture. In addition to being home to some of the world’s largest populations of black @-@ tailed jackrabbits, white @-@ tailed jackrabbits, blue @-@ tailed jackrabbits, red @-@ tailed jackrabbits, yellow @-.</p>\n                  </li>\n                </ul>\n              <h3 id=\"Sec7\">Ablation: Repetitions</h3><p>We find that data generated by language models in our experiments end up containing a large number of repeating phrases, as in Example 1. The repeating problem has been observed in nearly all text-generation models<sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 17\" title=\"Keskar, N. S., McCann, B., Varshney, L. R., Xiong, C. &amp; Socher, R. CTRL: a conditional transformer language model for controllable generation. Preprint at \n                  https://arxiv.org/abs/1909.05858\n                  \n                 (2019).\" href=\"about:/articles/s41586-024-07566-y#ref-CR17\" id=\"ref-link-section-d34320735e2081\">17</a>,<a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 18\" title=\"Shumailov, I. et al. in Proc. 2021 IEEE European Symposium on Security and Privacy (EuroS&amp;P) 212–231 (IEEE, 2021).\" href=\"about:/articles/s41586-024-07566-y#ref-CR18\" id=\"ref-link-section-d34320735e2084\">18</a></sup> and, to rule this out as the cause of model collapse, we further provide numerical experiments when models are explicitly encouraged to produce non-repeating sequences with a repeating penalty of 2.0. We find that this causes the models to produce lower score continuations to avoid using repeats, which—as a result—causes the consequent models to perform even worse. Model perplexities shift across the generations towards more probable token sequences, as measured using the model trained on the original real data distribution. Further illustrations are provided in the&nbsp;<a data-track=\"click\" data-track-label=\"link\" data-track-action=\"supplementary material anchor\" href=\"about:/articles/s41586-024-07566-y#MOESM1\">Supplementary Materials</a>. In particular, enforcing this for the LLM experiments causes the perplexity to double compared with the original. Models remain as susceptible to model collapse, if not more.</p><p>The described process demonstrates that fine-tuning of language models does not curb the effects of model collapse and models that are being fine-tuned are also vulnerable. We find that, over the generations, models tend to produce more probable sequences from the original data and start introducing their own improbable sequences, that is, errors.</p></div></div><div id=\"Sec8-section\" data-title=\"Discussion\"><h2 id=\"Sec8\">Discussion</h2><div id=\"Sec8-content\"><p>We now discuss the implications of model collapse on the underlying learning dynamics of LLMs. Long-term poisoning attacks on language models are not new. For example, we saw the creation of click, content and troll farms, a form of human ‘language models’, whose job is to misguide social networks and search algorithms. The negative effect that these poisoning attacks had on search results led to changes in search algorithms. For example, Google downgraded farmed articles<sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 19\" title=\"Google. Finding more high-quality sites in search. Google \n                  https://googleblog.blogspot.com/2011/02/finding-more-high-quality-sites-in.html\n                  \n                 (2011).\" href=\"about:/articles/s41586-024-07566-y#ref-CR19\" id=\"ref-link-section-d34320735e2103\">19</a></sup>, putting more emphasis on content produced by trustworthy sources, such as education domains, whereas DuckDuckGo removed them altogether<sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 20\" title=\"Mims, C. The search engine backlash against ‘content mills’. MIT Technology Review \n                  https://www.technologyreview.com/2010/07/26/26327/the-search-engine-backlash-against-content-mills/\n                  \n                 (2010).\" href=\"about:/articles/s41586-024-07566-y#ref-CR20\" id=\"ref-link-section-d34320735e2107\">20</a></sup>. What is different with the arrival of LLMs is the scale at which such poisoning can happen once it is automated. Preserving the ability of LLMs to model low-probability events is essential to the fairness of their predictions: such events are often relevant to marginalized groups. Low-probability events are also vital to understand complex systems<sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 21\" title=\"Taleb, N. N. Black swans and the domains of statistics. Am. Stat. 61, 198–200 (2007).\" href=\"about:/articles/s41586-024-07566-y#ref-CR21\" id=\"ref-link-section-d34320735e2111\">21</a></sup>.</p><p>Our evaluation suggests a ‘first mover advantage’ when it comes to training models such as LLMs. In our work, we demonstrate that training on samples from another generative model can induce a distribution shift, which—over time—causes model collapse. This in turn causes the model to mis-perceive the underlying learning task. To sustain learning over a long period of time, we need to make sure that access to the original data source is preserved and that further data not generated by LLMs remain available over time. The need to distinguish data generated by LLMs from other data raises questions about the provenance of content that is crawled from the Internet: it is unclear how content generated by LLMs can be tracked at scale. One option is community-wide coordination to ensure that different parties involved in LLM creation and deployment share the information needed to resolve questions of provenance. Otherwise, it may become increasingly difficult to train newer versions of LLMs without access to data that were crawled from the Internet before the mass adoption of the technology or direct access to data generated by humans at scale.</p></div></div>\n                </div><div>\n                <div id=\"data-availability-section\" data-title=\"Data availability\"><h2 id=\"data-availability\">Data availability</h2><p>Data generation code for GMM experiments is available in ref. <sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 13\" title=\"Shumailov, I. &amp; Shumaylov, Z. Public code for Model Collapse (0.1). Zenodo \n                  https://doi.org/10.5281/zenodo.10866595\n                  \n                 (2024).\" href=\"about:/articles/s41586-024-07566-y#ref-CR13\" id=\"ref-link-section-d34320735e2200\">13</a></sup>. Data used for VAE experiments are available in ref. <sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 22\" title=\"LeCun, Y., Cortes, C. &amp; Burges, C. J. C. The MNIST database of handwritten digits. \n                  http://yann.lecun.com/exdb/mnist/\n                  \n                 (1998).\" href=\"about:/articles/s41586-024-07566-y#ref-CR22\" id=\"ref-link-section-d34320735e2204\">22</a></sup>. Data used for LLM experiments are available in ref. <sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 16\" title=\"Merity, S., Xiong, C., Bradbury, J. &amp; Socher, R. in Proc. 5th International Conference on Learning Representations (ICLR, 2017).\" href=\"about:/articles/s41586-024-07566-y#ref-CR16\" id=\"ref-link-section-d34320735e2208\">16</a></sup>.</p></div><div id=\"code-availability-section\" data-title=\"Code availability\"><h2 id=\"code-availability\">Code availability</h2><p>Code for all experiments is publically available in ref. <sup><a data-track=\"click\" data-track-action=\"reference anchor\" data-track-label=\"link\" data-test=\"citation-ref\" aria-label=\"Reference 13\" title=\"Shumailov, I. &amp; Shumaylov, Z. Public code for Model Collapse (0.1). Zenodo \n                  https://doi.org/10.5281/zenodo.10866595\n                  \n                 (2024).\" href=\"about:/articles/s41586-024-07566-y#ref-CR13\" id=\"ref-link-section-d34320735e2220\">13</a></sup>.</p></div><div id=\"MagazineFulltextArticleBodySuffix\" aria-labelledby=\"Bib1\" data-title=\"References\"><h2 id=\"Bib1\">References</h2><div data-container-section=\"references\" id=\"Bib1-content\"><ol data-track-component=\"outbound reference\" data-track-context=\"references section\"><li data-counter=\"1.\"><p id=\"ref-CR1\">Radford, A. et al. Language models are unsupervised multitask learners. <i>OpenAI blog</i> <b>1</b>, 9 (2019).</p><p><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 1\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Language%20models%20are%20unsupervised%20multitask%20learners&amp;journal=OpenAI%20blog&amp;volume=1&amp;publication_year=2019&amp;author=Radford%2CA\">\n                    Google Scholar</a>&nbsp;\n                </p></li><li data-counter=\"2.\"><p id=\"ref-CR2\">Brown, T. et al. Language models are few-shot learners. <i>Adv. Neural Inf. Process. Syst.</i> <b>33</b>, 1877–1901 (2020).</p><p><a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 2\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Language%20models%20are%20few-shot%20learners&amp;journal=Adv.%20Neural%20Inf.%20Process.%20Syst.&amp;volume=33&amp;pages=1877-1901&amp;publication_year=2020&amp;author=Brown%2CT\">\n                    Google Scholar</a>&nbsp;\n                </p></li><li data-counter=\"3.\"><p id=\"ref-CR3\">OpenAI. GPT-4 Technical Report. <a href=\"https://cdn.openai.com/papers/gpt-4.pdf\" data-track=\"click_references\" data-track-action=\"external reference\" data-track-value=\"external reference\" data-track-label=\"https://cdn.openai.com/papers/gpt-4.pdf\">https://cdn.openai.com/papers/gpt-4.pdf</a> (2023).</p></li><li data-counter=\"4.\"><p id=\"ref-CR4\">Devlin, J., Chang, M.-W., Lee, K. &amp; Toutanova, K. in <i>Proc. 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)</i> (eds Burstein, J., Doran, C. &amp; Solorio, T.) 4171–4186 (Association for Computational Linguistics, 2019).</p></li><li data-counter=\"5.\"><p id=\"ref-CR5\">Liu, Y. et al. RoBERTa: a Robustly Optimized BERT Pretraining Approach. Preprint at <a href=\"https://arxiv.org/abs/1907.11692\" data-track=\"click_references\" data-track-action=\"external reference\" data-track-value=\"external reference\" data-track-label=\"https://arxiv.org/abs/1907.11692\">https://arxiv.org/abs/1907.11692</a> (2019).</p></li><li data-counter=\"6.\"><p id=\"ref-CR6\">Zhang, S. et al. Opt: open pre-trained transformer language models. Preprint at <a href=\"https://arxiv.org/abs/2205.01068\" data-track=\"click_references\" data-track-action=\"external reference\" data-track-value=\"external reference\" data-track-label=\"https://arxiv.org/abs/2205.01068\">https://arxiv.org/abs/2205.01068</a> (2022).</p></li><li data-counter=\"7.\"><p id=\"ref-CR7\">Aljundi, R., Kelchtermans, K. &amp; Tuytelaars, T. Task-free continual learning. in: <i>Proc. 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)</i> 11254–11263 (IEEE, 2019).</p></li><li data-counter=\"8.\"><p id=\"ref-CR8\">Carlini, N. &amp; Terzis, A. in <i>Proc. Tenth International Conference on Learning Representations</i> (ICLR, 2022).</p></li><li data-counter=\"9.\"><p id=\"ref-CR9\">Carlini, N. et al. in <i>Proc. 2024 IEEE Symposium on Security and Privacy (SP)</i> 179 (IEEE, 2024).</p></li><li data-counter=\"10.\"><p id=\"ref-CR10\">Mousavi-Hosseini, A., Park, S., Girotti, M., Mitliagkas, I. &amp; Erdogdu, M. A. in <i>Proc. Eleventh International Conference on Learning Representations</i> (ICLR, 2023).</p></li><li data-counter=\"11.\"><p id=\"ref-CR11\">Soudry, D., Hoffer, E., Nacson, M. S., Gunasekar, S. &amp; Srebro, N. The implicit bias of gradient descent on separable data. <i>J. Mach. Learn. Res.</i> <b>19</b>, 1–57 (2018).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"mathscinet reference\" data-track-action=\"mathscinet reference\" href=\"http://www.ams.org/mathscinet-getitem?mr=3899772\" aria-label=\"MathSciNet reference 11\">MathSciNet</a>&nbsp;\n    <a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 11\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=The%20implicit%20bias%20of%20gradient%20descent%20on%20separable%20data&amp;journal=J.%20Mach.%20Learn.%20Res.&amp;volume=19&amp;pages=1-57&amp;publication_year=2018&amp;author=Soudry%2CD&amp;author=Hoffer%2CE&amp;author=Nacson%2CMS&amp;author=Gunasekar%2CS&amp;author=Srebro%2CN\">\n                    Google Scholar</a>&nbsp;\n                </p></li><li data-counter=\"12.\"><p id=\"ref-CR12\">Gu, Y., Dong, L., Wei, F. &amp; Huang, M. in <i>Proc. Twelfth International Conference on Learning Representations</i> (ICLR, 2024).</p></li><li data-counter=\"13.\"><p id=\"ref-CR13\">Shumailov, I. &amp; Shumaylov, Z. Public code for Model Collapse (0.1). <i>Zenodo</i> <a href=\"https://doi.org/10.5281/zenodo.10866595\" data-track=\"click_references\" data-track-action=\"external reference\" data-track-value=\"external reference\" data-track-label=\"10.5281/zenodo.10866595\">https://doi.org/10.5281/zenodo.10866595</a> (2024).</p></li><li data-counter=\"14.\"><p id=\"ref-CR14\">Bommasani, R. et al. On the opportunities and risks of foundation models. Preprint at <a href=\"https://arxiv.org/abs/2108.07258\" data-track=\"click_references\" data-track-action=\"external reference\" data-track-value=\"external reference\" data-track-label=\"https://arxiv.org/abs/2108.07258\">https://arxiv.org/abs/2108.07258</a> (2022).</p></li><li data-counter=\"15.\"><p id=\"ref-CR15\">Strubell, E., Ganesh, A. &amp; McCallum, A. in <i>Proc. 57th Annual Meeting of the Association for Computational Linguistics</i> (eds Korhonen, A., Traum, D. &amp; Màrquez, L.) 3645–3650 (Association for Computational Linguistics, 2019).</p></li><li data-counter=\"16.\"><p id=\"ref-CR16\">Merity, S., Xiong, C., Bradbury, J. &amp; Socher, R. in <i>Proc. 5th International Conference on Learning Representations</i> (ICLR, 2017).</p></li><li data-counter=\"17.\"><p id=\"ref-CR17\">Keskar, N. S., McCann, B., Varshney, L. R., Xiong, C. &amp; Socher, R. CTRL: a conditional transformer language model for controllable generation. Preprint at <a href=\"https://arxiv.org/abs/1909.05858\" data-track=\"click_references\" data-track-action=\"external reference\" data-track-value=\"external reference\" data-track-label=\"https://arxiv.org/abs/1909.05858\">https://arxiv.org/abs/1909.05858</a> (2019).</p></li><li data-counter=\"18.\"><p id=\"ref-CR18\">Shumailov, I. et al. in <i>Proc. 2021 IEEE European Symposium on Security and Privacy (EuroS&amp;P)</i> 212–231 (IEEE, 2021).</p></li><li data-counter=\"19.\"><p id=\"ref-CR19\">Google. Finding more high-quality sites in search. <i>Google</i> <a href=\"https://googleblog.blogspot.com/2011/02/finding-more-high-quality-sites-in.html\" data-track=\"click_references\" data-track-action=\"external reference\" data-track-value=\"external reference\" data-track-label=\"https://googleblog.blogspot.com/2011/02/finding-more-high-quality-sites-in.html\">https://googleblog.blogspot.com/2011/02/finding-more-high-quality-sites-in.html</a> (2011).</p></li><li data-counter=\"20.\"><p id=\"ref-CR20\">Mims, C. The search engine backlash against ‘content mills’. <i>MIT Technology Review</i> <a href=\"https://www.technologyreview.com/2010/07/26/26327/the-search-engine-backlash-against-content-mills/\" data-track=\"click_references\" data-track-action=\"external reference\" data-track-value=\"external reference\" data-track-label=\"https://www.technologyreview.com/2010/07/26/26327/the-search-engine-backlash-against-content-mills/\">https://www.technologyreview.com/2010/07/26/26327/the-search-engine-backlash-against-content-mills/</a> (2010).</p></li><li data-counter=\"21.\"><p id=\"ref-CR21\">Taleb, N. N. Black swans and the domains of statistics. <i>Am. Stat.</i> <b>61</b>, 198–200 (2007).</p><p><a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"10.1198/000313007X219996\" data-track-item_id=\"10.1198/000313007X219996\" data-track-value=\"article reference\" data-track-action=\"article reference\" href=\"https://doi.org/10.1198%2F000313007X219996\" aria-label=\"Article reference 21\" data-doi=\"10.1198/000313007X219996\">Article</a>&nbsp;\n    <a data-track=\"click_references\" rel=\"nofollow noopener\" data-track-label=\"link\" data-track-item_id=\"link\" data-track-value=\"mathscinet reference\" data-track-action=\"mathscinet reference\" href=\"http://www.ams.org/mathscinet-getitem?mr=2393721\" aria-label=\"MathSciNet reference 21\">MathSciNet</a>&nbsp;\n    <a data-track=\"click_references\" data-track-action=\"google scholar reference\" data-track-value=\"google scholar reference\" data-track-label=\"link\" data-track-item_id=\"link\" rel=\"nofollow noopener\" aria-label=\"Google Scholar reference 21\" href=\"http://scholar.google.com/scholar_lookup?&amp;title=Black%20swans%20and%20the%20domains%20of%20statistics&amp;journal=Am.%20Stat.&amp;doi=10.1198%2F000313007X219996&amp;volume=61&amp;pages=198-200&amp;publication_year=2007&amp;author=Taleb%2CNN\">\n                    Google Scholar</a>&nbsp;\n                </p></li><li data-counter=\"22.\"><p id=\"ref-CR22\">LeCun, Y., Cortes, C. &amp; Burges, C. J. C. The MNIST database of handwritten digits. <a href=\"http://yann.lecun.com/exdb/mnist/\" data-track=\"click_references\" data-track-action=\"external reference\" data-track-value=\"external reference\" data-track-label=\"http://yann.lecun.com/exdb/mnist/\">http://yann.lecun.com/exdb/mnist/</a> (1998).</p></li></ol><p><a data-track=\"click\" data-track-action=\"download citation references\" data-track-label=\"link\" rel=\"nofollow\" href=\"https://citation-needed.springer.com/v2/references/10.1038/s41586-024-07566-y?format=refman&amp;flavour=references\">Download references</a></p></div></div><div id=\"Ack1-section\" data-title=\"Acknowledgements\"><h2 id=\"Ack1\">Acknowledgements</h2><p>This paper is dedicated to the memory of Professor Ross J. Anderson, our colleague and friend, who contributed much to this and other works we have produced over the years. We thank A. Thudi, D. Glukhov, P. Zaika, and D. Barak for useful discussions and feedback.</p></div><div id=\"author-information-section\" aria-labelledby=\"author-information\" data-title=\"Author information\"><h2 id=\"author-information\">Author information</h2><div id=\"author-information-content\"><p><span id=\"author-notes\">Author notes</span></p><ol><li id=\"na1\"><p>These authors contributed equally: Ilia Shumailov, Zakhar Shumaylov</p></li><li id=\"na2\"><p>Deceased: Ross Anderson</p></li></ol><h3 id=\"affiliations\">Authors and Affiliations</h3><ol><li id=\"Aff1\"><p>OATML, Department of Computer Science, University of Oxford, Oxford, UK</p><p>Ilia Shumailov&nbsp;&amp;&nbsp;Yarin Gal</p></li><li id=\"Aff2\"><p>Department of Applied Mathematics and Theoretical Physics, University of Cambridge, Cambridge, UK</p><p>Zakhar Shumaylov</p></li><li id=\"Aff3\"><p>Department of Electrical and Electronic Engineering, Imperial College London, London, UK</p><p>Yiren Zhao</p></li><li id=\"Aff4\"><p>University of Toronto, Toronto, Ontario, Canada</p><p>Nicolas Papernot</p></li><li id=\"Aff5\"><p>Vector Institute, Toronto, Ontario, Canada</p><p>Nicolas Papernot</p></li><li id=\"Aff6\"><p>Department of Computer Science and Technology, University of Cambridge, Cambridge, UK</p><p>Ross Anderson</p></li><li id=\"Aff7\"><p>School of Informatics, University of Edinburgh, Edinburgh, UK</p><p>Ross Anderson</p></li></ol><div data-test=\"author-info\"><p><span>Authors</span></p><ol><li id=\"auth-Ilia-Shumailov-Aff1\"><span>Ilia Shumailov</span><div><p>You can also search for this author in\n                        <span><a href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Ilia%20Shumailov\" data-track=\"click\" data-track-action=\"author link - pubmed\" data-track-label=\"link\" rel=\"nofollow\">PubMed</a><span>&nbsp;</span><a href=\"http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Ilia%20Shumailov%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en\" data-track=\"click\" data-track-action=\"author link - scholar\" data-track-label=\"link\" rel=\"nofollow\">Google Scholar</a></span></p></div></li><li id=\"auth-Zakhar-Shumaylov-Aff2\"><span>Zakhar Shumaylov</span><div><p>You can also search for this author in\n                        <span><a href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Zakhar%20Shumaylov\" data-track=\"click\" data-track-action=\"author link - pubmed\" data-track-label=\"link\" rel=\"nofollow\">PubMed</a><span>&nbsp;</span><a href=\"http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Zakhar%20Shumaylov%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en\" data-track=\"click\" data-track-action=\"author link - scholar\" data-track-label=\"link\" rel=\"nofollow\">Google Scholar</a></span></p></div></li><li id=\"auth-Yiren-Zhao-Aff3\"><span>Yiren Zhao</span><div><p>You can also search for this author in\n                        <span><a href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Yiren%20Zhao\" data-track=\"click\" data-track-action=\"author link - pubmed\" data-track-label=\"link\" rel=\"nofollow\">PubMed</a><span>&nbsp;</span><a href=\"http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Yiren%20Zhao%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en\" data-track=\"click\" data-track-action=\"author link - scholar\" data-track-label=\"link\" rel=\"nofollow\">Google Scholar</a></span></p></div></li><li id=\"auth-Nicolas-Papernot-Aff4-Aff5\"><span>Nicolas Papernot</span><div><p>You can also search for this author in\n                        <span><a href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Nicolas%20Papernot\" data-track=\"click\" data-track-action=\"author link - pubmed\" data-track-label=\"link\" rel=\"nofollow\">PubMed</a><span>&nbsp;</span><a href=\"http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Nicolas%20Papernot%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en\" data-track=\"click\" data-track-action=\"author link - scholar\" data-track-label=\"link\" rel=\"nofollow\">Google Scholar</a></span></p></div></li><li id=\"auth-Ross-Anderson-Aff6-Aff7\"><span>Ross Anderson</span><div><p>You can also search for this author in\n                        <span><a href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Ross%20Anderson\" data-track=\"click\" data-track-action=\"author link - pubmed\" data-track-label=\"link\" rel=\"nofollow\">PubMed</a><span>&nbsp;</span><a href=\"http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Ross%20Anderson%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en\" data-track=\"click\" data-track-action=\"author link - scholar\" data-track-label=\"link\" rel=\"nofollow\">Google Scholar</a></span></p></div></li><li id=\"auth-Yarin-Gal-Aff1\"><span>Yarin Gal</span><div><p>You can also search for this author in\n                        <span><a href=\"http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Yarin%20Gal\" data-track=\"click\" data-track-action=\"author link - pubmed\" data-track-label=\"link\" rel=\"nofollow\">PubMed</a><span>&nbsp;</span><a href=\"http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Yarin%20Gal%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en\" data-track=\"click\" data-track-action=\"author link - scholar\" data-track-label=\"link\" rel=\"nofollow\">Google Scholar</a></span></p></div></li></ol></div><h3 id=\"contributions\">Contributions</h3><p>I.S. and Z.S. proposed and developed the idea, led the research and mathematical modelling and developed the GMM and VAE experiments. I.S. and Y.Z. developed the language-model experiments. N.P., Y.G. and R.A. supervised and guided the project. All authors contributed to writing of the manuscript. Y.G. is supported by a Turing AI Fellowship financed by the UK government’s Office for Artificial Intelligence, through UK Research and Innovation (grant reference EP/V030302/1) and delivered by the Alan Turing Institute.</p><h3 id=\"corresponding-author\">Corresponding authors</h3><p id=\"corresponding-author-list\">Correspondence to\n                <a id=\"corresp-c1\" href=\"mailto:ilia.shumailov@chch.ox.ac.uk\">Ilia Shumailov</a>, <a id=\"corresp-c2\" href=\"mailto:zs334@cam.ac.uk\">Zakhar Shumaylov</a> or <a id=\"corresp-c3\" href=\"mailto:yarin@cs.ox.ac.uk\">Yarin Gal</a>.</p></div></div><div id=\"ethics-section\" data-title=\"Ethics declarations\"><h2 id=\"ethics\">Ethics declarations</h2><div id=\"ethics-content\">\n              \n                <h3 id=\"FPar5\">Competing interests</h3>\n                <p>The authors declare no competing interests.</p>\n              \n            </div></div><div id=\"peer-review-section\" data-title=\"Peer review\"><h2 id=\"peer-review\">Peer review</h2><div id=\"peer-review-content\">\n              \n              \n                <h3 id=\"FPar4\">Peer review information</h3>\n                <p><i>Nature</i> thanks the anonymous reviewers for their contribution to the peer review of this work.</p>\n              \n            </div></div><div id=\"additional-information-section\" data-title=\"Additional information\"><h2 id=\"additional-information\">Additional information</h2><p><b>Publisher’s note</b> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div><div id=\"Sec10-section\" data-title=\"Supplementary information\"><h2 id=\"Sec10\">Supplementary information</h2></div><div id=\"rightslink-section\" data-title=\"Rights and permissions\"><h2 id=\"rightslink\">Rights and permissions</h2><div id=\"rightslink-content\">\n                <p><b>Open Access</b>  This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <a href=\"http://creativecommons.org/licenses/by/4.0/\" rel=\"license\">http://creativecommons.org/licenses/by/4.0/</a>.</p>\n              <p><a data-track=\"click\" data-track-action=\"view rights and permissions\" data-track-label=\"link\" href=\"https://s100.copyright.com/AppDispatchServlet?title=AI%20models%20collapse%20when%20trained%20on%20recursively%20generated%20data&amp;author=Ilia%20Shumailov%20et%20al&amp;contentID=10.1038%2Fs41586-024-07566-y&amp;copyright=The%20Author%28s%29&amp;publication=0028-0836&amp;publicationDate=2024-07-24&amp;publisherName=SpringerNature&amp;orderBeanReset=true&amp;oa=CC%20BY\">Reprints and permissions</a></p></div></div><div id=\"article-info-section\" aria-labelledby=\"article-info\" data-title=\"About this article\"><h2 id=\"article-info\">About this article</h2><div id=\"article-info-content\"><p><a data-crossmark=\"10.1038/s41586-024-07566-y\" target=\"_blank\" rel=\"noopener\" href=\"https://crossmark.crossref.org/dialog/?doi=10.1038/s41586-024-07566-y\" data-track=\"click\" data-track-action=\"Click Crossmark\" data-track-label=\"link\" data-test=\"crossmark\"><img loading=\"lazy\" width=\"57\" height=\"81\" alt=\"Check for updates. Verify currency and authenticity via CrossMark\" src=\"data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>\"></a></p><div><h3 id=\"citeas\">Cite this article</h3><p>Shumailov, I., Shumaylov, Z., Zhao, Y. <i>et al.</i> AI models collapse when trained on recursively generated data.\n                    <i>Nature</i> <b>631</b>, 755–759 (2024). https://doi.org/10.1038/s41586-024-07566-y</p><p><a data-test=\"citation-link\" data-track=\"click\" data-track-action=\"download article citation\" data-track-label=\"link\" data-track-external=\"\" rel=\"nofollow\" href=\"https://citation-needed.springer.com/v2/references/10.1038/s41586-024-07566-y?format=refman&amp;flavour=citation\">Download citation</a></p><ul data-test=\"publication-history\"><li><p>Received<span>: </span><span><time datetime=\"2023-10-20\">20 October 2023</time></span></p></li><li><p>Accepted<span>: </span><span><time datetime=\"2024-05-14\">14 May 2024</time></span></p></li><li><p>Published<span>: </span><span><time datetime=\"2024-07-24\">24 July 2024</time></span></p></li><li><p>Issue Date<span>: </span><span><time datetime=\"2024-07-25\">25 July 2024</time></span></p></li><li><p><abbr title=\"Digital Object Identifier\">DOI</abbr><span>: </span><span>https://doi.org/10.1038/s41586-024-07566-y</span></p></li></ul></div></div></div>\n            </div></div>","textContent":"\n                    MainThe development of LLMs is very involved and requires large quantities of training data. Yet, although current LLMs2,4,5,6, including GPT-3, were trained on predominantly human-generated text, this may change. If the training data of most future models are also scraped from the web, then they will inevitably train on data produced by their predecessors. In this paper, we investigate what happens when text produced by, for example, a version of GPT forms most of the training dataset of following models. What happens to GPT generations GPT-{n} as n increases? We discover that indiscriminately learning from data produced by other models causes ‘model collapse’—a degenerative process whereby, over time, models forget the true underlying data distribution, even in the absence of a shift in the distribution over time. We give examples of model collapse for GMMs, VAEs and LLMs. We show that, over time, models start losing information about the true distribution, which first starts with tails disappearing, and learned behaviours converge over the generations to a point estimate with very small variance. Furthermore, we show that this process is inevitable, even for cases with almost ideal conditions for long-term learning, that is, no function estimation error. We also briefly mention two close concepts to model collapse from the existing literature: catastrophic forgetting arising in the framework of task-free continual learning7 and data poisoning8,9 maliciously leading to unintended behaviour. Neither is able to explain the phenomenon of model collapse fully, as the setting is fundamentally different, but they provide another perspective on the observed phenomenon and are discussed in more depth in the Supplementary Materials. Finally, we discuss the broader implications of model collapse. We note that access to the original data distribution is crucial: in learning tasks in which the tails of the underlying distribution matter, one needs access to real human-produced data. In other words, the use of LLMs at scale to publish content on the Internet will pollute the collection of data to train their successors: data about human interactions with LLMs will be increasingly valuable.What is model collapse?\n                Definition 2.1 (model collapse)\n                Model collapse is a degenerative process affecting generations of learned generative models, in which the data they generate end up polluting the training set of the next generation. Being trained on polluted data, they then mis-perceive reality. The process is depicted in Fig. 1a. We separate two special cases: early model collapse and late model collapse. In early model collapse, the model begins losing information about the tails of the distribution; in late model collapse, the model converges to a distribution that carries little resemblance to the original one, often with substantially reduced variance.\n              This process occurs owing to three specific sources of error compounding over generations and causing deviation from the original model:\n                \n                  Statistical approximation error. This is the primary type of error, which arises owing to the number of samples being finite, and disappears as the number of samples tends to infinity. This occurs because of a non-zero probability that information can get lost at every step of resampling.\n                \n                \n                  Functional expressivity error. This is a secondary type of error, arising owing to limited function approximator expressiveness. In particular, neural networks are only universal approximators as their size goes to infinity. As a result, a neural network can introduce non-zero likelihood outside the support of the original distribution or zero likelihood inside the support of the original distribution. A simple example of the expressivity error is if we tried fitting a mixture of two Gaussians with a single Gaussian. Even if we have perfect information about the data distribution (that is, infinite number of samples), model errors will be inevitable. However, in the absence of the other two types of error, this can only occur at the first generation.\n                \n                \n                  Functional approximation error. This is a secondary type of error, arising primarily from the limitations of learning procedures, for example, structural bias of stochastic gradient descent10,11 or choice of objective12. This error can be viewed as one arising in the limit of infinite data and perfect expressivity at each generation.\n                \n              Each of the above can cause model collapse to get worse or better. More approximation power can even be a double-edged sword—better expressiveness may counteract statistical noise, resulting in a good approximation of the true distribution, but it can equally compound the noise. More often than not, we get a cascading effect, in which individual inaccuracies combine to cause the overall error to grow. For example, overfitting the density model causes the model to extrapolate incorrectly and assigns high-density regions to low-density regions not covered in the training set support; these will then be sampled with arbitrary frequency. It is worth noting that other types of error exist. For example, computers have limited precision in practice. We now turn to mathematical intuition to explain how the above give rise to the errors observed, how different sources can compound and how we can quantify the average model divergence.Theoretical intuitionHere we provide a theoretical intuition for the phenomenon of model collapse. We argue that the process of model collapse is universal among generative models that recursively train on data generated by previous generations. We quantify the sources of errors discussed in the previous section by examining two mathematical models, which prove to be simple enough to provide analytical expressions for quantities of interest, but also portray the phenomenon of model collapse: a discrete distribution in the absence of functional expressivity and approximation errors, and a multidimensional Gaussian approximation, portraying joint functional expressivity and statistical errors. We further illustrate the impact of all three jointly for a more complex setting of density estimation in Hilbert spaces in the Supplementary Materials.The overall stochastic process we consider, which we call learning with generational data, is the following. The dataset at generation i is \\({{\\mathcal{D}}}_{i}\\), comprising independent and identically distributed random variables \\({X}_{j}^{i}\\) with distribution pi, j ∈ {1,…, Mi} denotes the size of the dataset. Going from generation i to generation i + 1, we aim to estimate the distribution of samples in \\({{\\mathcal{D}}}_{i}\\), with an approximation \\({p}_{{\\theta }_{i+1}}\\). This step is what we refer to as functional approximation, \\({p}_{{\\theta }_{i+1}}={{\\mathcal{F}}}_{\\theta }({p}_{i})\\). The dataset \\({{\\mathcal{D}}}_{i+1}\\) is then generated by sampling from \\({p}_{i+1}={\\alpha }_{i}{p}_{{\\theta }_{i+1}}+{\\beta }_{i}{p}_{i}+{\\gamma }_{i}{p}_{0}\\), with non-negative parameters αi, βi, γi summing to 1, that is, they represent proportions of data used from different generations. This corresponds to a mixing of data coming from the original distribution (γi), data used by the previous generation (βi) and data generated by the new model (αi). We refer to this as the sampling step. For the mathematical models to come, we consider αi = γi = 0, that is, data only from a single step are used, whereas numerical experiments are performed on more realistic choices of parameters.Discrete distributions with exact approximationIn this subsection, we consider a discrete probability distribution in absence of functional approximation and expressivity errors, that is, \\({\\mathcal{F}}(p)=p\\). In this case, model collapse arises only because of statistical errors from the sampling step. At first, the tails (low-probability events) begin to disappear as a result of the low probability of sampling them and, over time, support of the distribution shrinks. Denoting the sample size as M, if we consider state i with probability \\(q\\le \\frac{1}{M}\\), the expected number of samples with value i coming from those events will be less than 1. In practice, this would mean that we lose information about them. Considering more generally some state i with probability q, using standard conditional probability, we can show that the probability of losing information (that is, sampling no data at some generation) is equal to 1 − q, implying that the distribution must converge to a delta function positioned at some state, with the probability of ending up at a certain state equal to the probability of sampling said state from the original distribution.This can be shown directly by considering the process \\({{\\bf{X}}}^{i}\\to {\\mathcal{F}}\\,\\to \\)\\({p}_{i+1}\\to {{\\bf{X}}}^{i+1}\\) as a Markov chain, as Xi+1 only depends on Xi. Furthermore, if all the \\({X}_{j}^{i}\\) have the same value, then at the next generation, the approximated distribution will be exactly a delta function and therefore all of \\({X}_{j}^{i+1}\\) will also have the same value. This implies that the Markov chain contains at least one absorbing state and therefore, with probability 1, it will converge to one of the absorbing states. This is a well-known fact, of which a proof is provided in the Supplementary Materials. For this chain, the only absorbing states are those corresponding to delta functions. As a result, as we follow the progress of model collapse, we are guaranteed to end up in a constant state, having lost all the information of the original distribution when the chain is absorbed. This argument also works in general owing to floating-point representations being discrete, making the Markov chain over the parameters of the model discrete. Thus, as long as the model parameterization allows for delta functions, we will get to it, because—owing to sampling errors—the only possible absorbing states are delta functions. On the basis of the discussion above, we see how both early model collapse, in which only the low-probability events get cut off, and late stage model collapse, in which the process begins to collapse into a single mode, must arise in the case of discrete distributions with perfect functional approximation.Multidimensional GaussianFollowing the discussion about discrete distributions, we now present a more generic result, which can be shown in the Gaussian approximation setting, in which each generation is approximated using the unbiased estimates of the mean and the variance. A similar result holds more generally, which we detail in the Supplementary Materials.\n                  Theorem 3.1 (Gaussian model collapse)\n                  Assume the original data are sampled from distribution \\({{\\mathcal{D}}}_{0}\\) (not necessarily Gaussian), with non-zero sample variance. Assume Xn are fit recursively using the unbiased sample mean and variance estimators from the previous generation, \\({X}_{j}^{n}| {\\mu }_{n},{\\Sigma }_{n} \\sim {\\mathcal{N}}({\\mu }_{n},{\\Sigma }_{n})\\), with a fixed sample size. Then,$${\\mathbb{E}}[{{\\mathbb{W}}}_{2}^{2}({\\mathcal{N}}({\\mu }_{n},{\\Sigma }_{n}),{{\\mathcal{D}}}_{0})]\\to \\infty ;\\,{\\Sigma }_{n}\\,\\mathop{\\to }\\limits^{{\\rm{a}}.{\\rm{s}}.}\\,0\\,\\,{\\rm{a}}{\\rm{s}}\\,\\,n\\to \\infty ,$$in which \\({{\\mathbb{W}}}_{2}\\) denotes the Wasserstein-2 distance between the true distribution and its approximation at generation n.\n                In words, this implies that not only does the nth generation approximation diverge arbitrarily far from the original one but it also collapses to be zero variance as the number of generations increases, with probability 1. The results are very analogous to that seen in the discrete case, with this theorem illustrating the effect of late stage model collapse, in which the process begins to collapse to be zero variance. The early stage model collapse can also be seen and the interested reader is referred to the Supplementary Materials for a more in-depth discussion.Model collapse in language modelsIn this section, we evaluate the effect of model collapse on language models. We cover more interpretable machine learning models—VAEs and GMMs—in the Supplementary Materials. Code is publically available in ref. 13.Model collapse is universal across various families of machine learning models. Yet, if small models such as GMMs and VAEs are normally trained from scratch, LLMs are different. They are so expensive to retrain from scratch that they are typically initialized with pre-trained models such as BERT4, RoBERTa5 or GPT-2 (ref. 2), which are trained on large text corpora. They are then fine-tuned to various downstream tasks14.Here we explore what happens with language models when they are sequentially fine-tuned with data generated by other models. We can easily replicate all experiments covered in this paper with larger language models in non-fine-tuning settings to demonstrate model collapse. Given that training a single moderately large model produces twice the American lifetime’s worth of CO2 (ref. 15), we opted to not run such an experiment and instead focus on a more realistic setting for a proof of concept. Note that even the language experiments described in this paper took weeks to run. We evaluate the most common setting of training a language model—a fine-tuning setting for which each of the training cycles starts from a pre-trained model with recent data. The data here come from another fine-tuned pre-trained model. Because training is restricted to produce models that are close to the original pre-trained model, and data points generated by the models will generally produce very small gradients, the expectation here may be that the model should only change moderately after fine-tuning. We fine-tune the OPT-125m causal language model made available by Meta through Hugging Face6.We fine-tune it on the wikitext2 dataset16. For data generation from the trained models, we use a five-way beam search. We block training sequences to be 64 tokens long; then, for each token sequence in the training set, we ask the model to predict the next 64 tokens. We go through all of the original training dataset and produce an artificial dataset of the same size. Because we go through all of the original dataset and predict all of the blocks, if the model had 0 error, it would produce the original wikitext2 dataset. Training for each generation starts with generation from the original training data. Each experiment is run five times and the results are shown as five separate runs with different randomness seeds. The original model fine-tuned with real wikitext2 data obtains 34 mean perplexity, from the zero-shot baseline of 115, that is, it successfully learns the task. Finally, to be as realistic as possible, we use the best-performing model on the original task, evaluated using the original wikitext2 validation set, as the base model for the subsequent generations, meaning that—in practice—observed model collapse can be even more pronounced. Here we consider two different settings:\n                \n                  Five epochs, no original training data. Here the model is trained for five epochs starting on the original dataset but with no original data retained for subsequent runs. The overall original task performance is presented in Fig. 1b. We find that training with generated data allows us to adapt to the underlying task, losing some performance, from 20 to 28 perplexity points.\n                \n                \n                  Ten epochs, 10% of original training data preserved. Here the model is trained for ten epochs on the original dataset and with every new generation of training, a random 10% of the original data points is sampled. The overall original task performance is presented in Fig. 1c. We find that preservation of the original data allows for better model fine-tuning and leads to only minor degradation of performance.\n                \n              Both training regimes lead to degraded performance in our models, yet we do find that learning with generated data is possible and models can successfully learn (some of) the underlying task. In particular, from Fig. 1 and their 3D versions in the Supplementary Materials, we see that model collapse occurs, as the density of samples with low perplexity begins to accumulate over the generations. This in turn makes it likely that, over the generations, the sampled data will similarly collapse to a delta function.Fig. 1: The high-level description of the feedback mechanism in the learning process.a, Model collapse refers to a degenerative learning process in which models start forgetting improbable events over time, as the model becomes poisoned with its own projection of reality. Here data are assumed to be human-curated and start off clean; then model 0 is trained and data are sampled from it; at step n, data are added to the overall data from step n − 1 and this combination is used to train model n. Data obtained with Monte Carlo sampling should ideally be statistically close to the original, provided that fitting and sampling procedures are perfect. This process depicts what happens in real life with the Internet: model-generated data become pervasive. b,c, Performance of OPT-125m models of different generations evaluated using the original wikitext2 test dataset. Shown on the left are the histograms of perplexities of each individual data training sequence produced by different generations as evaluated by the very first model trained with the real data. Over the generations, models tend to produce samples that the original model trained with real data is more likely to produce. At the same time, a much longer tail appears for later generations. Later generations start producing samples that would never be produced by the original model, that is, they start misperceiving reality based on errors introduced by their ancestors. The same plots are shown in 3D in the Supplementary Materials. On the right, average perplexity and its standard deviation are shown for each independent run. The x axis refers to the generation of the model. ‘Real’ refers to the ‘model 0’ trained on the original wikitext2 dataset; model 1 was trained on the data produced by model 0, model 2 was trained on data produced by model 1 and so on, with all generated datasets equal in size. We find that models trained on generated data are able to learn some of the original task, but with errors, as seen from the increase in perplexity.Full size imageIt is important to note here that the observed behaviour is in line with the general intuition established in the section ‘Theoretical intuition’. To be precise, in all experiments, generational learning is only performed on a finite (usually small) number of generations, whereas claims of the section ‘Theoretical intuition’ are mostly presented in the limit of generations going to infinity. However, as seen from experiments on VAEs and GMMs in the Supplementary Materials, convergence to delta functions and specific rates of such convergence are highly related to the specifics of the problem considered, and complete collapse may or may not occur, even after a small number of steps. This is further illustrated theoretically in the Supplementary Materials, in which potentially notable divergence from the original model can occur even after a few generations.Figure 1b,c on the left shows histograms of individual data-point perplexities generated by the models of different generations as is evaluated by the first model developed with real wikitext2 training data. Here, over the generations, models tend to produce more sequences that the original model would produce with the higher likelihood. The observed effect is similar to that described for VAEs and GMMs in the Supplementary Materials, in which—over the generations—models started to produce samples that would be produced with higher probabilities by the original model. At the same time, we discover that generated data have much longer tails, suggesting that some of the data would never be produced by the original model—these are the errors that accumulate because of the learning with generational data.\n                Example 1\n                Example of text outputs of an OPT-125m model affected by model collapse—models degrade over generations, for which each new generation is trained on data produced by the previous generation.\n                  \n                    Input: some started before 1360 — was typically accomplished by a master mason and a small team of itinerant masons, supplemented by local parish labourers, according to Poyntz Wright. But other authors reject this model, suggesting instead that leading architects designed the parish church towers based on early examples of Perpendicular.\n                  \n                  \n                    Outputs:\n                  \n                  \n                    Gen 0: Revival architecture such as St. John’s Cathedral in London. The earliest surviving example of Perpendicular Revival architecture is found in the 18th @-@ century Church of Our Lady of Guernsey, which dates from the late 19th century. There are two types of perpendicular churches : those.\n                  \n                  \n                    Gen 1: architecture such as St. Peter’s Basilica in Rome or St. Peter’s Basilica in Buenos Aires. There is no evidence that any of these buildings were built during the reign of Pope Innocent III, but it is possible that they may have been built during the reign of his successor, Pope Innocent.\n                  \n                  \n                    Gen 5: ism, which had been translated into more than 100 languages including English, French, German, Italian, Spanish, Portuguese, Dutch, Swedish, Norwegian, Polish, Hungarian, Slovak, Lithuanian, Estonian, Finnish, Romanian, Bulgarian, Turkish, Croatian, Serbian, Ukrainian, Russian, Kazakh, Kyrgyz.\n                  \n                  \n                    Gen 9: architecture. In addition to being home to some of the world’s largest populations of black @-@ tailed jackrabbits, white @-@ tailed jackrabbits, blue @-@ tailed jackrabbits, red @-@ tailed jackrabbits, yellow @-.\n                  \n                \n              Ablation: RepetitionsWe find that data generated by language models in our experiments end up containing a large number of repeating phrases, as in Example 1. The repeating problem has been observed in nearly all text-generation models17,18 and, to rule this out as the cause of model collapse, we further provide numerical experiments when models are explicitly encouraged to produce non-repeating sequences with a repeating penalty of 2.0. We find that this causes the models to produce lower score continuations to avoid using repeats, which—as a result—causes the consequent models to perform even worse. Model perplexities shift across the generations towards more probable token sequences, as measured using the model trained on the original real data distribution. Further illustrations are provided in the Supplementary Materials. In particular, enforcing this for the LLM experiments causes the perplexity to double compared with the original. Models remain as susceptible to model collapse, if not more.The described process demonstrates that fine-tuning of language models does not curb the effects of model collapse and models that are being fine-tuned are also vulnerable. We find that, over the generations, models tend to produce more probable sequences from the original data and start introducing their own improbable sequences, that is, errors.DiscussionWe now discuss the implications of model collapse on the underlying learning dynamics of LLMs. Long-term poisoning attacks on language models are not new. For example, we saw the creation of click, content and troll farms, a form of human ‘language models’, whose job is to misguide social networks and search algorithms. The negative effect that these poisoning attacks had on search results led to changes in search algorithms. For example, Google downgraded farmed articles19, putting more emphasis on content produced by trustworthy sources, such as education domains, whereas DuckDuckGo removed them altogether20. What is different with the arrival of LLMs is the scale at which such poisoning can happen once it is automated. Preserving the ability of LLMs to model low-probability events is essential to the fairness of their predictions: such events are often relevant to marginalized groups. Low-probability events are also vital to understand complex systems21.Our evaluation suggests a ‘first mover advantage’ when it comes to training models such as LLMs. In our work, we demonstrate that training on samples from another generative model can induce a distribution shift, which—over time—causes model collapse. This in turn causes the model to mis-perceive the underlying learning task. To sustain learning over a long period of time, we need to make sure that access to the original data source is preserved and that further data not generated by LLMs remain available over time. The need to distinguish data generated by LLMs from other data raises questions about the provenance of content that is crawled from the Internet: it is unclear how content generated by LLMs can be tracked at scale. One option is community-wide coordination to ensure that different parties involved in LLM creation and deployment share the information needed to resolve questions of provenance. Otherwise, it may become increasingly difficult to train newer versions of LLMs without access to data that were crawled from the Internet before the mass adoption of the technology or direct access to data generated by humans at scale.\n                \n                Data availabilityData generation code for GMM experiments is available in ref. 13. Data used for VAE experiments are available in ref. 22. Data used for LLM experiments are available in ref. 16.Code availabilityCode for all experiments is publically available in ref. 13.ReferencesRadford, A. et al. Language models are unsupervised multitask learners. OpenAI blog 1, 9 (2019).\n                    Google Scholar \n                Brown, T. et al. Language models are few-shot learners. Adv. Neural Inf. Process. Syst. 33, 1877–1901 (2020).\n                    Google Scholar \n                OpenAI. GPT-4 Technical Report. https://cdn.openai.com/papers/gpt-4.pdf (2023).Devlin, J., Chang, M.-W., Lee, K. & Toutanova, K. in Proc. 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers) (eds Burstein, J., Doran, C. & Solorio, T.) 4171–4186 (Association for Computational Linguistics, 2019).Liu, Y. et al. RoBERTa: a Robustly Optimized BERT Pretraining Approach. Preprint at https://arxiv.org/abs/1907.11692 (2019).Zhang, S. et al. Opt: open pre-trained transformer language models. Preprint at https://arxiv.org/abs/2205.01068 (2022).Aljundi, R., Kelchtermans, K. & Tuytelaars, T. Task-free continual learning. in: Proc. 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 11254–11263 (IEEE, 2019).Carlini, N. & Terzis, A. in Proc. Tenth International Conference on Learning Representations (ICLR, 2022).Carlini, N. et al. in Proc. 2024 IEEE Symposium on Security and Privacy (SP) 179 (IEEE, 2024).Mousavi-Hosseini, A., Park, S., Girotti, M., Mitliagkas, I. & Erdogdu, M. A. in Proc. Eleventh International Conference on Learning Representations (ICLR, 2023).Soudry, D., Hoffer, E., Nacson, M. S., Gunasekar, S. & Srebro, N. The implicit bias of gradient descent on separable data. J. Mach. Learn. Res. 19, 1–57 (2018).MathSciNet \n    \n                    Google Scholar \n                Gu, Y., Dong, L., Wei, F. & Huang, M. in Proc. Twelfth International Conference on Learning Representations (ICLR, 2024).Shumailov, I. & Shumaylov, Z. Public code for Model Collapse (0.1). Zenodo https://doi.org/10.5281/zenodo.10866595 (2024).Bommasani, R. et al. On the opportunities and risks of foundation models. Preprint at https://arxiv.org/abs/2108.07258 (2022).Strubell, E., Ganesh, A. & McCallum, A. in Proc. 57th Annual Meeting of the Association for Computational Linguistics (eds Korhonen, A., Traum, D. & Màrquez, L.) 3645–3650 (Association for Computational Linguistics, 2019).Merity, S., Xiong, C., Bradbury, J. & Socher, R. in Proc. 5th International Conference on Learning Representations (ICLR, 2017).Keskar, N. S., McCann, B., Varshney, L. R., Xiong, C. & Socher, R. CTRL: a conditional transformer language model for controllable generation. Preprint at https://arxiv.org/abs/1909.05858 (2019).Shumailov, I. et al. in Proc. 2021 IEEE European Symposium on Security and Privacy (EuroS&P) 212–231 (IEEE, 2021).Google. Finding more high-quality sites in search. Google https://googleblog.blogspot.com/2011/02/finding-more-high-quality-sites-in.html (2011).Mims, C. The search engine backlash against ‘content mills’. MIT Technology Review https://www.technologyreview.com/2010/07/26/26327/the-search-engine-backlash-against-content-mills/ (2010).Taleb, N. N. Black swans and the domains of statistics. Am. Stat. 61, 198–200 (2007).Article \n    MathSciNet \n    \n                    Google Scholar \n                LeCun, Y., Cortes, C. & Burges, C. J. C. The MNIST database of handwritten digits. http://yann.lecun.com/exdb/mnist/ (1998).Download referencesAcknowledgementsThis paper is dedicated to the memory of Professor Ross J. Anderson, our colleague and friend, who contributed much to this and other works we have produced over the years. We thank A. Thudi, D. Glukhov, P. Zaika, and D. Barak for useful discussions and feedback.Author informationAuthor notesThese authors contributed equally: Ilia Shumailov, Zakhar ShumaylovDeceased: Ross AndersonAuthors and AffiliationsOATML, Department of Computer Science, University of Oxford, Oxford, UKIlia Shumailov & Yarin GalDepartment of Applied Mathematics and Theoretical Physics, University of Cambridge, Cambridge, UKZakhar ShumaylovDepartment of Electrical and Electronic Engineering, Imperial College London, London, UKYiren ZhaoUniversity of Toronto, Toronto, Ontario, CanadaNicolas PapernotVector Institute, Toronto, Ontario, CanadaNicolas PapernotDepartment of Computer Science and Technology, University of Cambridge, Cambridge, UKRoss AndersonSchool of Informatics, University of Edinburgh, Edinburgh, UKRoss AndersonAuthorsIlia ShumailovYou can also search for this author in\n                        PubMed Google ScholarZakhar ShumaylovYou can also search for this author in\n                        PubMed Google ScholarYiren ZhaoYou can also search for this author in\n                        PubMed Google ScholarNicolas PapernotYou can also search for this author in\n                        PubMed Google ScholarRoss AndersonYou can also search for this author in\n                        PubMed Google ScholarYarin GalYou can also search for this author in\n                        PubMed Google ScholarContributionsI.S. and Z.S. proposed and developed the idea, led the research and mathematical modelling and developed the GMM and VAE experiments. I.S. and Y.Z. developed the language-model experiments. N.P., Y.G. and R.A. supervised and guided the project. All authors contributed to writing of the manuscript. Y.G. is supported by a Turing AI Fellowship financed by the UK government’s Office for Artificial Intelligence, through UK Research and Innovation (grant reference EP/V030302/1) and delivered by the Alan Turing Institute.Corresponding authorsCorrespondence to\n                Ilia Shumailov, Zakhar Shumaylov or Yarin Gal.Ethics declarations\n              \n                Competing interests\n                The authors declare no competing interests.\n              \n            Peer review\n              \n              \n                Peer review information\n                Nature thanks the anonymous reviewers for their contribution to the peer review of this work.\n              \n            Additional informationPublisher’s note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.Supplementary informationRights and permissions\n                Open Access  This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit http://creativecommons.org/licenses/by/4.0/.\n              Reprints and permissionsAbout this articleCite this articleShumailov, I., Shumaylov, Z., Zhao, Y. et al. AI models collapse when trained on recursively generated data.\n                    Nature 631, 755–759 (2024). https://doi.org/10.1038/s41586-024-07566-yDownload citationReceived: 20 October 2023Accepted: 14 May 2024Published: 24 July 2024Issue Date: 25 July 2024DOI: https://doi.org/10.1038/s41586-024-07566-y\n            ","length":33876,"excerpt":"Stable diffusion revolutionized image creation from descriptive text. GPT-2 (ref. 1), GPT-3(.5) (ref. 2) and GPT-4 (ref. 3) demonstrated high performance across a variety of language tasks. ChatGPT introduced such language models to the public. It is now clear that generative artificial intelligence (AI) such as large language models (LLMs) is here to stay and will substantially change the ecosystem of online text and images. Here we consider what may happen to GPT-{n} once LLMs contribute much of the text found online. We find that indiscriminate use of model-generated content in training causes irreversible defects in the resulting models, in which tails of the original content distribution disappear. We refer to this effect as ‘model collapse’ and show that it can occur in LLMs as well as in variational autoencoders (VAEs) and Gaussian mixture models (GMMs). We build theoretical intuition behind the phenomenon and portray its ubiquity among all learned generative models. We demonstrate that it must be taken seriously if we are to sustain the benefits of training from large-scale data scraped from the web. Indeed, the value of data collected about genuine human interactions with systems will be increasingly valuable in the presence of LLM-generated content in data crawled from the Internet. &nbsp;Analysis shows that indiscriminately training generative artificial intelligence on real and generated content, usually done by scraping data from&nbsp;the Internet, can lead to a collapse in the ability of the models to generate diverse high-quality output.","byline":"Gal, Yarin","dir":null,"siteName":"Nature","lang":"en"},"finalizedMeta":{"title":"AI models collapse when trained on recursively generated data - Nature","description":"&nbsp;Analysis shows that indiscriminately training generative artificial intelligence on real and generated content, usually done by scraping data from&nbsp;the Internet, can lead to a collapse in the ability of the models to generate diverse high-quality output.","author":false,"creator":"","publisher":false,"date":"2024-10-09T18:55:14.863Z","topics":[]},"jsonLd":{"@type":"WebPage","headline":false,"description":false,"image":[],"mainEntityOfPage":{"@type":false,"@id":false},"datePublished":false,"dateModified":false,"isAccessibleForFree":false,"isPartOf":{"@type":[],"name":false,"productID":false},"discussionUrl":false,"license":false,"author":{"@type":false,"name":false,"description":false,"sameAs":false,"image":{"@type":false,"url":false},"givenName":false,"familyName":false,"alternateName":false,"publishingPrinciples":false},"publisher":{"@type":false,"name":false,"description":false,"sameAs":false,"logo":{"@type":false,"url":false},"publishingPrinciples":false},"editor":{"@type":false,"name":false,"description":false,"sameAs":false,"image":{"@type":false,"url":false},"givenName":false,"familyName":false,"alternateName":false,"publishingPrinciples":false},"mainEntity":{"headline":"AI models collapse when trained on recursively generated data","description":"Stable diffusion revolutionized image creation from descriptive text. GPT-2 (ref. 1), GPT-3(.5) (ref. 2) and GPT-4 (ref. 3) demonstrated high performance across a variety of language tasks. ChatGPT introduced such language models to the public. It is now clear that generative artificial intelligence (AI) such as large language models (LLMs) is here to stay and will substantially change the ecosystem of online text and images. Here we consider what may happen to GPT-{n} once LLMs contribute much of the text found online. We find that indiscriminate use of model-generated content in training causes irreversible defects in the resulting models, in which tails of the original content distribution disappear. We refer to this effect as ‘model collapse’ and show that it can occur in LLMs as well as in variational autoencoders (VAEs) and Gaussian mixture models (GMMs). We build theoretical intuition behind the phenomenon and portray its ubiquity among all learned generative models. We demonstrate that it must be taken seriously if we are to sustain the benefits of training from large-scale data scraped from the web. Indeed, the value of data collected about genuine human interactions with systems will be increasingly valuable in the presence of LLM-generated content in data crawled from the Internet.  Analysis shows that indiscriminately training generative artificial intelligence on real and generated content, usually done by scraping data from the Internet, can lead to a collapse in the ability of the models to generate diverse high-quality output.","datePublished":"2024-07-24T00:00:00Z","dateModified":"2024-07-24T00:00:00Z","pageStart":"755","pageEnd":"759","license":"http://creativecommons.org/licenses/by/4.0/","sameAs":"https://doi.org/10.1038/s41586-024-07566-y","keywords":["Computational science","Computer science","Science","Humanities and Social Sciences","multidisciplinary"],"image":["https://media.springernature.com/lw1200/springer-static/image/art%3A10.1038%2Fs41586-024-07566-y/MediaObjects/41586_2024_7566_Fig1_HTML.png"],"isPartOf":{"name":"Nature","issn":["1476-4687","0028-0836"],"volumeNumber":"631","@type":["Periodical","PublicationVolume"]},"publisher":{"name":"Nature Publishing Group UK","logo":{"url":"https://www.springernature.com/app-sn/public/images/logo-springernature.png","@type":"ImageObject"},"@type":"Organization"},"author":[{"name":"Ilia Shumailov","affiliation":[{"name":"University of Oxford","address":{"name":"OATML, Department of Computer Science, University of Oxford, Oxford, UK","@type":"PostalAddress"},"@type":"Organization"}],"email":"ilia.shumailov@chch.ox.ac.uk","@type":"Person"},{"name":"Zakhar Shumaylov","affiliation":[{"name":"University of Cambridge","address":{"name":"Department of Applied Mathematics and Theoretical Physics, University of Cambridge, Cambridge, UK","@type":"PostalAddress"},"@type":"Organization"}],"email":"zs334@cam.ac.uk","@type":"Person"},{"name":"Yiren Zhao","url":"http://orcid.org/0000-0002-3727-7463","affiliation":[{"name":"Imperial College London","address":{"name":"Department of Electrical and Electronic Engineering, Imperial College London, London, UK","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Nicolas Papernot","affiliation":[{"name":"University of Toronto","address":{"name":"University of Toronto, Toronto, Canada","@type":"PostalAddress"},"@type":"Organization"},{"name":"Vector Institute","address":{"name":"Vector Institute, Toronto, Canada","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Ross Anderson","url":"http://orcid.org/0000-0001-8697-5682","affiliation":[{"name":"University of Cambridge","address":{"name":"Department of Computer Science and Technology, University of Cambridge, Cambridge, UK","@type":"PostalAddress"},"@type":"Organization"},{"name":"University of Edinburgh","address":{"name":"School of Informatics, University of Edinburgh, Edinburgh, UK","@type":"PostalAddress"},"@type":"Organization"}],"@type":"Person"},{"name":"Yarin Gal","url":"http://orcid.org/0000-0002-2733-2078","affiliation":[{"name":"University of Oxford","address":{"name":"OATML, Department of Computer Science, University of Oxford, Oxford, UK","@type":"PostalAddress"},"@type":"Organization"}],"email":"yarin@cs.ox.ac.uk","@type":"Person"}],"isAccessibleForFree":true,"@type":"ScholarlyArticle"},"@context":"https://schema.org"},"twitterObj":false,"status":200,"metadata":{"author":false,"title":"AI models collapse when trained on recursively generated data | Nature","description":"Stable diffusion revolutionized image creation from descriptive text. GPT-2 (ref. 1), GPT-3(.5) (ref. 2) and GPT-4 (ref. 3) demonstrated high performance across a variety of language tasks. ChatGPT introduced such language models to the public. It is now clear that generative artificial intelligence (AI) such as large language models (LLMs) is here to stay and will substantially change the ecosystem of online text and images. Here we consider what may happen to GPT-{n} once LLMs contribute much of the text found online. We find that indiscriminate use of model-generated content in training causes irreversible defects in the resulting models, in which tails of the original content distribution disappear. We refer to this effect as ‘model collapse’ and show that it can occur in LLMs as well as in variational autoencoders (VAEs) and Gaussian mixture models (GMMs). We build theoretical intuition behind the phenomenon and portray its ubiquity among all learned generative models. We demonstrate that it must be taken seriously if we are to sustain the benefits of training from large-scale data scraped from the web. Indeed, the value of data collected about genuine human interactions with systems will be increasingly valuable in the presence of LLM-generated content in data crawled from the Internet. &nbsp;Analysis shows that indiscriminately training generative artificial intelligence on real and generated content, usually done by scraping data from&nbsp;the Internet, can lead to a collapse in the ability of the models to generate diverse high-quality output.","canonical":"https://www.nature.com/articles/s41586-024-07566-y","keywords":[],"image":"//pubads.g.doubleclick.net/gampad/ad?iu=/285/nature.com/article&sz=728x90&c=1638430036&t=pos%3Dtop%26type%3Darticle%26artid%3Ds41586-024-07566-y%26doi%3D10.1038/s41586-024-07566-y%26techmeta%3D119,123,129,141%26subjmeta%3D1042,117,639,705%26kwrd%3DComputational+science,Computer+science","firstParagraph":"Thank you for visiting nature.com. You are using a browser version with limited support for CSS. To obtain\n            the best experience, we recommend you use a more up to date browser (or turn off compatibility mode in\n            Internet Explorer). In the meantime, to ensure continued support, we are displaying the site without styles\n            and JavaScript."},"dublinCore":{},"opengraph":{"title":"AI models collapse when trained on recursively generated data - Nature","description":"&nbsp;Analysis shows that indiscriminately training generative artificial intelligence on real and generated content, usually done by scraping data from&nbsp;the Internet, can lead to a collapse in the ability of the models to generate diverse high-quality output.","url":"https://www.nature.com/articles/s41586-024-07566-y","site_name":"Nature","locale":false,"type":"article","typeObject":{"published_time":false,"modified_time":false,"author":false,"publisher":false,"section":false,"tag":[]},"image":"https://media.springernature.com/m685/springer-static/image/art%3A10.1038%2Fs41586-024-07566-y/MediaObjects/41586_2024_7566_Fig1_HTML.png"},"twitter":{"site":"@nature","description":"Nature - Analysis shows that indiscriminately training generative artificial intelligence on real and generated content, usually done by scraping data from the Internet, can lead to a collapse in...","card":"summary_large_image","creator":false,"title":"AI models collapse when trained on recursively generated data","image":"https://media.springernature.com/full/springer-static/image/art%3A10.1038%2Fs41586-024-07566-y/MediaObjects/41586_2024_7566_Fig1_HTML.png","image:alt":"Content cover image"},"archivedData":{"link":false,"wayback":false}}}