{"initialLink":"https://arstechnica.com/tech-policy/2024/06/ai-trained-on-photos-from-kids-entire-childhood-without-their-consent/","sanitizedLink":"https://arstechnica.com/tech-policy/2024/06/ai-trained-on-photos-from-kids-entire-childhood-without-their-consent/","finalLink":"https://arstechnica.com/tech-policy/2024/06/ai-trained-on-photos-from-kids-entire-childhood-without-their-consent/","htmlEmbed":"<script>window.contexterSetup=window.contexterSetup||function(){window.contexterSetupComplete=!0;class ContexterLink extends HTMLAnchorElement{constructor(){super()}connectedCallback(){this.setAttribute(\"target\",\"_blank\")}}customElements.define(\"contexter-link\",ContexterLink,{extends:\"a\"}),customElements.define(\"contexter-inner\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__inner\"}}),customElements.define(\"contexter-thumbnail\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__thumbnail\"}}),customElements.define(\"contexter-byline\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__byline\"}}),customElements.define(\"contexter-keywordset\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__keywordset\"}}),customElements.define(\"contexter-linkset\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__linkset\"}}),customElements.define(\"contexter-meta\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__meta\"}}),customElements.define(\"contexter-summary\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"p-summary entry-summary\"}}),customElements.define(\"contexter-box-head\",class extends HTMLElement{constructor(){super()}connectedCallback(){this.className=\"contexter-box__head\"}}),customElements.define(\"contexter-box-inner\",class extends HTMLElement{constructor(){super()}connectedCallback(){}});class ContexterBox extends HTMLElement{constructor(){super(),this.first=!0,this.shadow=this.attachShadow({mode:\"open\"})}connectedCallback(){if(this.first){this.first=!1;var style=document.createElement(\"style\"),lightDomStyle=(style.innerHTML=`:host {--background: #f5f6f7;--border: darkblue;--blue: #0000ee;--font-color: black;--inner-border: black;font-family: Franklin,Arial,Helvetica,sans-serif;font-size: 14px;background: var(--background);width: 600px;color: var(--font-color);min-height: 90px;display: block;padding: 8px;border: 1px solid var(--border);cursor: pointer;box-sizing: border-box;margin: 6px;contain: content;margin: 6px auto;}// can only select top-level nodes with slotted::slotted(*) {max-width: 100%;display:block;}::slotted([slot=thumbnail]) {max-width: 100%;display:block;}::slotted([slot=header]) {width: 100%;font-size: 1.25rem;font-weight: bold;display:block;margin-bottom: 6px;}::slotted([slot=author]) {max-width: 50%;font-size: 12px;display:inline-block;float: left;}::slotted([slot=time]) {max-width: 50%;font-size: 12px;display:inline-block;float: right;}::slotted([slot=summary]) {width: 100%;margin-top: 6px;padding: 10px 2px;border-top: 1px solid var(--inner-border);font-size: 15px;display:inline-block;margin-bottom: 6px;}contexter-meta {height: auto;margin-bottom: 4px;width: 100%;display: grid;position: relative;min-height: 16px;grid-template-columns: repeat(2, 1fr);}::slotted([slot=keywords]) {width: 80%;padding: 2px 4px;border-top: 1px solid var(--inner-border);font-size: 11px;display: block;float: right;font-style: italic;text-align: right;grid-column: 2/2;grid-row: 1;align-self: end;justify-self: end;}::slotted([slot=keywords]):empty {border-top: 0px solid var(--inner-border);}::slotted([slot=archive-link]) {font-size: 1em;display: inline;}::slotted([slot=archive-link])::after {content: \"|\";display: inline;color: var(--font-color);text-decoration: none;margin: 0 .5em;}::slotted([slot=read-link]) {font-size: 1em;display: inline;}contexter-linkset {width: 80%;padding: 2px 4px;font-size: 13px;float: left;font-weight: bold;grid-row: 1;grid-column: 1/2;align-self: end;justify-self: start;}/* Extra small devices (phones, 600px and down) */@media only screen and (max-width: 600px) {:host {width: 310px;}}/* Small devices (portrait tablets and large phones, 600px and up) */@media only screen and (min-width: 600px) {...}/* Medium devices (landscape tablets, 768px and up) */@media only screen and (min-width: 768px) {...}/* Large devices (laptops/desktops, 992px and up) */@media only screen and (min-width: 992px) {...}/* Extra large devices (large laptops and desktops, 1200px and up) */@media only screen and (min-width: 1200px) {...}@media (prefers-color-scheme: dark){:host {--background: #354150;--border: #1f2b37;--blue: #55b0ff;--font-color: #ffffff;--inner-border: #787a7c;background: var(--background);border: 1px solid var(--border)}}`,document.createElement(\"style\"));lightDomStyle.innerHTML=`contexter-box {contain: content;}contexter-box .read-link {font-weight: bold;}contexter-box a {color: #0000ee;}contexter-box img {width: 100%;border: 0;padding: 0;margin: 0;}/* Extra small devices (phones, 600px and down) */@media only screen and (max-width: 600px) {...}/* Small devices (portrait tablets and large phones, 600px and up) */@media only screen and (min-width: 600px) {...}/* Medium devices (landscape tablets, 768px and up) */@media only screen and (min-width: 768px) {...}/* Large devices (laptops/desktops, 992px and up) */@media only screen and (min-width: 992px) {...}/* Extra large devices (large laptops and desktops, 1200px and up) */@media only screen and (min-width: 1200px) {...}@media (prefers-color-scheme: dark){contexter-box a {color: #55b0ff;}}`,this.appendChild(lightDomStyle),this.shadow.appendChild(style);const innerContainer=document.createElement(\"contexter-box-inner\"),innerSlotThumbnail=(this.shadow.appendChild(innerContainer),document.createElement(\"slot\")),innerSlotHeader=(innerSlotThumbnail.name=\"thumbnail\",innerContainer.appendChild(innerSlotThumbnail),document.createElement(\"slot\")),innerSlotAuthor=(innerSlotHeader.name=\"header\",innerContainer.appendChild(innerSlotHeader),document.createElement(\"slot\")),innerSlotTime=(innerSlotAuthor.name=\"author\",innerContainer.appendChild(innerSlotAuthor),document.createElement(\"slot\")),innerSlotSummary=(innerSlotTime.name=\"time\",innerContainer.appendChild(innerSlotTime),document.createElement(\"slot\")),metaContainer=(innerSlotSummary.name=\"summary\",innerContainer.appendChild(innerSlotSummary),document.createElement(\"contexter-meta\")),innerSlotInfo=(innerContainer.appendChild(metaContainer),document.createElement(\"slot\")),linkContainer=(innerSlotInfo.name=\"keywords\",metaContainer.appendChild(innerSlotInfo),document.createElement(\"contexter-linkset\")),innerSlotArchiveLink=(metaContainer.appendChild(linkContainer),document.createElement(\"slot\")),innerSlotReadLink=(innerSlotArchiveLink.name=\"archive-link\",linkContainer.appendChild(innerSlotArchiveLink),document.createElement(\"slot\"));innerSlotReadLink.name=\"read-link\",linkContainer.appendChild(innerSlotReadLink),this.className=\"contexter-box\",this.onclick=e=>{if(!e.target.className.includes(\"read-link\")&&!e.target.className.includes(\"title-link\")){const mainLinks=this.querySelectorAll(\"a.main-link\");mainLinks[0].click()}}}}}customElements.define(\"contexter-box\",ContexterBox)},window.contexterSetupComplete||window.contexterSetup();</script><contexter-box class=\"link-card h-entry hentry\" itemscope=\"\" itemtype=\"https://schema.org/CreativeWork\"><contexter-thumbnail class=\"thumbnail\" slot=\"thumbnail\"></contexter-thumbnail><contexter-box-head slot=\"header\" class=\"p-name entry-title\" itemprop=\"headline\"><contexter-box-head slot=\"header\" class=\"p-name entry-title\" itemprop=\"headline\"><a is=\"contexter-link\" href=\"https://arstechnica.com/tech-policy/2024/06/ai-trained-on-photos-from-kids-entire-childhood-without-their-consent/\" itemprop=\"url\">AI trained on photos from kids’ entire childhood without their consent</a></contexter-box-head></contexter-box-head><contexter-byline class=\"p-author author\" slot=\"author\"><span class=\"p-name byline\" rel=\"author\" itemprop=\"author\">@ashleynbelanger</span></contexter-byline><time class=\"dt-published published\" slot=\"time\" itemprop=\"datePublished\" datetime=\"2024-06-12T13:15:37.000Z\">6/12/2024</time><contexter-summary class=\"p-summary entry-summary\" itemprop=\"abstract\" slot=\"summary\"><p>Kids \"easily traceable\" from photos used to train AI models, advocates warn.</p></contexter-summary><contexter-keywordset itemprop=\"keywords\" slot=\"keywords\"></contexter-keywordset><a href=\"https://web.archive.org/web/20240702203906/https://arstechnica.com/tech-policy/2024/06/ai-trained-on-photos-from-kids-entire-childhood-without-their-consent/\" is=\"contexter-link\" target=\"_blank\" rel=\"timemap\" class=\"read-link archive-link\" itemprop=\"archivedAt\" slot=\"archive-link\">Archived</a><a is=\"contexter-link\" href=\"https://arstechnica.com/tech-policy/2024/06/ai-trained-on-photos-from-kids-entire-childhood-without-their-consent/\" class=\"read-link main-link\" itemprop=\"sameAs\" slot=\"read-link\">Read</a></contexter-box>","linkId":"94161f5949bcb80ff30a2a75bce7225a49530009","data":{"originalLink":"https://arstechnica.com/tech-policy/2024/06/ai-trained-on-photos-from-kids-entire-childhood-without-their-consent/","sanitizedLink":"https://arstechnica.com/tech-policy/2024/06/ai-trained-on-photos-from-kids-entire-childhood-without-their-consent/","canonical":"https://arstechnica.com/tech-policy/2024/06/ai-trained-on-photos-from-kids-entire-childhood-without-their-consent/","htmlText":"<!DOCTYPE html>\n<html lang=\"en-us\">\n\n<head>\n  <title>AI trained on photos from kids’ entire childhood without their consent | Ars Technica</title>\n<script type=\"text/javascript\">\n  ars = {\"ASSETS\":\"https:\\/\\/cdn.arstechnica.net\\/wp-content\\/themes\\/ars\\/assets\",\"HOME_URL\":\"https:\\/\\/arstechnica.com\",\"CIVIS\":\"\\/civis\",\"THEME\":\"light\",\"VIEW\":\"grid\",\"MOBILE\":false,\"SUBSCRIBER\":false,\"PLUS_PLUS\":false,\"LOGGED\":false,\"USER_ID\":null,\"ENV\":\"production\",\"AD\":{\"tags\":[\"ai\",\"ai-dataset\",\"ai-deepfakes\",\"artificial-intelligence\",\"childrens-online-privacy\",\"generative-ai\",\"laion\",\"laion-5b\",\"online-child-safety\",\"openai\"],\"channel\":\"tech-policy\",\"slug\":\"ai-trained-on-photos-from-kids-entire-childhood-without-their-consent\",\"template_type\":\"article\",\"queue\":[],\"server\":\"production\"},\"TOTAL\":113340,\"UNREAD\":0,\"RECENT\":[2036094,2036085,2035991,2035995,2035434,2032516,2035900,2036032,2035899,2035885,2035942,2035809,2035842,2035880,2035869,2035805,2035856,2022814,2035720,2034631,2035544,2035696,2035501,2035658,2035566],\"LOGINS\":true,\"CROSS\":false,\"PARSELY\":\"arstechnica.com\",\"COMMENTS\":false,\"HOMEPAGE\":false,\"SITE\":1,\"READY\":[],\"SHOW_ADS\":true,\"IMG_PROXY\":\"https:\\/\\/cdn.arstechnica.net\\/i\\/\",\"CATEGORY\":\"tech-policy\",\"PAGETITLE\":\"\",\"ZEN_MODE\":false,\"MEMO_PID\":\"62012a7a19351c07620394e0\"};\n</script>\n<link rel=\"stylesheet\" type=\"text/css\" media=\"all\" href=\"https://cdn.arstechnica.net/wp-content/themes/ars/assets/css/main-b0320f54e6.css\" />\n    <link rel=\"alternate\" type=\"application/rss+xml\" href=\"http://feeds.arstechnica.com/arstechnica/index\" />\n  <link rel=\"shortcut icon\" href=\"https://cdn.arstechnica.net/favicon.ico\" />\n  <link rel=\"icon\" type=\"image/x-icon\" href=\"https://cdn.arstechnica.net/favicon.ico\" />\n  <link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"https://cdn.arstechnica.net/wp-content/themes/ars/assets/img/ars-ios-icon-d9a45f558c.png\" />\n  <link rel=\"mask-icon\" href=\"https://cdn.arstechnica.net/wp-content/themes/ars/assets/img/ars-macos-safari-8997f76b21.svg\" color=\"#ff4e00\">\n  <link rel=\"icon\" sizes=\"192x192\" href=\"https://cdn.arstechnica.net/wp-content/themes/ars/assets/img/material-ars-db41652381.png\" />\n  <link rel=\"me\" href=\"https://mastodon.social/@arstechnica\" />\n\n    <meta name=\"application-name\" content=\"Ars Technica\"/>\n  <meta name=\"msapplication-starturl\" content=\"http://arstechnica.com/\"/>\n  <meta name=\"msapplication-tooltip\" content=\"Ars Technica: Serving the technologist for 1.2 decades\"/>\n  <meta name=\"msapplication-task\" content=\"name=News;action-uri=http://arstechnica.com/;icon-uri=https://cdn.arstechnica.net/favicon.ico\"/>\n  <meta name=\"msapplication-task\" content=\"name=Features;action-uri=http://arstechnica.com/features/;icon-uri=https://cdn.arstechnica.net/ie-jump-menu/jump-features.ico\"/>\n  <meta name=\"msapplication-task\" content=\"name=OpenForum;action-uri=http://arstechnica.com/civis/;icon-uri=https://cdn.arstechnica.net/ie-jump-menu/jump-forum.ico\"/>\n  <meta name=\"msapplication-task\" content=\"name=Subscribe;action-uri=http://arstechnica.com/subscriptions/;icon-uri=https://cdn.arstechnica.net/ie-jump-menu/jump-subscribe.ico\"/>\n\n\n  <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />\n  <meta name=\"advertising\" content=\"ask\" />\n  <meta property=\"fb:admins\" content=\"592156917\" />\n  <meta property=\"fb:admins\" content=\"108943\" />\n  <meta property=\"fb:pages\" content=\"19374573752\" />\n\n  <meta name=\"format-detection\" content=\"telephone=no\" />\n  <meta name=\"theme-color\" content=\"#000000\" />\n\n  \n  <meta name=\"viewport\" content=\"width=device-width,initial-scale=1\">\n\n  <!-- cache hit 83:single/meta:a084c10cf9f3b1840bacc10a834ec50f -->\n<meta name='parsely-page' content='{\"title\":\"AI trained on photos from kids\\u2019 entire childhood without their consent\",\"link\":\"https:\\/\\/arstechnica.com\\/tech-policy\\/2024\\/06\\/ai-trained-on-photos-from-kids-entire-childhood-without-their-consent\\/\",\"type\":\"post\",\"author\":\"Ashley Belanger\",\"post_id\":2030521,\"pub_date\":\"2024-06-10T22:37:03Z\",\"section\":\"Policy\",\"tags\":[\"ai\",\"ai-dataset\",\"ai-deepfakes\",\"artificial-intelligence\",\"childrens-online-privacy\",\"generative-ai\",\"laion\",\"laion-5b\",\"online-child-safety\",\"openai\",\"type: report\"],\"image_url\":\"https:\\/\\/cdn.arstechnica.net\\/wp-content\\/uploads\\/2024\\/06\\/GettyImages-1328876959-150x150.jpg\"}'>\n<meta name='parsely-metadata' content='{\"type\":\"report\",\"title\":\"AI trained on photos from kids\\u2019 entire childhood without their consent\",\"post_id\":2030521,\"lower_deck\":\"Kids \\u0022easily traceable\\u0022 from photos used to train AI models, advocates warn.\",\"image_url\":\"https:\\/\\/cdn.arstechnica.net\\/wp-content\\/uploads\\/2024\\/06\\/GettyImages-1328876959-150x150.jpg\",\"listing_image_url\":\"https:\\/\\/cdn.arstechnica.net\\/wp-content\\/uploads\\/2024\\/06\\/GettyImages-1328876959-360x200.jpg\"}'>\n\n  <link rel=\"canonical\" href=\"https://arstechnica.com/tech-policy/2024/06/ai-trained-on-photos-from-kids-entire-childhood-without-their-consent/\" />\n\n<link rel=\"shorturl\" href=\"https://arstechnica.com/?p=2030521\" />\n\n<meta name=\"description\" content=\"Kids &#34;easily traceable&#34; from photos used to train AI models, advocates warn.\" />\n\n<meta name=\"twitter:card\" content=\"summary_large_image\">\n<meta name=\"twitter:url\" content=\"https://arstechnica.com/tech-policy/2024/06/ai-trained-on-photos-from-kids-entire-childhood-without-their-consent/\">\n<meta name=\"twitter:title\" content=\"AI trained on photos from kids’ entire childhood without their consent\">\n<meta name=\"twitter:description\" content=\"Kids &#34;easily traceable&#34; from photos used to train AI models, advocates warn.\">\n\n<meta name=\"twitter:site\" content=\"@arstechnica\">\n<meta name=\"twitter:domain\" content=\"arstechnica.com\">\n\n<meta property=\"og:site_name\" content=\"Ars Technica\" />\n\n<meta name=\"twitter:image:src\" content=\"https://cdn.arstechnica.net/wp-content/uploads/2024/06/GettyImages-1328876959-760x380.jpg\">\n  <meta name=\"twitter:image:width\" content=\"760\">\n  <meta name=\"twitter:image:height\" content=\"380\">\n\n  <meta name=\"twitter:creator\" content=\"@ashleynbelanger\">\n\n<meta property=\"og:url\" content=\"https://arstechnica.com/tech-policy/2024/06/ai-trained-on-photos-from-kids-entire-childhood-without-their-consent/\" />\n<meta property=\"og:title\" content=\"AI trained on photos from kids’ entire childhood without their consent\" />\n<meta property=\"og:image\" content=\"https://cdn.arstechnica.net/wp-content/uploads/2024/06/GettyImages-1328876959-760x380.jpg\" />\n<meta property=\"og:description\" content=\"Kids &#34;easily traceable&#34; from photos used to train AI models, advocates warn.\" />\n<meta property=\"og:type\" content=\"article\" />\n  <!-- cache hit 83:single/header:a084c10cf9f3b1840bacc10a834ec50f -->\n        \n\n<!-- OneTrust Cookies Consent Notice start -->\n<script src=\"https://cdn.cookielaw.org/scripttemplates/otSDKStub.js\" data-domain-script=\"b10882a1-8446-4e7d-bfb2-ce2c770ad910\">\n</script>\n<script id=\"oneTrustScripts\">\n    window.OptanonWrapper = function() {\n        var CCPAButton = document.getElementById('ot-sdk-btn');\n        CCPAButton && CCPAButton.classList.add('ot-sdk-btn--visible');\n        window.dataLayer && window.dataLayer.push({\n            event: 'OneTrustGroupsUpdated'\n        });\n        window.cnBus && window.cnBus.emit('onetrust.OneTrustGroupsUpdated');\n    };\n</script>\n<script src=\"https://cdn.cookielaw.org/opt-out/otCCPAiab.js\" ccpa-opt-out-ids=\"C0002,C0003,C0004,C0005\" ccpa-opt-out-geo=\"ca\" ccpa-opt-out-lspa=\"true\">\n</script>\n<!-- OneTrust Cookies Consent Notice end -->\n<!-- Google Tag Manager DataLayer -->\n<script>\nwindow.dataLayer = window.dataLayer || [];\nwindow.dataLayer.push({\"event\":\"data-layer-loaded\",\"user\":{\"ars_userId\":undefined,\"amg_userId\":undefined,\"uID\":undefined,\"sID\":undefined,\"loginStatus\":false,\"subscriberStatus\":\"none\",\"infinityId\":undefined,\"registrationSource\":undefined,\"mdw_cnd_id\":undefined,\"monthlyVisits\":undefined,\"accessPaywall\":undefined,\"view\":\"grid\",\"theme\":\"light\",\"show_comments\":false},\"content\":{\"pageTemplate\":\"single\",\"pageType\":\"article|report\",\"contentCategory\":\"tech-policy\",\"section\":\"tech policy\",\"subsection\":undefined,\"contributor\":\"Ashley Belanger\",\"contentID\":2030521,\"contentLength\":1665,\"display\":\"AI trained on photos from kids\\u2019 entire childhood without their consent\",\"contentSource\":\"web\",\"pageAssets\":undefined,\"uniqueContentCount\":undefined,\"monthlyContentCount\":undefined,\"publishDate\":\"2024-06-10T22:37:03-04:00\",\"modifiedDate\":\"2024-06-12T13:15:37-04:00\",\"keywords\":\"AI|ai dataset|ai deepfakes|Artificial Intelligence|children's online privacy|generative ai|LAION|LAION-5b|online child safety|openai\",\"dataSource\":undefined},\"marketing\":{\"campaignName\":undefined,\"circCampaignId\":undefined,\"internalCampaignId\":undefined,\"brand\":\"Ars Technica\",\"certified_mrc_data\":undefined,\"condeNastId\":undefined},\"page\":{\"pID\":undefined,\"syndicatorUrl\":undefined,\"pageURL\":\"https:\\/\\/arstechnica.com\\/?p=2030521\",\"canonical\":\"https:\\/\\/arstechnica.com\\/tech-policy\\/2024\\/06\\/ai-trained-on-photos-from-kids-entire-childhood-without-their-consent\\/\",\"canonicalPathName\":\"\\/tech-policy\\/2024\\/06\\/ai-trained-on-photos-from-kids-entire-childhood-without-their-consent\\/\"},\"search\":{\"facets\":undefined,\"searchTerms\":undefined},\"site\":{\"appVersion\":\"1.0.0\"}});\n</script>\n<!-- End Google Tag Manager DataLayer -->\n<!-- Google Tag Manager -->\n<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':\nnew Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],\nj=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=\n'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);\n})(window,document,'script','dataLayer','GTM-NLXNPCQ');</script>\n<!-- End Google Tag Manager -->\n<!-- Start Headline A/B -->\n<script type=\"text/javascript\">\n  class ABTest {\n    constructor(post_id, init_method) {\n      this.post_id = post_id;\n      this.ajaxurl = '/services/ars-ajax-handler.php';\n      this.expireDays = 1 / 48; // 30 min\n      this.group = this.getGroup();\n      this.uid = this.getUid();\n      this.init_method = init_method;\n      this.setTitle();\n\n      if (this.init_method === 'click') {\n        this.click();\n      } else {\n        this.impression();\n      }\n    }\n\n    setCookie(name, value, days) {\n      var expires = \"\";\n      if (days) {\n        var date = new Date();\n        date.setTime(date.getTime() + (days * 24 * 60 * 60 * 1000));\n        expires = \"; expires=\" + date.toUTCString();\n      }\n      document.cookie = name + \"=\" + (value || \"\") + expires + \"; path=/\";\n    }\n\n    getCookie(name) {\n      var nameEQ = name + \"=\";\n      var ca = document.cookie.split(';');\n      for (var i = 0; i < ca.length; i++) {\n        var c = ca[i];\n        while (c.charAt(0) == ' ') c = c.substring(1, c.length);\n        if (c.indexOf(nameEQ) == 0) return c.substring(nameEQ.length, c.length);\n      }\n      return null;\n    }\n\n    // Retrieves a unique id for determining whether the event should be recorded\n    getUid() {\n      var uid = this.getCookie('ars_ab_' + this.post_id + '_uid');\n      if (!uid) {\n        uid = (Math.random() + 1).toString(36).substring(2, 7);\n        this.setCookie('ars_ab_' + this.post_id + '_uid', uid, this.expireDays);\n      }\n      return uid;\n    };\n\n    // Places the user in either A or B for this post id\n    getGroup() {\n      var group = this.getCookie('ars_ab_' + this.post_id + '_group');\n      if (!group) {\n        group = String.fromCharCode(Math.floor(Math.random() * 2) + 65).toLowerCase();\n        this.setCookie('ars_ab_' + this.post_id + '_group', group, this.expireDays);\n      }\n      return group;\n    };\n\n    // Records a headline impression (from homepage or other listing)\n    impression() {\n      // Send fake ajax\n      var params = {\n        nonce: '261cc881c6',\n        action: 'ars_ab_impression',\n        id: this.post_id,\n        group: this.group,\n        uid: this.uid,\n        ts: (new Date()).getTime()\n      };\n      var url = this.ajaxurl + '?' + this.encodeParams(params);\n      document.write('\\x3Cscript type=\"text/javascript\" src=\"' + url + '\">\\x3C/script>');\n    };\n\n    // Records a headline click from the actual post page\n    click() {\n      // Send fake ajax\n      var params = {\n        nonce: '7d853820ef',\n        action: 'ars_ab_click',\n        id: this.post_id,\n        group: this.group,\n        uid: this.uid,\n        ts: (new Date()).getTime()\n      };\n      var url = this.ajaxurl + '?' + this.encodeParams(params);\n      document.write('\\x3Cscript type=\"text/javascript\" src=\"' + url + '\">\\x3C/script>');\n    };\n\n    // If user is in B group, dynamically set title\n    setTitle() {\n      if (this.group == 'b') {\n        var span = document.getElementById('ars_ab_' + this.post_id);\n        var title = span.parentNode;\n        title.innerHTML = span.getAttribute('data-title-b');\n      }\n    };\n\n    encodeParams(data) {\n      var ret = [];\n      for (var d in data)\n        ret.push(encodeURIComponent(d) + \"=\" + encodeURIComponent(data[d]));\n      return ret.join(\"&\");\n    };\n\n  };\n</script>\n<!-- End Headline A/B -->\n<script>\n  window.permutiveCohorts = {\"cached_until\":{\"date\":\"2024-07-10 15:43:12.151335\",\"timezone_type\":3,\"timezone\":\"UTC\"},\"cohorts\":[\"bybf\",\"bjfa\",\"bxxe\"],\"gam\":[\"bybf\",\"bjfa\",\"bxxe\"],\"xandr\":[]};\n  window.permutiveContextInfo = {\"pageProperties\":{\"client\":{\"url\":\"https:\\/\\/arstechnica.com\\/tech-policy\\/2024\\/06\\/ai-trained-on-photos-from-kids-entire-childhood-without-their-consent\\/\",\"referrer\":\"\",\"type\":\"web\",\"user_agent\":\"Mozilla\\/5.0 (Macintosh; Intel Mac OS X 10_11_1) AppleWebKit\\/601.2.4 (KHTML, like Gecko) Version\\/9.0.1 Safari\\/601.2.4 facebookexternalhit\\/1.1 Facebot Twitterbot\\/1.0\",\"domain\":\"arstechnica.com\",\"title\":\"AI trained on photos from kids\\u2019 entire childhood without their consent &#8211; Ars Technica\"},\"type\":\"article\",\"article\":{\"id\":\"2030521\",\"category\":\"tech-policy\",\"subcategory\":\"\",\"title\":\"AI trained on photos from kids\\u2019 entire childhood without their consent\",\"tags\":[\"ai\",\"ai-dataset\",\"ai-deepfakes\",\"artificial-intelligence\",\"childrens-online-privacy\",\"generative-ai\",\"laion\",\"laion-5b\",\"online-child-safety\",\"openai\"]}},\"url\":\"https:\\/\\/arstechnica.com\\/tech-policy\\/2024\\/06\\/ai-trained-on-photos-from-kids-entire-childhood-without-their-consent\\/\"};\n</script>\n<script src=\"https://www.googletagservices.com/tag/js/gpt.js\" id=\"gpt-script\" async></script>\n<script>\n  window.googletag = window.googletag || {};\n  window.googletag.cmd = window.googletag.cmd || [];\n  window.cns = window.cns || {};\n  window.cns.queue = [];\n  window.cns.async = function(s, c) {\n    cns.queue.push({\n      service: s,\n      callback: c\n    })\n  };\n</script>\n<script>\n  window.cns.pageContext = {\"contentType\":\"article\",\"templateType\":\"article\",\"channel\":\"tech-policy\",\"subChannel\":\"\",\"slug\":\"ai-trained-on-photos-from-kids-entire-childhood-without-their-consent\",\"server\":\"production\",\"keywords\":{\"tags\":[\"ai\",\"ai-dataset\",\"ai-deepfakes\",\"artificial-intelligence\",\"childrens-online-privacy\",\"generative-ai\",\"laion\",\"laion-5b\",\"online-child-safety\",\"openai\"],\"cm\":[],\"platform\":[\"wordpress\"],\"copilotid\":\"\"}};\n</script>\n<script src=\"https://ads-static.conde.digital/production/cns/builds/ars-technica/ars-technica.min.js\" async></script>\n<script type=\"text/javascript\" src=\"https://cdn.arstechnica.net/wp-content/themes/ars/assets/js/ars-dc1d08cbd8.ads.us.js\"></script>\n  <script type=\"text/javascript\">!(function(o,_name){function n(){(n.q=n.q||[]).push(arguments)}n.v=1,o[_name]=o[_name]||n;!(function(o,t,n,c){function e(n){(function(){try{return(localStorage.getItem(\"v4ac1eiZr0\")||\"\").split(\",\")[4]>0}catch(o){}return!1})()&&(n=o[t].pubads())&&n.setTargeting(\"admiral-engaged\",\"true\")}(c=o[t]=o[t]||{}).cmd=c.cmd||[],typeof c.pubads===n?e():typeof c.cmd.unshift===n?c.cmd.unshift(e):c.cmd.push(e)})(window,\"googletag\",\"function\");})(window,String.fromCharCode(97,100,109,105,114,97,108));!(function(t,c,i){i=t.createElement(c),t=t.getElementsByTagName(c)[0],i.async=1,i.src=\"https://shiverscissors.com/v2fumwIJOo-LsCB0dlG18VSTW43CpWhUEPJuKeRTzrEQdSPPlMr5GymU\",t.parentNode.insertBefore(i,t)})(document,\"script\");</script>\n\n  <!-- Taboola -->\n  <script type=\"text/javascript\">\n    window._taboola = window._taboola || [];\n    _taboola.push({\n      article: 'auto'\n    });\n    ! function(e, f, u, i) {\n      if (!document.getElementById(i)) {\n        e.async = 1;\n        e.src = u;\n        e.id = i;\n        f.parentNode.insertBefore(e, f);\n      }\n    }(document.createElement('script'),\n      document.getElementsByTagName('script')[0],\n      '//cdn.taboola.com/libtrc/condenast1-network/loader.js',\n      'tb_loader_script');\n    if (window.performance && typeof window.performance.mark == 'function') {\n      window.performance.mark('tbl_ic');\n    }\n  </script>\n  <meta name='robots' content='max-image-preview:large' />\n<link rel='dns-prefetch' href='//cdn.arstechnica.net' />\n<link rel='dns-prefetch' href='//s.w.org' />\n<link rel='dns-prefetch' href='//arstechnica-apps.s3.amazonaws.com' />\n<link rel='stylesheet' id='wp-block-library-css'  href='https://cdn.arstechnica.net/wp/wp-includes/css/dist/block-library/style.min.css?ver=6.0.3' type='text/css' media='all' />\n<style id='global-styles-inline-css' type='text/css'>\nbody{--wp--preset--color--black: #000000;--wp--preset--color--cyan-bluish-gray: #abb8c3;--wp--preset--color--white: #ffffff;--wp--preset--color--pale-pink: #f78da7;--wp--preset--color--vivid-red: #cf2e2e;--wp--preset--color--luminous-vivid-orange: #ff6900;--wp--preset--color--luminous-vivid-amber: #fcb900;--wp--preset--color--light-green-cyan: #7bdcb5;--wp--preset--color--vivid-green-cyan: #00d084;--wp--preset--color--pale-cyan-blue: #8ed1fc;--wp--preset--color--vivid-cyan-blue: #0693e3;--wp--preset--color--vivid-purple: #9b51e0;--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple: linear-gradient(135deg,rgba(6,147,227,1) 0%,rgb(155,81,224) 100%);--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan: linear-gradient(135deg,rgb(122,220,180) 0%,rgb(0,208,130) 100%);--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange: linear-gradient(135deg,rgba(252,185,0,1) 0%,rgba(255,105,0,1) 100%);--wp--preset--gradient--luminous-vivid-orange-to-vivid-red: linear-gradient(135deg,rgba(255,105,0,1) 0%,rgb(207,46,46) 100%);--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray: linear-gradient(135deg,rgb(238,238,238) 0%,rgb(169,184,195) 100%);--wp--preset--gradient--cool-to-warm-spectrum: linear-gradient(135deg,rgb(74,234,220) 0%,rgb(151,120,209) 20%,rgb(207,42,186) 40%,rgb(238,44,130) 60%,rgb(251,105,98) 80%,rgb(254,248,76) 100%);--wp--preset--gradient--blush-light-purple: linear-gradient(135deg,rgb(255,206,236) 0%,rgb(152,150,240) 100%);--wp--preset--gradient--blush-bordeaux: linear-gradient(135deg,rgb(254,205,165) 0%,rgb(254,45,45) 50%,rgb(107,0,62) 100%);--wp--preset--gradient--luminous-dusk: linear-gradient(135deg,rgb(255,203,112) 0%,rgb(199,81,192) 50%,rgb(65,88,208) 100%);--wp--preset--gradient--pale-ocean: linear-gradient(135deg,rgb(255,245,203) 0%,rgb(182,227,212) 50%,rgb(51,167,181) 100%);--wp--preset--gradient--electric-grass: linear-gradient(135deg,rgb(202,248,128) 0%,rgb(113,206,126) 100%);--wp--preset--gradient--midnight: linear-gradient(135deg,rgb(2,3,129) 0%,rgb(40,116,252) 100%);--wp--preset--duotone--dark-grayscale: url('#wp-duotone-dark-grayscale');--wp--preset--duotone--grayscale: url('#wp-duotone-grayscale');--wp--preset--duotone--purple-yellow: url('#wp-duotone-purple-yellow');--wp--preset--duotone--blue-red: url('#wp-duotone-blue-red');--wp--preset--duotone--midnight: url('#wp-duotone-midnight');--wp--preset--duotone--magenta-yellow: url('#wp-duotone-magenta-yellow');--wp--preset--duotone--purple-green: url('#wp-duotone-purple-green');--wp--preset--duotone--blue-orange: url('#wp-duotone-blue-orange');--wp--preset--font-size--small: 13px;--wp--preset--font-size--medium: 20px;--wp--preset--font-size--large: 36px;--wp--preset--font-size--x-large: 42px;}.has-black-color{color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-color{color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-color{color: var(--wp--preset--color--white) !important;}.has-pale-pink-color{color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-color{color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-color{color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-color{color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-color{color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-color{color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-color{color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-color{color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-color{color: var(--wp--preset--color--vivid-purple) !important;}.has-black-background-color{background-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-background-color{background-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-background-color{background-color: var(--wp--preset--color--white) !important;}.has-pale-pink-background-color{background-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-background-color{background-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-background-color{background-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-background-color{background-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-background-color{background-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-background-color{background-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-background-color{background-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-background-color{background-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-background-color{background-color: var(--wp--preset--color--vivid-purple) !important;}.has-black-border-color{border-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-border-color{border-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-border-color{border-color: var(--wp--preset--color--white) !important;}.has-pale-pink-border-color{border-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-border-color{border-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-border-color{border-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-border-color{border-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-border-color{border-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-border-color{border-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-border-color{border-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-border-color{border-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-border-color{border-color: var(--wp--preset--color--vivid-purple) !important;}.has-vivid-cyan-blue-to-vivid-purple-gradient-background{background: var(--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple) !important;}.has-light-green-cyan-to-vivid-green-cyan-gradient-background{background: var(--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan) !important;}.has-luminous-vivid-amber-to-luminous-vivid-orange-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange) !important;}.has-luminous-vivid-orange-to-vivid-red-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-orange-to-vivid-red) !important;}.has-very-light-gray-to-cyan-bluish-gray-gradient-background{background: var(--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray) !important;}.has-cool-to-warm-spectrum-gradient-background{background: var(--wp--preset--gradient--cool-to-warm-spectrum) !important;}.has-blush-light-purple-gradient-background{background: var(--wp--preset--gradient--blush-light-purple) !important;}.has-blush-bordeaux-gradient-background{background: var(--wp--preset--gradient--blush-bordeaux) !important;}.has-luminous-dusk-gradient-background{background: var(--wp--preset--gradient--luminous-dusk) !important;}.has-pale-ocean-gradient-background{background: var(--wp--preset--gradient--pale-ocean) !important;}.has-electric-grass-gradient-background{background: var(--wp--preset--gradient--electric-grass) !important;}.has-midnight-gradient-background{background: var(--wp--preset--gradient--midnight) !important;}.has-small-font-size{font-size: var(--wp--preset--font-size--small) !important;}.has-medium-font-size{font-size: var(--wp--preset--font-size--medium) !important;}.has-large-font-size{font-size: var(--wp--preset--font-size--large) !important;}.has-x-large-font-size{font-size: var(--wp--preset--font-size--x-large) !important;}\n</style>\n<link rel='stylesheet' id='article_forum_connect_comments-css'  href='https://cdn.arstechnica.net/wp-content/plugins/article-forum-connect/public/css/comments.css?ver=1.2.2' type='text/css' media='all' />\n<link rel='stylesheet' id='article_forum_connect_paywall-css'  href='https://cdn.arstechnica.net/wp-content/plugins/article-forum-connect/public/css/paywall.css?ver=1.2.2' type='text/css' media='all' />\n<meta property=\"article:published_time\" content=\"2024-06-10T22:37:03+00:00\">\n<meta property=\"article:modified_time\" content=\"2024-06-12T13:15:37+00:00\">\n<meta name=\"twitter:partner\" content=\"tfwp\" />\n<!--\n\tgenerated 99 seconds ago\n\tgenerated in 0.281 seconds\n\tserved from batcache in 0.002 seconds\n\texpires in 201 seconds\n\tbillboard: forced \n\tview: grid \n\ttheme: light \n -->\n</head>\n\n<body class=\"post-template-default single single-post postid-2030521 single-format-standard grid-view light blog-us\">\n  <!-- Google Tag Manager (noscript) -->\n<noscript><iframe src=\"https://www.googletagmanager.com/ns.html?id=GTM-NLXNPCQ\" height=\"0\" width=\"0\" style=\"display:none;visibility:hidden\"></iframe></noscript>\n<!-- End Google Tag Manager (noscript) -->\n\n      \t<aside class=\"ad ad_crown\" aria-label=\"Top of page advertisement\"></aside>\n  \n  <div class=\"site-wrapper\">\n    <a class=\"screen-reader-text skip-link\" href=\"#main\" aria-label=\"Skip to main content\">Skip to main content</a>\n    <header class=\"site-header\">\n      <div class=\"header-left\">\n        <a href=\"https://arstechnica.com\" id=\"header-logo\" title=\"Ars Technica Homepage\">\n      <span class=\"icon icon-logo-ars-us\"></span>\n  </a>\n      </div>\n\n      <div class=\"header-right\">\n        <nav id=\"header-nav-primary\">\n          <ul>\n            \n  <li><a class=\"nav-link section-information-technology \" href=\"/information-technology/\">Biz &amp; IT</a></li>\n  <li><a class=\"nav-link section-gadgets \" href=\"/gadgets/\">Tech</a></li>\n  <li><a class=\"nav-link section-science \" href=\"/science/\">Science</a></li>\n  <li><a class=\"nav-link section-tech-policy active\" href=\"/tech-policy/\">Policy</a></li>\n  <li><a class=\"nav-link section-cars \" href=\"/cars/\">Cars</a></li>\n  <li><a class=\"nav-link section-gaming \" href=\"/gaming/\">Gaming &amp; Culture</a></li>\n  <li><a class=\"nav-link store\" href=\"/store/\">Store</a></li>\n  <li><a class=\"nav-link forums\" href=\"/civis/\">Forums</a></li>\n          </ul>\n        </nav>\n\n                              <a href=\"/store/product/subscriptions/\" class=\"header-highlight-link\">Subscribe</a>\n                                  <div class=\"dropdown\" id=\"header-search\">\n          <a href=\"/search/\" class=\"dropdown-toggle search-toggle\" aria-label=\"Search\" aria-expanded=\"false\">\n            <span class=\"icon icon-search-mag-glass\"></span>\n          </a>\n          <div class=\"dropdown-content\">\n            <form action=\"/search/\" method=\"GET\" id=\"search_form\">\n  <input type=\"hidden\" name=\"ie\" value=\"UTF-8\">\n  <input type=\"text\" name=\"q\" id=\"hdr_search_input\" value=\"\" aria-label=\"Search...\" placeholder=\"Search...\">\n</form>\n<a class=\"nav-search-close\">Close</a>\n          </div>\n        </div>\n        <div class=\"dropdown dropdown-mega\" id=\"header-burger\">\n          <a href=\"#site-menu\" class=\"dropdown-toggle\" aria-label=\"Menu\" aria-expanded=\"false\">\n            <span></span>\n          </a>\n          <div id=\"site-menu\" class=\"dropdown-content\">\n            <section class=\"burger-navigate\">\n  <h3>\n    <span class=\"icon icon-half-target\"></span>\n    Navigate\n  </h3>\n  <ul>\n          <li><a class=\"nav-link store\" href=\"/store/\">Store</a></li>\n      <li><a class=\"nav-link subscribe\" href=\"/store/product/subscriptions/\">Subscribe</a></li>\n        <li><a class=\"nav-link videos\" href=\"http://arstechnica.com/video/\">Videos</a></li>\n    <li><a class=\"nav-link section-features\" href=\"/features/\">Features</a></li>\n    <li><a class=\"nav-link section-reviews\" href=\"/reviews/\">Reviews</a></li>\n  </ul>\n\n  <ul>\n    <li><a class=\"nav-link page-rss-feeds\" href=\"/rss-feeds/\">RSS Feeds</a></li>\n    <li><a class=\"nav-link mobile\" href=\"/?view=mobile\">Mobile Site</a></li>\n  </ul>\n\n  <ul>\n    <li><a class=\"nav-link page-about-us\" href=\"/about-us/\">About Ars</a></li>\n    <li><a class=\"nav-link page-staff-directory\" href=\"/staff-directory/\">Staff Directory</a></li>\n    <li><a class=\"nav-link page-contact-us\" href=\"/contact-us/\">Contact Us</a></li>\n  </ul>\n\n  <ul>\n    <li><a class=\"nav-link page-advertise-with-us\" href=\"https://advertising.condenast.com/brands/ars-technica\">Advertise with Ars</a></li>\n    <li><a class=\"nav-link page-reprints\" href=\"/reprints/\">Reprints</a></li>\n  </ul>\n</section>\n\n<section class=\"burger-filter\">\n  <h3>\n    <span class=\"icon icon-half-mag\"></span>\n    Filter by topic\n  </h3>\n  <ul id=\"burger-nav-primary\">\n    \n  <li><a class=\"nav-link section-information-technology \" href=\"/information-technology/\">Biz &amp; IT</a></li>\n  <li><a class=\"nav-link section-gadgets \" href=\"/gadgets/\">Tech</a></li>\n  <li><a class=\"nav-link section-science \" href=\"/science/\">Science</a></li>\n  <li><a class=\"nav-link section-tech-policy active\" href=\"/tech-policy/\">Policy</a></li>\n  <li><a class=\"nav-link section-cars \" href=\"/cars/\">Cars</a></li>\n  <li><a class=\"nav-link section-gaming \" href=\"/gaming/\">Gaming &amp; Culture</a></li>\n  <li><a class=\"nav-link store\" href=\"/store/\">Store</a></li>\n  <li><a class=\"nav-link forums\" href=\"/civis/\">Forums</a></li>\n  </ul>\n</section>\n\n<section class=\"burger-settings\">\n  <h3>\n    <span class=\"icon icon-half-gear\"></span>\n    Settings\n  </h3>\n  <div>\n    <div class=\"burger-layout\">\n      \n<p>Front page layout</p>\n<div class=\"burger-layout-grid\">\n  <a rel=\"nofollow\" href=\"/tech-policy/2024/06/ai-trained-on-photos-from-kids-entire-childhood-without-their-consent/?view=grid\">\n    <span class=\"icon icon-grid\"></span><br>\n    Grid\n    <div class=\"faux-radio active\"></div>\n  </a>\n</div>\n\n<div class=\"burger-layout-list\">\n  <a rel=\"nofollow\" href=\"/tech-policy/2024/06/ai-trained-on-photos-from-kids-entire-childhood-without-their-consent/?view=archive\">\n    <span class=\"icon icon-list\"></span><br>\n    List\n    <div class=\"faux-radio \"></div>\n  </a>\n</div>\n\n    </div>\n    <div class=\"burger-theme\">\n      <p>Site theme</p>\n  <div class=\"burger-theme-light\">\n    <a rel=\"nofollow\" href=\"/tech-policy/2024/06/ai-trained-on-photos-from-kids-entire-childhood-without-their-consent/?theme=light\">\n      <span><span>light</span></span>\n      <div class=\"faux-radio active\"></div>\n    </a>\n  </div>\n  <div class=\"burger-theme-dark\">\n    <a rel=\"nofollow\" href=\"/tech-policy/2024/06/ai-trained-on-photos-from-kids-entire-childhood-without-their-consent/?theme=dark\">\n      <span><span>dark</span></span>\n      <div class=\"faux-radio \"></div>\n    </a>\n  </div>\n    </div>\n  </div>\n</section>\n          </div>\n        </div>\n              <a class=\"navlink login-link\" href=\"https://arstechnica.com/civis/login?_xfRedirect=%2Ftech-policy%2F2024%2F06%2Fai-trained-on-photos-from-kids-entire-childhood-without-their-consent%2F\">\n      Sign in\n    </a>\n  \n        </div>\n    </header>\n\n              \n    <main id=\"main\" class=\"content-wrapper\">\n\n<script type=\"text/javascript\">\n  ars.ARTICLE = {\"url\":\"https:\\/\\/arstechnica.com\\/tech-policy\\/2024\\/06\\/ai-trained-on-photos-from-kids-entire-childhood-without-their-consent\\/\",\"short_url\":\"https:\\/\\/arstechnica.com\\/?p=2030521\",\"title\":\"AI trained on photos from kids\\u2019 entire childhood without their consent\",\"author\":855306,\"authorName\":\"Ashley Belanger\",\"pubDate\":\"2024-06-10T22:37:03Z\",\"id\":2030521,\"topic\":1501217,\"pages\":2,\"current_page\":1,\"superscroll\":true,\"promoted\":[],\"single_page\":false,\"comments\":136,\"fullwidth\":false,\"slug\":\"ai-trained-on-photos-from-kids-entire-childhood-without-their-consent\",\"arsStaff\":{\"104481\":{\"name\":\"Aaron Zimmerman\",\"title\":\"Copy Chief\",\"staff\":true},\"332715\":{\"name\":\"Andrew Cunningham\",\"title\":\"Senior Technology Reporter\",\"staff\":true},\"855306\":{\"name\":\"Ashley Belanger\",\"title\":\"Senior Policy Reporter\",\"staff\":true},\"1002\":{\"name\":\"Aurich Lawson\",\"title\":\"Creative Director\",\"staff\":true},\"857898\":{\"name\":\"Benj Edwards\",\"title\":\"Senior AI Reporter\",\"staff\":true},\"509873\":{\"name\":\"Beth Mole\",\"title\":\"Senior Health Reporter\",\"staff\":true},\"453791\":{\"name\":\"Cathleen O'Grady\",\"title\":\"Contributing science reporter\",\"staff\":false},\"102179\":{\"name\":\"Chris Lee\",\"title\":\"Associate writer\",\"staff\":true},\"329388\":{\"name\":\"Dan Goodin\",\"title\":\"Security Editor\",\"staff\":true},\"254631\":{\"name\":\"Diana Gitig\",\"title\":\"Associate Writer\",\"staff\":false},\"25862\":{\"name\":\"Eric Bangeman\",\"title\":\"Managing Editor\",\"staff\":true},\"512413\":{\"name\":\"Eric Berger\",\"title\":\"Senior Space Editor\",\"staff\":true},\"46707\":{\"name\":\"Iljitsch van Beijnum\",\"title\":\"Associate Writer\",\"staff\":false},\"316010\":{\"name\":\"Jason Marlin\",\"title\":\"Technical Director\",\"staff\":true},\"746799\":{\"name\":\"Jennifer Ouellette\",\"title\":\"Senior Writer\",\"staff\":true},\"15365\":{\"name\":\"Jeremy Reimer\",\"title\":\"Senior Niche Technology Historian\",\"staff\":false},\"52979\":{\"name\":\"John Timmer\",\"title\":\"Senior Science Editor\",\"staff\":true},\"312082\":{\"name\":\"Jon Brodkin\",\"title\":\"Senior IT Reporter\",\"staff\":true},\"14317\":{\"name\":\"Jonathan M. Gitlin\",\"title\":\"Automotive Editor\",\"staff\":true},\"998\":{\"name\":\"Ken Fisher\",\"title\":\"Editor in Chief\",\"staff\":true},\"440179\":{\"name\":\"Kerry Staurseth\",\"title\":\"Associate Copyeditor\",\"staff\":true},\"856780\":{\"name\":\"Kevin Purdy\",\"title\":\"Senior Technology Reporter\",\"staff\":true},\"328283\":{\"name\":\"Kyle Orland\",\"title\":\"Senior Gaming Editor\",\"staff\":true},\"10243\":{\"name\":\"Lee Hutchinson\",\"title\":\"Senior Technology Editor\",\"staff\":true},\"173191\":{\"name\":\"Matthew Lasar\",\"title\":\"Associate writer\",\"staff\":true},\"182268\":{\"name\":\"Nate Anderson\",\"title\":\"Deputy Editor\",\"staff\":true},\"1991\":{\"name\":\"Ohrmazd\",\"title\":\"\",\"staff\":false},\"588289\":{\"name\":\"Samuel Axon\",\"title\":\"Senior Editor\",\"staff\":true},\"294205\":{\"name\":\"Scott K. Johnson\",\"title\":\"Associate Writer\",\"staff\":true},\"173910\":{\"name\":\"Timothy B. Lee\",\"title\":\"Senior tech policy reporter\",\"staff\":false}},\"tags\":[\"ai\",\"ai-dataset\",\"ai-deepfakes\",\"artificial-intelligence\",\"childrens-online-privacy\",\"generative-ai\",\"laion\",\"laion-5b\",\"online-child-safety\",\"openai\"],\"zen_mode\":false};\n</script>\n\n<article itemscope itemtype=\"http://schema.org/NewsArticle\" class=\"article-single standalone intro-standard \" id=\"\">\n      <div class=\"column-wrapper\">\n    <div class=\"left-column\">\n        <header class=\"article-header\">\n            <h4 class=\"post-upperdek\">\n      I guess this is growing up?    &mdash;\n</h4>\n            <h1 itemprop=\"headline\">AI trained on photos from kids’ entire childhood without their consent</h1>\n            <h2 itemprop=\"description\">Kids \"easily traceable\" from photos used to train AI models, advocates warn.</h2>\n            <section class=\"post-meta\">\n\n  \n<p class=\"byline\" itemprop=\"author creator\" itemscope itemtype=\"http://schema.org/Person\">\n      <a itemprop=\"url\" href=\"https://arstechnica.com/author/ashleybelanger/\"  rel=\"author\" ><span itemprop=\"name\">Ashley Belanger</span></a>\n    -    <time class=\"date\" data-time=\"1718059023\" datetime=\"2024-06-10T22:37:03+00:00\">Jun 10, 2024 10:37 pm UTC</time>\n</p>\n\n  \n</section>        </header>\n        <section class=\"article-guts\">\n            <div itemprop=\"articleBody\" class=\"article-content post-page\">\n                                    \n<figure class=\"intro-image intro-left\">\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2024/06/GettyImages-1328876959-800x534.jpg\" alt=\"AI trained on photos from kids’ entire childhood without their consent\">\n      <figcaption class=\"caption\"><div class=\"caption-text\"><a href=\"https://cdn.arstechnica.net/wp-content/uploads/2024/06/GettyImages-1328876959.jpg\" class=\"enlarge-link\" data-height=\"1414\" data-width=\"2120\">Enlarge</a></div><div class=\"caption-credit\"><a rel=\"nofollow\" class=\"caption-link\" href=\"https://www.gettyimages.com/detail/photo/latin-boy-is-in-his-room-playing-on-his-cell-phone-royalty-free-image/1328876959?phrase=Brazilian+kids+online&amp;adppopup=true\">RicardoImagen | E+</a></div></figcaption>  </figure>\n\n  <aside id=\"social-left\" class=\"social-left\" aria-label=\"Read the comments or share this article\">\n          <a class=\"comment-count icon-comment-bubble-down\" href=\"https://arstechnica.com/tech-policy/2024/06/ai-trained-on-photos-from-kids-entire-childhood-without-their-consent/?comments=1\">\n      <h4 class=\"comment-count-before\">reader comments</h4>\n  \n  <span class=\"comment-count-number\">136</span>\n  </a>\n        </aside>\n\n\n\n\n<!-- cache hit 83:single/related:a084c10cf9f3b1840bacc10a834ec50f --><!-- empty -->\n<p>Photos of Brazilian kids—sometimes spanning their entire childhood—have been used without their consent to power AI tools, including popular image generators like Stable Diffusion, Human Rights Watch (HRW) <a href=\"https://www.hrw.org/news/2024/06/10/brazil-childrens-personal-photos-misused-power-ai-tools\">warned on Monday</a>.</p>\n<p>This act poses urgent privacy risks to kids and seems to increase risks of non-consensual AI-generated images bearing their likenesses, HRW's report said.</p>\n<p>An HRW researcher, Hye Jung Han, helped expose the problem. She analyzed \"less than 0.0001 percent\" of LAION-5B, a dataset built from Common Crawl snapshots of the public web. The dataset does not contain the actual photos but includes image-text pairs derived from 5.85 billion images and captions posted online since 2008.</p>\n<p>Among those images linked in the dataset, Han found 170 photos of children from at least 10 Brazilian states. These were mostly family photos uploaded to personal and parenting blogs most Internet surfers wouldn't easily stumble upon, \"as well as stills from YouTube videos with small view counts, seemingly uploaded to be shared with family and friends,\" Wired <a href=\"https://www.wired.com/story/ai-tools-are-secretly-training-on-real-childrens-faces/\">reported</a>.</p>\n<p>LAION, the German nonprofit that created the dataset, has worked with HRW to remove the links to the children's images in the dataset.</p>\n<p>That may not completely resolve the problem, though. HRW's report warned that the removed links are \"likely to be a significant undercount of the total amount of children’s personal data that exists in LAION-5B.\" Han told Wired that she fears that the dataset may still be referencing personal photos of kids \"from all over the world.\"</p>\n<p>Removing the links also does not remove the images from the public web, where they can still be referenced and used in other AI datasets, particularly those relying on Common Crawl, LAION's spokesperson, Nate Tyler, told Ars.</p>\n<p>\"This is a larger and very concerning issue, and as a nonprofit, volunteer organization, we will do our part to help,\" Tyler told Ars.</p>\n<p>Han told Ars that \"Common Crawl should stop scraping children’s personal data, given the privacy risks involved and the potential for new forms of misuse.\"</p>\n<p>According to HRW's analysis, many of the Brazilian children's identities were \"easily traceable,\" due to children's names and locations being included in image captions that were processed when building the LAION dataset.</p>                                                                        <div class=\"ars-interlude-container\"></div>\n                                                                                \n<p>And at a time when <a href=\"https://arstechnica.com/tech-policy/2024/03/florida-middle-schoolers-charged-with-making-deepfake-nudes-of-classmates/\">middle</a> and <a href=\"https://arstechnica.com/tech-policy/2023/11/deepfake-nudes-of-high-schoolers-spark-police-probe-in-nj/\">high school-aged students</a> are <a href=\"https://arstechnica.com/tech-policy/2024/01/surge-of-fake-ai-child-sex-images-thwarts-investigations-into-real-child-abuse/\">at greater risk of being targeted</a> by bullies or bad actors turning \"innocuous photos\" into explicit imagery, it's possible that AI tools may be better equipped to generate AI clones of kids whose images are referenced in AI datasets, HRW suggested.</p>\n<p>\"The photos reviewed span the entirety of childhood,\" HRW's report said. \"They capture intimate moments of babies being born into the gloved hands of doctors, young children blowing out candles on their birthday cake or dancing in their underwear at home, students giving a presentation at school, and teenagers posing for photos at their high school’s carnival.\"</p>\n<p>There is less risk that the Brazilian kids' photos are currently powering AI tools since \"all publicly available versions of LAION-5B were taken down\" <a href=\"https://laion.ai/notes/laion-maintenance/\">in December</a>, Tyler told Ars. That decision came out of an \"abundance of caution\" after a Stanford University <a href=\"https://purl.stanford.edu/kh752sm9123\">report</a> \"found links in the dataset pointing to illegal content on the public web,\" Tyler said, including 3,226 suspected instances of child sexual abuse material.</p>\n<p>Han told Ars that \"the version of the dataset that we examined pre-dates LAION’s temporary removal of its dataset in December 2023.\" The dataset will not be available again until LAION determines that all flagged illegal content has been removed.</p>\n<p>\"LAION is currently working with the Internet Watch Foundation, the Canadian Centre for Child Protection, Stanford, and Human Rights Watch to remove all known references to illegal content from LAION-5B,\" Tyler told Ars. \"We are grateful for their support and hope to republish a revised LAION-5B soon.\"</p>\n<p>In Brazil, \"at least 85 girls\" have reported classmates harassing them by using AI tools to \"create sexually explicit deepfakes of the girls based on photos taken from their social media profiles,\" HRW reported. Once these explicit deepfakes are posted online, they can inflict \"lasting harm,\" HRW warned, potentially remaining online for their entire lives.</p>\n<p>“Children should not have to live in fear that their photos might be stolen and weaponized against them,” Han said. “The government should urgently adopt policies to protect children’s data from AI-fueled misuse.”</p>\n<p>Ella Irwin, the SVP of Integrity for Stable Diffusion maker Stability AI provided Ars with a statement, confirming that \"Stability AI models were trained on a filtered subset of the LAION-5B dataset. In addition, we subsequently fine-tuned these models to mitigate residual behaviours.\"</p>\n<p>\"Stability AI is committed to preventing the misuse of AI,\" Irwin said. \"We prohibit the use of our image models and services for unlawful activity, including attempts to edit or create non-consensual content.”</p>\n\n                                                </div>\n\n            \n            \n                            <nav class=\"page-numbers\">Page: <span class=\"numbers\">1 <a href=\"https://arstechnica.com/tech-policy/2024/06/ai-trained-on-photos-from-kids-entire-childhood-without-their-consent/2/\">2</a> <a href=\"https://arstechnica.com/tech-policy/2024/06/ai-trained-on-photos-from-kids-entire-childhood-without-their-consent/2/\"><span class=\"next\">Next <span class=\"arrow\">&rarr;</span></span></a></span></nav>\n            \n        </section>\n    </div>\n    <div class=\"xrail\">\n        <div class=\"xrail-content\">\n            \n            \n            \n                                        \n            \n                            <aside class=\"ad ad_xrail ad_xrail_top ad_xrail_last\" aria-label=\"Top sidebar advertisement\"></aside>\n                    </div>\n    </div>\n</div>\n\n<div class=\"column-wrapper\">\n    <div class=\"left-column\">\n        <div id=\"social-footer\">\n                  <a class=\"comment-count icon-comment-bubble-down\" href=\"https://arstechnica.com/tech-policy/2024/06/ai-trained-on-photos-from-kids-entire-childhood-without-their-consent/?comments=1\">\n      <h4 class=\"comment-count-before\">reader comments</h4>\n  \n  <span class=\"comment-count-number\">136</span>\n  </a>\n          </div>\n                    <!-- cache hit 83:single/author:8ec5c1a1d558683879afb66eaba9c0ea -->  <section class=\"article-author\">\n          <a style=\"background-image:url('https://cdn.arstechnica.net/wp-content/uploads/2022/06/Ashley-Belanger-400x400.jpg');\" class=\"author-photo\" href=\"/author/ashleybelanger\" tabindex=\"-1\" role=\"presentation\" aria-hidden=\"true\"></a>\n    \n    <div class=\"author-bio\">\n      <section class=\"author-bio-top\">\n        <a href=\"/author/ashleybelanger\" class=\"author-name\">Ashley Belanger</a>\n        Ashley is a senior policy reporter for Ars Technica, dedicated to tracking social impacts of emerging policies and new technologies. She is a Chicago-based journalist with 20 years of experience.      </section>\n    </div>\n\n  </section>\n            </div>\n    <div class=\"xrail\"></div>\n</div>\n<div id=\"article-footer-wrap\">\n            <aside class=\"ad_wrapper\" aria-label=\"Full width advertisement\">\n    <span class=\"ad_notice\">Advertisement </span>        \n    <div class=\"ad ad_fullwidth fullwidth\"></div>\n</aside>\n    \n            <section id=\"comments-area\" class=\"comments-area column-wrapper\">\n      <div class=\"row comments-row left-column\">\n      <a name=\"comments-bar\"></a>\n      \n<div class=\"wp-forum-connect-container\">\n\n    \n\n    \n</div>\n\n    </div>\n          <div class=\"xrail xrail-comments\">\n        <div class=\"xrail-content-wrapper\">\n          <div class=\"xrail-content xrail-content-comments\">\n            <aside class=\"ad ad_xrail ad_xrail_comments\" aria-label=\"Comments sidebar advertisement\"></aside>\n          </div>\n        </div>\n                  <div class=\"xrail-content-wrapper xrail-content-wrapper-bottom\">\n            <div class=\"xrail-content xrail-content-comments\">\n              <aside class=\"ad ad_xrail ad_xrail_comments\" aria-label=\"Comments sidebar advertisement\"></aside>\n            </div>\n          </div>\n              </div>\n      </section>\n                    <section class=\"inline-playlist\">\n  <div class='ars-video-playlist'>\n    <h3 class=\"ars-video-playlist-module-header\">Channel <span>Ars Technica</span></h3>\n    <div class='ars-video-playlist-module' data-playlist-id='arstechnica-channel-ars-tech-policy' data-video-options='[]'></div>\n  </div>\n</section>\n                <div class=\"prev-next-links\">\n  <a href=\"https://arstechnica.com/information-technology/2024/06/hackers-steal-significant-volume-of-data-from-hundreds-of-snowflake-customers/\" rel=\"prev\"><span class=\"arrow\">&larr;</span> Previous story</a>  <a href=\"https://arstechnica.com/science/2024/06/neutrinos-are-infuriating-but-we-still-have-to-study-them/\" rel=\"next\">Next story <span class=\"arrow\">&rarr;</span></a></div>\n        <footer id=\"article-footer\">\n  <div class=\"recommendations-footer\">\n    <div id=\"story-recommendations\">\n  <div class=\"heading-column\">\n    <h3>Related Stories</h3>\n  </div>\n  <ul id=\"story-recs\" class=\"rec-wrap\"></ul>\n</div>\n  </div>\n      <div id=\"taboola-below-article-thumbnails---at\"></div>\n<script type=\"text/javascript\">\n  window._taboola = window._taboola || [];\n  _taboola.push({\n    mode: 'thumbnails-a-6x1',\n    container: 'taboola-below-article-thumbnails---at',\n    placement: 'Below Article Thumbnails - AT',\n    target_type: 'mix'\n  });\n</script>\n    <div class=\"recommendations-footer\">\n    <div id=\"latest-stories\">\n  <div class=\"heading-column\">\n    <h3>Today on Ars</h3>\n  </div>\n  <ul id=\"latest-recs\" class=\"rec-wrap\"></ul>\n</div>\n  </div>\n</footer>\n    </div>\n  </article>\n  </main>\n\n  <footer class=\"site-footer\">\n    <nav class=\"nav-footer\">\n\n  <section>\n    <ul>\n      <li><a href=\"/store/\">Store</a></li>\n      <li><a href=\"/store/product/subscriptions/\">Subscribe</a></li>\n      <li><a href=\"/about-us/\">About Us</a></li>\n      <li><a href=\"/rss-feeds/\">RSS Feeds</a></li>\n      <li><a rel=\"nofollow\" href=\"/tech-policy/2024/06/ai-trained-on-photos-from-kids-entire-childhood-without-their-consent/?view=mobile\">View Mobile Site</a></li>\n    </ul>\n  </section>\n\n  <section>\n    <ul>\n      <li><a href=\"/contact-us/\">Contact Us</a></li>\n      <li><a href=\"/staff-directory/\">Staff</a></li>\n      <li><a href=\"https://advertising.condenast.com/brands/ars-technica\">Advertise with us</a></li>\n      <li><a href=\"/reprints/\">Reprints</a></li>\n    </ul>\n  </section>\n\n  <section class=\"footer-newsletter\">\n    <div class=\"newsletter-wrapper\">\n      <h3>\n        <a href=\"/newsletters/\" class=\"footer-newsletter-sign-up\">Newsletter Signup</a>\n      </h3>\n      <p>Join the Ars Orbital Transmission mailing list to get weekly updates delivered to your inbox. <a href=\"/newsletters/\" class=\"footer-newsletter-sign-up\">Sign me up &rarr;</a></p>\n\n      <div class=\"footer-social-links\">\n        <a href=\"https://twitter.com/arstechnica\" class=\"footer-social-twitter\">\n          <svg style=\"height: 40px; width: 40px;\" id=\"b\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" viewBox=\"0 0 40 40\">\n            <defs>\n              <clipPath id=\"e\">\n                <rect width=\"40\" height=\"40\" fill=\"none\" />\n              </clipPath>\n              <clipPath id=\"f\">\n                <rect width=\"40\" height=\"40\" fill=\"none\" />\n              </clipPath>\n            </defs>\n            <g id=\"c\">\n              <g id=\"d\">\n                <g clip-path=\"url(#e)\">\n                  <g clip-path=\"url(#f)\">\n                    <path d=\"M16.3,28.1c7.5,0,11.7-6.3,11.7-11.7s0-.4,0-.5c.8-.6,1.5-1.3,2-2.1-.7,.3-1.5,.5-2.4,.6,.9-.5,1.5-1.3,1.8-2.3-.8,.5-1.7,.8-2.6,1-.6-.7-1.4-1.1-2.3-1.2s-1.8,0-2.6,.4c-.8,.4-1.4,1.1-1.8,1.9-.4,.8-.5,1.7-.3,2.6-1.6,0-3.2-.5-4.7-1.2-1.5-.7-2.7-1.8-3.8-3-.5,.9-.7,2-.5,3,.2,1,.9,1.9,1.7,2.5-.7,0-1.3-.2-1.9-.5h0c0,1,.3,1.9,.9,2.7,.6,.7,1.4,1.2,2.4,1.4-.6,.2-1.2,.2-1.9,0,.3,.8,.8,1.5,1.5,2s1.5,.8,2.4,.8c-1.5,1.1-3.2,1.8-5.1,1.8-.3,0-.7,0-1,0,1.9,1.2,4.1,1.8,6.3,1.8\" fill=\"currentColor\" />\n                  </g>\n                </g>\n              </g>\n            </g>\n          </svg>\n        </a>\n        <a href=\"https://mastodon.social/@arstechnica\" class=\"footer-social-mastodon\">\n          <svg style=\"height: 40px; width: 40px;\" id=\"b\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" viewBox=\"0 0 40 40\">\n            <defs>\n              <clipPath id=\"e\">\n                <rect width=\"40\" height=\"40\" fill=\"none\" />\n              </clipPath>\n              <clipPath id=\"f\">\n                <rect width=\"40\" height=\"40\" fill=\"none\" />\n              </clipPath>\n            </defs>\n            <g id=\"c\">\n              <g id=\"d\">\n                <g clip-path=\"url(#e)\">\n                  <g clip-path=\"url(#f)\">\n                    <path d=\"M29.3,16.6c0-4.3-2.8-5.6-2.8-5.6-1.4-.7-3.9-.9-6.5-1h0c-2.6,0-5,.3-6.4,1,0,0-2.8,1.3-2.8,5.6s0,2.2,0,3.4c.1,4.2,.8,8.4,4.7,9.5,1.8,.5,3.4,.6,4.6,.5,2.3-.1,3.5-.8,3.5-.8v-1.6c0,0-1.7,.5-3.5,.4-1.8,0-3.7-.2-4-2.4,0-.2,0-.4,0-.6,0,0,1.8,.4,4,.5,1.4,0,2.7,0,4-.2,2.5-.3,4.7-1.8,5-3.3,.4-2.2,.4-5.4,.4-5.4h0Zm-3.4,5.6h-2.1v-5.1c0-1.1-.5-1.6-1.4-1.6s-1.5,.6-1.5,1.9v2.8h-2.1v-2.8c0-1.3-.5-1.9-1.5-1.9s-1.4,.5-1.4,1.6v5.1h-2.1v-5.3c0-1.1,.3-1.9,.8-2.6,.6-.6,1.3-1,2.2-1s1.9,.4,2.4,1.2l.5,.9,.5-.9c.5-.8,1.3-1.2,2.4-1.2s1.7,.3,2.2,1c.6,.6,.8,1.5,.8,2.6v5.3Z\" fill=\"currentColor\" />\n                  </g>\n                </g>\n              </g>\n            </g>\n          </svg>\n        </a>\n        <a href=\"https://www.facebook.com/arstechnica\" class=\"footer-social-facebook\">\n          <svg style=\"height: 40px; width: 40px;\" id=\"b\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" viewBox=\"0 0 40 40\">\n            <defs>\n              <clipPath id=\"e\">\n                <rect width=\"40\" height=\"40\" fill=\"none\" />\n              </clipPath>\n              <clipPath id=\"f\">\n                <rect width=\"40\" height=\"40\" fill=\"none\" />\n              </clipPath>\n            </defs>\n            <g id=\"c\">\n              <g id=\"d\">\n                <g clip-path=\"url(#e)\">\n                  <g clip-path=\"url(#f)\">\n                    <path d=\"M17.3,13.9v2.8h-2v3.4h2v10h4.2v-10h2.8s.3-1.6,.4-3.4h-3.2v-2.3c0-.3,.5-.8,.9-.8h2.3v-3.5h-3.1c-4.4,0-4.3,3.4-4.3,3.9\" fill=\"currentColor\" />\n                  </g>\n                </g>\n              </g>\n            </g>\n          </svg>\n        </a>\n        <a href=\"https://www.youtube.com/@arstechnica\" class=\"footer-social-youtube\">\n          <svg style=\"height: 40px; width: 40px;\" id=\"b\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" viewBox=\"0 0 40 40\">\n            <defs>\n              <clipPath id=\"e\">\n                <rect width=\"40\" height=\"40\" fill=\"none\" />\n              </clipPath>\n              <clipPath id=\"f\">\n                <rect width=\"40\" height=\"40\" fill=\"none\" />\n              </clipPath>\n            </defs>\n            <g id=\"c\">\n              <g id=\"d\">\n                <g clip-path=\"url(#e)\">\n                  <g clip-path=\"url(#f)\">\n                    <path d=\"M29.6,15.2c-.1-.4-.3-.8-.6-1.1-.3-.3-.7-.5-1.1-.7-1.6-.4-7.8-.4-7.8-.4,0,0-6.3,0-7.8,.4-.4,.1-.8,.3-1.1,.7-.3,.3-.5,.7-.6,1.1-.4,1.6-.4,4.8-.4,4.8,0,0,0,3.3,.4,4.8,.1,.4,.3,.8,.6,1.1,.3,.3,.7,.5,1.1,.7,1.6,.4,7.8,.4,7.8,.4,0,0,6.3,0,7.8-.4,.4-.1,.8-.3,1.1-.7s.5-.7,.6-1.1c.4-1.6,.4-4.8,.4-4.8,0,0,0-3.3-.4-4.8m-11.6,7.8v-5.9l5.2,3-5.2,3Z\" fill=\"currentColor\" />\n                  </g>\n                </g>\n              </g>\n            </g>\n          </svg>\n        </a>\n        <a href=\"https://www.instagram.com/arstechnica/\" class=\"footer-social-instagram\">\n          <svg style=\"height: 40px; width: 40px;\" id=\"b\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" viewBox=\"0 0 40 40\">\n            <defs>\n              <clipPath id=\"e\">\n                <rect width=\"40\" height=\"40\" fill=\"none\" />\n              </clipPath>\n              <clipPath id=\"f\">\n                <rect width=\"40\" height=\"40\" fill=\"none\" />\n              </clipPath>\n            </defs>\n            <g id=\"c\">\n              <g id=\"d\">\n                <g clip-path=\"url(#e)\">\n                  <g clip-path=\"url(#f)\">\n                    <path d=\"M20,10c2.7,0,3.1,0,4.1,0,1.1,0,1.8,.2,2.4,.5,.7,.3,1.2,.6,1.8,1.2,.6,.6,.9,1.1,1.2,1.8,.2,.6,.4,1.4,.5,2.4,0,1.1,0,1.4,0,4.1s0,3.1,0,4.1c0,1.1-.2,1.8-.5,2.4-.3,.7-.6,1.3-1.2,1.8-.6,.6-1.1,.9-1.8,1.2-.6,.2-1.4,.4-2.4,.5-1.1,0-1.4,0-4.1,0s-3.1,0-4.1,0c-1.1,0-1.8-.2-2.4-.5-.7-.3-1.3-.6-1.8-1.2-.5-.5-.9-1.1-1.2-1.8-.2-.6-.4-1.4-.5-2.4,0-1.1,0-1.4,0-4.1s0-3.1,0-4.1c0-1.1,.2-1.8,.5-2.4,.3-.7,.6-1.2,1.2-1.8,.6-.6,1.1-.9,1.8-1.2,.6-.2,1.4-.4,2.4-.5,1.1,0,1.4,0,4.1,0m0,2.5c-2.4,0-2.7,0-3.7,0-.9,0-1.4,.2-1.7,.3-.4,.1-.8,.4-1.1,.7-.3,.3-.5,.6-.7,1.1-.1,.3-.3,.8-.3,1.7,0,1,0,1.3,0,3.7s0,2.7,0,3.7c0,.9,.2,1.4,.3,1.7,.2,.4,.4,.7,.7,1.1,.3,.3,.6,.5,1.1,.7,.3,.1,.8,.3,1.7,.3,1,0,1.3,0,3.7,0s2.7,0,3.7,0c.9,0,1.4-.2,1.7-.3,.4-.2,.7-.4,1.1-.7,.3-.3,.5-.6,.7-1.1,.1-.3,.3-.8,.3-1.7,0-1,0-1.3,0-3.7s0-2.7,0-3.7c0-.9-.2-1.4-.3-1.7-.1-.4-.4-.8-.7-1.1-.3-.3-.7-.5-1.1-.7-.3-.1-.8-.3-1.7-.3-1,0-1.3,0-3.7,0m0,2.2c.7,0,1.4,.1,2,.4,.6,.3,1.2,.7,1.7,1.1,.5,.5,.9,1.1,1.1,1.7,.3,.6,.4,1.3,.4,2s-.1,1.4-.4,2c-.3,.6-.7,1.2-1.1,1.7-.5,.5-1.1,.9-1.7,1.1-.6,.3-1.3,.4-2,.4-1.4,0-2.7-.6-3.7-1.5-1-1-1.5-2.3-1.5-3.7s.6-2.7,1.5-3.7,2.3-1.5,3.7-1.5m0,8.3c.8,0,1.5-.3,2.1-.9,.6-.6,.9-1.3,.9-2.1s-.3-1.5-.9-2.1c-.6-.6-1.3-.9-2.1-.9s-1.5,.3-2.1,.9c-.6,.6-.9,1.3-.9,2.1s.3,1.5,.9,2.1c.6,.6,1.3,.9,2.1,.9m6.6-8.1c0,.4-.2,.7-.4,1s-.6,.4-1,.4-.7-.2-1-.4c-.3-.3-.4-.6-.4-1s.2-.7,.4-1c.3-.3,.6-.4,1-.4s.7,.2,1,.4c.3,.3,.4,.6,.4,1\" fill=\"currentColor\" />\n                  </g>\n                </g>\n              </g>\n            </g>\n          </svg>\n        </a>\n      </div>\n\n    </div>\n  </section>\n</nav>\n\n<section class=\"footer-terms-logo\">\n  <div class=\"cn-logo\">\n    <a href=\"http://condenast.com/\" class=\"icon icon-logo-cn-us\" title=\"Visit Condé Nast\"></a>\n  </div>\n\n  <p id=\"copyright-terms\">\n  CNMN Collection<br>\n  WIRED Media Group<br>\n  © 2024 Condé Nast. All rights reserved. Use of and/or registration on any portion of this site constitutes acceptance of our <a href=\"https://www.condenast.com/user-agreement/\">User Agreement</a> (updated 1/1/20) and <a href=\"https://www.condenast.com/privacy-policy/\">Privacy Policy</a> and <a href=\"/amendment-to-conde-nast-user-agreement-privacy-policy/\">Ars Technica Addendum</a>. Ars may earn compensation on sales from links on this site. <a href=\"/affiliate-link-policy/\">Read our affiliate link policy</a>.<br>\n  <span style=\"display: inline-flex; flex-flow: row nowrap; align-items: center; gap: 5px;\"><a href=\"https://www.condenast.com/privacy-policy/#california\">Your California Privacy Rights</a> | <img src=\"https://cdn.arstechnica.net/wp-content/themes/ars/assets/img/privacyoptions123x59-c5c9972158.png\" style=\"height: 1em; width: auto;\" /> <a id=\"ot-sdk-btn\" class=\"ot-sdk-show-settings\">Do Not Sell My Personal Information</a></span><br>\n  The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Condé Nast.<br>\n  <a href=\"https://www.aboutads.info/\">Ad Choices</a>\n</p>\n</section>\n  </footer>\n  </div>\n\n  <script type=\"text/javascript\" src=\"https://cdn.arstechnica.net/wp-content/themes/ars/assets/js/main-d1ad651ce0.js\"></script>\n\n\n<!-- cache hit 83:single/javascript-footer:a084c10cf9f3b1840bacc10a834ec50f -->\n        \n\n\n    <!-- Taboola -->\n  <script type=\"text/javascript\">\n    window._taboola = window._taboola || [];\n    _taboola.push({\n      flush: true\n    });\n  </script>\n\n  <!-- Parse.ly start -->\n<script type=\"text/plain\" class=\"optanon-category-C0002\" id=\"parsely-cfg\" src=\"//fpa-cdn.arstechnica.com/keys/arstechnica.com/p.js\"></script>\n<!-- Parse.ly end -->\n\n<!-- Memo start -->\n<script type=\"text/javascript\">\n__memo_config = {\n\tpid: ars.MEMO_PID,\n\turl: ars.ARTICLE.url,\n\tauthor: [ars.ARTICLE.authorName],\n\ttitle: ars.ARTICLE.title,\n\tdate: ars.ARTICLE.pubDate,\n};\n(function(){\n\tvar s = document.createElement('script'); \n\ts.async = true; \n\ts.type = 'text/javascript'; \n\ts.src = document.location.protocol + '//cdn.memo.co/js/memo.js';\n\t(document.getElementsByTagName('head')[0] || document.getElementsByTagName('body') [0]).appendChild(s); \n})();\n</script>\n<!-- Memo end -->\n\n  \n  \n    \n<script>\n  // Load the interlude player.\n  window.loadInterludePlayer = function() {\n    const src = 'https://player.cnevids.com/interlude/arstechnica.js';\n\n    // Test that script isn't already loaded.\n    if (document.querySelector('script[src=\"' + src + '\"]')) {\n      return;\n    }\n\n    const s = document.createElement('script');\n    s.setAttribute('async', true);\n    s.setAttribute('src', src);\n    document.body.appendChild(s);\n  };\n\n  (function() {\n    // Only load the interlude player if the container is present.\n    if (!document.querySelector('.ars-interlude-container')) {\n      return;\n    }\n\n    loadInterludePlayer();\n  })();\n</script>\n\n<script id=\"conde-polar\" src=\"https://cdn.mediavoice.com/nativeads/script/condenastcorporate/conde-asa-polar-master.js\" async></script>\n<script type=\"text/javascript\" src=\"//s.skimresources.com/js/100098X1555750.skimlinks.js\"></script>\n<script type='text/javascript' id='snowplow-js-before'>\nwindow.snowplowQueue = window.snowplowQueue || []; window.snowplowContexts = {\"site\":{\"orgId\":\"4gKgcFGUFUvCGFzHakTPfYp85Yi8\",\"orgAppId\":null,\"appVersion\":null,\"env\":\"production\"},\"content\":{\"functionalTags\":null,\"hasBuyButtons\":null,\"noOfRevisions\":null,\"editorNames\":null,\"author_name\":\"Ashley Belanger\",\"contentId\":\"2030521\",\"contentLength\":2,\"contentTitle\":\"AI trained on photos from kids\\u2019 entire childhood without their consent\",\"contentSource\":\"web\",\"authorIds\":\"46028\",\"publishDate\":\"2024-06-10T22:37:03Z\",\"modifiedDate\":\"2024-06-12T13:15:37Z\",\"tags\":\"AI|ai dataset|ai deepfakes|Artificial Intelligence|children's online privacy|generative ai|LAION|LAION-5b|online child safety|openai\",\"contentLang\":\"en-US\",\"galleryName\":null,\"totalGalleryImages\":null,\"wordCount\":1524,\"contentType\":null,\"templateType\":\"article_standard_two_column\",\"primaryTag\":null,\"contentFlag\":\"news\",\"isCommerceContent\":null,\"pageTypeProperties\":null,\"section\":\"tech policy\",\"subsection\":null,\"subsection2\":null,\"dataSource\":\"web\",\"content_type\":\"article\"},\"syndication\":{\"content\":null,\"originalSource\":null,\"originalContentLanguage\":null},\"page\":{\"canonical\":\"https:\\/\\/arstechnica.com\\/tech-policy\\/2024\\/06\\/ai-trained-on-photos-from-kids-entire-childhood-without-their-consent\\/\",\"syndicatorUrl\":null},\"user\":{\"amguuid\":null}}; window.snowplowConfig = {\"SNOWPLOW_COLLECTOR\":\"c.arstechnica.com\",\"SNOWPLOW_SCRIPT\":\"https:\\/\\/globalservices.conde.digital\\/p77xzrbz9z.js\",\"AVO_API_KEY\":\"FTJO6mVPBIzdGhjn2Ruy\",\"APP_ID\":\"ars-technica\",\"APP_NAME\":\"ars-technica\",\"APP_ENV\":\"production\",\"APP_VERSION\":\"1.0.0\",\"COOKIE_DOMAIN\":\".arstechnica.com\"};\n</script>\n<script type='text/javascript' src='https://cdn.arstechnica.net/wp-content/mu-plugins/ars-snowplow/ars-snowplow-js/dist/main-1-0-4.js?ver=1.0.4' id='snowplow-js'></script>\n<script type='text/javascript' src='https://cdn.arstechnica.net/wp-content/plugins/article-forum-connect/public/js/iframeResizer.min.js?ver=1.2.2' id='article_forum_connect_iframe_resizer-js'></script>\n<script type='text/javascript' src='https://cdn.arstechnica.net/wp-content/plugins/article-forum-connect/public/js/iframe.js?ver=1.2.2' id='article_forum_connect_iframe-js'></script>\n  </body>\n\n  </html>","oembed":false,"readabilityObject":{"title":"AI trained on photos from kids’ entire childhood without their consent","content":"<div id=\"readability-page-1\" class=\"page\"><div itemprop=\"articleBody\">\n                                    \n<figure>\n  <img src=\"https://cdn.arstechnica.net/wp-content/uploads/2024/06/GettyImages-1328876959-800x534.jpg\" alt=\"AI trained on photos from kids’ entire childhood without their consent\">\n      <figcaption></figcaption>  </figure>\n\n  \n\n\n\n\n<!-- cache hit 83:single/related:a084c10cf9f3b1840bacc10a834ec50f --><!-- empty -->\n<p>Photos of Brazilian kids—sometimes spanning their entire childhood—have been used without their consent to power AI tools, including popular image generators like Stable Diffusion, Human Rights Watch (HRW) <a href=\"https://www.hrw.org/news/2024/06/10/brazil-childrens-personal-photos-misused-power-ai-tools\">warned on Monday</a>.</p>\n<p>This act poses urgent privacy risks to kids and seems to increase risks of non-consensual AI-generated images bearing their likenesses, HRW's report said.</p>\n<p>An HRW researcher, Hye Jung Han, helped expose the problem. She analyzed \"less than 0.0001 percent\" of LAION-5B, a dataset built from Common Crawl snapshots of the public web. The dataset does not contain the actual photos but includes image-text pairs derived from 5.85 billion images and captions posted online since 2008.</p>\n<p>Among those images linked in the dataset, Han found 170 photos of children from at least 10 Brazilian states. These were mostly family photos uploaded to personal and parenting blogs most Internet surfers wouldn't easily stumble upon, \"as well as stills from YouTube videos with small view counts, seemingly uploaded to be shared with family and friends,\" Wired <a href=\"https://www.wired.com/story/ai-tools-are-secretly-training-on-real-childrens-faces/\">reported</a>.</p>\n<p>LAION, the German nonprofit that created the dataset, has worked with HRW to remove the links to the children's images in the dataset.</p>\n<p>That may not completely resolve the problem, though. HRW's report warned that the removed links are \"likely to be a significant undercount of the total amount of children’s personal data that exists in LAION-5B.\" Han told Wired that she fears that the dataset may still be referencing personal photos of kids \"from all over the world.\"</p>\n<p>Removing the links also does not remove the images from the public web, where they can still be referenced and used in other AI datasets, particularly those relying on Common Crawl, LAION's spokesperson, Nate Tyler, told Ars.</p>\n<p>\"This is a larger and very concerning issue, and as a nonprofit, volunteer organization, we will do our part to help,\" Tyler told Ars.</p>\n<p>Han told Ars that \"Common Crawl should stop scraping children’s personal data, given the privacy risks involved and the potential for new forms of misuse.\"</p>\n<p>According to HRW's analysis, many of the Brazilian children's identities were \"easily traceable,\" due to children's names and locations being included in image captions that were processed when building the LAION dataset.</p>                                                                        \n                                                                                \n<p>And at a time when <a href=\"https://arstechnica.com/tech-policy/2024/03/florida-middle-schoolers-charged-with-making-deepfake-nudes-of-classmates/\">middle</a> and <a href=\"https://arstechnica.com/tech-policy/2023/11/deepfake-nudes-of-high-schoolers-spark-police-probe-in-nj/\">high school-aged students</a> are <a href=\"https://arstechnica.com/tech-policy/2024/01/surge-of-fake-ai-child-sex-images-thwarts-investigations-into-real-child-abuse/\">at greater risk of being targeted</a> by bullies or bad actors turning \"innocuous photos\" into explicit imagery, it's possible that AI tools may be better equipped to generate AI clones of kids whose images are referenced in AI datasets, HRW suggested.</p>\n<p>\"The photos reviewed span the entirety of childhood,\" HRW's report said. \"They capture intimate moments of babies being born into the gloved hands of doctors, young children blowing out candles on their birthday cake or dancing in their underwear at home, students giving a presentation at school, and teenagers posing for photos at their high school’s carnival.\"</p>\n<p>There is less risk that the Brazilian kids' photos are currently powering AI tools since \"all publicly available versions of LAION-5B were taken down\" <a href=\"https://laion.ai/notes/laion-maintenance/\">in December</a>, Tyler told Ars. That decision came out of an \"abundance of caution\" after a Stanford University <a href=\"https://purl.stanford.edu/kh752sm9123\">report</a> \"found links in the dataset pointing to illegal content on the public web,\" Tyler said, including 3,226 suspected instances of child sexual abuse material.</p>\n<p>Han told Ars that \"the version of the dataset that we examined pre-dates LAION’s temporary removal of its dataset in December 2023.\" The dataset will not be available again until LAION determines that all flagged illegal content has been removed.</p>\n<p>\"LAION is currently working with the Internet Watch Foundation, the Canadian Centre for Child Protection, Stanford, and Human Rights Watch to remove all known references to illegal content from LAION-5B,\" Tyler told Ars. \"We are grateful for their support and hope to republish a revised LAION-5B soon.\"</p>\n<p>In Brazil, \"at least 85 girls\" have reported classmates harassing them by using AI tools to \"create sexually explicit deepfakes of the girls based on photos taken from their social media profiles,\" HRW reported. Once these explicit deepfakes are posted online, they can inflict \"lasting harm,\" HRW warned, potentially remaining online for their entire lives.</p>\n<p>“Children should not have to live in fear that their photos might be stolen and weaponized against them,” Han said. “The government should urgently adopt policies to protect children’s data from AI-fueled misuse.”</p>\n<p>Ella Irwin, the SVP of Integrity for Stable Diffusion maker&nbsp;Stability AI provided Ars with a statement, confirming that \"Stability AI models were trained on a filtered subset of the LAION-5B dataset. In addition, we subsequently fine-tuned these models to mitigate residual behaviours.\"</p>\n<p>\"Stability AI is committed to preventing the misuse of AI,\" Irwin said. \"We prohibit the use of our image models and services for unlawful activity, including attempts to edit or create non-consensual content.”</p>\n\n                                                </div></div>","textContent":"\n                                    \n\n  \n        \n\n  \n\n\n\n\n\nPhotos of Brazilian kids—sometimes spanning their entire childhood—have been used without their consent to power AI tools, including popular image generators like Stable Diffusion, Human Rights Watch (HRW) warned on Monday.\nThis act poses urgent privacy risks to kids and seems to increase risks of non-consensual AI-generated images bearing their likenesses, HRW's report said.\nAn HRW researcher, Hye Jung Han, helped expose the problem. She analyzed \"less than 0.0001 percent\" of LAION-5B, a dataset built from Common Crawl snapshots of the public web. The dataset does not contain the actual photos but includes image-text pairs derived from 5.85 billion images and captions posted online since 2008.\nAmong those images linked in the dataset, Han found 170 photos of children from at least 10 Brazilian states. These were mostly family photos uploaded to personal and parenting blogs most Internet surfers wouldn't easily stumble upon, \"as well as stills from YouTube videos with small view counts, seemingly uploaded to be shared with family and friends,\" Wired reported.\nLAION, the German nonprofit that created the dataset, has worked with HRW to remove the links to the children's images in the dataset.\nThat may not completely resolve the problem, though. HRW's report warned that the removed links are \"likely to be a significant undercount of the total amount of children’s personal data that exists in LAION-5B.\" Han told Wired that she fears that the dataset may still be referencing personal photos of kids \"from all over the world.\"\nRemoving the links also does not remove the images from the public web, where they can still be referenced and used in other AI datasets, particularly those relying on Common Crawl, LAION's spokesperson, Nate Tyler, told Ars.\n\"This is a larger and very concerning issue, and as a nonprofit, volunteer organization, we will do our part to help,\" Tyler told Ars.\nHan told Ars that \"Common Crawl should stop scraping children’s personal data, given the privacy risks involved and the potential for new forms of misuse.\"\nAccording to HRW's analysis, many of the Brazilian children's identities were \"easily traceable,\" due to children's names and locations being included in image captions that were processed when building the LAION dataset.                                                                        \n                                                                                \nAnd at a time when middle and high school-aged students are at greater risk of being targeted by bullies or bad actors turning \"innocuous photos\" into explicit imagery, it's possible that AI tools may be better equipped to generate AI clones of kids whose images are referenced in AI datasets, HRW suggested.\n\"The photos reviewed span the entirety of childhood,\" HRW's report said. \"They capture intimate moments of babies being born into the gloved hands of doctors, young children blowing out candles on their birthday cake or dancing in their underwear at home, students giving a presentation at school, and teenagers posing for photos at their high school’s carnival.\"\nThere is less risk that the Brazilian kids' photos are currently powering AI tools since \"all publicly available versions of LAION-5B were taken down\" in December, Tyler told Ars. That decision came out of an \"abundance of caution\" after a Stanford University report \"found links in the dataset pointing to illegal content on the public web,\" Tyler said, including 3,226 suspected instances of child sexual abuse material.\nHan told Ars that \"the version of the dataset that we examined pre-dates LAION’s temporary removal of its dataset in December 2023.\" The dataset will not be available again until LAION determines that all flagged illegal content has been removed.\n\"LAION is currently working with the Internet Watch Foundation, the Canadian Centre for Child Protection, Stanford, and Human Rights Watch to remove all known references to illegal content from LAION-5B,\" Tyler told Ars. \"We are grateful for their support and hope to republish a revised LAION-5B soon.\"\nIn Brazil, \"at least 85 girls\" have reported classmates harassing them by using AI tools to \"create sexually explicit deepfakes of the girls based on photos taken from their social media profiles,\" HRW reported. Once these explicit deepfakes are posted online, they can inflict \"lasting harm,\" HRW warned, potentially remaining online for their entire lives.\n“Children should not have to live in fear that their photos might be stolen and weaponized against them,” Han said. “The government should urgently adopt policies to protect children’s data from AI-fueled misuse.”\nElla Irwin, the SVP of Integrity for Stable Diffusion maker Stability AI provided Ars with a statement, confirming that \"Stability AI models were trained on a filtered subset of the LAION-5B dataset. In addition, we subsequently fine-tuned these models to mitigate residual behaviours.\"\n\"Stability AI is committed to preventing the misuse of AI,\" Irwin said. \"We prohibit the use of our image models and services for unlawful activity, including attempts to edit or create non-consensual content.”\n\n                                                ","length":5266,"excerpt":"Kids \"easily traceable\" from photos used to train AI models, advocates warn.","byline":"Ashley Belanger\n    -    Jun 10, 2024 10:37 pm UTC","dir":null,"siteName":"Ars Technica","lang":"en-us"},"finalizedMeta":{"title":"AI trained on photos from kids’ entire childhood without their consent","description":"Kids \"easily traceable\" from photos used to train AI models, advocates warn.","author":false,"creator":"@ashleynbelanger","publisher":false,"date":"2024-06-12T13:15:37+00:00","topics":[]},"jsonLd":{"@type":false,"headline":false,"description":false,"image":[],"mainEntityOfPage":{"@type":false,"@id":false},"datePublished":false,"dateModified":false,"isAccessibleForFree":false,"isPartOf":{"@type":[],"name":false,"productID":false},"discussionUrl":false,"license":false,"author":{"@type":false,"name":false,"description":false,"sameAs":false,"image":{"@type":false,"url":false},"givenName":false,"familyName":false,"alternateName":false,"publishingPrinciples":false},"publisher":{"@type":false,"name":false,"description":false,"sameAs":false,"logo":{"@type":false,"url":false},"publishingPrinciples":false},"editor":{"@type":false,"name":false,"description":false,"sameAs":false,"image":{"@type":false,"url":false},"givenName":false,"familyName":false,"alternateName":false,"publishingPrinciples":false}},"twitterObj":false,"status":200,"metadata":{"author":false,"title":"AI trained on photos from kids’ entire childhood without their consent | Ars Technica","description":"Kids \"easily traceable\" from photos used to train AI models, advocates warn.","canonical":"https://arstechnica.com/tech-policy/2024/06/ai-trained-on-photos-from-kids-entire-childhood-without-their-consent/","keywords":[],"image":"https://cdn.arstechnica.net/wp-content/uploads/2024/06/GettyImages-1328876959-800x534.jpg","firstParagraph":"Front page layout"},"dublinCore":{},"opengraph":{"title":"AI trained on photos from kids’ entire childhood without their consent","description":"Kids \"easily traceable\" from photos used to train AI models, advocates warn.","url":"https://arstechnica.com/tech-policy/2024/06/ai-trained-on-photos-from-kids-entire-childhood-without-their-consent/","site_name":"Ars Technica","locale":false,"type":"article","typeObject":{"published_time":"2024-06-10T22:37:03+00:00","modified_time":"2024-06-12T13:15:37+00:00","author":false,"publisher":false,"section":false,"tag":[]},"image":"https://cdn.arstechnica.net/wp-content/uploads/2024/06/GettyImages-1328876959-760x380.jpg"},"twitter":{"site":"@arstechnica","description":"Kids \"easily traceable\" from photos used to train AI models, advocates warn.","card":"summary_large_image","creator":"@ashleynbelanger","title":"AI trained on photos from kids’ entire childhood without their consent","image":false,"url":"https://arstechnica.com/tech-policy/2024/06/ai-trained-on-photos-from-kids-entire-childhood-without-their-consent/","domain":"arstechnica.com","image:src":"https://cdn.arstechnica.net/wp-content/uploads/2024/06/GettyImages-1328876959-760x380.jpg","image:width":"760","image:height":"380","partner":"tfwp"},"archivedData":{"link":"https://web.archive.org/web/20240702203906/https://arstechnica.com/tech-policy/2024/06/ai-trained-on-photos-from-kids-entire-childhood-without-their-consent/","wayback":"https://web.archive.org/web/20240702203906/https://arstechnica.com/tech-policy/2024/06/ai-trained-on-photos-from-kids-entire-childhood-without-their-consent/"}}}