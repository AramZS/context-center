{"initialLink":"https://acoup.blog/2023/02/17/collections-on-chatgpt/","sanitizedLink":"https://acoup.blog/2023/02/17/collections-on-chatgpt/","finalLink":"https://acoup.blog/2023/02/17/collections-on-chatgpt/","htmlEmbed":"<script>window.contexterSetup=window.contexterSetup||function(){window.contexterSetupComplete=!0;class ContexterLink extends HTMLAnchorElement{constructor(){super()}connectedCallback(){this.setAttribute(\"target\",\"_blank\")}}customElements.define(\"contexter-link\",ContexterLink,{extends:\"a\"}),customElements.define(\"contexter-inner\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__inner\"}}),customElements.define(\"contexter-thumbnail\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__thumbnail\"}}),customElements.define(\"contexter-byline\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__byline\"}}),customElements.define(\"contexter-keywordset\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__keywordset\"}}),customElements.define(\"contexter-linkset\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__linkset\"}}),customElements.define(\"contexter-meta\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__meta\"}}),customElements.define(\"contexter-summary\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"p-summary entry-summary\"}}),customElements.define(\"contexter-box-head\",class extends HTMLElement{constructor(){super()}connectedCallback(){this.className=\"contexter-box__head\"}}),customElements.define(\"contexter-box-inner\",class extends HTMLElement{constructor(){super()}connectedCallback(){}});class ContexterBox extends HTMLElement{constructor(){super(),this.first=!0,this.shadow=this.attachShadow({mode:\"open\"})}connectedCallback(){if(this.first){this.first=!1;var style=document.createElement(\"style\"),lightDomStyle=(style.innerHTML=`:host {--background: #f5f6f7;--border: darkblue;--blue: #0000ee;--font-color: black;--inner-border: black;font-family: Franklin,Arial,Helvetica,sans-serif;font-size: 14px;background: var(--background);width: 600px;color: var(--font-color);min-height: 90px;display: block;padding: 8px;border: 1px solid var(--border);cursor: pointer;box-sizing: border-box;margin: 6px;contain: content;margin: 6px auto;}// can only select top-level nodes with slotted::slotted(*) {max-width: 100%;display:block;}::slotted([slot=thumbnail]) {max-width: 100%;display:block;}::slotted([slot=header]) {width: 100%;font-size: 1.25rem;font-weight: bold;display:block;margin-bottom: 6px;}::slotted([slot=author]) {max-width: 50%;font-size: 12px;display:inline-block;float: left;}::slotted([slot=time]) {max-width: 50%;font-size: 12px;display:inline-block;float: right;}::slotted([slot=summary]) {width: 100%;margin-top: 6px;padding: 10px 2px;border-top: 1px solid var(--inner-border);font-size: 15px;display:inline-block;margin-bottom: 6px;}contexter-meta {height: auto;margin-bottom: 4px;width: 100%;display: grid;position: relative;min-height: 16px;grid-template-columns: repeat(2, 1fr);}::slotted([slot=keywords]) {width: 80%;padding: 2px 4px;border-top: 1px solid var(--inner-border);font-size: 11px;display: block;float: right;font-style: italic;text-align: right;grid-column: 2/2;grid-row: 1;align-self: end;justify-self: end;}::slotted([slot=keywords]):empty {border-top: 0px solid var(--inner-border);}::slotted([slot=archive-link]) {font-size: 1em;display: inline;}::slotted([slot=archive-link])::after {content: \"|\";display: inline;color: var(--font-color);text-decoration: none;margin: 0 .5em;}::slotted([slot=read-link]) {font-size: 1em;display: inline;}contexter-linkset {width: 80%;padding: 2px 4px;font-size: 13px;float: left;font-weight: bold;grid-row: 1;grid-column: 1/2;align-self: end;justify-self: start;}/* Extra small devices (phones, 600px and down) */@media only screen and (max-width: 600px) {:host {width: 310px;}}/* Small devices (portrait tablets and large phones, 600px and up) */@media only screen and (min-width: 600px) {...}/* Medium devices (landscape tablets, 768px and up) */@media only screen and (min-width: 768px) {...}/* Large devices (laptops/desktops, 992px and up) */@media only screen and (min-width: 992px) {...}/* Extra large devices (large laptops and desktops, 1200px and up) */@media only screen and (min-width: 1200px) {...}@media (prefers-color-scheme: dark){:host {--background: #354150;--border: #1f2b37;--blue: #55b0ff;--font-color: #ffffff;--inner-border: #787a7c;background: var(--background);border: 1px solid var(--border)}}`,document.createElement(\"style\"));lightDomStyle.innerHTML=`contexter-box {contain: content;}contexter-box .read-link {font-weight: bold;}contexter-box a {color: #0000ee;}contexter-box img {width: 100%;border: 0;padding: 0;margin: 0;}/* Extra small devices (phones, 600px and down) */@media only screen and (max-width: 600px) {...}/* Small devices (portrait tablets and large phones, 600px and up) */@media only screen and (min-width: 600px) {...}/* Medium devices (landscape tablets, 768px and up) */@media only screen and (min-width: 768px) {...}/* Large devices (laptops/desktops, 992px and up) */@media only screen and (min-width: 992px) {...}/* Extra large devices (large laptops and desktops, 1200px and up) */@media only screen and (min-width: 1200px) {...}@media (prefers-color-scheme: dark){contexter-box a {color: #55b0ff;}}`,this.appendChild(lightDomStyle),this.shadow.appendChild(style);const innerContainer=document.createElement(\"contexter-box-inner\"),innerSlotThumbnail=(this.shadow.appendChild(innerContainer),document.createElement(\"slot\")),innerSlotHeader=(innerSlotThumbnail.name=\"thumbnail\",innerContainer.appendChild(innerSlotThumbnail),document.createElement(\"slot\")),innerSlotAuthor=(innerSlotHeader.name=\"header\",innerContainer.appendChild(innerSlotHeader),document.createElement(\"slot\")),innerSlotTime=(innerSlotAuthor.name=\"author\",innerContainer.appendChild(innerSlotAuthor),document.createElement(\"slot\")),innerSlotSummary=(innerSlotTime.name=\"time\",innerContainer.appendChild(innerSlotTime),document.createElement(\"slot\")),metaContainer=(innerSlotSummary.name=\"summary\",innerContainer.appendChild(innerSlotSummary),document.createElement(\"contexter-meta\")),innerSlotInfo=(innerContainer.appendChild(metaContainer),document.createElement(\"slot\")),linkContainer=(innerSlotInfo.name=\"keywords\",metaContainer.appendChild(innerSlotInfo),document.createElement(\"contexter-linkset\")),innerSlotArchiveLink=(metaContainer.appendChild(linkContainer),document.createElement(\"slot\")),innerSlotReadLink=(innerSlotArchiveLink.name=\"archive-link\",linkContainer.appendChild(innerSlotArchiveLink),document.createElement(\"slot\"));innerSlotReadLink.name=\"read-link\",linkContainer.appendChild(innerSlotReadLink),this.className=\"contexter-box\",this.onclick=e=>{if(!e.target.className.includes(\"read-link\")&&!e.target.className.includes(\"title-link\")){const mainLinks=this.querySelectorAll(\"a.main-link\");mainLinks[0].click()}}}}}customElements.define(\"contexter-box\",ContexterBox)},window.contexterSetupComplete||window.contexterSetup();</script><contexter-box class=\"link-card h-entry hentry\" itemscope=\"\" itemtype=\"https://schema.org/CreativeWork\"><contexter-thumbnail class=\"thumbnail\" slot=\"thumbnail\"></contexter-thumbnail><contexter-box-head slot=\"header\" class=\"p-name entry-title\" itemprop=\"headline\"><contexter-box-head slot=\"header\" class=\"p-name entry-title\" itemprop=\"headline\"><a is=\"contexter-link\" href=\"https://acoup.blog/2023/02/17/collections-on-chatgpt/\" itemprop=\"url\">Collections: On ChatGPT</a></contexter-box-head></contexter-box-head><time class=\"dt-published published\" slot=\"time\" itemprop=\"datePublished\" datetime=\"2023-02-17T22:47:59.000Z\">2/17/2023</time><contexter-summary class=\"p-summary entry-summary\" itemprop=\"abstract\" slot=\"summary\"><p>So I stirred up a bit of conversation on Twitter last week when I noted that I had already been handed ChatGPT produced assignments. For those who are unaware, ChatGPT is an ‘AI’ chatbo…</p></contexter-summary><contexter-keywordset itemprop=\"keywords\" slot=\"keywords\"></contexter-keywordset><a href=\"https://web.archive.org/web/20230425140625/https://acoup.blog/2023/02/17/collections-on-chatgpt/\" is=\"contexter-link\" target=\"_blank\" rel=\"timemap\" class=\"read-link archive-link\" itemprop=\"archivedAt\" slot=\"archive-link\">Archived</a><a is=\"contexter-link\" href=\"https://acoup.blog/2023/02/17/collections-on-chatgpt/\" class=\"read-link main-link\" itemprop=\"sameAs\" slot=\"read-link\">Read</a></contexter-box>","linkId":"2acea29cadf975c6f9cf53f8414d047d85619e8d","data":{"originalLink":"https://acoup.blog/2023/02/17/collections-on-chatgpt/","sanitizedLink":"https://acoup.blog/2023/02/17/collections-on-chatgpt/","canonical":"https://acoup.blog/2023/02/17/collections-on-chatgpt/","htmlText":"<!DOCTYPE html>\n<html lang=\"en-US\">\n<head>\n<meta charset=\"UTF-8\">\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1\">\n<link rel=\"profile\" href=\"http://gmpg.org/xfn/11\">\n\n<title>Collections: On ChatGPT &#8211; A Collection of Unmitigated Pedantry</title>\n<script type=\"text/javascript\">\n  WebFontConfig = {\"google\":{\"families\":[\"Fondamento:r:latin,latin-ext\"]},\"api_url\":\"https:\\/\\/fonts-api.wp.com\\/css\"};\n  (function() {\n    var wf = document.createElement('script');\n    wf.src = 'https://acoup.blog/wp-content/mu-plugins/wpcomsh/vendor/automattic/custom-fonts/js/webfont.js';\n    wf.type = 'text/javascript';\n    wf.async = 'true';\n    var s = document.getElementsByTagName('script')[0];\n    s.parentNode.insertBefore(wf, s);\n\t})();\n</script><style id=\"jetpack-custom-fonts-css\">.wf-active #tinymce h1, .wf-active #tinymce h2, .wf-active #tinymce h3, .wf-active #tinymce h4, .wf-active #tinymce h5, .wf-active #tinymce h6, .wf-active .comment-content h1, .wf-active .comment-content h2, .wf-active .comment-content h3, .wf-active .comment-content h4, .wf-active .comment-content h5, .wf-active .comment-content h6, .wf-active .entry-content h1, .wf-active .entry-content h2, .wf-active .entry-content h3, .wf-active .entry-content h4, .wf-active .entry-content h5, .wf-active .entry-content h6, .wf-active .entry-summary h1, .wf-active .entry-summary h2, .wf-active .entry-summary h3, .wf-active .entry-summary h4, .wf-active .entry-summary h5, .wf-active .entry-summary h6, .wf-active .widget_text h1, .wf-active .widget_text h2, .wf-active .widget_text h3, .wf-active .widget_text h4, .wf-active .widget_text h5, .wf-active .widget_text h6{font-family:\"Fondamento\",cursive;font-style:normal;font-weight:400}.wf-active h1{font-style:normal;font-weight:400}.wf-active h2{font-style:normal;font-weight:400}.wf-active h3{font-style:normal;font-weight:400}.wf-active h4{font-style:normal;font-weight:400}.wf-active h5{font-style:normal;font-weight:400}.wf-active h6{font-style:normal;font-weight:400}.wf-active blockquote h1, .wf-active blockquote h2, .wf-active blockquote h3, .wf-active blockquote h4{font-family:\"Fondamento\",cursive;font-weight:400;font-style:normal}.wf-active div#jp-relatedposts h3.jp-relatedposts-headline em{font-family:\"Fondamento\",cursive;font-style:normal;font-weight:400}.wf-active .comment-reply-title, .wf-active .comments-title{font-family:\"Fondamento\",cursive;font-weight:400;font-style:normal}.wf-active .image-post-title{font-family:\"Fondamento\",cursive;font-weight:400;font-style:normal}.wf-active .page-header:not(.page-header-light) h1{font-style:normal;font-weight:400}.wf-active .entry-title{font-family:\"Fondamento\",cursive;font-style:normal;font-weight:400}.wf-active #post-cover-image .cover-meta .single-post-title{font-family:\"Fondamento\",cursive;font-style:normal;font-weight:400}.wf-active #hero-header .site-title{font-family:\"Fondamento\",cursive;font-style:normal;font-weight:400}.wf-active .site-header .site-title{font-style:normal;font-weight:400}.wf-active .site-header .site-description{font-style:normal;font-weight:400}</style>\n<meta name='robots' content='max-image-preview:large' />\n<link rel='dns-prefetch' href='//s0.wp.com' />\n<link rel='dns-prefetch' href='//secure.gravatar.com' />\n<link rel='dns-prefetch' href='//stats.wp.com' />\n<link rel='dns-prefetch' href='//widgets.wp.com' />\n<link rel='dns-prefetch' href='//jetpack.wordpress.com' />\n<link rel='dns-prefetch' href='//public-api.wordpress.com' />\n<link rel='dns-prefetch' href='//0.gravatar.com' />\n<link rel='dns-prefetch' href='//1.gravatar.com' />\n<link rel='dns-prefetch' href='//2.gravatar.com' />\n<link rel='dns-prefetch' href='//i0.wp.com' />\n<link rel='dns-prefetch' href='//c0.wp.com' />\n<link href='https://fonts.gstatic.com' crossorigin rel='preconnect' />\n<link rel=\"alternate\" type=\"application/rss+xml\" title=\"A Collection of Unmitigated Pedantry &raquo; Feed\" href=\"https://acoup.blog/feed/\" />\n<link rel=\"alternate\" type=\"application/rss+xml\" title=\"A Collection of Unmitigated Pedantry &raquo; Comments Feed\" href=\"https://acoup.blog/comments/feed/\" />\n<link rel=\"alternate\" type=\"application/rss+xml\" title=\"A Collection of Unmitigated Pedantry &raquo; Collections: On ChatGPT Comments Feed\" href=\"https://acoup.blog/2023/02/17/collections-on-chatgpt/feed/\" />\n\t\t<!-- This site uses the Google Analytics by MonsterInsights plugin v8.14.1 - Using Analytics tracking - https://www.monsterinsights.com/ -->\n\t\t\t\t\t\t\t<script src=\"//www.googletagmanager.com/gtag/js?id=G-DPPH6QBP1L\"  data-cfasync=\"false\" data-wpfc-render=\"false\" type=\"text/javascript\" async></script>\n\t\t\t<script data-cfasync=\"false\" data-wpfc-render=\"false\" type=\"text/javascript\">\n\t\t\t\tvar mi_version = '8.14.1';\n\t\t\t\tvar mi_track_user = true;\n\t\t\t\tvar mi_no_track_reason = '';\n\t\t\t\t\n\t\t\t\t\t\t\t\tvar disableStrs = [\n\t\t\t\t\t\t\t\t\t\t'ga-disable-G-DPPH6QBP1L',\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t'ga-disable-UA-198425729-1',\n\t\t\t\t\t\t\t\t\t];\n\n\t\t\t\t/* Function to detect opted out users */\n\t\t\t\tfunction __gtagTrackerIsOptedOut() {\n\t\t\t\t\tfor (var index = 0; index < disableStrs.length; index++) {\n\t\t\t\t\t\tif (document.cookie.indexOf(disableStrs[index] + '=true') > -1) {\n\t\t\t\t\t\t\treturn true;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\treturn false;\n\t\t\t\t}\n\n\t\t\t\t/* Disable tracking if the opt-out cookie exists. */\n\t\t\t\tif (__gtagTrackerIsOptedOut()) {\n\t\t\t\t\tfor (var index = 0; index < disableStrs.length; index++) {\n\t\t\t\t\t\twindow[disableStrs[index]] = true;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\t/* Opt-out function */\n\t\t\t\tfunction __gtagTrackerOptout() {\n\t\t\t\t\tfor (var index = 0; index < disableStrs.length; index++) {\n\t\t\t\t\t\tdocument.cookie = disableStrs[index] + '=true; expires=Thu, 31 Dec 2099 23:59:59 UTC; path=/';\n\t\t\t\t\t\twindow[disableStrs[index]] = true;\n\t\t\t\t\t}\n\t\t\t\t}\n\n\t\t\t\tif ('undefined' === typeof gaOptout) {\n\t\t\t\t\tfunction gaOptout() {\n\t\t\t\t\t\t__gtagTrackerOptout();\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\t\t\t\t\twindow.dataLayer = window.dataLayer || [];\n\n\t\t\t\twindow.MonsterInsightsDualTracker = {\n\t\t\t\t\thelpers: {},\n\t\t\t\t\ttrackers: {},\n\t\t\t\t};\n\t\t\t\tif (mi_track_user) {\n\t\t\t\t\tfunction __gtagDataLayer() {\n\t\t\t\t\t\tdataLayer.push(arguments);\n\t\t\t\t\t}\n\n\t\t\t\t\tfunction __gtagTracker(type, name, parameters) {\n\t\t\t\t\t\tif (!parameters) {\n\t\t\t\t\t\t\tparameters = {};\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif (parameters.send_to) {\n\t\t\t\t\t\t\t__gtagDataLayer.apply(null, arguments);\n\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif (type === 'event') {\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tparameters.send_to = monsterinsights_frontend.v4_id;\n\t\t\t\t\t\t\tvar hookName = name;\n\t\t\t\t\t\t\tif (typeof parameters['event_category'] !== 'undefined') {\n\t\t\t\t\t\t\t\thookName = parameters['event_category'] + ':' + name;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tif (typeof MonsterInsightsDualTracker.trackers[hookName] !== 'undefined') {\n\t\t\t\t\t\t\t\tMonsterInsightsDualTracker.trackers[hookName](parameters);\n\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t__gtagDataLayer('event', name, parameters);\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tparameters.send_to = monsterinsights_frontend.ua;\n\t\t\t\t\t\t\t__gtagDataLayer(type, name, parameters);\n\t\t\t\t\t\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t__gtagDataLayer.apply(null, arguments);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t__gtagTracker('js', new Date());\n\t\t\t\t\t__gtagTracker('set', {\n\t\t\t\t\t\t'developer_id.dZGIzZG': true,\n\t\t\t\t\t\t\t\t\t\t\t});\n\t\t\t\t\t\t\t\t\t\t__gtagTracker('config', 'G-DPPH6QBP1L', {\"forceSSL\":\"true\",\"link_attribution\":\"true\"} );\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t__gtagTracker('config', 'UA-198425729-1', {\"forceSSL\":\"true\",\"link_attribution\":\"true\"} );\n\t\t\t\t\t\t\t\t\t\twindow.gtag = __gtagTracker;\t\t\t\t\t\t\t\t\t\t(function () {\n\t\t\t\t\t\t/* https://developers.google.com/analytics/devguides/collection/analyticsjs/ */\n\t\t\t\t\t\t/* ga and __gaTracker compatibility shim. */\n\t\t\t\t\t\tvar noopfn = function () {\n\t\t\t\t\t\t\treturn null;\n\t\t\t\t\t\t};\n\t\t\t\t\t\tvar newtracker = function () {\n\t\t\t\t\t\t\treturn new Tracker();\n\t\t\t\t\t\t};\n\t\t\t\t\t\tvar Tracker = function () {\n\t\t\t\t\t\t\treturn null;\n\t\t\t\t\t\t};\n\t\t\t\t\t\tvar p = Tracker.prototype;\n\t\t\t\t\t\tp.get = noopfn;\n\t\t\t\t\t\tp.set = noopfn;\n\t\t\t\t\t\tp.send = function () {\n\t\t\t\t\t\t\tvar args = Array.prototype.slice.call(arguments);\n\t\t\t\t\t\t\targs.unshift('send');\n\t\t\t\t\t\t\t__gaTracker.apply(null, args);\n\t\t\t\t\t\t};\n\t\t\t\t\t\tvar __gaTracker = function () {\n\t\t\t\t\t\t\tvar len = arguments.length;\n\t\t\t\t\t\t\tif (len === 0) {\n\t\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\tvar f = arguments[len - 1];\n\t\t\t\t\t\t\tif (typeof f !== 'object' || f === null || typeof f.hitCallback !== 'function') {\n\t\t\t\t\t\t\t\tif ('send' === arguments[0]) {\n\t\t\t\t\t\t\t\t\tvar hitConverted, hitObject = false, action;\n\t\t\t\t\t\t\t\t\tif ('event' === arguments[1]) {\n\t\t\t\t\t\t\t\t\t\tif ('undefined' !== typeof arguments[3]) {\n\t\t\t\t\t\t\t\t\t\t\thitObject = {\n\t\t\t\t\t\t\t\t\t\t\t\t'eventAction': arguments[3],\n\t\t\t\t\t\t\t\t\t\t\t\t'eventCategory': arguments[2],\n\t\t\t\t\t\t\t\t\t\t\t\t'eventLabel': arguments[4],\n\t\t\t\t\t\t\t\t\t\t\t\t'value': arguments[5] ? arguments[5] : 1,\n\t\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\tif ('pageview' === arguments[1]) {\n\t\t\t\t\t\t\t\t\t\tif ('undefined' !== typeof arguments[2]) {\n\t\t\t\t\t\t\t\t\t\t\thitObject = {\n\t\t\t\t\t\t\t\t\t\t\t\t'eventAction': 'page_view',\n\t\t\t\t\t\t\t\t\t\t\t\t'page_path': arguments[2],\n\t\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\tif (typeof arguments[2] === 'object') {\n\t\t\t\t\t\t\t\t\t\thitObject = arguments[2];\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\tif (typeof arguments[5] === 'object') {\n\t\t\t\t\t\t\t\t\t\tObject.assign(hitObject, arguments[5]);\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\tif ('undefined' !== typeof arguments[1].hitType) {\n\t\t\t\t\t\t\t\t\t\thitObject = arguments[1];\n\t\t\t\t\t\t\t\t\t\tif ('pageview' === hitObject.hitType) {\n\t\t\t\t\t\t\t\t\t\t\thitObject.eventAction = 'page_view';\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\tif (hitObject) {\n\t\t\t\t\t\t\t\t\t\taction = 'timing' === arguments[1].hitType ? 'timing_complete' : hitObject.eventAction;\n\t\t\t\t\t\t\t\t\t\thitConverted = mapArgs(hitObject);\n\t\t\t\t\t\t\t\t\t\t__gtagTracker('event', action, hitConverted);\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\tfunction mapArgs(args) {\n\t\t\t\t\t\t\t\tvar arg, hit = {};\n\t\t\t\t\t\t\t\tvar gaMap = {\n\t\t\t\t\t\t\t\t\t'eventCategory': 'event_category',\n\t\t\t\t\t\t\t\t\t'eventAction': 'event_action',\n\t\t\t\t\t\t\t\t\t'eventLabel': 'event_label',\n\t\t\t\t\t\t\t\t\t'eventValue': 'event_value',\n\t\t\t\t\t\t\t\t\t'nonInteraction': 'non_interaction',\n\t\t\t\t\t\t\t\t\t'timingCategory': 'event_category',\n\t\t\t\t\t\t\t\t\t'timingVar': 'name',\n\t\t\t\t\t\t\t\t\t'timingValue': 'value',\n\t\t\t\t\t\t\t\t\t'timingLabel': 'event_label',\n\t\t\t\t\t\t\t\t\t'page': 'page_path',\n\t\t\t\t\t\t\t\t\t'location': 'page_location',\n\t\t\t\t\t\t\t\t\t'title': 'page_title',\n\t\t\t\t\t\t\t\t};\n\t\t\t\t\t\t\t\tfor (arg in args) {\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tif (!(!args.hasOwnProperty(arg) || !gaMap.hasOwnProperty(arg))) {\n\t\t\t\t\t\t\t\t\t\thit[gaMap[arg]] = args[arg];\n\t\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\t\thit[arg] = args[arg];\n\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\treturn hit;\n\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\ttry {\n\t\t\t\t\t\t\t\tf.hitCallback();\n\t\t\t\t\t\t\t} catch (ex) {\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t};\n\t\t\t\t\t\t__gaTracker.create = newtracker;\n\t\t\t\t\t\t__gaTracker.getByName = newtracker;\n\t\t\t\t\t\t__gaTracker.getAll = function () {\n\t\t\t\t\t\t\treturn [];\n\t\t\t\t\t\t};\n\t\t\t\t\t\t__gaTracker.remove = noopfn;\n\t\t\t\t\t\t__gaTracker.loaded = true;\n\t\t\t\t\t\twindow['__gaTracker'] = __gaTracker;\n\t\t\t\t\t})();\n\t\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\t\tconsole.log(\"\");\n\t\t\t\t\t(function () {\n\t\t\t\t\t\tfunction __gtagTracker() {\n\t\t\t\t\t\t\treturn null;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\twindow['__gtagTracker'] = __gtagTracker;\n\t\t\t\t\t\twindow['gtag'] = __gtagTracker;\n\t\t\t\t\t})();\n\t\t\t\t\t\t\t\t\t}\n\t\t\t</script>\n\t\t\t\t<!-- / Google Analytics by MonsterInsights -->\n\t\t<script type=\"text/javascript\">\nwindow._wpemojiSettings = {\"baseUrl\":\"https:\\/\\/s.w.org\\/images\\/core\\/emoji\\/14.0.0\\/72x72\\/\",\"ext\":\".png\",\"svgUrl\":\"https:\\/\\/s.w.org\\/images\\/core\\/emoji\\/14.0.0\\/svg\\/\",\"svgExt\":\".svg\",\"source\":{\"concatemoji\":\"https:\\/\\/acoup.blog\\/wp-includes\\/js\\/wp-emoji-release.min.js?ver=6.2\"}};\n/*! This file is auto-generated */\n!function(e,a,t){var n,r,o,i=a.createElement(\"canvas\"),p=i.getContext&&i.getContext(\"2d\");function s(e,t){p.clearRect(0,0,i.width,i.height),p.fillText(e,0,0);e=i.toDataURL();return p.clearRect(0,0,i.width,i.height),p.fillText(t,0,0),e===i.toDataURL()}function c(e){var t=a.createElement(\"script\");t.src=e,t.defer=t.type=\"text/javascript\",a.getElementsByTagName(\"head\")[0].appendChild(t)}for(o=Array(\"flag\",\"emoji\"),t.supports={everything:!0,everythingExceptFlag:!0},r=0;r<o.length;r++)t.supports[o[r]]=function(e){if(p&&p.fillText)switch(p.textBaseline=\"top\",p.font=\"600 32px Arial\",e){case\"flag\":return s(\"\\ud83c\\udff3\\ufe0f\\u200d\\u26a7\\ufe0f\",\"\\ud83c\\udff3\\ufe0f\\u200b\\u26a7\\ufe0f\")?!1:!s(\"\\ud83c\\uddfa\\ud83c\\uddf3\",\"\\ud83c\\uddfa\\u200b\\ud83c\\uddf3\")&&!s(\"\\ud83c\\udff4\\udb40\\udc67\\udb40\\udc62\\udb40\\udc65\\udb40\\udc6e\\udb40\\udc67\\udb40\\udc7f\",\"\\ud83c\\udff4\\u200b\\udb40\\udc67\\u200b\\udb40\\udc62\\u200b\\udb40\\udc65\\u200b\\udb40\\udc6e\\u200b\\udb40\\udc67\\u200b\\udb40\\udc7f\");case\"emoji\":return!s(\"\\ud83e\\udef1\\ud83c\\udffb\\u200d\\ud83e\\udef2\\ud83c\\udfff\",\"\\ud83e\\udef1\\ud83c\\udffb\\u200b\\ud83e\\udef2\\ud83c\\udfff\")}return!1}(o[r]),t.supports.everything=t.supports.everything&&t.supports[o[r]],\"flag\"!==o[r]&&(t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&t.supports[o[r]]);t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&!t.supports.flag,t.DOMReady=!1,t.readyCallback=function(){t.DOMReady=!0},t.supports.everything||(n=function(){t.readyCallback()},a.addEventListener?(a.addEventListener(\"DOMContentLoaded\",n,!1),e.addEventListener(\"load\",n,!1)):(e.attachEvent(\"onload\",n),a.attachEvent(\"onreadystatechange\",function(){\"complete\"===a.readyState&&t.readyCallback()})),(e=t.source||{}).concatemoji?c(e.concatemoji):e.wpemoji&&e.twemoji&&(c(e.twemoji),c(e.wpemoji)))}(window,document,window._wpemojiSettings);\n</script>\n<style type=\"text/css\">\nimg.wp-smiley,\nimg.emoji {\n\tdisplay: inline !important;\n\tborder: none !important;\n\tbox-shadow: none !important;\n\theight: 1em !important;\n\twidth: 1em !important;\n\tmargin: 0 0.07em !important;\n\tvertical-align: -0.1em !important;\n\tbackground: none !important;\n\tpadding: 0 !important;\n}\n</style>\n\t<link rel='stylesheet' id='all-css-db805d030c9939ebb06a84a66e5728a5' href='https://acoup.blog/_static/??-eJyVUe1uwyAMfKFRuk6a2h/THqUiYBGvfAlDs7z9nKSR0i5b2z/ggzvOProkdAwFQpHJVYuBpK0MG8hWNhWdkY2L+iQcNlnlXlLpHWw00Uv3rLS04P+UOtXHWoTNaP73+IKSlD7N+/EMwcQsVS3Rq1JQzzfijAZiykB01Q4YLCwYAcmRxCt0syEG7aoBdiLpmazAcd/cwRIk7heycGCV7jcew1013y3xqoax1E4RoRZjWrSkzUn4KuYwuqSjp1b+DqHAd5kMRYfGQhFjqpPH5WTg3IvZR1MHmcMTrw/9zJHnkRYCZGQKrZe3j0zjSgwGEg/DRyLVxiG1HPNu3fiOZph0+uUnhUP/o6EY8300ImpVBqOM6ccSg30oKYoalRMu2khXYO3vb18YZrzUA/XTf7y+73dv28P+sP0Buul6eg==' type='text/css' media='all' />\n<style id='wp-block-library-inline-css'>\n.has-text-align-justify{text-align:justify;}\n</style>\n<style id='independent-publisher-2-style-inline-css'>\n#hero-header { background: url(\"https://acoup.blog/wp-content/uploads/2019/05/cropped-altar-of-domitius-ahenobarb.jpg\") no-repeat center; background-size: cover; background-attachment: scroll; }\n#hero-header { background: url(\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?resize=1440%2C600&#038;ssl=1\") no-repeat center; background-size: cover; background-attachment: scroll; }\n</style>\n<style id='boldblocks-icon-separator-style-inline-css'>\n.wp-block-boldblocks-icon-separator{width:100%}.wp-block-boldblocks-icon-separator[style*=\"--bb--margin-top--sm\"]{margin-top:var(--bb--margin-top--sm)!important}@media(min-width:768px){.wp-block-boldblocks-icon-separator[style*=\"--bb--margin-top--md\"]{margin-top:var(--bb--margin-top--md)!important}}@media(min-width:1024px){.wp-block-boldblocks-icon-separator[style*=\"--bb--margin-top--lg\"]{margin-top:var(--bb--margin-top--lg)!important}}.wp-block-boldblocks-icon-separator[style*=\"--bb--margin-bottom--sm\"]{margin-bottom:var(--bb--margin-bottom--sm)!important}@media(min-width:768px){.wp-block-boldblocks-icon-separator[style*=\"--bb--margin-bottom--md\"]{margin-bottom:var(--bb--margin-bottom--md)!important}}@media(min-width:1024px){.wp-block-boldblocks-icon-separator[style*=\"--bb--margin-bottom--lg\"]{margin-bottom:var(--bb--margin-bottom--lg)!important}}.wp-block-boldblocks-icon-separator__inner{align-items:center;display:flex}.wp-block-boldblocks-icon-separator__inner[style*=\"--bb--width--sm\"]{width:var(--bb--width--sm)}@media(min-width:768px){.wp-block-boldblocks-icon-separator__inner[style*=\"--bb--width--md\"]{width:var(--bb--width--md)}}@media(min-width:1024px){.wp-block-boldblocks-icon-separator__inner[style*=\"--bb--width--lg\"]{width:var(--bb--width--lg)}}.wp-block-boldblocks-icon-separator__inner:after,.wp-block-boldblocks-icon-separator__inner:before{border-top:var(--bb-border);content:\"\";flex:1}.wp-block-boldblocks-icon-separator__inner svg{display:block;height:auto;margin:0 var(--bb--icon-spacing,1em);width:var(--bb--icon-width,1em)}.wp-block-boldblocks-icon-separator__inner[style*=\"--bb--icon-fill-color\"] svg,.wp-block-boldblocks-icon-separator__inner[style*=\"--bb--icon-fill-color\"] svg *{fill:var(--bb--icon-fill-color)!important}.wp-block-boldblocks-icon-separator__inner[style*=\"--bb--icon-stroke-color\"] svg,.wp-block-boldblocks-icon-separator__inner[style*=\"--bb--icon-stroke-color\"] svg *{stroke:var(--bb--icon-stroke-color,currentColor)!important}.wp-block-boldblocks-icon-separator__inner.icon-left:before{display:none}.wp-block-boldblocks-icon-separator__inner.icon-left svg{margin-left:0}.wp-block-boldblocks-icon-separator__inner.icon-right:after{display:none}.wp-block-boldblocks-icon-separator__inner.icon-right svg{margin-right:0}.wp-block-boldblocks-icon-separator__inner.is-align-center{margin-left:auto;margin-right:auto}.wp-block-boldblocks-icon-separator__inner.is-align-left{margin-right:auto}.wp-block-boldblocks-icon-separator__inner.is-align-right{margin-left:auto}\n\n</style>\n<style id='global-styles-inline-css'>\nbody{--wp--preset--color--black: #000000;--wp--preset--color--cyan-bluish-gray: #abb8c3;--wp--preset--color--white: #fff;--wp--preset--color--pale-pink: #f78da7;--wp--preset--color--vivid-red: #cf2e2e;--wp--preset--color--luminous-vivid-orange: #ff6900;--wp--preset--color--luminous-vivid-amber: #fcb900;--wp--preset--color--light-green-cyan: #7bdcb5;--wp--preset--color--vivid-green-cyan: #00d084;--wp--preset--color--pale-cyan-blue: #8ed1fc;--wp--preset--color--vivid-cyan-blue: #0693e3;--wp--preset--color--vivid-purple: #9b51e0;--wp--preset--color--medium-blue: #0087be;--wp--preset--color--bright-blue: #00aadc;--wp--preset--color--dark-gray: #4d4d4b;--wp--preset--color--light-gray: #b3b3b1;--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple: linear-gradient(135deg,rgba(6,147,227,1) 0%,rgb(155,81,224) 100%);--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan: linear-gradient(135deg,rgb(122,220,180) 0%,rgb(0,208,130) 100%);--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange: linear-gradient(135deg,rgba(252,185,0,1) 0%,rgba(255,105,0,1) 100%);--wp--preset--gradient--luminous-vivid-orange-to-vivid-red: linear-gradient(135deg,rgba(255,105,0,1) 0%,rgb(207,46,46) 100%);--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray: linear-gradient(135deg,rgb(238,238,238) 0%,rgb(169,184,195) 100%);--wp--preset--gradient--cool-to-warm-spectrum: linear-gradient(135deg,rgb(74,234,220) 0%,rgb(151,120,209) 20%,rgb(207,42,186) 40%,rgb(238,44,130) 60%,rgb(251,105,98) 80%,rgb(254,248,76) 100%);--wp--preset--gradient--blush-light-purple: linear-gradient(135deg,rgb(255,206,236) 0%,rgb(152,150,240) 100%);--wp--preset--gradient--blush-bordeaux: linear-gradient(135deg,rgb(254,205,165) 0%,rgb(254,45,45) 50%,rgb(107,0,62) 100%);--wp--preset--gradient--luminous-dusk: linear-gradient(135deg,rgb(255,203,112) 0%,rgb(199,81,192) 50%,rgb(65,88,208) 100%);--wp--preset--gradient--pale-ocean: linear-gradient(135deg,rgb(255,245,203) 0%,rgb(182,227,212) 50%,rgb(51,167,181) 100%);--wp--preset--gradient--electric-grass: linear-gradient(135deg,rgb(202,248,128) 0%,rgb(113,206,126) 100%);--wp--preset--gradient--midnight: linear-gradient(135deg,rgb(2,3,129) 0%,rgb(40,116,252) 100%);--wp--preset--font-size--small: 13px;--wp--preset--font-size--medium: 20px;--wp--preset--font-size--large: 36px;--wp--preset--font-size--x-large: 42px;--wp--preset--font-family--albert-sans: 'Albert Sans';--wp--preset--font-family--alegreya: Alegreya;--wp--preset--font-family--arvo: Arvo;--wp--preset--font-family--bodoni-moda: 'Bodoni Moda';--wp--preset--font-family--cabin: Cabin;--wp--preset--font-family--chivo: Chivo;--wp--preset--font-family--commissioner: Commissioner;--wp--preset--font-family--cormorant: Cormorant;--wp--preset--font-family--courier-prime: 'Courier Prime';--wp--preset--font-family--crimson-pro: 'Crimson Pro';--wp--preset--font-family--dm-mono: 'DM Mono';--wp--preset--font-family--dm-sans: 'DM Sans';--wp--preset--font-family--domine: Domine;--wp--preset--font-family--eb-garamond: 'EB Garamond';--wp--preset--font-family--epilogue: Epilogue;--wp--preset--font-family--figtree: Figtree;--wp--preset--font-family--fira-sans: 'Fira Sans';--wp--preset--font-family--fraunces: Fraunces;--wp--preset--font-family--ibm-plex-mono: 'IBM Plex Mono';--wp--preset--font-family--ibm-plex-sans: 'IBM Plex Sans';--wp--preset--font-family--inter: Inter;--wp--preset--font-family--josefin-sans: 'Josefin Sans';--wp--preset--font-family--jost: Jost;--wp--preset--font-family--libre-baskerville: 'Libre Baskerville';--wp--preset--font-family--libre-franklin: 'Libre Franklin';--wp--preset--font-family--literata: Literata;--wp--preset--font-family--lora: Lora;--wp--preset--font-family--merriweather: Merriweather;--wp--preset--font-family--montserrat: Montserrat;--wp--preset--font-family--newsreader: Newsreader;--wp--preset--font-family--nunito: Nunito;--wp--preset--font-family--open-sans: 'Open Sans';--wp--preset--font-family--overpass: Overpass;--wp--preset--font-family--petrona: Petrona;--wp--preset--font-family--piazzolla: Piazzolla;--wp--preset--font-family--playfair-display: 'Playfair Display';--wp--preset--font-family--plus-jakarta-sans: 'Plus Jakarta Sans';--wp--preset--font-family--poppins: Poppins;--wp--preset--font-family--raleway: Raleway;--wp--preset--font-family--roboto-slab: 'Roboto Slab';--wp--preset--font-family--roboto: Roboto;--wp--preset--font-family--rubik: Rubik;--wp--preset--font-family--sora: Sora;--wp--preset--font-family--source-sans-pro: 'Source Sans Pro';--wp--preset--font-family--source-serif-pro: 'Source Serif Pro';--wp--preset--font-family--space-mono: 'Space Mono';--wp--preset--font-family--texturina: Texturina;--wp--preset--font-family--work-sans: 'Work Sans';--wp--preset--spacing--20: 0.44rem;--wp--preset--spacing--30: 0.67rem;--wp--preset--spacing--40: 1rem;--wp--preset--spacing--50: 1.5rem;--wp--preset--spacing--60: 2.25rem;--wp--preset--spacing--70: 3.38rem;--wp--preset--spacing--80: 5.06rem;--wp--preset--shadow--natural: 6px 6px 9px rgba(0, 0, 0, 0.2);--wp--preset--shadow--deep: 12px 12px 50px rgba(0, 0, 0, 0.4);--wp--preset--shadow--sharp: 6px 6px 0px rgba(0, 0, 0, 0.2);--wp--preset--shadow--outlined: 6px 6px 0px -3px rgba(255, 255, 255, 1), 6px 6px rgba(0, 0, 0, 1);--wp--preset--shadow--crisp: 6px 6px 0px rgba(0, 0, 0, 1);}:where(.is-layout-flex){gap: 0.5em;}body .is-layout-flow > .alignleft{float: left;margin-inline-start: 0;margin-inline-end: 2em;}body .is-layout-flow > .alignright{float: right;margin-inline-start: 2em;margin-inline-end: 0;}body .is-layout-flow > .aligncenter{margin-left: auto !important;margin-right: auto !important;}body .is-layout-constrained > .alignleft{float: left;margin-inline-start: 0;margin-inline-end: 2em;}body .is-layout-constrained > .alignright{float: right;margin-inline-start: 2em;margin-inline-end: 0;}body .is-layout-constrained > .aligncenter{margin-left: auto !important;margin-right: auto !important;}body .is-layout-constrained > :where(:not(.alignleft):not(.alignright):not(.alignfull)){max-width: var(--wp--style--global--content-size);margin-left: auto !important;margin-right: auto !important;}body .is-layout-constrained > .alignwide{max-width: var(--wp--style--global--wide-size);}body .is-layout-flex{display: flex;}body .is-layout-flex{flex-wrap: wrap;align-items: center;}body .is-layout-flex > *{margin: 0;}body .is-layout-grid{display: grid;}body .is-layout-grid > *{margin: 0;}:where(.wp-block-columns.is-layout-flex){gap: 2em;}.has-black-color{color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-color{color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-color{color: var(--wp--preset--color--white) !important;}.has-pale-pink-color{color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-color{color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-color{color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-color{color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-color{color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-color{color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-color{color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-color{color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-color{color: var(--wp--preset--color--vivid-purple) !important;}.has-black-background-color{background-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-background-color{background-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-background-color{background-color: var(--wp--preset--color--white) !important;}.has-pale-pink-background-color{background-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-background-color{background-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-background-color{background-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-background-color{background-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-background-color{background-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-background-color{background-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-background-color{background-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-background-color{background-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-background-color{background-color: var(--wp--preset--color--vivid-purple) !important;}.has-black-border-color{border-color: var(--wp--preset--color--black) !important;}.has-cyan-bluish-gray-border-color{border-color: var(--wp--preset--color--cyan-bluish-gray) !important;}.has-white-border-color{border-color: var(--wp--preset--color--white) !important;}.has-pale-pink-border-color{border-color: var(--wp--preset--color--pale-pink) !important;}.has-vivid-red-border-color{border-color: var(--wp--preset--color--vivid-red) !important;}.has-luminous-vivid-orange-border-color{border-color: var(--wp--preset--color--luminous-vivid-orange) !important;}.has-luminous-vivid-amber-border-color{border-color: var(--wp--preset--color--luminous-vivid-amber) !important;}.has-light-green-cyan-border-color{border-color: var(--wp--preset--color--light-green-cyan) !important;}.has-vivid-green-cyan-border-color{border-color: var(--wp--preset--color--vivid-green-cyan) !important;}.has-pale-cyan-blue-border-color{border-color: var(--wp--preset--color--pale-cyan-blue) !important;}.has-vivid-cyan-blue-border-color{border-color: var(--wp--preset--color--vivid-cyan-blue) !important;}.has-vivid-purple-border-color{border-color: var(--wp--preset--color--vivid-purple) !important;}.has-vivid-cyan-blue-to-vivid-purple-gradient-background{background: var(--wp--preset--gradient--vivid-cyan-blue-to-vivid-purple) !important;}.has-light-green-cyan-to-vivid-green-cyan-gradient-background{background: var(--wp--preset--gradient--light-green-cyan-to-vivid-green-cyan) !important;}.has-luminous-vivid-amber-to-luminous-vivid-orange-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-amber-to-luminous-vivid-orange) !important;}.has-luminous-vivid-orange-to-vivid-red-gradient-background{background: var(--wp--preset--gradient--luminous-vivid-orange-to-vivid-red) !important;}.has-very-light-gray-to-cyan-bluish-gray-gradient-background{background: var(--wp--preset--gradient--very-light-gray-to-cyan-bluish-gray) !important;}.has-cool-to-warm-spectrum-gradient-background{background: var(--wp--preset--gradient--cool-to-warm-spectrum) !important;}.has-blush-light-purple-gradient-background{background: var(--wp--preset--gradient--blush-light-purple) !important;}.has-blush-bordeaux-gradient-background{background: var(--wp--preset--gradient--blush-bordeaux) !important;}.has-luminous-dusk-gradient-background{background: var(--wp--preset--gradient--luminous-dusk) !important;}.has-pale-ocean-gradient-background{background: var(--wp--preset--gradient--pale-ocean) !important;}.has-electric-grass-gradient-background{background: var(--wp--preset--gradient--electric-grass) !important;}.has-midnight-gradient-background{background: var(--wp--preset--gradient--midnight) !important;}.has-small-font-size{font-size: var(--wp--preset--font-size--small) !important;}.has-medium-font-size{font-size: var(--wp--preset--font-size--medium) !important;}.has-large-font-size{font-size: var(--wp--preset--font-size--large) !important;}.has-x-large-font-size{font-size: var(--wp--preset--font-size--x-large) !important;}\n:where(.wp-block-columns.is-layout-flex){gap: 2em;}\n.wp-block-pullquote{font-size: 1.5em;line-height: 1.6;}\n.wp-block-navigation a:where(:not(.wp-element-button)){color: inherit;}\n</style>\n<style id='jetpack-global-styles-frontend-style-inline-css'>\n:root { --font-headings: unset; --font-base: unset; --font-headings-default: -apple-system,BlinkMacSystemFont,\"Segoe UI\",Roboto,Oxygen-Sans,Ubuntu,Cantarell,\"Helvetica Neue\",sans-serif; --font-base-default: -apple-system,BlinkMacSystemFont,\"Segoe UI\",Roboto,Oxygen-Sans,Ubuntu,Cantarell,\"Helvetica Neue\",sans-serif;}\n</style>\n<script src='https://s0.wp.com/wp-content/plugins/video/assets/js/videojs/videopress-iframe-api.js?ver=202317' id='jetpack-videopress-video-block-view-iframe-api-js'></script>\n<script type='text/javascript'  src='https://acoup.blog/wp-content/plugins/google-analytics-for-wordpress/assets/js/frontend-gtag.min.js?m=1681271374'></script>\n<script data-cfasync=\"false\" data-wpfc-render=\"false\" type=\"text/javascript\" id='monsterinsights-frontend-script-js-extra'>/* <![CDATA[ */\nvar monsterinsights_frontend = {\"js_events_tracking\":\"true\",\"download_extensions\":\"doc,pdf,ppt,zip,xls,docx,pptx,xlsx\",\"inbound_paths\":\"[{\\\"path\\\":\\\"\\\\\\/go\\\\\\/\\\",\\\"label\\\":\\\"affiliate\\\"},{\\\"path\\\":\\\"\\\\\\/recommend\\\\\\/\\\",\\\"label\\\":\\\"affiliate\\\"}]\",\"home_url\":\"https:\\/\\/acoup.blog\",\"hash_tracking\":\"false\",\"ua\":\"UA-198425729-1\",\"v4_id\":\"G-DPPH6QBP1L\"};/* ]]> */\n</script>\n<script id='media-video-jwt-bridge-js-extra'>\nvar videopressAjax = {\"ajaxUrl\":\"https:\\/\\/acoup.blog\\/wp-admin\\/admin-ajax.php\",\"bridgeUrl\":\"https:\\/\\/acoup.blog\\/wp-content\\/plugins\\/jetpack\\/jetpack_vendor\\/automattic\\/jetpack-videopress\\/src\\/..\\/build\\/lib\\/token-bridge.js\",\"post_id\":\"17368\"};\n</script>\n<script src='https://acoup.blog/wp-content/plugins/jetpack/jetpack_vendor/automattic/jetpack-videopress/src/../build/lib/token-bridge.js?ver=0.13.8' id='media-video-jwt-bridge-js'></script>\n<link rel=\"https://api.w.org/\" href=\"https://acoup.blog/wp-json/\" /><link rel=\"alternate\" type=\"application/json\" href=\"https://acoup.blog/wp-json/wp/v2/posts/17368\" /><link rel=\"EditURI\" type=\"application/rsd+xml\" title=\"RSD\" href=\"https://acoup.blog/xmlrpc.php?rsd\" />\n<link rel=\"wlwmanifest\" type=\"application/wlwmanifest+xml\" href=\"https://acoup.blog/wp-includes/wlwmanifest.xml\" />\n\n<link rel=\"canonical\" href=\"https://acoup.blog/2023/02/17/collections-on-chatgpt/\" />\n<link rel='shortlink' href='https://wp.me/paWMNs-4w8' />\n<link rel=\"alternate\" type=\"application/json+oembed\" href=\"https://acoup.blog/wp-json/oembed/1.0/embed?url=https%3A%2F%2Facoup.blog%2F2023%2F02%2F17%2Fcollections-on-chatgpt%2F\" />\n<link rel=\"alternate\" type=\"text/xml+oembed\" href=\"https://acoup.blog/wp-json/oembed/1.0/embed?url=https%3A%2F%2Facoup.blog%2F2023%2F02%2F17%2Fcollections-on-chatgpt%2F&#038;format=xml\" />\n\t<style>img#wpstats{display:none}</style>\n\t\t<link rel=\"pingback\" href=\"https://acoup.blog/xmlrpc.php\"><meta name=\"description\" content=\"So I stirred up a bit of conversation on Twitter last week when I noted that I had already been handed ChatGPT produced assignments. For those who are unaware, ChatGPT is an &#039;AI&#039; chatbot that given a prompt can produce texts; it is one of most sophisticated bots of this sort yet devised, trained on&hellip;\" />\n<style type=\"text/css\" id=\"custom-background-css\">\nbody.custom-background { background-color: #413e4a; }\n</style>\n\t<!-- There is no amphtml version available for this URL. -->\t\t\t<style type=\"text/css\">\n\t\t\t\t/* If html does not have either class, do not show lazy loaded images. */\n\t\t\t\thtml:not( .jetpack-lazy-images-js-enabled ):not( .js ) .jetpack-lazy-image {\n\t\t\t\t\tdisplay: none;\n\t\t\t\t}\n\t\t\t</style>\n\t\t\t<script>\n\t\t\t\tdocument.documentElement.classList.add(\n\t\t\t\t\t'jetpack-lazy-images-js-enabled'\n\t\t\t\t);\n\t\t\t</script>\n\t\t\n<!-- Jetpack Open Graph Tags -->\n<meta property=\"og:type\" content=\"article\" />\n<meta property=\"og:title\" content=\"Collections: On ChatGPT\" />\n<meta property=\"og:url\" content=\"https://acoup.blog/2023/02/17/collections-on-chatgpt/\" />\n<meta property=\"og:description\" content=\"So I stirred up a bit of conversation on Twitter last week when I noted that I had already been handed ChatGPT produced assignments. For those who are unaware, ChatGPT is an &#8216;AI&#8217; chatbo…\" />\n<meta property=\"article:published_time\" content=\"2023-02-17T06:44:30+00:00\" />\n<meta property=\"article:modified_time\" content=\"2023-02-17T22:47:59+00:00\" />\n<meta property=\"og:site_name\" content=\"A Collection of Unmitigated Pedantry\" />\n<meta property=\"og:image\" content=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?fit=1200%2C875&#038;ssl=1\" />\n<meta property=\"og:image:width\" content=\"1200\" />\n<meta property=\"og:image:height\" content=\"875\" />\n<meta property=\"og:image:alt\" content=\"\" />\n<meta property=\"og:locale\" content=\"en_US\" />\n<meta name=\"twitter:text:title\" content=\"Collections: On ChatGPT\" />\n<meta name=\"twitter:image\" content=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?fit=1200%2C875&#038;ssl=1&#038;w=640\" />\n<meta name=\"twitter:card\" content=\"summary_large_image\" />\n\n<!-- End Jetpack Open Graph Tags -->\n<style type=\"text/css\" id=\"custom-colors-css\">.has-header-image .site-title a,.has-header-image .site-title a:visited{color:#fff}@media screen and (max-width:32.374em){.main-navigation ul ul{background:transparent !important}.main-navigation ul ul a{color:inherit !important}}.widget_recent_comments a,.widget_recent_entries a,body,input,select,textarea,.menu-toggle{color:#b5b5b5}#infinite-footer .blog-info a:hover,#infinite-footer .blog-credits a:hover{color:#b5b5b5}.posts-navigation .nav-links a,.main-navigation ul ul a,.main-navigation>div>ul>li.current-menu-item>ul>li a,.main-navigation>div>ul>li.current_page_item>ul>li a{color:#515151}input[type=\"button\"],input[type=\"button\"]:hover,input[type=\"reset\"],input[type=\"reset\"]:hover,input[type=\"submit\"],input[type=\"submit\"]:hover,button,.button,.button:hover,#content #infinite-handle span button,#content #infinite-handle span button:hover,.more-link,.more-link:hover,.more-link:visited{color:#6d6d6d}.site-main>.hentry:nth-child(n+2),.site .infinite-wrap>.hentry:nth-child(n+2),.entry-author-wrapper,.post-navigation,.comment,.page-links a:hover,.main-navigation li{border-color:#ddd}.site-main>.hentry:nth-child(n+2),.site .infinite-wrap>.hentry:nth-child(n+2),.entry-author-wrapper,.post-navigation,.comment,.page-links a:hover,.main-navigation li{border-color:rgba(221,221,221,.25)}#infinite-footer .blog-info a,#infinite-footer .blog-credits,#infinite-footer .blog-credits a{color:#ddd}.post-details,.post-details a,.post-details a:visited,.post-edit-link a,.post-edit-link a:visited{color:#b5b5b4}.post-tags li:first-child,.jetpack-social-navigation li a:hover,.widget_wpcom_social_media_icons_widget li a:hover,.jetpack-social-navigation li a:focus,.widget_wpcom_social_media_icons_widget li a:focus,.jetpack-social-navigation li a:active,.widget_wpcom_social_media_icons_widget li a:active{color:#b5b5b5}.jetpack-social-navigation li a,.widget_wpcom_social_media_icons_widget li a{color:#b5b5b5}.post-navigation .nav-links a:hover,.post-navigation .nav-links a:focus,.post-navigation .nav-links a:active,.entry-author .author-bio,.site-posted-on time,.site-description{color:#b5b5b5}.comment .comment-meta,.comment-form label,.light-text,.light-text a,.light-text a:visited,.widget_rss .rss-date,.widget_rss li>cite{color:#b5b5b4}.light-text a:hover{color:#b5b5b4}body{background-color:#413e4a}#infinite-footer .container{background-color:#413e4a}#infinite-footer .container{background-color:rgba(65,62,74,.7)}.post-edit-link a{background-color:#3c3a45}.entry-author .author-title,.entry-title,.entry-title a,.entry-title a:visited,.site-posted-on strong,.site-title,.site-title a,.site-title a:visited,.entry-title a:hover,.site-title a:hover,h1,h2,h3,h4,h5,h6,.page-header:not(.page-header-light) h1,.comment .comment-meta .comment-author .fn{color:#bcb2b8}.comment-form input[type=\"email\"]:active,.comment-form input[type=\"email\"]:focus,.comment-form input[type=\"password\"]:active,.comment-form input[type=\"password\"]:focus,.comment-form input[type=\"search\"]:active,.comment-form input[type=\"search\"]:focus,.comment-form input[type=\"text\"]:active,.comment-form input[type=\"text\"]:focus,.comment-form input[type=\"url\"]:active,.comment-form input[type=\"url\"]:focus,.comment-form textarea:active,.comment-form textarea:focus,blockquote,input[type=\"email\"]:focus,input[type=\"password\"]:focus,input[type=\"search\"]:focus,input[type=\"text\"]:focus,input[type=\"url\"]:focus,textarea:focus{border-color:#e8c3df}.comment .comment-meta .comment-metadata a:hover,.comment-form span.required,.pingback:before,.post-details a:hover,.post-edit-link a:active,.post-edit-link a:focus,.post-edit-link a:hover,.site-info a:hover,.trackback:before,a,a:visited{color:#e8c3df}.main-navigation>div>ul>li.current-menu-item>a,.main-navigation>div>ul>li.current_page_item>a,a:active,a:focus,a:hover,.page-links a:hover{color:#e8c3df}.posts-navigation .nav-links a,.main-navigation ul ul{background-color:#e8c3df}button,input[type=\"button\"],input[type=\"reset\"],input[type=\"submit\"],.button,#content #infinite-handle span button,.more-link{background-color:#fff}button:not(\".components-button\"):hover,input[type=\"button\"]:hover,input[type=\"reset\"]:hover,input[type=\"submit\"]:hover,.button:hover,#content #infinite-handle span button:hover,.more-link:hover{background-color:#e5e5e5}</style>\n<link rel=\"icon\" href=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2019/05/cropped-altar-of-domitius-ahenobarb-1-1.jpg?fit=32%2C32&#038;ssl=1\" sizes=\"32x32\" />\n<link rel=\"icon\" href=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2019/05/cropped-altar-of-domitius-ahenobarb-1-1.jpg?fit=192%2C192&#038;ssl=1\" sizes=\"192x192\" />\n<link rel=\"apple-touch-icon\" href=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2019/05/cropped-altar-of-domitius-ahenobarb-1-1.jpg?fit=180%2C180&#038;ssl=1\" />\n<meta name=\"msapplication-TileImage\" content=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2019/05/cropped-altar-of-domitius-ahenobarb-1-1.jpg?fit=270%2C270&#038;ssl=1\" />\n<!-- Your Google Analytics Plugin is missing the tracking ID -->\r\n</head>\n\n<body class=\"post-template-default single single-post postid-17368 single-format-standard custom-background wp-embed-responsive has-sidebar has-header-image custom-colors\">\n\n<div id=\"page\" class=\"hfeed site\">\n\t<a class=\"skip-link screen-reader-text\" href=\"#content\">Skip to content</a>\n\n\t<div id=\"hero-header\" class=\"site-hero-section\">\n\t\t<header id=\"masthead\" class=\"site-header\" role=\"banner\">\n\t\t\t<div class=\"inner\">\n\t\t\t\t<div class=\"site-branding\">\n\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t<p class=\"site-title\"><a href=\"https://acoup.blog/\" rel=\"home\">A Collection of Unmitigated Pedantry</a></p>\n\t\t\t\t\t\t\t\t\t\t\t\t\t<p class=\"site-description\">A look at history and popular culture</p>\n\t\t\t\t\t\t\t\t\t</div><!-- .site-branding -->\n\n\t\t\t\t\n\t\t\t\t\t\t\t\t\t<button class=\"menu-toggle\" aria-controls=\"primary-menu\" aria-expanded=\"false\" id=\"primary-menu-button\">\n\t\t\t\t\t\tMenu\t\t\t\t\t</button><!-- .menu-toggle -->\n\t\t\t\t\n\t\t\t</div><!-- .inner -->\n\t\t</header><!-- #masthead -->\n\t</div>\n\n\t\t\t\t<nav id=\"site-navigation\" class=\"main-navigation\" role=\"navigation\">\n\t\t\t<div class=\"menu-primary-container\"><ul id=\"primary-menu\" class=\"menu\"><li id=\"menu-item-6\" class=\"menu-item menu-item-type-custom menu-item-object-custom menu-item-6\"><a href=\"/\">Home</a></li>\n<li id=\"menu-item-1628\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1628\"><a href=\"https://acoup.blog/resources-for-teachers/\">Resources for Teachers</a></li>\n<li id=\"menu-item-1629\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-1629\"><a href=\"https://acoup.blog/resources-for-world-builders/\">Resources for World-Builders</a></li>\n<li id=\"menu-item-6018\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-6018\"><a href=\"https://acoup.blog/book-recommendation-list/\">Book Recommendation List</a></li>\n<li id=\"menu-item-7448\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-7448\"><a href=\"https://acoup.blog/guest-posts/\">Guest Posts</a></li>\n<li id=\"menu-item-7\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-7\"><a href=\"https://acoup.blog/contact/\">Contact</a></li>\n<li id=\"menu-item-5399\" class=\"menu-item menu-item-type-post_type menu-item-object-page menu-item-5399\"><a href=\"https://acoup.blog/about-the-pedant/\">About the Pedant</a></li>\n</ul></div>\t\t</nav><!-- .main-navigation -->\n\t\n\t\n\t\n\t<div id=\"content-wrapper\" class=\"content-wrapper\">\n\t\t<div id=\"content\" class=\"site-content\">\n\n\t<div id=\"primary\" class=\"content-area\">\n\t\t<main id=\"main\" class=\"site-main\" role=\"main\">\n\n\t\t\n\t\t\t\n<article id=\"post-17368\" class=\"post-17368 post type-post status-publish format-standard has-post-thumbnail hentry category-collections tag-academia tag-modern tag-pedagogy tag-technology tag-writing\">\n\t\t\t<header class=\"entry-header\">\n\t\t\t<h1 class=\"entry-title\">Collections: On ChatGPT</h1>\t\t</header><!-- .entry-header -->\t\t<div class=\"entry-meta\">\n\t\t\t<span class=\"byline\">\n\t\t\t\t<a href=\"https://acoup.blog/author/aimedtact/\" title=\"Posts by Bret Devereaux\" rel=\"author\">Bret Devereaux</a>\t\t\t</span>\n\t\t\t\t\t\t\t<span class=\"cat-links\">\n\t\t\t\t\t<a href=\"https://acoup.blog/category/collections/\" rel=\"category tag\">Collections</a>\t\t\t\t</span><!-- .cat-links -->\n\t\t\t\n\t\t\t\n\t\t\t<span class=\"published-on\">\n\t\t\t\t<time class=\"entry-date published\" datetime=\"2023-02-17T01:44:30-05:00\">February 17, 2023</time><time class=\"updated\" datetime=\"2023-02-17T17:47:59-05:00\">February 17, 2023</time>\t\t\t</span>\n\n\t\t\t<span class=\"word-count\">38 Minutes</span>\t\t</div><!-- .entry-meta -->\n\t\n\t<div class=\"entry-content\">\n\t\t\n<p>So I stirred up a bit of conversation on Twitter last week when I noted that I had already been handed ChatGPT produced assignments.<span id='easy-footnote-1-17368' class='easy-footnote-margin-adjust'></span><span class='easy-footnote'><a href='#easy-footnote-bottom-1-17368' title='And I should be clear right here ahead of time that nothing that follows is particular to any paper(s) I may have received.  Do not ask &amp;#8220;what happened to the student(s)?&amp;#8221; or &amp;#8220;how did you know?&amp;#8221; or &amp;#8220;what class was this in?&amp;#8221; because I can&amp;#8217;t tell you.  &lt;a href=&quot;https://en.wikipedia.org/wiki/Family_Educational_Rights_and_Privacy_Act&quot; data-type=&quot;URL&quot; data-id=&quot;https://en.wikipedia.org/wiki/Family_Educational_Rights_and_Privacy_Act&quot;&gt;Student privacy laws&lt;/a&gt; in the United States protect that sort of information and it is a good thing they do.  The observations that follow are not based on student papers, instead they are based on a number of responses I had ChatGPT produce for me to get a sense of what such an effort at cheating might look like and how I might detect it.'><sup>1</sup></a></span>  For those who are unaware, ChatGPT is an &#8216;AI&#8217; chatbot that given a prompt can produce texts; it is one of most sophisticated bots of this sort yet devised, trained on a massive amount of writing (along with substantial human input in the training process, something we&#8217;ll come back to).  And its appearance has made a lot of waves and caused a fair bit of consternation.</p>\n\n\n\n<p>Now I should note at the outset that while I am going to argue that ChatGPT is &#8211; or at least ought to be &#8211; basically useless for doing college assignments, it is also <em>wrong</em> to use it for this purpose.  Functionally all university honor codes prohibit something like &#8216;unauthorized aid or assistance&#8217; when completing an assignment.  Having a chatbot write an assignment &#8211; or any part of that assignment &#8211; <em>for you</em> pretty clearly meets that definition.  Consequently using ChatGPT on a college essay is pretty clearly an impermissible outside aid &#8211; that is to say, &#8216;cheating.&#8217;  At most universities, this sort of cheating is an offense that can lead to failing classes or expulsion.  So however irritating that paper may be, it is probably not worth getting thrown out of college, money wasted, without a degree.  Learn.  Don&#8217;t cheat.</p>\n\n\n\n<p>That said I want to move through a few of my basic issues: first, what ChatGPT <em>is</em> in contrast to what people seem to <em>think</em> it is.  Second, why I think that functionality serves little purpose in essay writing &#8211; or more correctly why I think folks that think it &#8216;solves&#8217; essay writing misunderstand what essay writing is <em>for</em>.  Third, why I think that same functionality serves little purpose in my classroom &#8211; or more correctly why I think that folks that think is solves issues in the classroom fundamentally misunderstand what I am teaching and how.</p>\n\n\n\n<p>Now I do want to be clear at the outset that I am not saying that this technology has no viable uses (though I can&#8217;t say I&#8217;ve yet seen an example of a use I would consider <em>good</em> rather than merely economically viable for ChatGPT in particular) and I am certainly not saying that future machine-learning based products, be they large language models or other products, will not be useful (though I do think that boosters of this technology frequently <em>assume</em> applications in fields they do not understand). <strong> Machine learning products are, in fact, <em>already</em> useful and in common use in ways that are good</strong>.  But I think I will stipulate that much of the boosterism for ChatGPT amounts to what <a href=\"https://youtube.com/watch?v=YQ_xWvX1n9g&amp;feature=shares&amp;t=1408\" data-type=\"URL\" data-id=\"https://youtube.com/watch?v=YQ_xWvX1n9g&amp;feature=shares&amp;t=1408\">Dan Olsen (commenting on cryptocurrency) describes as</a>, &#8220;technofetishistic egotism,&#8221; a condition in which tech creators fall into the trap where, &#8220;They don&#8217;t understand anything about the ecosystems they&#8217;re trying to disrupt&#8230;and assume that because they understand one very complicated thing, [difficult programming challenges]&#8230;that all other complicated things must be lesser in complexity and naturally lower in the hierarchy of reality, nails easily driven by the hammer that they have created.&#8221;</p>\n\n\n\n<p>Of course that goes both ways which is why I am not going to say what capabilities machine learning may bring tomorrow.  It is evidently a potentially powerful technology and I am not able to assess what it may be able to do in the future.  But I <em>can</em> assess the observes capabilities of ChatGPT <em>right now</em> and talk about the implication those capabilities have in a classroom environment, which I do understand.<span id='easy-footnote-2-17368' class='easy-footnote-margin-adjust'></span><span class='easy-footnote'><a href='#easy-footnote-bottom-2-17368' title='After all I may not have experience as a creator of large language models, but I am a fully qualified &lt;em&gt;end user&lt;/em&gt;. I cannot and indeed will not critique how ChatGPT was created, but I am perfectly qualified to say, &amp;#8220;this product as delivered does not meet any of my needs.&amp;#8221;'><sup>2</sup></a></span>  That means &#8211; and I should be clear on this &#8211; <strong>this is a post about the capabilities of ChatGPT in its current form; not some other machine learning tool or AI that one imagines might exist in the future</strong>.  And in that context what I see does not convince me that <em>this </em>technology is going to improve the learning experience; <strong>where it is disruptive it seems almost entirely negatively so and even then the disruption is less profound than one might think.</strong></p>\n\n\n\n<p>Now because I am not a chatbot but instead a living, breathing human who in theory needs to eat to survive, I should remind you that if you like what you are reading here you can help by sharing what I write (for I rely on word of mouth for my audience) and by supporting me on <a href=\"https://www.patreon.com/user?u=20122096\">Patreon</a>. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings, assuming there is still a Twitter by the time this post goes live.</p>\n\n\n<div class=\"jetpack_subscription_widget\"><h2 class=\"widgettitle\"></h2>\n\t\t\t<div class=\"wp-block-jetpack-subscriptions__container\">\n\t\t\t<form action=\"#\" method=\"post\" accept-charset=\"utf-8\" id=\"subscribe-blog-1\"\n\t\t\t\tdata-blog=\"161773962\"\n\t\t\t\tdata-post_access_level=\"everybody\" >\n\t\t\t\t\t\t\t\t\t<p id=\"subscribe-email\">\n\t\t\t\t\t\t<label id=\"jetpack-subscribe-label\"\n\t\t\t\t\t\t\tclass=\"screen-reader-text\"\n\t\t\t\t\t\t\tfor=\"subscribe-field-1\">\n\t\t\t\t\t\t\tEmail Address\t\t\t\t\t\t</label>\n\t\t\t\t\t\t<input type=\"email\" name=\"email\" required=\"required\"\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tvalue=\"\"\n\t\t\t\t\t\t\tid=\"subscribe-field-1\"\n\t\t\t\t\t\t\tplaceholder=\"Email Address\"\n\t\t\t\t\t\t/>\n\t\t\t\t\t</p>\n\n\t\t\t\t\t<p id=\"subscribe-submit\"\n\t\t\t\t\t\t\t\t\t\t\t>\n\t\t\t\t\t\t<input type=\"hidden\" name=\"action\" value=\"subscribe\"/>\n\t\t\t\t\t\t<input type=\"hidden\" name=\"source\" value=\"https://acoup.blog/2023/02/17/collections-on-chatgpt/\"/>\n\t\t\t\t\t\t<input type=\"hidden\" name=\"sub-type\" value=\"widget\"/>\n\t\t\t\t\t\t<input type=\"hidden\" name=\"redirect_fragment\" value=\"subscribe-blog-1\"/>\n\t\t\t\t\t\t\t\t\t\t\t\t<button type=\"submit\"\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tclass=\"wp-block-button__link\"\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tstyle=\"margin: 0px; margin-left: 0px;\"\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tname=\"jetpack_subscriptions_widget\"\n\t\t\t\t\t\t>\n\t\t\t\t\t\t\tSubscribe!\t\t\t\t\t\t</button>\n\t\t\t\t\t</p>\n\t\t\t\t\t\t\t</form>\n\t\t\t\t\t\t</div>\n\t\t\t\n</div>\n\n\n\n<figure class=\"wp-block-image size-large\"><img data-attachment-id=\"17508\" data-permalink=\"https://acoup.blog/2023/02/17/collections-on-chatgpt/title-image-4/\" data-orig-file=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?fit=1561%2C1138&amp;ssl=1\" data-orig-size=\"1561,1138\" data-comments-opened=\"1\" data-image-meta=\"{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}\" data-image-title=\"title image\" data-image-description data-image-caption data-medium-file=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?fit=300%2C219&amp;ssl=1\" data-large-file=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?fit=1024%2C747&amp;ssl=1\" decoding=\"async\" width=\"1024\" height=\"747\" src=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?resize=1024%2C747&#038;ssl=1\" alt class=\"wp-image-17508 jetpack-lazy-image\" data-recalc-dims=\"1\" data-lazy-srcset=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?resize=1024%2C747&amp;ssl=1 1024w, https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?resize=300%2C219&amp;ssl=1 300w, https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?resize=768%2C560&amp;ssl=1 768w, https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?resize=1536%2C1120&amp;ssl=1 1536w, https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?resize=1200%2C875&amp;ssl=1 1200w, https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?resize=1100%2C802&amp;ssl=1 1100w, https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?w=1561&amp;ssl=1 1561w\" data-lazy-sizes=\"(max-width: 1024px) 100vw, 1024px\" data-lazy-src=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?resize=1024%2C747&amp;is-pending-load=1#038;ssl=1\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\"><noscript><img data-lazy-fallback=\"1\" data-attachment-id=\"17508\" data-permalink=\"https://acoup.blog/2023/02/17/collections-on-chatgpt/title-image-4/\" data-orig-file=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?fit=1561%2C1138&amp;ssl=1\" data-orig-size=\"1561,1138\" data-comments-opened=\"1\" data-image-meta=\"{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}\" data-image-title=\"title image\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?fit=300%2C219&amp;ssl=1\" data-large-file=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?fit=1024%2C747&amp;ssl=1\" decoding=\"async\" loading=\"lazy\" width=\"1024\" height=\"747\" src=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?resize=1024%2C747&#038;ssl=1\" alt=\"\" class=\"wp-image-17508\" srcset=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?resize=1024%2C747&amp;ssl=1 1024w, https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?resize=300%2C219&amp;ssl=1 300w, https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?resize=768%2C560&amp;ssl=1 768w, https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?resize=1536%2C1120&amp;ssl=1 1536w, https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?resize=1200%2C875&amp;ssl=1 1200w, https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?resize=1100%2C802&amp;ssl=1 1100w, https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?w=1561&amp;ssl=1 1561w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" data-recalc-dims=\"1\"  /></noscript></figure>\n\n\n\n<h2 class=\"wp-block-heading\">The Heck is a ChatGPT?</h2>\n\n\n\n<p>But I think we want to start by discussing what ChatGPT is and what it is <em>not</em>; it is the latter actually that is most important for this discussion.  <strong>The tricky part is that ChatGPT and chatbots like it are designed to make use of a very influential human cognitive bias that we all have: <a href=\"https://en.wikipedia.org/wiki/Anthropomorphism\" data-type=\"URL\" data-id=\"https://en.wikipedia.org/wiki/Anthropomorphism\">the tendency to view things which are not people as people or at least as being like people</a>.</strong>  We all do this; we imagine our pets understand more than they can, have emotions more similar to ours than they do,<span id='easy-footnote-3-17368' class='easy-footnote-margin-adjust'></span><span class='easy-footnote'><a href='#easy-footnote-bottom-3-17368' title='Not that pets don&amp;#8217;t have emotions or some kind of understanding, but we anthropomorphize our pets &lt;em&gt;a lot&lt;/em&gt; as a way of relating to them.'><sup>3</sup></a></span> or that inanimate objects are not merely animate but <em>human</em> in their feelings, memories and so on.  We even imagine that the waves and winds are like people too and assign them attributes as divine beings with human-like emotions and often human-like appearances.  We beg and plead with the impersonal forces of the world like we would with <em>people</em> who might be moved by those emotions.</p>\n\n\n\n<p><strong>The way ChatGPT and other chatbots abuse that tendency is that they <em>pretend</em> to be like minds &#8211; like human minds.</strong>  But <strong>it is only pretend, <em>there is no mind there</em></strong> and that is the key to understanding what ChatGPT is (and thus what it is capable of).  Now I can&#8217;t claim to understand the complex computer science that produced this program (indeed, with machine learning programs, even the creators sometimes cannot truly understand &#8216;how&#8217; the program comes to a specific result), but enough concerning how it functions has been discussed to get a sense of what it can and cannot do.  Moreover its limitations (demonstrated in its <em>use</em> and thus available for interrogation by the non-specialist) are illustrative of its capabilities.</p>\n\n\n\n<p><strong>ChatGPT is chatbot (a program designed to mimic human conversation) that uses a large language model (a giant model of probabilities of what words will appear and in what order).  </strong>That large language model was produced through a giant text base (<a href=\"https://www.sciencefocus.com/future-technology/gpt-3/\" data-type=\"URL\" data-id=\"https://www.sciencefocus.com/future-technology/gpt-3/\">some 570GB, reportedly</a>) though I can&#8217;t find that OpenAI has been transparent about what was and was not in that training base (though no part of that training data is post-2021, apparently).  <a href=\"https://www.assemblyai.com/blog/how-chatgpt-actually-works/\" data-type=\"URL\" data-id=\"https://www.assemblyai.com/blog/how-chatgpt-actually-works/\">The program was then trained</a> by human trainers who both gave the model a prompt and an appropriate output to that prompt (supervised fine tuning) or else had the model generate several responses to a prompt and then humans sorted those responses best to worst (the reward model).  At each stage the model is refined (<a href=\"https://youtube.com/watch?v=R9OHn5ZF4Uo&amp;feature=shares\" data-type=\"URL\" data-id=\"https://youtube.com/watch?v=R9OHn5ZF4Uo&amp;feature=shares\">CGP Grey has a very accessible description of how this works</a>) to produce results more in keeping with what the human trainers expect or desire.  This last step is really important whenever anyone suggests that it would be trivial to train ChatGPT on a large new dataset; <strong>a lot of human intervention was in fact required to get these results.</strong></p>\n\n\n\n<p>It is <em>crucial</em> to note, however,<strong> what the data is that is being collected and refined in the training system here: it is purely information about how words appear in relation to each other</strong>.  That is, how often words occur together, how closely, in what relative positions and so on.  It is not, as we do, storing <em>definitions</em> or associations between those words and their real world referents, nor is it storing a perfect copy of the training material for future reference.  ChatGPT does not sit atop a great library it can peer through at will; it has read every book in the library <em>once</em> and distilled the statistical relationships between the words in that library <em>and then burned the library</em>.</p>\n\n\n\n<p>ChatGPT does not understand the <em>logical</em> correlations of these words or the actual things that the words (as symbols) signify (their &#8216;referents&#8217;).  It does not know that water makes you wet, only that &#8216;water&#8217; and &#8216;wet&#8217; tend to appear together and humans sometimes say &#8216;water makes you wet&#8217; (in that order) for reasons it does not and cannot understand.</p>\n\n\n\n<p>In that sense, ChatGPT&#8217;s greatest limitation is that it <em>doesn&#8217;t</em> <em>know anything about anything</em>; it isn&#8217;t storing definitions of words or a sense of their meanings or connections to real world objects or facts to reference about them.  <strong>ChatGPT is, in fact, incapable of knowing anything at all</strong>.  The assumption so many people make is that when they ask ChatGPT a question, it &#8216;researches&#8217; the answer the way we would, perhaps by checking Wikipedia for the relevant information.  But ChatGPT doesn&#8217;t have &#8216;information&#8217; in this sense; it has no discrete facts.  To put it one way, ChatGPT does not and cannot know that &#8220;World War I started in 1914.&#8221;  What it <em>does</em> know is that &#8220;World War I&#8221; &#8220;1914&#8221; and &#8220;start&#8221; (and its synonyms) tend to appear together in its training material, so when you ask, &#8220;when did WWI start?&#8221; it can give that answer.  <strong>But it can also give absolutely nonsensical or blatantly wrong answers with <em>exactly</em> the same kind of confidence because the language model has no space for <em>knowledge</em> as we understand it</strong>; it merely has a model of the statistical relationships between how words appear in its training material.</p>\n\n\n\n<p>In artificial intelligence studies, this habit of manufacturing false information gets called an &#8220;<a href=\"https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence)\" data-type=\"URL\" data-id=\"https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence)\">artificial hallucination</a>,&#8221; but I&#8217;ll be frank I think this sort of terminology begs the question.<span id='easy-footnote-4-17368' class='easy-footnote-margin-adjust'></span><span class='easy-footnote'><a href='#easy-footnote-bottom-4-17368' title='Since I am going to use this phrase a lot I should be clear on its meaning.  To &amp;#8216;beg the question&amp;#8217; is not to ask someone to ask you something, but rather to ask your interlocutor in a debate or discussion to concede as a first step the very thesis you wanted to prove.  If we were, say, debating the value of Jane Austin&amp;#8217;s writing and I lead by saying, &amp;#8220;well, you must first concede she writes extremely well!&amp;#8221; that would be question begging.  It&amp;#8217;s more common to see actual question begging occur as a definitional exercise; an attorney that defines the defendant at a trial as a &amp;#8216;criminal&amp;#8217; has begged the question, assuming the guilt of the person whose guilt has not yet judged in the proceeding where that is the primary concern.'><sup>4</sup></a></span>   ChatGPT gets called an artificial intelligence by some boosters (the company that makes it has the somewhat unearned name of &#8216;OpenAI&#8217;) but it is not some sort of synthetic mind so much as it is an extremely sophisticated form of the software on your phone that tries to guess what you will type next.  And ChatGPT isn&#8217;t suffering some form of hallucination &#8211; which is a distortion of sense-perception.  Even if we were to say that it can sense-perceive at all (and this is <em>also</em> question-begging), its sense-perception has worked just fine: it has absorbed its training materials with perfect accuracy, after all; it merely lacks the capacity to understand or verify those materials.  ChatGPT isn&#8217;t a mind suffering a disorder but a program functioning perfectly as it returns an undesired output.  When ChatGPT invents a title and author of a book that does not exist because you asked it to cite something, the program has not failed: it has done exactly what was asked of it, putting words together in a statistically probable relationship based on your prompt.  <strong>But calling this a hallucination is already ascribing mind-like qualities to something that <em>is not a mind</em> or even particularly mind-like in its function.</strong></p>\n\n\n\n<p>Now I should note the counter-argument here is that by associating words together ChatGPT can &#8216;know&#8217; things in some sense because it can link those associations.  But there are some major differences here.  First, human minds assess the reliability of those associations: how often when asked a question does an answer pop into your mind that you realize quickly cannot be right or you realize you don&#8217;t know the answer at all and must look it up?  Part of that process, of course, is that the mental associations we make are &#8216;checked&#8217; against the real world realities they describe.  In fancy terms, words are merely <em>symbols</em> of actual real things (their &#8216;<a href=\"https://en.wikipedia.org/wiki/Referent\" data-type=\"URL\" data-id=\"https://en.wikipedia.org/wiki/Referent\">referents</a>&#8216; &#8211; the things to which they refer) and so the truth value of words may be checked against the actual status of their referents.  For most people, this connection is very strong.  Chances are, if I say &#8216;wool blanket&#8217; your mind is going to not merely play word association but also conjure up some memories of <em>actual</em> wool blankets &#8211; their sight, touch or smell.  ChatGPT lacks this capability; <em>all</em> it has are the statistical relationship between words stripped entirely of their referents.  It will thus invent descriptions for scientific phenomenon that aren&#8217;t real, embellish descriptions of books that do not exist and if asked to cite things it will invent works to cite, <strong>because none of those things is any more or less real to ChatGPT than <em>actual real existing things</em></strong>.</p>\n\n\n\n<p>All it knows, <em>all it knows</em> are the statistical relationships of how words appear together, refined by the responses that its human trainers prefer.  Thus the statement that ChatGPT doesn&#8217;t know anything about anything or more correctly it cannot know anything about the topics it is asked to write about.</p>\n\n\n\n<p>All of that is important to understand what ChatGPT is doing when you tell it to, say, write an essay.  It is not considering the topic, looking up references, thinking up the best answer and then mobilizing evidence for that answer.  <strong>Instead it is taking a great big pile of words, picking out the words which are most likely to be related to the prompt and putting those words together in the order-relationships (but not necessarily the <em>logical</em> relationships) that they most often have, modified by the training process it has gone through to produce &#8216;better&#8217; results</strong>.  As one technical writer, Ted Chiang, has put it,<strong> <a href=\"https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web\" data-type=\"URL\" data-id=\"https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web\">the result is merely a &#8216;very lossy&#8217; (that is, not very faithful) reproduction of its training materials, rather than anything new or based on any actual understanding of the underlying objects or ideas</a>.</strong>  But, because it is a chatbot, its can dole those words out in tremendous quantity, with flawless spelling and grammar and to follow whatever formula (more or less) the prompt asks for.  But it doesn&#8217;t know what those words mean; indeed coming from the chatbot, in a sense they mean nothing.</p>\n\n\n\n<p>I stress this functionality at the beginning because I want readers to understand that many of the mental processes &#8211; analysis, verification, logical organization &#8211; that we take for granted from a thinking person are things ChatGPT does not do and <em>is entirely incapable of</em> in the same way that an electric can-opener cannot also double as a cell phone.  Those capabilities are both entirely outside of the structure of the current iteration of ChatGPT and also entirely outside of the processes that the training procedures which produced ChatGPT will train.  Incremental improvements in the can-opener will not turn it into a cell phone either; the cell phone is an entirely different sort of machine.  Thus the confidence among some that the &#8216;hallucination&#8217; problem will be inevitably solved seems premature to me.  It may well be solved, but it may well not; doing so will probably require the creation of an entirely new sort of machine of a type never before created.  That eventuality cannot be taken for granted; it is not even something that we know is <em>possible</em> (though it may well be!).  It most certainly will not happen on its own.</p>\n\n\n\n<h2 class=\"wp-block-heading\">The Heck Is an Essay?</h2>\n\n\n\n<p>So that is what ChatGPT does: in response to a prompt, it puts together an answer that is composed of words in its training material organized based on the statistical probability that those words appear together and the degree to which they are related to the prompt (processed through an extremely complex language model).  It thus assembles words from its big bag of words in a way that looks like the assemblages of words it has seen in its training and which its human trainers have ranked highly.  And if all you want ChatGPT to do is precisely that: somewhat randomly assemble a bunch of words loosely related to a topic in a form that <em>resembles</em> communication, it can do that for you.  I&#8217;m not sure <em>why</em> you want it to do that, but that is the one and only thing it can do.</p>\n\n\n\n<p>But can ChatGPT write an essay?</p>\n\n\n\n<p>It has been suggested that this endangers or even makes obsolete the essay or particularly the &#8216;college essay,&#8217; and I think this misunderstands what the purpose of an essay is.  Now the definition of an essay is somewhat nebulous, especially when it comes to length; essays are shorter than books but longer than notes but these too are nebulously defined.  Still we can have a useful definition:</p>\n\n\n\n<p><strong>An essay is a piece of relatively short writing designed to express an <em>argument</em> &#8211; that is, it asserts a truth about something real outside of the essay itself &#8211; by communicating the idea of argument itself (the <em>thesis</em>) and assembling <em>evidence</em> chosen to prove that argument to a reader</strong>.  Communication is thus <em>part</em> of writing an essay, but not the only part or even necessarily the most important.  Indeed, the communication element may come in entirely different forms from the traditional essay.  Consider video essays or photo essays: both have radically changed the form of communication but they remain essays because the important part &#8211; the argument asserting a truth about something supported by assembled evidence &#8211; remains the same, even as the nature of the evidence and communication has changed.</p>\n\n\n\n<p>Writing an essay thus involves a number of steps, of which communication is merely the last.  Ideally, the essay writer has first observed their subject, then drawn some sort of analytical conclusion about that subject,<span id='easy-footnote-5-17368' class='easy-footnote-margin-adjust'></span><span class='easy-footnote'><a href='#easy-footnote-bottom-5-17368' title='In our previous definition this conclusion is an &lt;em&gt;argument&lt;/em&gt;, but we could easily expand our definition to also include &lt;em&gt;descriptive&lt;/em&gt; essays (which aim not to make a new conclusion about something but merely assemble a collection of generally accepted facts).  There is still an analytical process here because the writer must determine what facts to trust, which are important enough to include and how they ought to be arranged, even though no &lt;em&gt;explicit&lt;/em&gt; argument is being made.  Indeed, such a descriptive essay (like a Wikipedia article) makes an &lt;em&gt;implicit&lt;/em&gt; argument based on what it is considered important enough to be included (e.g. on Wikipedia, what exactly is &amp;#8216;notable&amp;#8217;).'><sup>5</sup></a></span> then organized their evidence in a way that expresses the logical connections between various pieces of evidence, before finally communicating that to a reader in a way that is clear and persuasive.</p>\n\n\n\n<p>ChatGPT is entirely incapable of the first two steps (though it may <em>appear</em> to do either of them) and incompetent at the third; it&#8217;s capabilities are entirely on the last step (and even there generally inferior to a well-trained human writer at present).</p>\n\n\n\n<p>When it comes to observing a subject, as noted ChatGPT is not capable of research so the best it can do, to borrow Ted Chiang&#8217;s phrasing again, is provide a &#8216;lossy&#8217; replica of the research of others and only if that research has somehow found its way into ChatGPT&#8217;s training materials.  Even when the necessary <em>information</em> is contained within the works in ChatGPT&#8217;s training material, it can&#8217;t actually <em>understand</em> those things, it can only reproduce them, so if they do not <em>explicitly</em> draw the conclusion it needs in as many words, ChatGPT can&#8217;t do so either.  We can demonstrate this by asking ChatGPT an almost trivially easy research question, like, &#8220;What is the relationship between Edward Luttwak&#8217;s <em>Grand Strategy of the Roman Empire</em> and Benjamin Isaac&#8217;s <em>The Limits of Empire</em>?&#8221;  And so we did:</p>\n\n\n\n<figure class=\"wp-block-image size-full\"><img data-attachment-id=\"17419\" data-permalink=\"https://acoup.blog/2023/02/17/collections-on-chatgpt/limits-of-empire-2/\" data-orig-file=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/limits-of-empire-2.png?fit=737%2C715&amp;ssl=1\" data-orig-size=\"737,715\" data-comments-opened=\"1\" data-image-meta=\"{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}\" data-image-title=\"limits-of-empire-2\" data-image-description data-image-caption data-medium-file=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/limits-of-empire-2.png?fit=300%2C291&amp;ssl=1\" data-large-file=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/limits-of-empire-2.png?fit=737%2C715&amp;ssl=1\" decoding=\"async\" width=\"737\" height=\"715\" src=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/limits-of-empire-2.png?resize=737%2C715&#038;ssl=1\" alt class=\"wp-image-17419 jetpack-lazy-image\" data-recalc-dims=\"1\" data-lazy-srcset=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/limits-of-empire-2.png?w=737&amp;ssl=1 737w, https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/limits-of-empire-2.png?resize=300%2C291&amp;ssl=1 300w\" data-lazy-sizes=\"(max-width: 737px) 100vw, 737px\" data-lazy-src=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/limits-of-empire-2.png?resize=737%2C715&amp;is-pending-load=1#038;ssl=1\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\"><noscript><img data-lazy-fallback=\"1\" data-attachment-id=\"17419\" data-permalink=\"https://acoup.blog/2023/02/17/collections-on-chatgpt/limits-of-empire-2/\" data-orig-file=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/limits-of-empire-2.png?fit=737%2C715&amp;ssl=1\" data-orig-size=\"737,715\" data-comments-opened=\"1\" data-image-meta=\"{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}\" data-image-title=\"limits-of-empire-2\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/limits-of-empire-2.png?fit=300%2C291&amp;ssl=1\" data-large-file=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/limits-of-empire-2.png?fit=737%2C715&amp;ssl=1\" decoding=\"async\" loading=\"lazy\" width=\"737\" height=\"715\" src=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/limits-of-empire-2.png?resize=737%2C715&#038;ssl=1\" alt=\"\" class=\"wp-image-17419\" srcset=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/limits-of-empire-2.png?w=737&amp;ssl=1 737w, https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/limits-of-empire-2.png?resize=300%2C291&amp;ssl=1 300w\" sizes=\"(max-width: 737px) 100vw, 737px\" data-recalc-dims=\"1\"  /></noscript></figure>\n\n\n\n<p>If you know nothing about either book, this answer almost sounds useful (it isn&#8217;t).<span id='easy-footnote-6-17368' class='easy-footnote-margin-adjust'></span><span class='easy-footnote'><a href='#easy-footnote-bottom-6-17368' title='the description of &lt;em&gt;The Limits of Empire&lt;/em&gt; in particular is poor and mostly misses the book&amp;#8217;s core argument that there was no Roman &amp;#8216;grand strategy&amp;#8217; because the Romans were &lt;em&gt;incapable&lt;/em&gt; of conceiving of strategy in that way.'><sup>6</sup></a></span>  Now this is a <em>trivial</em> research task; simply typing &#8216;the limits of empire review&#8217; into Google and then clicking on the very first non-paywalled result (<a href=\"https://bmcr.brynmawr.edu/1990/1990.01.12/\" data-type=\"URL\" data-id=\"https://bmcr.brynmawr.edu/1990/1990.01.12/\">this review of the book by David Potter from 1990</a>) and reading <em><strong>the first paragraph</strong></em> makes almost immediately clear the correct answer is that Isaac&#8217;s book is an intentional and explicit <em>rebuttal</em> of Luttwak&#8217;s book, or as Potter puts it, &#8220;Ben Isaac’s <em>The Limits of Empire</em> offers a new and formidable challenge to Luttwack.&#8221;  A human being who <em>understands the words and what they mean</em> could immediately answer the question, but ChatGPT which doesn&#8217;t, cannot: it can only BS around the answer by describing both books and then lamely saying they &#8220;intersect in some ways.&#8221;  The <em>information</em> ChatGPT needed was clearly in its training materials (or it wouldn&#8217;t have a description of either book to make a lossy copy of),<span id='easy-footnote-7-17368' class='easy-footnote-margin-adjust'></span><span class='easy-footnote'><a href='#easy-footnote-bottom-7-17368' title='I&amp;#8217;m pretty sure from the other responses I have seen (but cannot be 100% confident) that the BMCR, which is open and available to all, was included in ChatGPT&amp;#8217;s corpus.'><sup>7</sup></a></span> but it lacks the capacity to understand that information <em>as information</em> (rather than as a statistically correlated sequence of words).<span id='easy-footnote-8-17368' class='easy-footnote-margin-adjust'></span><span class='easy-footnote'><a href='#easy-footnote-bottom-8-17368' title='While we&amp;#8217;re here I should note that I think &lt;em&gt;The Limits of Empire&lt;/em&gt; is hardly the last word on this question.  On why, you want to read E. Wheeler, &amp;#8220;Methodological Limits and the Mirage of Roman Strategy&amp;#8221; &lt;em&gt;JMH&lt;/em&gt; 57.1 and 57.2 (1993); Wheeler systematically destroys nearly all of Isaac&amp;#8217;s arguments.  I also asked ChatGPT to tell me what Wheeler&amp;#8217;s critiques were, but since Wheeler isn&amp;#8217;t in its training corpus, it couldn&amp;#8217;t tell me.  When I asked for a list of Isaac&amp;#8217;s most prominent critics, it didn&amp;#8217;t list Wheeler because, I suppose, no one in its corpus discussed his article, despite it being (to the best of my knowledge) generally understood that Wheeler&amp;#8217;s critique has been the most influential, as for instance noted by J.E. Lendon&lt;a href=&quot;https://www.jstor.org/stable/3298451&quot; data-type=&quot;URL&quot; data-id=&quot;https://www.jstor.org/stable/3298451&quot;&gt; in this review of the topic&lt;/a&gt; for &lt;em&gt;Classical Journal&lt;/em&gt; back in 2002.  ChatGPT can&amp;#8217;t tell you any of that because it can only tell you things other people have already written in its training corpus.  Instead, it listed Adrian Goldsworthy, Jeremy Armstrong, John W.I. Lee and Christopher S. Mackay because they all wrote reviews of the book; none of these scholars (some of whom are &lt;em&gt;great &lt;/em&gt;scholars) are particularly involved in the Roman strategy debate, so all of these answers are wrong.  The latest in this debate is James Lacey&amp;#8217;s &lt;em&gt;Rome: Strategy of Empire&lt;/em&gt; (2022), which is a solid reiteration of the Luttwakian side of the debate (valuable if only because Luttwak himself is a poor interlocutor in all of this) but seems unlikely to end it.  It is possible I am working on trying to say something useful on this topic at some point in the future.'><sup>8</sup></a></span>  Consequently it cannot draw the right conclusion and so talks around the question in a convincing, but erronous way.</p>\n\n\n\n<p>Note that no analysis was required for the above question!  It was a <em>pure</em> reading comprehension question that could be solved by merely recognizing that something in the training set already <em>said the answer</em> and <em>copying it</em>, but ChatGPT wasn&#8217;t even capable of that because while it has a big bag of words related to both books, it lacks the capability to understand and grab the <em>relevant</em> words.  This is an example of the not at all uncommon situation where Google is a far better research tool than ChatGPT, because Google can rely on your reading comprehension to understand the places it points you to which may have the answer you seek.</p>\n\n\n\n<p>So research and observation are out; what about analysis?  Well, if you have been following along you&#8217;ll realize that ChatGPT is incapable of doing that too.  What it can do is find something that <em>looks</em> like analysis (though it may not be analysis or it may be quite bad analysis) and then reproduce it (in a lossy form) for you.  But the point of analysis is to be able to provide novel insight, that is to either suggest a conclusion hitherto unconsidered for a given problem or equally importantly to come up with a conclusion for a problem that is only being encountered for the very first time.  ChatGPT, limited entirely to remixing <em>existing</em> writings, cannot do either.</p>\n\n\n\n<p>As a system to produce essays, this makes ChatGPT not very useful at all.  <strong>Generally when people want an essay, they don&#8217;t actually want <em>the essay</em>; the essay they are reading is instead a <em>container</em> for what they actually want which is the analysis and evidence.  An essay in this sense is a word-box that we put thoughts in so that we can give those thoughts to someone else</strong>.  But ChatGPT cannot <em>have</em> original thoughts, it can only remix writing that is already in its training material; it can only poorly copy writing someone else has already done <em>better</em> somewhere.<span id='easy-footnote-9-17368' class='easy-footnote-margin-adjust'></span><span class='easy-footnote'><a href='#easy-footnote-bottom-9-17368' title='It also isn&amp;#8217;t very good at discoverability.  It can&amp;#8217;t tell you &lt;em&gt;who&lt;/em&gt; or &lt;em&gt;where&lt;/em&gt; that better idea is from if you find yourself wanting more explanation or context.  Once again, as a research tool, Google is pretty clearly superior.'><sup>9</sup></a></span>  <strong>ChatGPT in this sense is like a friendly, if somewhat daft neighbor who noticed one day that every so often you get a box from Amazon and that you seem quite happy to get it and so decides to do you a favor by regularly ordering empty Amazon boxes to your house</strong>.  The poor fellow does not know and cannot understand that it was the <em>thing in the box</em> &#8211; in this case, the <em>thoughts</em> (original observations, analysis, evidence) in the essay &#8211; that you actually wanted.  ChatGPT doesn&#8217;t have any thoughts to give you (though it can somewhat garble someone else&#8217;s thoughts), but it sure can order you up a bunch of very OK boxes.</p>\n\n\n\n<p><strong>In a very real sense then, ChatGPT cannot write an essay. </strong> It can <em>imitate</em> an essay, but because it is incapable of the tasks which give an essay its actual use value (original thought and analysis), it can only produce inferior copies of other writing.  That quite a few people, including some journalists, have supposed that ChatGPT <em>can</em> write an essay suggests to me that they have an impoverished idea of what an essay <em>is</em>, viewing it only as &#8216;content&#8217; rather than as a box that thoughts go into for delivery, or haven&#8217;t really scrutinized what ChatGPT outputs closely enough.</p>\n\n\n\n<p><strong>Now there are, in that previous analogy, box-sellers online: outlets who really do not care about the thoughts in the essay but merely want units of text to throw up to generate clicks</strong>.  Few reputable publications function this way &#8211; that&#8217;s why they have editors whose job is to try to figure out if your essay has a thought in it actually worth sharing and then if so to help guide you to the most effective presentation of that thought (that&#8217;s the editing process).  But there are a lot of content mills online which are really looking to just supply large amounts of vaguely relevant text at the lowest possible cost hoping to harvest views from gullible search engines.  <strong>For those content mills, ChatGPT potentially has a lot of value but those content mills provide almost no value to us, the consumer.  Far from it, they are one of the major reasons why folks <a href=\"https://freakonomics.com/podcast/is-google-getting-worse/\" data-type=\"URL\" data-id=\"https://freakonomics.com/podcast/is-google-getting-worse/\">report declining search engine quality</a>, as they crowd out actually useful content</strong>.<span id='easy-footnote-10-17368' class='easy-footnote-margin-adjust'></span><span class='easy-footnote'><a href='#easy-footnote-bottom-10-17368' title='This is painfully obvious when it comes to trying to get information about video games.  In ye days of yore, Google would swiftly send you to the GameFaqs page (remember those!?) or the helpful fan Wiki, but more recently it becomes necessary to slog through a page or two of overly long (because Google prefers pages with at least a certain amount of text) answers to very simple questions in order to find what you are looking for (which usually ends up being a helpful response to someone&amp;#8217;s question on Reddit or a Steam guide or, because I still like to live in 2004, an actual GameFaqs page).'><sup>10</sup></a></span></p>\n\n\n\n<p>That said I don&#8217;t want to rule out ChatGPT&#8217;s ability to produce functional formulaic documents entirely.  I&#8217;ve heard it suggested that it could massively reduce the cost of producing formula-driven legal and corporate documents and perhaps it can.  It&#8217;s also been suggested it could be trained to write code, though my understanding is that as of now, most of the code it produces looks good but does not work well.  I don&#8217;t write those sorts of things, though, so I can&#8217;t speak to the question.  I would be concerned though, because ChatGPT can make some very bad mistakes and has no way of catching those mistakes, so very high stakes legal or corporate documents seems like a risky use of ChatGPT.  ChatGPT can&#8217;t write a good essay, but a bad essay only wastes a few minutes of your time; a bad contract can cost a company millions and a single bad line of code can crash an entire program (or just cause it to fail to compile and in either case waste hours and hours of bug-hunting to determine what went wrong).</p>\n\n\n\n<p><strong>But the core work of the essay?  This ChatGPT cannot do</strong>.  And importantly it is not some capacity which merely requires iterative improvements on the product.  <strong>While ChatGPT can <em>fake</em> an original essay, the jump from faking that essay to writing an actually original thought certainly looks like it would require a completely different program, one capable of observing the real world, analyzing facts about it and then reaching conclusions</strong>.</p>\n\n\n\n<h2 class=\"wp-block-heading\">The Heck is the Teaching Essay For?</h2>\n\n\n\n<p>That leaves the role of ChatGPT in the classroom.  And here some of the previous objections do indeed break down.  A classroom essay, after all, isn&#8217;t meant to be original; the instructor is often assigning an entire class to write essays on the same topic, producing a kaleidoscope of quite similar essays using similar sources.  Moreover classroom essays are far more likely to be about the kind of &#8216;Wikipedia-famous&#8217; people and works which have enough of a presence in ChatGPT&#8217;s training materials for the program to be able to cobble together a workable response (by quietly taking a bunch of other such essays, putting them into the blender and handing out the result, a process which in the absence of citation we probably ought to understand as plagiarism).  In short, many students are often asked to write an essay that many hundreds of students have already written before them.  And so there were quite a few pronouncements that ChatGPT <a href=\"https://www.theatlantic.com/technology/archive/2022/12/chatgpt-ai-writing-college-student-essays/672371/\" data-type=\"URL\" data-id=\"https://www.theatlantic.com/technology/archive/2022/12/chatgpt-ai-writing-college-student-essays/672371/\">had &#8216;killed&#8217; the college essay</a>. And indeed, in my own experience in the Twitter discourse around the system, one frequent line of argument was that ChatGPT was <em>going</em> to disrupt my classroom, so shouldn&#8217;t I just go ahead and get on board with the new technology?</p>\n\n\n\n<p><strong>This both misunderstands what the college essay is <em>for</em> as well as the role of disruption in the classroom</strong>.  Let&#8217;s start with the first question: what is the teaching essay (at any level of schooling) <em>for</em>?  It&#8217;s an important question and one that arises out of a consistent problem in how we teach students, which is that we rarely <em>explain our pedagogy</em> (our &#8216;teaching strategy&#8217;) to the students.  That tends to leave many assignments feeling arbitrary even when teachers have in fact put a great deal of thought into why they are assigning what they are and what skills they are supposed to train.  So let&#8217;s talk about why we assign essays, what those assignments are supposed to accomplish and why ChatGPT has little to offer in that realm.</p>\n\n\n\n<p><strong>In practice there are three things that I am aiming for an essay assignment to accomplish in a classroom.  The first and probably least important is to get students to think about a specific historical topic or idea, since they (in theory) must do this in order to write about it</strong>.  In my own planning I sometimes refer to these assignments as &#8216;pedagogical&#8217; essays (not a perfect term) where the assignment &#8211; typically a &#8216;potted&#8217; essay (short essay with pre-chosen sources handed to students, opposite of a &#8216;research&#8217; essay) &#8211; is meant to have students ponder a specific question for the value of that question.  One example is an essay prompt I sometimes use in my ancient history survey asking students, &#8220;On what basis do we consider Alexander to be &#8216;great&#8217;?  Is this a sound basis to apply this title?&#8221;  Obviously I want students here to both understand something about Alexander but also to <em>think about the idea of greatness</em> and what that means; does successfully killing a lot of people and then failing to administer what remains qualify as greatness and if so what does that say about what we value?  Writing the essay forces them to ponder the question.  That value is obviously lost if they just let ChatGPT copy some other essay for them.</p>\n\n\n\n<p>That said this first sort of goal is often the least important.  While of course I think my course material matters, the fact is few students will need to be able to recall from memory the details of Alexander the Great at some point in their life.  They&#8217;ll be able to look him up and hopefully with the broad knowledge framework I&#8217;ve given them and the research and analysis skills, be able to reach for these same conclusions.  Which brings us to:</p>\n\n\n\n<p><strong>The second goal and middle in importance is training the student in how to write essays</strong>.  I&#8217;ve made this element of my approach more explicit in recent years, making the assignments more closely resemble the real world writing forms they train for.  Thus the classics 3-5 page paper becomes the c. 1000 word think-piece (though I do require a bit more citation than a print publication would in a &#8216;show your work&#8217; sort of way), the sort paper becomes a 700-800 word op-ed, etc.  The idea here is to signal to students more clearly that they are training to write real things that exist in the world outside of the classroom.  That said, while a lot of students can imagine situations in which they might want to write an op-ed or a think piece or a short speech, many of them won&#8217;t ever write another formal essay after leaving college.</p>\n\n\n\n<p><strong>Thus the last and most important thing I am trying to train is not the form of the essay nor its content, but the basic skills of having a thought and putting it in a box that we outlined earlier</strong>.  Even if your job or hobbies do not involve formal writing, chances are (especially if your job requires a college degree) you are still expected to observe something real, make conclusions about it and then present those conclusions to someone else (boss, subordinates, co-workers, customers, etc.) in a clear way, supported by convincing evidence if challenged.  <strong>What we are practicing then is how to have good thoughts, put them in good boxes and then effectively hand that box to someone else</strong>.  That can be done in a formal written form (the essay), in informal writing (emails, memos, notes, Slack conversations), or verbally (speeches, but also arguments, debates and discussions).  The skills of having the idea, supporting it with evidence, organizing that evidence effectively to be understood and then communicating that effectively are transferable and the most important skills that are being practiced when a student writes an essay.</p>\n\n\n\n<p>Crucially &#8211; and somehow this point seems to be <em>missed</em> by many of ChatGPT&#8217;s boosters I encountered on social media &#8211; <strong>at no point in this process do I actually want the essays</strong>.  Yes, they have to be turned in to me and graded and commented because that feedback in turn is meant to both motivate students to improve but also to signal where they need to improve.<span id='easy-footnote-11-17368' class='easy-footnote-margin-adjust'></span><span class='easy-footnote'><a href='#easy-footnote-bottom-11-17368' title='And thus, dear students, if you are not &lt;em&gt;reading the comments&lt;/em&gt; you are not getting what you paid tens of thousands of dollars for when you paid tuition.  Read the comments.  You are in college to &lt;em&gt;learn things&lt;/em&gt; not prove what you already know or how smart you already are.  We know you are smart, that&amp;#8217;s why you got admitted to college; the question now is about drive and willingness to &lt;em&gt;learn&lt;/em&gt;.'><sup>11</sup></a></span>  <strong>But I did not assign the project because I wanted the essays</strong>.  To indulge in an analogy, I am not asking my students to forge some nails because I want a whole bunch of nails &#8211; the nails they forge on early attempts will be quite bad <em>anyway</em>.  I am asking them to forge nails so that they <em>learn how to forge nails</em> (which is why I inspect the nails and explain their defects each time) and by extension also learn how to forge <em>other things</em> that are akin to nails.  <strong>I want students to learn how to analyze, organize ideas and communicate those ideas</strong>.</p>\n\n\n\n<p>What one can immediately see is that a student who simply uses ChatGPT to write their essay for them has simply cheated themselves out of the opportunity to learn (and also wasted my time in providing comments and grades).  As we&#8217;ve seen above, ChatGPT cannot effectively replace the actual core tasks we are training for, so this is not a case where the existence of spinning jennies renders most training at hand spinning obsolete.  And it certainly doesn&#8217;t fulfill the purpose of the assignment.</p>\n\n\n\n<p><strong>To which some boosters of the technology respond that what I should <em>really</em> be <a href=\"https://twitter.com/BradDFelix/status/1624094644043755541\" data-type=\"URL\" data-id=\"https://twitter.com/BradDFelix/status/1624094644043755541\">doing </a>is <a href=\"https://twitter.com/eranshir/status/1624340970492899332\" data-type=\"URL\" data-id=\"https://twitter.com/eranshir/status/1624340970492899332\">training </a><a href=\"https://twitter.com/shaun_harrison/status/1624006980183400449\" data-type=\"URL\" data-id=\"https://twitter.com/shaun_harrison/status/1624006980183400449\">students </a>on how to most effectively use ChatGPT as a tool</strong>.  But it is not clear to me that ChatGPT functions well as a tool for any part of this process.  One suggestion is to write an outline and then feed that into ChatGPT to generate a paper, but that fails to train the essential communication component of the assignment and in any case, ChatGPT is actually pretty bad at the nuts of and bolts of writing paragraphs.  Its tendency in particular to invent facts or invent non-existent sources to cite makes it an enormous liability here; it is a <em>very bad</em> research tool because it is unreliable.  Alternately the suggestion is that students could use ChatGPT to produce an essay they edit to fit or an outline they fill in; both problems run into the issue that the student is now trying to offload the most important part of the task for them to <em>learn</em>: the actual thinking and analysis.  <strong>And the crucial thing to note is that the skill that is not being trained in both cases is a skill that current large language models like ChatGPT cannot perform or perform very poorly</strong>.<span id='easy-footnote-12-17368' class='easy-footnote-margin-adjust'></span><span class='easy-footnote'><a href='#easy-footnote-bottom-12-17368' title='There is thus a meaningful difference between this and the &amp;#8216;why did I need to learn math without a calculator&amp;#8217; example that gets reused here, in that a calculator can at least do basic math for you, but ChatGPT cannot think for you.  That said, I had quite a difficult time learning that sort of thing as a kid, but (with some extra effort from my parents) I did learn it and I&amp;#8217;ve found it tremendously useful in life.  Being able to calculate a tip in my head or compare the per-unit price of, say, 3-for-whatever sale on 12pack sodas vs. a 24pack of the same brand without having to plug it into my phone is really handy.  I thus find myself somewhat confused by folks I run into who are bitter they were forced to learn mathematics first without a calculator.'><sup>12</sup></a></span></p>\n\n\n\n<p>I suspect this argument looks plausible to people because they are not thinking in terms of being trained to think about novel problems, but in terms of the assignment itself; they are thinking about the most efficient way to produce &#8216;one unit of essay.&#8217;   <strong>But what we&#8217;re actually doing is practicing a non-novel problem (by <em>treating</em> it as a novel problem for the purpose of the assignment), so that when we run into novel problems, we&#8217;ll be able to apply the same skills</strong>.  Consequently they imagine that ChatGPT, trained as it is on what seems to be an awful lot of mediocre student essays (it mimics the form of a bad student essay with <em>remarkable</em> accuracy), can perform the actual final task in question, but it cannot.</p>\n\n\n\n<h2 class=\"wp-block-heading\">Conclusion: Preparing to Be &#8216;Disrupted.&#8217;</h2>\n\n\n\n<p>The reply that all of this gets has generally been some combination of how this technology is &#8216;the future,&#8217; that it will make essay writing obsolete so I should focus on training for it,<span id='easy-footnote-13-17368' class='easy-footnote-margin-adjust'></span><span class='easy-footnote'><a href='#easy-footnote-bottom-13-17368' title='A point we have already addressed.'><sup>13</sup></a></span>, and most of all that the technology will soon be so good, if it is not already, that<a href=\"https://twitter.com/theobserver42/status/1624156895782273025\" data-type=\"URL\" data-id=\"https://twitter.com/theobserver42/status/1624156895782273025\"> any competent student will be able to use it to perfectly fake good papers</a>.  <strong>Thus, I am told, my classroom is doomed to be &#8216;disrupted&#8217; by this technology so I should preemptively surrender and get on board.</strong></p>\n\n\n\n<p>And no.  No, I don&#8217;t think so.</p>\n\n\n\n<p>I do think there are classrooms that will be disrupted by ChatGPT, but those are classrooms where something is already broken.  <strong>Certainly for a history classroom, if ChatGPT can churn out a decent essay for your assignment, chances are the assignment is poorly designed</strong>.  ChatGPT after all cannot analyze a primary source (unless it is already been analyzed many times in its training materials), it struggles to cite scholarship (more often inventing fake sources) and it generally avoids specific evidence.  Well-designed assignments which demand proper citation, <em>specific</em> evidence to support claims (rather than general statements) and a clear thesis are going to be beyond ChatGPT and indeed require so much editing to produce from a ChatGPT framework as to make it hardly worth the effort to cheat.  <strong>If your essay prompt can be successfully answered using nothing but vague ChatGPT generated platitudes, it is a bad prompt</strong>.<span id='easy-footnote-14-17368' class='easy-footnote-margin-adjust'></span><span class='easy-footnote'><a href='#easy-footnote-bottom-14-17368' title='The one exception here are online courses using &amp;#8216;closed book&amp;#8217; online essay tests.  That is an exam model which will be rendered difficult by this technology.  I think clever prompt writing (demand the students do things &amp;#8211;  be specific in evidence or reference specific works &amp;#8211; that ChatGPT is bad at) or use alternative assignments (a capstone project or essay instead).  For in-person classes, the entire problem is obviated by the written in-class essay.'><sup>14</sup></a></span></p>\n\n\n\n<p>Meanwhile, ChatGPT responses seem to be actually pretty easy to spot once you know how to look for the limitations built into the system.  There are already programs designed to detect if a piece of writing is machine-written; they&#8217;re not fully reliable yet but I suspect they will become more reliable over time mostly because it is in the interests of both AI-developers (who do not want their models trained on non-human produced writing) and search engines (who want to be able to exclude from search results the veritable river of machine-produced content-mill garbage we all know is coming) to develop that capability.  But because of the ways ChatGPT is limited, a human grader should also be able to flag ChatGPT generated responses very quickly too.</p>\n\n\n\n<p>It should be trivially easy, for instance, for a grader to confirm if the sources a paper cites exist.<span id='easy-footnote-15-17368' class='easy-footnote-margin-adjust'></span><span class='easy-footnote'><a href='#easy-footnote-bottom-15-17368' title='And if they &lt;em&gt;don&amp;#8217;t&lt;/em&gt;, that&amp;#8217;s academic dishonestly regardless of who wrote the paper.'><sup>15</sup></a></span>  A paper with a bunch of convincing sounding but entirely invented sources is probably machine-written because humans don&#8217;t tend to make that mistake.  If instead, as is its wont, the paper refers merely vaguely to works written by a given author or on a given topic, insist the student produce those works (and <em>require citation on all papers</em>) &#8211; this will be very hard for the student with the ChatGPT paper as those works will not, in fact, exist.<span id='easy-footnote-16-17368' class='easy-footnote-margin-adjust'></span><span class='easy-footnote'><a href='#easy-footnote-bottom-16-17368' title='And a student that cannot or will not cite their sources has plagiarized, regardless of who wrote their paper.  ChatGPT is such a mess of academic dishonesty that it isn&amp;#8217;t even necessary to prove its products were machine-written because the machine &lt;em&gt;also&lt;/em&gt; does the sort of things which can get you kicked out of college.'><sup>16</sup></a></span>  ChatGPT also has a habit of mistaking non-famous people for famous people with similar names; again for a grader familiar with the material this should be quite obvious.</p>\n\n\n\n<p>And then of course there are the errors.  ChatGPT makes a lot of factual mistakes, especially as it gets into more technical questions where the amount of material for it to be trained on is less.  While the text it produces often <em>looks</em> authoritative to someone with minimal knowledge in that field, in theory the person grading the paper should have enough grounding to spot some of the obvious howlers that are bound to sneak in over the course of a longer research paper.<span id='easy-footnote-17-17368' class='easy-footnote-margin-adjust'></span><span class='easy-footnote'><a href='#easy-footnote-bottom-17-17368' title='And if the student has gone back and done the research to be able to correct those errors and rewrite those sentences in advance&amp;#8230;at this point why not just write the paper honestly and not risk being thrown out of college?'><sup>17</sup></a></span>  By way of example, I asked ChatGPT to write  on, &#8220;the causes of Roman military success in the third and second centuries BCE.&#8221;  Hardly a niche topic.<span id='easy-footnote-18-17368' class='easy-footnote-margin-adjust'></span><span class='easy-footnote'><a href='#easy-footnote-bottom-18-17368' title='In the event I asked for 8,000 words because I wanted to see how it would handle organizing a larger piece of writing.  Now in the free version it can&amp;#8217;t write that many words before it runs out of &amp;#8216;tokens,&amp;#8217; but I wanted to see how the introduction would set up the organization for the bits it wouldn&amp;#8217;t get to.  In practice it set up an essay in three or four chunks the first of which was 224 words; ChatGPT doesn&amp;#8217;t seem to be able to even set up a larger and more complex piece of writing.  It also doesn&amp;#8217;t plan for a number of words limited by how many it can get to before running out of tokens either, in case anyone thinks that&amp;#8217;s what it was doing: to get to the end of the essay with all of the components it laid out in the introduction I had to jog it twice.'><sup>18</sup></a></span>   The whole thing was sufficiently full of problems and errors that I&#8217;m just going to include an annotated word document pointing them all out here:</p>\n\n\n\n<div class=\"wp-block-file\"><a id=\"wp-block-file--media-bb9f6dab-8cf3-4596-9419-a9319214beaa\" href=\"https://acoup.blog/wp-content/uploads/2023/02/ChatGPT-on-Roman-Military-Success.docx\">ChatGPT-on-Roman-Military-Success</a><a href=\"https://acoup.blog/wp-content/uploads/2023/02/ChatGPT-on-Roman-Military-Success.docx\" class=\"wp-block-file__button wp-element-button\" download aria-describedby=\"wp-block-file--media-bb9f6dab-8cf3-4596-9419-a9319214beaa\">Download</a></div>\n\n\n\n<p>Needless to say, this would not be a passing (C or higher) paper in my class.  Exact counting here will vary but I identified 38 factual claims, of which 7 were correct, 7 were badly distorted and 24 were simply wrong.  A trainwreck this bad would absolutely have me meeting with a student and raising questions which &#8211; if the paper was machine written &#8211; might be very hard for the student to answer.  Indeed, a research paper with just three or four of these errors would probably prompt a meeting with a student to talk about their research methods.  This is certainly then also an error rate which is going to draw my attention and now cause me to ask questions about who exactly wrote the essay and how.<span id='easy-footnote-19-17368' class='easy-footnote-margin-adjust'></span><span class='easy-footnote'><a href='#easy-footnote-bottom-19-17368' title='Of course if the student has just tried honestly and failed, they&amp;#8217;ll be able to document that process quite easily, with the works they read and where each wrong fact came from, whereas the student who has cheated using ChatGPT will be incapable of doing so.'><sup>19</sup></a></span></p>\n\n\n\n<p>And that&#8217;s the thing: in a free market, a competitor cannot simply exclude a disruptive new technology.  But in a <em>classroom</em>, we can <em>absolutely</em> do this thing.  I am one of those professors who doesn&#8217;t allow laptops for note-taking (unless it is a disability accommodation, of course) because there&#8217;s <a href=\"https://blueprintlabs.mit.edu/research/the-impact-of-computer-usage-on-academic-performance-evidence-from-a-randomized-trial-at-the-united-states-military-academy/\" data-type=\"URL\" data-id=\"https://blueprintlabs.mit.edu/research/the-impact-of-computer-usage-on-academic-performance-evidence-from-a-randomized-trial-at-the-united-states-military-academy/\">quite a bit</a> <a href=\"https://journals.sagepub.com/doi/10.1177/0956797614524581\" data-type=\"URL\" data-id=\"https://journals.sagepub.com/doi/10.1177/0956797614524581\">of evidence</a> that laptops as note-taking devices lower student performance (quite apart from their potential to distract) and my goal is to maximize learning.  This isn&#8217;t me being a luddite; I would ban, say, classroom firecrackers or a live jazz band for the same reason and if laptops <em>improved</em> learning outcomes somehow (again, the research suggests they don&#8217;t), I&#8217;d immediately permit them.  <strong>Given that detecting machine-writing isn&#8217;t particularly hard and that designing assignments that focus on the skills humans can learn that the machines cannot (and struggle to fake) is good pedagogical practice anyway, excluding the technology from my classroom is not only <em>possible</em> it is indeed <em>necessary</em></strong>.</p>\n\n\n\n<p>Now will this disrupt some classrooms?  Yes.  Overworked or indifferent graders will probably be fooled by these papers or more correctly they will not care who wrote the paper because those instructors or graders are either not very much invested in learning outcomes or not given the time and resources <em>to invest</em> however much they might wish to.  I think schools are going to need to think particularly about the workload on adjuncts and TAs who are sometimes asked to grade through absurdly high amounts of papers in relatively little time and thus will simply lack the time read carefully enough.  Of course given how much students are <em>paying</em> for this, one would assume that resources could be made available to allow for the bare minimum of scrutiny these assignments deserve.  Schools may also need to rethink the tradeoffs of hiring indifferent teachers &#8216;for their research&#8217; or for the prestige of their PhD institutions because the gap between good, dedicated teachers and bad, indifferent ones is going to grow wider as a result of this technology.</p>\n\n\n\n<p>Likewise, poorly designed assignments will be easier for students to cheat on, but that simply calls on all of us to be more careful and intentional with our assignment design (though in practice in my experience most professors, at least in history and classics, generally are).  I will confess every time I see a news story about how ChatGPT supposedly passed this or that exam, I find myself more than a little baffled and quite concerned about the level of work being expected in those programs.  <a href=\"https://www.cnn.com/2023/01/26/tech/chatgpt-passes-exams/index.html\" data-type=\"URL\" data-id=\"https://www.cnn.com/2023/01/26/tech/chatgpt-passes-exams/index.html\">If ChatGPT can pass business school</a>, that might say something rather concerning about business school (or at least the bar they set for passing).</p>\n\n\n\n<p>The final argument I hear is that while ChatGPT or large language models like it may not make my job obsolete <em>now</em>, they will <em>inevitably</em> do so in the future, that these programs are inevitably going to improve to the point where all of the limitations I&#8217;ve outlined will be surpassed.  And I&#8217;ll admit some of that is <em>possible</em> but I do not think it is by any means <em>certain</em>.  Of the processes we&#8217;ve laid out here, observing, analyzing those observations, arranging evidence to support conclusions and then communicating all of that, ChatGPT only does (or pretends to do) the last task.  As I noted above, an <em>entirely new machine</em> would be necessary for these other processes and it is not certain that such a machine is possible within the limits of the computing power now available to us.  I rather <em>suspect</em> it is, but it doesn&#8217;t seem certain that it is.</p>\n\n\n\n<p>More broadly, as far as I can tell it seems that a lot of AI research (I actually dislike a lot of these terms which seem to me to imply that what we&#8217;ve achieved is a lot closer to a synthetic mind than it really is, at least for now) has proceeded on a &#8216;fake it till you make it&#8217; model.  <strong>It makes sense as a strategy: want to produce a mind, but we don&#8217;t <em>really</em> know how a mind works at full complexity, so we&#8217;ve chosen instead to try to create machines which can convincingly <em>fake</em> being a mind in the hopes that a maximally convincing fake will turn out to <em>be a mind</em> of some sort</strong>.  I have no trouble imagining that strategy <em>could</em> work, but what I think AI-boosters need to consider is that it also may not.  It may in fact turn out that the sort of machine learning we are doing is a dead end.</p>\n\n\n\n<p>It wouldn&#8217;t be the first time!  <a href=\"https://en.wikipedia.org/wiki/Alchemy\" data-type=\"URL\" data-id=\"https://en.wikipedia.org/wiki/Alchemy\">Early alchemists</a> spent a lot of time trying to transmute lead into gold; they ended up pioneering a lot of chemistry, exploring chemical reactions to try to achieve that result.  Important things were learned, but you know what no amount of alchemical proto-chemistry was ever going to do?  Turn lead into gold.  As a means of <em>making gold</em> those experiments were dead ends; if you want to turn lead into gold you have to figure out some way of <a href=\"https://en.wikipedia.org/wiki/Nuclear_transmutation\" data-type=\"URL\" data-id=\"https://en.wikipedia.org/wiki/Nuclear_transmutation\">ripping three protons off of a lead atom</a> which purely chemical reactions cannot do.  The alchemist who devised chemical reactions aiming to produce progressively more convincing fakes of gold until he at last managed the perfect fake that would be the real thing was bound to fail because that final step turns out to be impossible.  The problem was that the alchemist had to experiment without knowing what made some things (<a href=\"https://en.wikipedia.org/wiki/Chemical_compound\" data-type=\"URL\" data-id=\"https://en.wikipedia.org/wiki/Chemical_compound\">compounds</a>) different from other things (<a href=\"https://en.wikipedia.org/wiki/Chemical_element\" data-type=\"URL\" data-id=\"https://en.wikipedia.org/wiki/Chemical_element\">elements</a>) and so couldn&#8217;t know that while compounds could be altered in chemical reactions, elements could not.</p>\n\n\n\n<p>In short, just as the alchemist labored without really knowing what gold <em>was</em> or how it <em>worked</em>, but was only able to observe its outward qualities, so too our AI engineers are forced to work without really knowing what a mind <em>is</em> or how it <em>works</em>.  This present research may turn out to be the way that we end up learning what a mind really is and how it really works, or it may be a dead end.  We may never turn ChatGPT into gold.  It may be impossible to do so.  Hopefully even if that is the case, we&#8217;ll have developed some useful tools along the way, just like those alchemists pioneered much of chemistry in the pursuit of things chemistry was incapable of doing.</p>\n\n\n\n<p><strong>In the meantime, I am asking our tech pioneers to please be more alive to the consequences of the machines you create</strong>.  Just because something <em>can</em> be done doesn&#8217;t mean it <em>should</em> be done.  We <em>could</em> decide to empirically test if 2,000 nuclear detonations will actually produce a nuclear winter,<span id='easy-footnote-20-17368' class='easy-footnote-margin-adjust'></span><span class='easy-footnote'><a href='#easy-footnote-bottom-20-17368' title='a hotly debated topic, actually!'><sup>20</sup></a></span> <em>but we shouldn&#8217;t</em>.  Some inventions &#8211; say, <a href=\"https://acoup.blog/2020/03/20/collections-why-dont-we-use-chemical-weapons-anymore/\" data-type=\"URL\" data-id=\"https://acoup.blog/2020/03/20/collections-why-dont-we-use-chemical-weapons-anymore/\">sarin gas</a> &#8211; <em>shouldn&#8217;t be used</em>.  <strong>Discovering what we <em>can</em> do is always laudable; <em>doing it</em> is not always so</strong>.  And yet again and again these new machines are created and deployed with vanishingly little concern about what their impacts might be.  Will ChatGPT improve society, <a href=\"https://twitter.com/Roelkonijn/status/1626292591980433408\" data-type=\"URL\" data-id=\"https://twitter.com/Roelkonijn/status/1626292591980433408\">or just clutter the internet with more junk that will take real humans more time to sort through</a>?  Is this a tool for learning or just a tool to disrupt the market in cheating?</p>\n\n\n\n<figure class=\"wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter\"><div class=\"wp-block-embed__wrapper\">\n<blockquote class=\"twitter-tweet\" data-width=\"550\" data-dnt=\"true\"><p lang=\"en\" dir=\"ltr\">Sci-Fi Author: In my book I invented the Torment Nexus as a cautionary tale<br><br>Tech Company: At long last, we have created the Torment Nexus from classic sci-fi novel Don&#39;t Create The Torment Nexus</p>&mdash; Alex Blechman (@AlexBlechman) <a href=\"https://twitter.com/AlexBlechman/status/1457842724128833538?ref_src=twsrc%5Etfw\">November 8, 2021</a></blockquote><script async src=\"https://platform.twitter.com/widgets.js\" charset=\"utf-8\"></script>\n</div></figure>\n\n\n\n<p>Too often the response to these questions is, &#8220;well if it can be done, someone will do it, so I might as well do it first (and become famous or rich),&#8221; which is both an immorally self-serving justification but also a suicidal rule of conduct to adopt for a species which has the capacity to fatally irradiate its only biosphere.  <strong>The amount of power our species has to create and destroy <em>long ago</em> exceeded the point where we could survive on that basis</strong>.</p>\n\n\n\n<p>And that problem &#8211; that we need to think hard about the ethics of our inventions before we let them escape our labs &#8211; that is a thinking problem and thus one in which ChatGPT is entirely powerless to help us.</p>\n<div class=\"sharedaddy sd-sharing-enabled\"><div class=\"robots-nocontent sd-block sd-social sd-social-icon-text sd-sharing\"><h3 class=\"sd-title\">Share this:</h3><div class=\"sd-content\"><ul><li class=\"share-twitter\"><a rel=\"nofollow noopener noreferrer\" data-shared=\"sharing-twitter-17368\" class=\"share-twitter sd-button share-icon\" href=\"https://acoup.blog/2023/02/17/collections-on-chatgpt/?share=twitter\" target=\"_blank\" title=\"Click to share on Twitter\" ><span>Twitter</span></a></li><li class=\"share-facebook\"><a rel=\"nofollow noopener noreferrer\" data-shared=\"sharing-facebook-17368\" class=\"share-facebook sd-button share-icon\" href=\"https://acoup.blog/2023/02/17/collections-on-chatgpt/?share=facebook\" target=\"_blank\" title=\"Click to share on Facebook\" ><span>Facebook</span></a></li><li class=\"share-end\"></li></ul></div></div></div><ol class=\"easy-footnotes-wrapper\"><li class=\"easy-footnote-single\"><span id=\"easy-footnote-bottom-1-17368\" class=\"easy-footnote-margin-adjust\"></span>And I should be clear right here ahead of time that nothing that follows is particular to any paper(s) I may have received.  Do not ask &#8220;what happened to the student(s)?&#8221; or &#8220;how did you know?&#8221; or &#8220;what class was this in?&#8221; because I can&#8217;t tell you.  <a href=\"https://en.wikipedia.org/wiki/Family_Educational_Rights_and_Privacy_Act\" data-type=\"URL\" data-id=\"https://en.wikipedia.org/wiki/Family_Educational_Rights_and_Privacy_Act\">Student privacy laws</a> in the United States protect that sort of information and it is a good thing they do.  The observations that follow are not based on student papers, instead they are based on a number of responses I had ChatGPT produce for me to get a sense of what such an effort at cheating might look like and how I might detect it.<a class=\"easy-footnote-to-top\" href=\"#easy-footnote-1-17368\"></a></li><li class=\"easy-footnote-single\"><span id=\"easy-footnote-bottom-2-17368\" class=\"easy-footnote-margin-adjust\"></span>After all I may not have experience as a creator of large language models, but I am a fully qualified <em>end user</em>. I cannot and indeed will not critique how ChatGPT was created, but I am perfectly qualified to say, &#8220;this product as delivered does not meet any of my needs.&#8221;<a class=\"easy-footnote-to-top\" href=\"#easy-footnote-2-17368\"></a></li><li class=\"easy-footnote-single\"><span id=\"easy-footnote-bottom-3-17368\" class=\"easy-footnote-margin-adjust\"></span>Not that pets don&#8217;t have emotions or some kind of understanding, but we anthropomorphize our pets <em>a lot</em> as a way of relating to them.<a class=\"easy-footnote-to-top\" href=\"#easy-footnote-3-17368\"></a></li><li class=\"easy-footnote-single\"><span id=\"easy-footnote-bottom-4-17368\" class=\"easy-footnote-margin-adjust\"></span>Since I am going to use this phrase a lot I should be clear on its meaning.  To &#8216;beg the question&#8217; is not to ask someone to ask you something, but rather to ask your interlocutor in a debate or discussion to concede as a first step the very thesis you wanted to prove.  If we were, say, debating the value of Jane Austin&#8217;s writing and I lead by saying, &#8220;well, you must first concede she writes extremely well!&#8221; that would be question begging.  It&#8217;s more common to see actual question begging occur as a definitional exercise; an attorney that defines the defendant at a trial as a &#8216;criminal&#8217; has begged the question, assuming the guilt of the person whose guilt has not yet judged in the proceeding where that is the primary concern.<a class=\"easy-footnote-to-top\" href=\"#easy-footnote-4-17368\"></a></li><li class=\"easy-footnote-single\"><span id=\"easy-footnote-bottom-5-17368\" class=\"easy-footnote-margin-adjust\"></span>In our previous definition this conclusion is an <em>argument</em>, but we could easily expand our definition to also include <em>descriptive</em> essays (which aim not to make a new conclusion about something but merely assemble a collection of generally accepted facts).  There is still an analytical process here because the writer must determine what facts to trust, which are important enough to include and how they ought to be arranged, even though no <em>explicit</em> argument is being made.  Indeed, such a descriptive essay (like a Wikipedia article) makes an <em>implicit</em> argument based on what it is considered important enough to be included (e.g. on Wikipedia, what exactly is &#8216;notable&#8217;).<a class=\"easy-footnote-to-top\" href=\"#easy-footnote-5-17368\"></a></li><li class=\"easy-footnote-single\"><span id=\"easy-footnote-bottom-6-17368\" class=\"easy-footnote-margin-adjust\"></span>the description of <em>The Limits of Empire</em> in particular is poor and mostly misses the book&#8217;s core argument that there was no Roman &#8216;grand strategy&#8217; because the Romans were <em>incapable</em> of conceiving of strategy in that way.<a class=\"easy-footnote-to-top\" href=\"#easy-footnote-6-17368\"></a></li><li class=\"easy-footnote-single\"><span id=\"easy-footnote-bottom-7-17368\" class=\"easy-footnote-margin-adjust\"></span>I&#8217;m pretty sure from the other responses I have seen (but cannot be 100% confident) that the BMCR, which is open and available to all, was included in ChatGPT&#8217;s corpus.<a class=\"easy-footnote-to-top\" href=\"#easy-footnote-7-17368\"></a></li><li class=\"easy-footnote-single\"><span id=\"easy-footnote-bottom-8-17368\" class=\"easy-footnote-margin-adjust\"></span>While we&#8217;re here I should note that I think <em>The Limits of Empire</em> is hardly the last word on this question.  On why, you want to read E. Wheeler, &#8220;Methodological Limits and the Mirage of Roman Strategy&#8221; <em>JMH</em> 57.1 and 57.2 (1993); Wheeler systematically destroys nearly all of Isaac&#8217;s arguments.  I also asked ChatGPT to tell me what Wheeler&#8217;s critiques were, but since Wheeler isn&#8217;t in its training corpus, it couldn&#8217;t tell me.  When I asked for a list of Isaac&#8217;s most prominent critics, it didn&#8217;t list Wheeler because, I suppose, no one in its corpus discussed his article, despite it being (to the best of my knowledge) generally understood that Wheeler&#8217;s critique has been the most influential, as for instance noted by J.E. Lendon<a href=\"https://www.jstor.org/stable/3298451\" data-type=\"URL\" data-id=\"https://www.jstor.org/stable/3298451\"> in this review of the topic</a> for <em>Classical Journal</em> back in 2002.  ChatGPT can&#8217;t tell you any of that because it can only tell you things other people have already written in its training corpus.  Instead, it listed Adrian Goldsworthy, Jeremy Armstrong, John W.I. Lee and Christopher S. Mackay because they all wrote reviews of the book; none of these scholars (some of whom are <em>great </em>scholars) are particularly involved in the Roman strategy debate, so all of these answers are wrong.  The latest in this debate is James Lacey&#8217;s <em>Rome: Strategy of Empire</em> (2022), which is a solid reiteration of the Luttwakian side of the debate (valuable if only because Luttwak himself is a poor interlocutor in all of this) but seems unlikely to end it.  It is possible I am working on trying to say something useful on this topic at some point in the future.<a class=\"easy-footnote-to-top\" href=\"#easy-footnote-8-17368\"></a></li><li class=\"easy-footnote-single\"><span id=\"easy-footnote-bottom-9-17368\" class=\"easy-footnote-margin-adjust\"></span>It also isn&#8217;t very good at discoverability.  It can&#8217;t tell you <em>who</em> or <em>where</em> that better idea is from if you find yourself wanting more explanation or context.  Once again, as a research tool, Google is pretty clearly superior.<a class=\"easy-footnote-to-top\" href=\"#easy-footnote-9-17368\"></a></li><li class=\"easy-footnote-single\"><span id=\"easy-footnote-bottom-10-17368\" class=\"easy-footnote-margin-adjust\"></span>This is painfully obvious when it comes to trying to get information about video games.  In ye days of yore, Google would swiftly send you to the GameFaqs page (remember those!?) or the helpful fan Wiki, but more recently it becomes necessary to slog through a page or two of overly long (because Google prefers pages with at least a certain amount of text) answers to very simple questions in order to find what you are looking for (which usually ends up being a helpful response to someone&#8217;s question on Reddit or a Steam guide or, because I still like to live in 2004, an actual GameFaqs page).<a class=\"easy-footnote-to-top\" href=\"#easy-footnote-10-17368\"></a></li><li class=\"easy-footnote-single\"><span id=\"easy-footnote-bottom-11-17368\" class=\"easy-footnote-margin-adjust\"></span>And thus, dear students, if you are not <em>reading the comments</em> you are not getting what you paid tens of thousands of dollars for when you paid tuition.  Read the comments.  You are in college to <em>learn things</em> not prove what you already know or how smart you already are.  We know you are smart, that&#8217;s why you got admitted to college; the question now is about drive and willingness to <em>learn</em>.<a class=\"easy-footnote-to-top\" href=\"#easy-footnote-11-17368\"></a></li><li class=\"easy-footnote-single\"><span id=\"easy-footnote-bottom-12-17368\" class=\"easy-footnote-margin-adjust\"></span>There is thus a meaningful difference between this and the &#8216;why did I need to learn math without a calculator&#8217; example that gets reused here, in that a calculator can at least do basic math for you, but ChatGPT cannot think for you.  That said, I had quite a difficult time learning that sort of thing as a kid, but (with some extra effort from my parents) I did learn it and I&#8217;ve found it tremendously useful in life.  Being able to calculate a tip in my head or compare the per-unit price of, say, 3-for-whatever sale on 12pack sodas vs. a 24pack of the same brand without having to plug it into my phone is really handy.  I thus find myself somewhat confused by folks I run into who are bitter they were forced to learn mathematics first without a calculator.<a class=\"easy-footnote-to-top\" href=\"#easy-footnote-12-17368\"></a></li><li class=\"easy-footnote-single\"><span id=\"easy-footnote-bottom-13-17368\" class=\"easy-footnote-margin-adjust\"></span>A point we have already addressed.<a class=\"easy-footnote-to-top\" href=\"#easy-footnote-13-17368\"></a></li><li class=\"easy-footnote-single\"><span id=\"easy-footnote-bottom-14-17368\" class=\"easy-footnote-margin-adjust\"></span>The one exception here are online courses using &#8216;closed book&#8217; online essay tests.  That is an exam model which will be rendered difficult by this technology.  I think clever prompt writing (demand the students do things &#8211;  be specific in evidence or reference specific works &#8211; that ChatGPT is bad at) or use alternative assignments (a capstone project or essay instead).  For in-person classes, the entire problem is obviated by the written in-class essay.<a class=\"easy-footnote-to-top\" href=\"#easy-footnote-14-17368\"></a></li><li class=\"easy-footnote-single\"><span id=\"easy-footnote-bottom-15-17368\" class=\"easy-footnote-margin-adjust\"></span>And if they <em>don&#8217;t</em>, that&#8217;s academic dishonestly regardless of who wrote the paper.<a class=\"easy-footnote-to-top\" href=\"#easy-footnote-15-17368\"></a></li><li class=\"easy-footnote-single\"><span id=\"easy-footnote-bottom-16-17368\" class=\"easy-footnote-margin-adjust\"></span>And a student that cannot or will not cite their sources has plagiarized, regardless of who wrote their paper.  ChatGPT is such a mess of academic dishonesty that it isn&#8217;t even necessary to prove its products were machine-written because the machine <em>also</em> does the sort of things which can get you kicked out of college.<a class=\"easy-footnote-to-top\" href=\"#easy-footnote-16-17368\"></a></li><li class=\"easy-footnote-single\"><span id=\"easy-footnote-bottom-17-17368\" class=\"easy-footnote-margin-adjust\"></span>And if the student has gone back and done the research to be able to correct those errors and rewrite those sentences in advance&#8230;at this point why not just write the paper honestly and not risk being thrown out of college?<a class=\"easy-footnote-to-top\" href=\"#easy-footnote-17-17368\"></a></li><li class=\"easy-footnote-single\"><span id=\"easy-footnote-bottom-18-17368\" class=\"easy-footnote-margin-adjust\"></span>In the event I asked for 8,000 words because I wanted to see how it would handle organizing a larger piece of writing.  Now in the free version it can&#8217;t write that many words before it runs out of &#8216;tokens,&#8217; but I wanted to see how the introduction would set up the organization for the bits it wouldn&#8217;t get to.  In practice it set up an essay in three or four chunks the first of which was 224 words; ChatGPT doesn&#8217;t seem to be able to even set up a larger and more complex piece of writing.  It also doesn&#8217;t plan for a number of words limited by how many it can get to before running out of tokens either, in case anyone thinks that&#8217;s what it was doing: to get to the end of the essay with all of the components it laid out in the introduction I had to jog it twice.<a class=\"easy-footnote-to-top\" href=\"#easy-footnote-18-17368\"></a></li><li class=\"easy-footnote-single\"><span id=\"easy-footnote-bottom-19-17368\" class=\"easy-footnote-margin-adjust\"></span>Of course if the student has just tried honestly and failed, they&#8217;ll be able to document that process quite easily, with the works they read and where each wrong fact came from, whereas the student who has cheated using ChatGPT will be incapable of doing so.<a class=\"easy-footnote-to-top\" href=\"#easy-footnote-19-17368\"></a></li><li class=\"easy-footnote-single\"><span id=\"easy-footnote-bottom-20-17368\" class=\"easy-footnote-margin-adjust\"></span>a hotly debated topic, actually!<a class=\"easy-footnote-to-top\" href=\"#easy-footnote-20-17368\"></a></li></ol><div class='sharedaddy sd-block sd-like jetpack-likes-widget-wrapper jetpack-likes-widget-unloaded' id='like-post-wrapper-161773962-17368-6447e04227daa' data-src='https://widgets.wp.com/likes/#blog_id=161773962&amp;post_id=17368&amp;origin=acoup.blog&amp;obj_id=161773962-17368-6447e04227daa' data-name='like-post-frame-161773962-17368-6447e04227daa' data-title='Like or Reblog'><h3 class=\"sd-title\">Like this:</h3><div class='likes-widget-placeholder post-likes-widget-placeholder' style='height: 55px;'><span class='button'><span>Like</span></span> <span class=\"loading\">Loading...</span></div><span class='sd-text-color'></span><a class='sd-link-color'></a></div>\t</div><!-- .entry-content -->\n\n\t<div class=\"entry-footer\">\n\t\t<ul class=\"post-tags light-text\"><li>Tagged</li><li><a href=\"https://acoup.blog/tag/academia/\" rel=\"tag\">Academia</a></li><li><a href=\"https://acoup.blog/tag/modern/\" rel=\"tag\">Modern</a></li><li><a href=\"https://acoup.blog/tag/pedagogy/\" rel=\"tag\">Pedagogy</a></li><li><a href=\"https://acoup.blog/tag/technology/\" rel=\"tag\">Technology</a></li><li><a href=\"https://acoup.blog/tag/writing/\" rel=\"tag\">Writing</a></li></ul><!-- .post-tags -->\t</div><!-- .entry-footer -->\n\n\t<div class=\"entry-author-wrapper\">\n\t\t\t<div class=\"entry-author\">\n\t\t<div class=\"author-avatar\">\n\t\t\t<img alt src=\"https://secure.gravatar.com/avatar/3f4e8a2b40f543b00032bb1f567dea75?s=80&#038;d=identicon&#038;r=g\" class=\"avatar avatar-80 photo jetpack-lazy-image\" height=\"80\" width=\"80\" decoding=\"async\" data-lazy-srcset=\"https://secure.gravatar.com/avatar/3f4e8a2b40f543b00032bb1f567dea75?s=160&#038;d=identicon&#038;r=g 2x\" data-lazy-src=\"https://secure.gravatar.com/avatar/3f4e8a2b40f543b00032bb1f567dea75?s=80&amp;is-pending-load=1#038;d=identicon&#038;r=g\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\"><noscript><img data-lazy-fallback=\"1\" alt='' src='https://secure.gravatar.com/avatar/3f4e8a2b40f543b00032bb1f567dea75?s=80&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/3f4e8a2b40f543b00032bb1f567dea75?s=160&#038;d=identicon&#038;r=g 2x' class='avatar avatar-80 photo' height='80' width='80' loading='lazy' decoding='async' /></noscript>\t\t</div><!-- .author-avatar -->\n\n\t\t<div class=\"author-heading\">\n\t\t\t<h2 class=\"author-title\">\n\t\t\t\tPublished by <span class=\"author-name\">Bret Devereaux</span>\t\t\t</h2>\n\t\t</div><!-- .author-heading -->\n\n\t\t<p class=\"author-bio\">\n\t\t\t\t\t\t<a class=\"author-link\" href=\"https://acoup.blog/author/aimedtact/\" rel=\"author\">\n\t\t\t\tView all posts by Bret Devereaux\t\t\t</a>\n\t\t</p><!-- .author-bio -->\n\t</div><!-- .entry-auhtor -->\n\t\t\t<div class=\"site-posted-on\">\n\t\t\t<strong>Published</strong>\n\t\t\t<time class=\"entry-date published\" datetime=\"2023-02-17T01:44:30-05:00\">February 17, 2023</time><time class=\"updated\" datetime=\"2023-02-17T17:47:59-05:00\">February 17, 2023</time>\t\t</div><!-- .site-posted-on -->\n\t</div>\n</article><!-- #post-## -->\n\n\t\t\t\n\t<nav class=\"navigation post-navigation\" aria-label=\"Posts\">\n\t\t<h2 class=\"screen-reader-text\">Post navigation</h2>\n\t\t<div class=\"nav-links\"><div class=\"nav-previous\"><a href=\"https://acoup.blog/2023/02/10/fireside-friday-february-10-2023-on-academic-freedom/\" rel=\"prev\"><span class=\"meta-nav screen-reader-text\">Previous Post</span> Fireside Friday, February 10, 2023 (On Academic Freedom)</a></div><div class=\"nav-next\"><a href=\"https://acoup.blog/2023/02/24/collections-one-year-into-the-war-in-ukraine/\" rel=\"next\"><span class=\"meta-nav screen-reader-text\">Next Post</span> Collections: One Year Into the War in Ukraine</a></div></div>\n\t</nav>\n\t\t\t\n<div id=\"comments\" class=\"comments-area\">\n\n\t\n\t\t\t<h2 class=\"comments-title\">\n\t\t\t349 thoughts on &ldquo;<span>Collections: On ChatGPT</span>&rdquo;\t\t</h2><!-- .comments-title -->\n\n\t\t\t\t\t<nav id=\"comment-nav-above\" class=\"navigation comment-navigation\" role=\"navigation\">\n\t\t\t\t<h2 class=\"screen-reader-text\">Comment navigation</h2>\n\t\t\t\t<div class=\"nav-links\">\n\n\t\t\t\t\t<div class=\"nav-previous\"><a href=\"https://acoup.blog/2023/02/17/collections-on-chatgpt/comment-page-2/#comments\" >Older Comments</a></div>\n\t\t\t\t\t<div class=\"nav-next\"></div>\n\n\t\t\t\t</div><!-- .nav-links -->\n\t\t\t</nav><!-- #comment-nav-above -->\n\t\t\n\t\t<ol class=\"comment-list\">\n\t\t\t\t\t<li id=\"comment-51292\" class=\"comment even thread-even depth-1\">\n\t\t\t<article id=\"div-comment-51292\" class=\"comment-body\">\n\t\t\t\t<footer class=\"comment-meta\">\n\t\t\t\t\t<div class=\"comment-author vcard\">\n\t\t\t\t\t\t<img alt src=\"https://secure.gravatar.com/avatar/1796998dbeaa1965634e99376c8eead2?s=48&#038;d=identicon&#038;r=g\" class=\"avatar avatar-48 photo jetpack-lazy-image\" height=\"48\" width=\"48\" decoding=\"async\" data-lazy-srcset=\"https://secure.gravatar.com/avatar/1796998dbeaa1965634e99376c8eead2?s=96&#038;d=identicon&#038;r=g 2x\" data-lazy-src=\"https://secure.gravatar.com/avatar/1796998dbeaa1965634e99376c8eead2?s=48&amp;is-pending-load=1#038;d=identicon&#038;r=g\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\"><noscript><img data-lazy-fallback=\"1\" alt='' src='https://secure.gravatar.com/avatar/1796998dbeaa1965634e99376c8eead2?s=48&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/1796998dbeaa1965634e99376c8eead2?s=96&#038;d=identicon&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' loading='lazy' decoding='async' /></noscript>\t\t\t\t\t\t<b class=\"fn\">Mark</b> <span class=\"says\">says:</span>\t\t\t\t\t</div><!-- .comment-author -->\n\n\t\t\t\t\t<div class=\"comment-metadata\">\n\t\t\t\t\t\t<a href=\"https://acoup.blog/2023/02/17/collections-on-chatgpt/comment-page-3/#comment-51292\"><time datetime=\"2023-03-10T20:23:21-05:00\">March 10, 2023 at 8:23 pm</time></a>\t\t\t\t\t</div><!-- .comment-metadata -->\n\n\t\t\t\t\t\t\t\t\t</footer><!-- .comment-meta -->\n\n\t\t\t\t<div class=\"comment-content\">\n\t\t\t\t\t<p>I&#8217;m a naturally terse writer &#8212; I can write a three-page essay in two and a half pages.  Back when I was in school, I would normally spend more hours on an essay assignment padding it out to meet the length requirements than I spent writing it in the first place.  ChatGPT would have saved me a great deal of time, as I could write an essay without worrying about length, and then let the computer fluff it up to the required size.</p>\n<div class='jetpack-comment-likes-widget-wrapper jetpack-likes-widget-unloaded' id='like-comment-wrapper-161773962-51292-6447e0422e3b4' data-src='https://widgets.wp.com/likes/#blog_id=161773962&amp;comment_id=51292&amp;origin=acoup.blog&amp;obj_id=161773962-51292-6447e0422e3b4' data-name='like-comment-frame-161773962-51292-6447e0422e3b4'>\n<div class='likes-widget-placeholder comment-likes-widget-placeholder comment-likes'><span class='loading'>Loading...</span></div>\n<div class='comment-likes-widget jetpack-likes-widget comment-likes'><span class='comment-like-feedback'></span><span class='sd-text-color'></span><a class='sd-link-color'></a></div>\n</div>\n\t\t\t\t</div><!-- .comment-content -->\n\n\t\t\t\t<div class=\"reply\"><a rel='nofollow' class='comment-reply-link' href='https://acoup.blog/2023/02/17/collections-on-chatgpt/comment-page-3/?replytocom=51292#respond' data-commentid=\"51292\" data-postid=\"17368\" data-belowelement=\"div-comment-51292\" data-respondelement=\"respond\" data-replyto=\"Reply to Mark\" aria-label='Reply to Mark'>Reply</a></div>\t\t\t</article><!-- .comment-body -->\n\t\t</li><!-- #comment-## -->\n\t\t<li id=\"comment-51601\" class=\"comment odd alt thread-odd thread-alt depth-1\">\n\t\t\t<article id=\"div-comment-51601\" class=\"comment-body\">\n\t\t\t\t<footer class=\"comment-meta\">\n\t\t\t\t\t<div class=\"comment-author vcard\">\n\t\t\t\t\t\t<img alt src=\"https://secure.gravatar.com/avatar/d73e540e747f9e36c4482be4e3f1c322?s=48&#038;d=identicon&#038;r=g\" class=\"avatar avatar-48 photo jetpack-lazy-image\" height=\"48\" width=\"48\" decoding=\"async\" data-lazy-srcset=\"https://secure.gravatar.com/avatar/d73e540e747f9e36c4482be4e3f1c322?s=96&#038;d=identicon&#038;r=g 2x\" data-lazy-src=\"https://secure.gravatar.com/avatar/d73e540e747f9e36c4482be4e3f1c322?s=48&amp;is-pending-load=1#038;d=identicon&#038;r=g\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\"><noscript><img data-lazy-fallback=\"1\" alt='' src='https://secure.gravatar.com/avatar/d73e540e747f9e36c4482be4e3f1c322?s=48&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/d73e540e747f9e36c4482be4e3f1c322?s=96&#038;d=identicon&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' loading='lazy' decoding='async' /></noscript>\t\t\t\t\t\t<b class=\"fn\">Antony</b> <span class=\"says\">says:</span>\t\t\t\t\t</div><!-- .comment-author -->\n\n\t\t\t\t\t<div class=\"comment-metadata\">\n\t\t\t\t\t\t<a href=\"https://acoup.blog/2023/02/17/collections-on-chatgpt/comment-page-3/#comment-51601\"><time datetime=\"2023-03-23T19:22:49-04:00\">March 23, 2023 at 7:22 pm</time></a>\t\t\t\t\t</div><!-- .comment-metadata -->\n\n\t\t\t\t\t\t\t\t\t</footer><!-- .comment-meta -->\n\n\t\t\t\t<div class=\"comment-content\">\n\t\t\t\t\t<p>I was playing around to see what kind of bs ChatGPT would try to spin me about the Spartans, and I asked about spartan military defeats. This poor little bot told me that a &#8220;significant Spartan defeat occurred in 404 BC during the Peloponnesian War, when the Spartans were defeated by the Athenians and their allies. This defeat marked the end of the war and the decline of Spartan power.&#8221;<br />\nIt made me laugh so hard I scared my cats.</p>\n<div class='jetpack-comment-likes-widget-wrapper jetpack-likes-widget-unloaded' id='like-comment-wrapper-161773962-51601-6447e0422ee02' data-src='https://widgets.wp.com/likes/#blog_id=161773962&amp;comment_id=51601&amp;origin=acoup.blog&amp;obj_id=161773962-51601-6447e0422ee02' data-name='like-comment-frame-161773962-51601-6447e0422ee02'>\n<div class='likes-widget-placeholder comment-likes-widget-placeholder comment-likes'><span class='loading'>Loading...</span></div>\n<div class='comment-likes-widget jetpack-likes-widget comment-likes'><span class='comment-like-feedback'></span><span class='sd-text-color'></span><a class='sd-link-color'></a></div>\n</div>\n\t\t\t\t</div><!-- .comment-content -->\n\n\t\t\t\t<div class=\"reply\"><a rel='nofollow' class='comment-reply-link' href='https://acoup.blog/2023/02/17/collections-on-chatgpt/comment-page-3/?replytocom=51601#respond' data-commentid=\"51601\" data-postid=\"17368\" data-belowelement=\"div-comment-51601\" data-respondelement=\"respond\" data-replyto=\"Reply to Antony\" aria-label='Reply to Antony'>Reply</a></div>\t\t\t</article><!-- .comment-body -->\n\t\t</li><!-- #comment-## -->\n\t\t<li id=\"comment-51703\" class=\"comment even thread-even depth-1\">\n\t\t\t<article id=\"div-comment-51703\" class=\"comment-body\">\n\t\t\t\t<footer class=\"comment-meta\">\n\t\t\t\t\t<div class=\"comment-author vcard\">\n\t\t\t\t\t\t<img alt src=\"https://secure.gravatar.com/avatar/a7811e71cce9fa8e4e6b04d36e90dab3?s=48&#038;d=identicon&#038;r=g\" class=\"avatar avatar-48 photo jetpack-lazy-image\" height=\"48\" width=\"48\" decoding=\"async\" data-lazy-srcset=\"https://secure.gravatar.com/avatar/a7811e71cce9fa8e4e6b04d36e90dab3?s=96&#038;d=identicon&#038;r=g 2x\" data-lazy-src=\"https://secure.gravatar.com/avatar/a7811e71cce9fa8e4e6b04d36e90dab3?s=48&amp;is-pending-load=1#038;d=identicon&#038;r=g\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\"><noscript><img data-lazy-fallback=\"1\" alt='' src='https://secure.gravatar.com/avatar/a7811e71cce9fa8e4e6b04d36e90dab3?s=48&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/a7811e71cce9fa8e4e6b04d36e90dab3?s=96&#038;d=identicon&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' loading='lazy' decoding='async' /></noscript>\t\t\t\t\t\t<b class=\"fn\">Nathanael</b> <span class=\"says\">says:</span>\t\t\t\t\t</div><!-- .comment-author -->\n\n\t\t\t\t\t<div class=\"comment-metadata\">\n\t\t\t\t\t\t<a href=\"https://acoup.blog/2023/02/17/collections-on-chatgpt/comment-page-3/#comment-51703\"><time datetime=\"2023-03-26T02:14:13-04:00\">March 26, 2023 at 2:14 am</time></a>\t\t\t\t\t</div><!-- .comment-metadata -->\n\n\t\t\t\t\t\t\t\t\t</footer><!-- .comment-meta -->\n\n\t\t\t\t<div class=\"comment-content\">\n\t\t\t\t\t<p>Great essay.  Since I actually know the tech, I knew that ChatGPT is basically a very fancy version of a Markov chainer, which all CS people played with as kids.  Usable only for comedy.</p>\n<p>I will note one thing, pedagogically.  Assigned essays never helped me learn how to write essays.  Turns out I&#8217;m quite good at writing essays but I hated assigned-topic essays and they were frankly an obstruction to learning how to write essays.  Teachers (like you) simply should not assign them for that purpose &#8212; ever.  It doesn&#8217;t work.  I can only write about a topic I care about.  Give me something I care about and ask me to make a convincing argument, *then* I&#8217;m going to put in the work to learn how to write an essay which will convince you&#8230;</p>\n<div class='jetpack-comment-likes-widget-wrapper jetpack-likes-widget-unloaded' id='like-comment-wrapper-161773962-51703-6447e0422f814' data-src='https://widgets.wp.com/likes/#blog_id=161773962&amp;comment_id=51703&amp;origin=acoup.blog&amp;obj_id=161773962-51703-6447e0422f814' data-name='like-comment-frame-161773962-51703-6447e0422f814'>\n<div class='likes-widget-placeholder comment-likes-widget-placeholder comment-likes'><span class='loading'>Loading...</span></div>\n<div class='comment-likes-widget jetpack-likes-widget comment-likes'><span class='comment-like-feedback'></span><span class='sd-text-color'></span><a class='sd-link-color'></a></div>\n</div>\n\t\t\t\t</div><!-- .comment-content -->\n\n\t\t\t\t<div class=\"reply\"><a rel='nofollow' class='comment-reply-link' href='https://acoup.blog/2023/02/17/collections-on-chatgpt/comment-page-3/?replytocom=51703#respond' data-commentid=\"51703\" data-postid=\"17368\" data-belowelement=\"div-comment-51703\" data-respondelement=\"respond\" data-replyto=\"Reply to Nathanael\" aria-label='Reply to Nathanael'>Reply</a></div>\t\t\t</article><!-- .comment-body -->\n\t\t</li><!-- #comment-## -->\n\t\t<li id=\"comment-51893\" class=\"comment odd alt thread-odd thread-alt depth-1 parent\">\n\t\t\t<article id=\"div-comment-51893\" class=\"comment-body\">\n\t\t\t\t<footer class=\"comment-meta\">\n\t\t\t\t\t<div class=\"comment-author vcard\">\n\t\t\t\t\t\t<img alt src=\"https://secure.gravatar.com/avatar/3221a241dbd520e2f5fba940c104012e?s=48&#038;d=identicon&#038;r=g\" class=\"avatar avatar-48 photo jetpack-lazy-image\" height=\"48\" width=\"48\" decoding=\"async\" data-lazy-srcset=\"https://secure.gravatar.com/avatar/3221a241dbd520e2f5fba940c104012e?s=96&#038;d=identicon&#038;r=g 2x\" data-lazy-src=\"https://secure.gravatar.com/avatar/3221a241dbd520e2f5fba940c104012e?s=48&amp;is-pending-load=1#038;d=identicon&#038;r=g\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\"><noscript><img data-lazy-fallback=\"1\" alt='' src='https://secure.gravatar.com/avatar/3221a241dbd520e2f5fba940c104012e?s=48&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/3221a241dbd520e2f5fba940c104012e?s=96&#038;d=identicon&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' loading='lazy' decoding='async' /></noscript>\t\t\t\t\t\t<b class=\"fn\">Lien</b> <span class=\"says\">says:</span>\t\t\t\t\t</div><!-- .comment-author -->\n\n\t\t\t\t\t<div class=\"comment-metadata\">\n\t\t\t\t\t\t<a href=\"https://acoup.blog/2023/02/17/collections-on-chatgpt/comment-page-3/#comment-51893\"><time datetime=\"2023-04-03T15:34:56-04:00\">April 3, 2023 at 3:34 pm</time></a>\t\t\t\t\t</div><!-- .comment-metadata -->\n\n\t\t\t\t\t\t\t\t\t</footer><!-- .comment-meta -->\n\n\t\t\t\t<div class=\"comment-content\">\n\t\t\t\t\t<p>Why would you ban chat GPT out of a reactionary reflex rather than requiring that, similarly as it is done for using human authors&#8217; work, it has to be quoted adequately (which I guess for AI tools would mean providing the prompt and the raw output as an annex) ?</p>\n<div class='jetpack-comment-likes-widget-wrapper jetpack-likes-widget-unloaded' id='like-comment-wrapper-161773962-51893-6447e04230218' data-src='https://widgets.wp.com/likes/#blog_id=161773962&amp;comment_id=51893&amp;origin=acoup.blog&amp;obj_id=161773962-51893-6447e04230218' data-name='like-comment-frame-161773962-51893-6447e04230218'>\n<div class='likes-widget-placeholder comment-likes-widget-placeholder comment-likes'><span class='loading'>Loading...</span></div>\n<div class='comment-likes-widget jetpack-likes-widget comment-likes'><span class='comment-like-feedback'></span><span class='sd-text-color'></span><a class='sd-link-color'></a></div>\n</div>\n\t\t\t\t</div><!-- .comment-content -->\n\n\t\t\t\t<div class=\"reply\"><a rel='nofollow' class='comment-reply-link' href='https://acoup.blog/2023/02/17/collections-on-chatgpt/comment-page-3/?replytocom=51893#respond' data-commentid=\"51893\" data-postid=\"17368\" data-belowelement=\"div-comment-51893\" data-respondelement=\"respond\" data-replyto=\"Reply to Lien\" aria-label='Reply to Lien'>Reply</a></div>\t\t\t</article><!-- .comment-body -->\n\t\t<ol class=\"children\">\n\t\t<li id=\"comment-52262\" class=\"comment even depth-2\">\n\t\t\t<article id=\"div-comment-52262\" class=\"comment-body\">\n\t\t\t\t<footer class=\"comment-meta\">\n\t\t\t\t\t<div class=\"comment-author vcard\">\n\t\t\t\t\t\t<img alt src=\"https://secure.gravatar.com/avatar/0079148a4f382623304a768a54a399ac?s=48&#038;d=identicon&#038;r=g\" class=\"avatar avatar-48 photo jetpack-lazy-image\" height=\"48\" width=\"48\" decoding=\"async\" data-lazy-srcset=\"https://secure.gravatar.com/avatar/0079148a4f382623304a768a54a399ac?s=96&#038;d=identicon&#038;r=g 2x\" data-lazy-src=\"https://secure.gravatar.com/avatar/0079148a4f382623304a768a54a399ac?s=48&amp;is-pending-load=1#038;d=identicon&#038;r=g\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\"><noscript><img data-lazy-fallback=\"1\" alt='' src='https://secure.gravatar.com/avatar/0079148a4f382623304a768a54a399ac?s=48&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/0079148a4f382623304a768a54a399ac?s=96&#038;d=identicon&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' loading='lazy' decoding='async' /></noscript>\t\t\t\t\t\t<b class=\"fn\">Bargher</b> <span class=\"says\">says:</span>\t\t\t\t\t</div><!-- .comment-author -->\n\n\t\t\t\t\t<div class=\"comment-metadata\">\n\t\t\t\t\t\t<a href=\"https://acoup.blog/2023/02/17/collections-on-chatgpt/comment-page-3/#comment-52262\"><time datetime=\"2023-04-22T16:45:40-04:00\">April 22, 2023 at 4:45 pm</time></a>\t\t\t\t\t</div><!-- .comment-metadata -->\n\n\t\t\t\t\t\t\t\t\t</footer><!-- .comment-meta -->\n\n\t\t\t\t<div class=\"comment-content\">\n\t\t\t\t\t<p>Because as clearly demonstrated in this essay it just makes stuff up! You may as well cite the neighbour kid selling lemonade in your paper on late Republic Roman law.</p>\n<div class='jetpack-comment-likes-widget-wrapper jetpack-likes-widget-unloaded' id='like-comment-wrapper-161773962-52262-6447e04230b40' data-src='https://widgets.wp.com/likes/#blog_id=161773962&amp;comment_id=52262&amp;origin=acoup.blog&amp;obj_id=161773962-52262-6447e04230b40' data-name='like-comment-frame-161773962-52262-6447e04230b40'>\n<div class='likes-widget-placeholder comment-likes-widget-placeholder comment-likes'><span class='loading'>Loading...</span></div>\n<div class='comment-likes-widget jetpack-likes-widget comment-likes'><span class='comment-like-feedback'></span><span class='sd-text-color'></span><a class='sd-link-color'></a></div>\n</div>\n\t\t\t\t</div><!-- .comment-content -->\n\n\t\t\t\t<div class=\"reply\"><a rel='nofollow' class='comment-reply-link' href='https://acoup.blog/2023/02/17/collections-on-chatgpt/comment-page-3/?replytocom=52262#respond' data-commentid=\"52262\" data-postid=\"17368\" data-belowelement=\"div-comment-52262\" data-respondelement=\"respond\" data-replyto=\"Reply to Bargher\" aria-label='Reply to Bargher'>Reply</a></div>\t\t\t</article><!-- .comment-body -->\n\t\t</li><!-- #comment-## -->\n</ol><!-- .children -->\n</li><!-- #comment-## -->\n\t\t<li id=\"comment-52043\" class=\"comment odd alt thread-even depth-1\">\n\t\t\t<article id=\"div-comment-52043\" class=\"comment-body\">\n\t\t\t\t<footer class=\"comment-meta\">\n\t\t\t\t\t<div class=\"comment-author vcard\">\n\t\t\t\t\t\t<img alt src=\"https://secure.gravatar.com/avatar/0224cd3cbcf5f12befd576b4f3da316e?s=48&#038;d=identicon&#038;r=g\" class=\"avatar avatar-48 photo jetpack-lazy-image\" height=\"48\" width=\"48\" decoding=\"async\" data-lazy-srcset=\"https://secure.gravatar.com/avatar/0224cd3cbcf5f12befd576b4f3da316e?s=96&#038;d=identicon&#038;r=g 2x\" data-lazy-src=\"https://secure.gravatar.com/avatar/0224cd3cbcf5f12befd576b4f3da316e?s=48&amp;is-pending-load=1#038;d=identicon&#038;r=g\" srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\"><noscript><img data-lazy-fallback=\"1\" alt='' src='https://secure.gravatar.com/avatar/0224cd3cbcf5f12befd576b4f3da316e?s=48&#038;d=identicon&#038;r=g' srcset='https://secure.gravatar.com/avatar/0224cd3cbcf5f12befd576b4f3da316e?s=96&#038;d=identicon&#038;r=g 2x' class='avatar avatar-48 photo' height='48' width='48' loading='lazy' decoding='async' /></noscript>\t\t\t\t\t\t<b class=\"fn\">kaiyatime</b> <span class=\"says\">says:</span>\t\t\t\t\t</div><!-- .comment-author -->\n\n\t\t\t\t\t<div class=\"comment-metadata\">\n\t\t\t\t\t\t<a href=\"https://acoup.blog/2023/02/17/collections-on-chatgpt/comment-page-3/#comment-52043\"><time datetime=\"2023-04-13T04:29:57-04:00\">April 13, 2023 at 4:29 am</time></a>\t\t\t\t\t</div><!-- .comment-metadata -->\n\n\t\t\t\t\t\t\t\t\t</footer><!-- .comment-meta -->\n\n\t\t\t\t<div class=\"comment-content\">\n\t\t\t\t\t<p>This was a good essay, and I find ChatGTP as laughable as anyone, but it did bring something to mind: there _really_ isn&#8217;t any reason, in my experience, to think that professors want anything _other_ than a &#8220;unit of essay&#8221;. I&#8217;ve been reading your blog for awhile now, it is very interesting, but I was genuinely stunned to learn that you were an academic, because you&#8217;re both knowledgeable about the subject you teach, _and_ able to explain the first thing about it.</p>\n<p>In my experience, even at the University level, college courses and essays are basically an endeavor in chaining the words together required to get an A on the subject. The courses are largely unrelated to the test material, except in the sense that the books you get extorted into purchasing from the school for huge sums despite _already paying tuition_ probably contain the information on the test within them. Essays can just be more or less stream-of-consciousness&#8217;d together, you just pick something sort of related to the topic, write about it for a few hundred words, then chain to a new concept loosely connected to the topic, write about _that_ for a few hundred words, and once you&#8217;re near the wordcount total, you just write a 300 word summary of what you already said, prefaced by &#8220;in conclusion.&#8221;</p>\n<p>Bam, you get a B+, if not an A, and I usually only got the B+ because I lost 10% because I could never understand how to arrange the citations the way they wanted me to, so I lost points because it was unaesthetic.</p>\n<p>The academic justification side of this essay was mind-boggling to me, because I have literally never seen college pitched as somewhere you go to learn important skills outside high school propaganda and feel-good media bits, the whole point of college, again, in my experience, is screwing around until you get a certificate that says &#8220;You get to earn more money now, because you paid your dues&#8221;, and I had to be informed by a friend from one of the Northern states that apparently some colleges are actually educational institutions, rather than high schools with better PR.</p>\n<p>Basically, it makes total sense to assume a chatbot would &#8220;solve&#8221; college essays for good, because you get graded based on your ability to string a bunch of words loosely related to a particular topic together, and then to fill in a bunch of bubbles on an exam, based on stuff you knew before you ever got to college, or which you read in a book while you weren&#8217;t even on campus.</p>\n<div class='jetpack-comment-likes-widget-wrapper jetpack-likes-widget-unloaded' id='like-comment-wrapper-161773962-52043-6447e04231518' data-src='https://widgets.wp.com/likes/#blog_id=161773962&amp;comment_id=52043&amp;origin=acoup.blog&amp;obj_id=161773962-52043-6447e04231518' data-name='like-comment-frame-161773962-52043-6447e04231518'>\n<div class='likes-widget-placeholder comment-likes-widget-placeholder comment-likes'><span class='loading'>Loading...</span></div>\n<div class='comment-likes-widget jetpack-likes-widget comment-likes'><span class='comment-like-feedback'></span><span class='sd-text-color'></span><a class='sd-link-color'></a></div>\n</div>\n\t\t\t\t</div><!-- .comment-content -->\n\n\t\t\t\t<div class=\"reply\"><a rel='nofollow' class='comment-reply-link' href='https://acoup.blog/2023/02/17/collections-on-chatgpt/comment-page-3/?replytocom=52043#respond' data-commentid=\"52043\" data-postid=\"17368\" data-belowelement=\"div-comment-52043\" data-respondelement=\"respond\" data-replyto=\"Reply to kaiyatime\" aria-label='Reply to kaiyatime'>Reply</a></div>\t\t\t</article><!-- .comment-body -->\n\t\t</li><!-- #comment-## -->\n\t\t</ol><!-- .comment-list -->\n\n\t\t\t\t\t<nav id=\"comment-nav-below\" class=\"navigation comment-navigation\" role=\"navigation\">\n\t\t\t\t<h2 class=\"screen-reader-text\">Comment navigation</h2>\n\t\t\t\t<div class=\"nav-links\">\n\n\t\t\t\t\t<div class=\"nav-previous\"><a href=\"https://acoup.blog/2023/02/17/collections-on-chatgpt/comment-page-2/#comments\" >Older Comments</a></div>\n\t\t\t\t\t<div class=\"nav-next\"></div>\n\n\t\t\t\t</div><!-- .nav-links -->\n\t\t\t</nav><!-- #comment-nav-below -->\n\t\t\n\t\n\t\n\t\n\t\t<div id=\"respond\" class=\"comment-respond\">\n\t\t\t\t\t\t\t<h3 id=\"reply-title\" class=\"comment-reply-title\">Leave a Reply\t\t\t\t\t<small><a rel=\"nofollow\" id=\"cancel-comment-reply-link\" href=\"/2023/02/17/collections-on-chatgpt/#respond\" style=\"display:none;\">Cancel reply</a></small>\n\t\t\t\t</h3>\n\t\t\t\t\t\t<form id=\"commentform\" class=\"comment-form\">\n\t\t\t\t<iframe\n\t\t\t\t\ttitle=\"Comment Form\"\n\t\t\t\t\tsrc=\"https://jetpack.wordpress.com/jetpack-comment/?blogid=161773962&#038;postid=17368&#038;comment_registration=0&#038;require_name_email=1&#038;stc_enabled=1&#038;stb_enabled=1&#038;show_avatars=1&#038;avatar_default=identicon&#038;greeting=Leave+a+Reply&#038;jetpack_comments_nonce=da56ad4845&#038;greeting_reply=Leave+a+Reply+to+%25s&#038;color_scheme=light&#038;lang=en_US&#038;jetpack_version=12.1-a.7&#038;show_cookie_consent=10&#038;has_cookie_consent=0&#038;token_key=%3Bnormal%3B&#038;sig=06477dd03300592e57fb15d97dd1099b24a76942#parent=https%3A%2F%2Facoup.blog%2F2023%2F02%2F17%2Fcollections-on-chatgpt%2F\"\n\t\t\t\t\t\t\t\t\t\t\tname=\"jetpack_remote_comment\"\n\t\t\t\t\t\tstyle=\"width:100%; height: 430px; border:0;\"\n\t\t\t\t\t\t\t\t\t\tclass=\"jetpack_remote_comment\"\n\t\t\t\t\tid=\"jetpack_remote_comment\"\n\t\t\t\t\tsandbox=\"allow-same-origin allow-top-navigation allow-scripts allow-forms allow-popups\"\n\t\t\t\t>\n\t\t\t\t\t\t\t\t\t</iframe>\n\t\t\t\t\t\t\t\t\t<!--[if !IE]><!-->\n\t\t\t\t\t<script>\n\t\t\t\t\t\tdocument.addEventListener('DOMContentLoaded', function () {\n\t\t\t\t\t\t\tvar commentForms = document.getElementsByClassName('jetpack_remote_comment');\n\t\t\t\t\t\t\tfor (var i = 0; i < commentForms.length; i++) {\n\t\t\t\t\t\t\t\tcommentForms[i].allowTransparency = false;\n\t\t\t\t\t\t\t\tcommentForms[i].scrolling = 'no';\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\t});\n\t\t\t\t\t</script>\n\t\t\t\t\t<!--<![endif]-->\n\t\t\t\t\t\t\t</form>\n\t\t</div>\n\n\t\t\n\t\t<input type=\"hidden\" name=\"comment_parent\" id=\"comment_parent\" value=\"\" />\n\n\t\t\n</div><!-- #comments -->\n\n\t\t\n\t\t</main><!-- #main -->\n\t</div><!-- #primary -->\n\n<div id=\"secondary\" class=\"widget-area\" role=\"complementary\">\n\t<aside id=\"search-3\" class=\"widget widget_search\"><form role=\"search\" method=\"get\" class=\"search-form\" action=\"https://acoup.blog/\">\n\t\t\t\t<label>\n\t\t\t\t\t<span class=\"screen-reader-text\">Search for:</span>\n\t\t\t\t\t<input type=\"search\" class=\"search-field\" placeholder=\"Search &hellip;\" value=\"\" name=\"s\" />\n\t\t\t\t</label>\n\t\t\t\t<input type=\"submit\" class=\"search-submit\" value=\"Search\" />\n\t\t\t</form></aside><aside id=\"text-5\" class=\"widget widget_text\">\t\t\t<div class=\"textwidget\"><p>Updates every Friday!</p>\n<p>You can support this project via <a href=\"https://www.patreon.com/user?u=20122096\">Patreon</a>, and by spreading the word!</p>\n</div>\n\t\t</aside><aside id=\"twitter_timeline-3\" class=\"widget widget_twitter_timeline\"><a class=\"twitter-timeline\" data-theme=\"dark\" data-border-color=\"#e8e8e8\" data-tweet-limit=\"2\" data-lang=\"EN\" data-partner=\"jetpack\" data-chrome=\"transparent\" href=\"https://twitter.com/@BretDevereaux\" href=\"https://twitter.com/@BretDevereaux\">My Tweets</a></aside>\n\t\t<aside id=\"recent-posts-3\" class=\"widget widget_recent_entries\">\n\t\t<h1 class=\"widget-title\">Recent Posts</h1>\n\t\t<ul>\n\t\t\t\t\t\t\t\t\t\t\t<li>\n\t\t\t\t\t<a href=\"https://acoup.blog/2023/04/20/gap-week-april-20-2023/\">Gap Week: April 20, 2023</a>\n\t\t\t\t\t\t\t\t\t</li>\n\t\t\t\t\t\t\t\t\t\t\t<li>\n\t\t\t\t\t<a href=\"https://acoup.blog/2023/04/14/collections-how-to-polis-part-iii-people-and-gods-beyond-the-politai/\">Collections: How to Polis, Part III: People and Gods Beyond the Politai</a>\n\t\t\t\t\t\t\t\t\t</li>\n\t\t\t\t\t\t\t\t\t\t\t<li>\n\t\t\t\t\t<a href=\"https://acoup.blog/2023/04/07/collections-how-to-polis-101-part-iic-the-courts/\">Collections: How to Polis 101, Part IIc: The Courts</a>\n\t\t\t\t\t\t\t\t\t</li>\n\t\t\t\t\t\t\t\t\t\t\t<li>\n\t\t\t\t\t<a href=\"https://acoup.blog/2023/03/31/michael-taylor-on-john-keegans-the-face-of-battle-a-retrospective/\">Michael Taylor on John Keegan&#8217;s The Face of Battle: A Retrospective</a>\n\t\t\t\t\t\t\t\t\t</li>\n\t\t\t\t\t\t\t\t\t\t\t<li>\n\t\t\t\t\t<a href=\"https://acoup.blog/2023/03/24/collections-how-to-polis-101-part-iib-archons/\">Collections: How to Polis, 101, Part IIb: Archons</a>\n\t\t\t\t\t\t\t\t\t</li>\n\t\t\t\t\t\t\t\t\t\t\t<li>\n\t\t\t\t\t<a href=\"https://acoup.blog/2023/03/17/collections-how-to-polis-part-iia-politeia-in-the-polis/\">Collections: How to Polis, 101, Part IIa: Politeia in the Polis</a>\n\t\t\t\t\t\t\t\t\t</li>\n\t\t\t\t\t</ul>\n\n\t\t</aside><aside id=\"text-3\" class=\"widget widget_text\"><h1 class=\"widget-title\">Questions? Requests?</h1>\t\t\t<div class=\"textwidget\"><p>Have a topic you want me to post about?  A question on a post?  Do you want to scream incoherently into the endless void that is the internet?</p>\n<p>The best place to find me is on twitter <a href=\"https://twitter.com/BretDevereaux\">@BretDevereaux</a><br />\nFollowing me on Twitter is the best way to be informed of new posts as they appear.</p>\n</div>\n\t\t</aside><aside id=\"tag_cloud-3\" class=\"widget widget_tag_cloud\"><h1 class=\"widget-title\">Tags</h1><div class=\"tagcloud\"><a href=\"https://acoup.blog/tag/academia/\" class=\"tag-cloud-link tag-link-6942 tag-link-position-1\" style=\"font-size: 14.307692307692pt;\" aria-label=\"Academia (12 items)\">Academia</a>\n<a href=\"https://acoup.blog/tag/ancient/\" class=\"tag-cloud-link tag-link-9554 tag-link-position-2\" style=\"font-size: 22pt;\" aria-label=\"Ancient (40 items)\">Ancient</a>\n<a href=\"https://acoup.blog/tag/armor/\" class=\"tag-cloud-link tag-link-40879 tag-link-position-3\" style=\"font-size: 14.307692307692pt;\" aria-label=\"Armor (12 items)\">Armor</a>\n<a href=\"https://acoup.blog/tag/artillery/\" class=\"tag-cloud-link tag-link-483437 tag-link-position-4\" style=\"font-size: 10.307692307692pt;\" aria-label=\"Artillery (6 items)\">Artillery</a>\n<a href=\"https://acoup.blog/tag/blacksmithing/\" class=\"tag-cloud-link tag-link-65688 tag-link-position-5\" style=\"font-size: 8pt;\" aria-label=\"Blacksmithing (4 items)\">Blacksmithing</a>\n<a href=\"https://acoup.blog/tag/broader-mediterranean/\" class=\"tag-cloud-link tag-link-716950117 tag-link-position-6\" style=\"font-size: 13.230769230769pt;\" aria-label=\"Broader Mediterranean (10 items)\">Broader Mediterranean</a>\n<a href=\"https://acoup.blog/tag/castles/\" class=\"tag-cloud-link tag-link-59509 tag-link-position-7\" style=\"font-size: 8pt;\" aria-label=\"Castles (4 items)\">Castles</a>\n<a href=\"https://acoup.blog/tag/cavalry/\" class=\"tag-cloud-link tag-link-376050 tag-link-position-8\" style=\"font-size: 12.615384615385pt;\" aria-label=\"Cavalry (9 items)\">Cavalry</a>\n<a href=\"https://acoup.blog/tag/cities/\" class=\"tag-cloud-link tag-link-38369 tag-link-position-9\" style=\"font-size: 11.076923076923pt;\" aria-label=\"Cities (7 items)\">Cities</a>\n<a href=\"https://acoup.blog/tag/cohesion/\" class=\"tag-cloud-link tag-link-607169 tag-link-position-10\" style=\"font-size: 14.923076923077pt;\" aria-label=\"Cohesion (13 items)\">Cohesion</a>\n<a href=\"https://acoup.blog/tag/command/\" class=\"tag-cloud-link tag-link-716950091 tag-link-position-11\" style=\"font-size: 8pt;\" aria-label=\"Command (4 items)\">Command</a>\n<a href=\"https://acoup.blog/tag/content-warning/\" class=\"tag-cloud-link tag-link-1406840 tag-link-position-12\" style=\"font-size: 9.2307692307692pt;\" aria-label=\"Content Warning (5 items)\">Content Warning</a>\n<a href=\"https://acoup.blog/tag/culture/\" class=\"tag-cloud-link tag-link-1098 tag-link-position-13\" style=\"font-size: 17.538461538462pt;\" aria-label=\"Culture (20 items)\">Culture</a>\n<a href=\"https://acoup.blog/tag/customs/\" class=\"tag-cloud-link tag-link-77865 tag-link-position-14\" style=\"font-size: 18.153846153846pt;\" aria-label=\"Customs (22 items)\">Customs</a>\n<a href=\"https://acoup.blog/tag/demography/\" class=\"tag-cloud-link tag-link-80260 tag-link-position-15\" style=\"font-size: 11.076923076923pt;\" aria-label=\"Demography (7 items)\">Demography</a>\n<a href=\"https://acoup.blog/tag/doctrine/\" class=\"tag-cloud-link tag-link-63205 tag-link-position-16\" style=\"font-size: 9.2307692307692pt;\" aria-label=\"Doctrine (5 items)\">Doctrine</a>\n<a href=\"https://acoup.blog/tag/dune/\" class=\"tag-cloud-link tag-link-238814 tag-link-position-17\" style=\"font-size: 8pt;\" aria-label=\"Dune (4 items)\">Dune</a>\n<a href=\"https://acoup.blog/tag/early-modern/\" class=\"tag-cloud-link tag-link-135590 tag-link-position-18\" style=\"font-size: 10.307692307692pt;\" aria-label=\"Early Modern (6 items)\">Early Modern</a>\n<a href=\"https://acoup.blog/tag/economic-history/\" class=\"tag-cloud-link tag-link-40690 tag-link-position-19\" style=\"font-size: 11.076923076923pt;\" aria-label=\"Economic History (7 items)\">Economic History</a>\n<a href=\"https://acoup.blog/tag/economy/\" class=\"tag-cloud-link tag-link-8590 tag-link-position-20\" style=\"font-size: 10.307692307692pt;\" aria-label=\"Economy (6 items)\">Economy</a>\n<a href=\"https://acoup.blog/tag/empire/\" class=\"tag-cloud-link tag-link-6995 tag-link-position-21\" style=\"font-size: 10.307692307692pt;\" aria-label=\"Empire (6 items)\">Empire</a>\n<a href=\"https://acoup.blog/tag/farming/\" class=\"tag-cloud-link tag-link-23327 tag-link-position-22\" style=\"font-size: 13.846153846154pt;\" aria-label=\"Farming (11 items)\">Farming</a>\n<a href=\"https://acoup.blog/tag/fireside-chat/\" class=\"tag-cloud-link tag-link-161655 tag-link-position-23\" style=\"font-size: 13.846153846154pt;\" aria-label=\"Fireside Chat (11 items)\">Fireside Chat</a>\n<a href=\"https://acoup.blog/tag/food/\" class=\"tag-cloud-link tag-link-586 tag-link-position-24\" style=\"font-size: 10.307692307692pt;\" aria-label=\"Food (6 items)\">Food</a>\n<a href=\"https://acoup.blog/tag/fortifications/\" class=\"tag-cloud-link tag-link-260130 tag-link-position-25\" style=\"font-size: 11.076923076923pt;\" aria-label=\"Fortifications (7 items)\">Fortifications</a>\n<a href=\"https://acoup.blog/tag/game-of-thrones/\" class=\"tag-cloud-link tag-link-443849 tag-link-position-26\" style=\"font-size: 13.846153846154pt;\" aria-label=\"Game of Thrones (11 items)\">Game of Thrones</a>\n<a href=\"https://acoup.blog/tag/gaming/\" class=\"tag-cloud-link tag-link-1256 tag-link-position-27\" style=\"font-size: 13.230769230769pt;\" aria-label=\"Gaming (10 items)\">Gaming</a>\n<a href=\"https://acoup.blog/tag/greece/\" class=\"tag-cloud-link tag-link-716950096 tag-link-position-28\" style=\"font-size: 8pt;\" aria-label=\"Greece (4 items)\">Greece</a>\n<a href=\"https://acoup.blog/tag/history/\" class=\"tag-cloud-link tag-link-678 tag-link-position-29\" style=\"font-size: 11.076923076923pt;\" aria-label=\"History (7 items)\">History</a>\n<a href=\"https://acoup.blog/tag/hollywood-tactics/\" class=\"tag-cloud-link tag-link-56658427 tag-link-position-30\" style=\"font-size: 13.230769230769pt;\" aria-label=\"Hollywood Tactics (10 items)\">Hollywood Tactics</a>\n<a href=\"https://acoup.blog/tag/horses/\" class=\"tag-cloud-link tag-link-15978 tag-link-position-31\" style=\"font-size: 9.2307692307692pt;\" aria-label=\"Horses (5 items)\">Horses</a>\n<a href=\"https://acoup.blog/tag/household/\" class=\"tag-cloud-link tag-link-11756 tag-link-position-32\" style=\"font-size: 9.2307692307692pt;\" aria-label=\"Household (5 items)\">Household</a>\n<a href=\"https://acoup.blog/tag/humanities/\" class=\"tag-cloud-link tag-link-29791 tag-link-position-33\" style=\"font-size: 11.076923076923pt;\" aria-label=\"Humanities (7 items)\">Humanities</a>\n<a href=\"https://acoup.blog/tag/imperialism/\" class=\"tag-cloud-link tag-link-137041 tag-link-position-34\" style=\"font-size: 8pt;\" aria-label=\"Imperialism (4 items)\">Imperialism</a>\n<a href=\"https://acoup.blog/tag/infantry/\" class=\"tag-cloud-link tag-link-117906 tag-link-position-35\" style=\"font-size: 11.846153846154pt;\" aria-label=\"Infantry (8 items)\">Infantry</a>\n<a href=\"https://acoup.blog/tag/iron/\" class=\"tag-cloud-link tag-link-50338 tag-link-position-36\" style=\"font-size: 9.2307692307692pt;\" aria-label=\"Iron (5 items)\">Iron</a>\n<a href=\"https://acoup.blog/tag/kingship/\" class=\"tag-cloud-link tag-link-2633590 tag-link-position-37\" style=\"font-size: 10.307692307692pt;\" aria-label=\"Kingship (6 items)\">Kingship</a>\n<a href=\"https://acoup.blog/tag/logistics/\" class=\"tag-cloud-link tag-link-29960 tag-link-position-38\" style=\"font-size: 17.538461538462pt;\" aria-label=\"Logistics (20 items)\">Logistics</a>\n<a href=\"https://acoup.blog/tag/lord-of-the-rings/\" class=\"tag-cloud-link tag-link-97773 tag-link-position-39\" style=\"font-size: 15.384615384615pt;\" aria-label=\"Lord of the Rings (14 items)\">Lord of the Rings</a>\n<a href=\"https://acoup.blog/tag/medieval/\" class=\"tag-cloud-link tag-link-44421 tag-link-position-40\" style=\"font-size: 19.692307692308pt;\" aria-label=\"Medieval (28 items)\">Medieval</a>\n<a href=\"https://acoup.blog/tag/middle-ages/\" class=\"tag-cloud-link tag-link-16972 tag-link-position-41\" style=\"font-size: 15.384615384615pt;\" aria-label=\"Middle Ages (14 items)\">Middle Ages</a>\n<a href=\"https://acoup.blog/tag/military-history/\" class=\"tag-cloud-link tag-link-716949896 tag-link-position-42\" style=\"font-size: 11.846153846154pt;\" aria-label=\"Military History (8 items)\">Military History</a>\n<a href=\"https://acoup.blog/tag/modern/\" class=\"tag-cloud-link tag-link-4690 tag-link-position-43\" style=\"font-size: 13.230769230769pt;\" aria-label=\"Modern (10 items)\">Modern</a>\n<a href=\"https://acoup.blog/tag/oh-no/\" class=\"tag-cloud-link tag-link-151916 tag-link-position-44\" style=\"font-size: 18.923076923077pt;\" aria-label=\"Oh no (25 items)\">Oh no</a>\n<a href=\"https://acoup.blog/tag/operations/\" class=\"tag-cloud-link tag-link-28285 tag-link-position-45\" style=\"font-size: 12.615384615385pt;\" aria-label=\"Operations (9 items)\">Operations</a>\n<a href=\"https://acoup.blog/tag/organic-economy/\" class=\"tag-cloud-link tag-link-199500558 tag-link-position-46\" style=\"font-size: 18.153846153846pt;\" aria-label=\"Organic Economy (22 items)\">Organic Economy</a>\n<a href=\"https://acoup.blog/tag/paradox/\" class=\"tag-cloud-link tag-link-19479 tag-link-position-47\" style=\"font-size: 15.384615384615pt;\" aria-label=\"Paradox (14 items)\">Paradox</a>\n<a href=\"https://acoup.blog/tag/paradox-development-studio/\" class=\"tag-cloud-link tag-link-716950112 tag-link-position-48\" style=\"font-size: 11.846153846154pt;\" aria-label=\"Paradox Development Studio (8 items)\">Paradox Development Studio</a>\n<a href=\"https://acoup.blog/tag/political-history/\" class=\"tag-cloud-link tag-link-716950049 tag-link-position-49\" style=\"font-size: 10.307692307692pt;\" aria-label=\"Political History (6 items)\">Political History</a>\n<a href=\"https://acoup.blog/tag/political-systems/\" class=\"tag-cloud-link tag-link-611090 tag-link-position-50\" style=\"font-size: 19.692307692308pt;\" aria-label=\"Political Systems (28 items)\">Political Systems</a>\n<a href=\"https://acoup.blog/tag/production/\" class=\"tag-cloud-link tag-link-5905 tag-link-position-51\" style=\"font-size: 9.2307692307692pt;\" aria-label=\"Production (5 items)\">Production</a>\n<a href=\"https://acoup.blog/tag/religion/\" class=\"tag-cloud-link tag-link-116 tag-link-position-52\" style=\"font-size: 14.307692307692pt;\" aria-label=\"Religion (12 items)\">Religion</a>\n<a href=\"https://acoup.blog/tag/rings-of-power/\" class=\"tag-cloud-link tag-link-716950149 tag-link-position-53\" style=\"font-size: 8pt;\" aria-label=\"Rings of Power (4 items)\">Rings of Power</a>\n<a href=\"https://acoup.blog/tag/roman/\" class=\"tag-cloud-link tag-link-38542 tag-link-position-54\" style=\"font-size: 11.076923076923pt;\" aria-label=\"Roman (7 items)\">Roman</a>\n<a href=\"https://acoup.blog/tag/roman-empire/\" class=\"tag-cloud-link tag-link-435902 tag-link-position-55\" style=\"font-size: 14.307692307692pt;\" aria-label=\"Roman Empire (12 items)\">Roman Empire</a>\n<a href=\"https://acoup.blog/tag/roman-republic/\" class=\"tag-cloud-link tag-link-716949871 tag-link-position-56\" style=\"font-size: 11.846153846154pt;\" aria-label=\"Roman Republic (8 items)\">Roman Republic</a>\n<a href=\"https://acoup.blog/tag/rome/\" class=\"tag-cloud-link tag-link-9641 tag-link-position-57\" style=\"font-size: 18.153846153846pt;\" aria-label=\"Rome (22 items)\">Rome</a>\n<a href=\"https://acoup.blog/tag/science-fiction/\" class=\"tag-cloud-link tag-link-10615 tag-link-position-58\" style=\"font-size: 11.076923076923pt;\" aria-label=\"Science Fiction (7 items)\">Science Fiction</a>\n<a href=\"https://acoup.blog/tag/siege/\" class=\"tag-cloud-link tag-link-185962 tag-link-position-59\" style=\"font-size: 9.2307692307692pt;\" aria-label=\"Siege (5 items)\">Siege</a>\n<a href=\"https://acoup.blog/tag/siege-warfare/\" class=\"tag-cloud-link tag-link-716949919 tag-link-position-60\" style=\"font-size: 9.2307692307692pt;\" aria-label=\"Siege Warfare (5 items)\">Siege Warfare</a>\n<a href=\"https://acoup.blog/tag/slavery/\" class=\"tag-cloud-link tag-link-52713 tag-link-position-61\" style=\"font-size: 11.076923076923pt;\" aria-label=\"Slavery (7 items)\">Slavery</a>\n<a href=\"https://acoup.blog/tag/social-history/\" class=\"tag-cloud-link tag-link-375808 tag-link-position-62\" style=\"font-size: 20.769230769231pt;\" aria-label=\"Social History (33 items)\">Social History</a>\n<a href=\"https://acoup.blog/tag/sparta/\" class=\"tag-cloud-link tag-link-445578 tag-link-position-63\" style=\"font-size: 11.076923076923pt;\" aria-label=\"Sparta (7 items)\">Sparta</a>\n<a href=\"https://acoup.blog/tag/states/\" class=\"tag-cloud-link tag-link-31304 tag-link-position-64\" style=\"font-size: 9.2307692307692pt;\" aria-label=\"States (5 items)\">States</a>\n<a href=\"https://acoup.blog/tag/steppe-nomads/\" class=\"tag-cloud-link tag-link-46769825 tag-link-position-65\" style=\"font-size: 9.2307692307692pt;\" aria-label=\"steppe nomads (5 items)\">steppe nomads</a>\n<a href=\"https://acoup.blog/tag/strategy/\" class=\"tag-cloud-link tag-link-8553 tag-link-position-66\" style=\"font-size: 9.2307692307692pt;\" aria-label=\"Strategy (5 items)\">Strategy</a>\n<a href=\"https://acoup.blog/tag/tactics/\" class=\"tag-cloud-link tag-link-1535 tag-link-position-67\" style=\"font-size: 14.923076923077pt;\" aria-label=\"Tactics (13 items)\">Tactics</a>\n<a href=\"https://acoup.blog/tag/technology/\" class=\"tag-cloud-link tag-link-6 tag-link-position-68\" style=\"font-size: 14.307692307692pt;\" aria-label=\"Technology (12 items)\">Technology</a>\n<a href=\"https://acoup.blog/tag/textiles/\" class=\"tag-cloud-link tag-link-32893 tag-link-position-69\" style=\"font-size: 11.076923076923pt;\" aria-label=\"Textiles (7 items)\">Textiles</a>\n<a href=\"https://acoup.blog/tag/trade/\" class=\"tag-cloud-link tag-link-1595 tag-link-position-70\" style=\"font-size: 9.2307692307692pt;\" aria-label=\"Trade (5 items)\">Trade</a>\n<a href=\"https://acoup.blog/tag/ukraine/\" class=\"tag-cloud-link tag-link-716950058 tag-link-position-71\" style=\"font-size: 11.076923076923pt;\" aria-label=\"Ukraine (7 items)\">Ukraine</a>\n<a href=\"https://acoup.blog/tag/video-games/\" class=\"tag-cloud-link tag-link-1914 tag-link-position-72\" style=\"font-size: 12.615384615385pt;\" aria-label=\"Video Games (9 items)\">Video Games</a>\n<a href=\"https://acoup.blog/tag/war-and-society/\" class=\"tag-cloud-link tag-link-3075431 tag-link-position-73\" style=\"font-size: 9.2307692307692pt;\" aria-label=\"War and Society (5 items)\">War and Society</a>\n<a href=\"https://acoup.blog/tag/warfare/\" class=\"tag-cloud-link tag-link-103772 tag-link-position-74\" style=\"font-size: 11.846153846154pt;\" aria-label=\"Warfare (8 items)\">Warfare</a>\n<a href=\"https://acoup.blog/tag/weapons/\" class=\"tag-cloud-link tag-link-53309 tag-link-position-75\" style=\"font-size: 8pt;\" aria-label=\"Weapons (4 items)\">Weapons</a></div>\n</aside><aside id=\"archives-3\" class=\"widget widget_archive\"><h1 class=\"widget-title\">Archives</h1>\n\t\t\t<ul>\n\t\t\t\t\t<li><a href='https://acoup.blog/2023/04/'>April 2023</a>&nbsp;(3)</li>\n\t<li><a href='https://acoup.blog/2023/03/'>March 2023</a>&nbsp;(5)</li>\n\t<li><a href='https://acoup.blog/2023/02/'>February 2023</a>&nbsp;(4)</li>\n\t<li><a href='https://acoup.blog/2023/01/'>January 2023</a>&nbsp;(4)</li>\n\t<li><a href='https://acoup.blog/2022/12/'>December 2022</a>&nbsp;(5)</li>\n\t<li><a href='https://acoup.blog/2022/10/'>October 2022</a>&nbsp;(5)</li>\n\t<li><a href='https://acoup.blog/2022/09/'>September 2022</a>&nbsp;(5)</li>\n\t<li><a href='https://acoup.blog/2022/08/'>August 2022</a>&nbsp;(5)</li>\n\t<li><a href='https://acoup.blog/2022/07/'>July 2022</a>&nbsp;(5)</li>\n\t<li><a href='https://acoup.blog/2022/06/'>June 2022</a>&nbsp;(4)</li>\n\t<li><a href='https://acoup.blog/2022/05/'>May 2022</a>&nbsp;(4)</li>\n\t<li><a href='https://acoup.blog/2022/04/'>April 2022</a>&nbsp;(5)</li>\n\t<li><a href='https://acoup.blog/2022/03/'>March 2022</a>&nbsp;(4)</li>\n\t<li><a href='https://acoup.blog/2022/02/'>February 2022</a>&nbsp;(4)</li>\n\t<li><a href='https://acoup.blog/2022/01/'>January 2022</a>&nbsp;(4)</li>\n\t<li><a href='https://acoup.blog/2021/12/'>December 2021</a>&nbsp;(5)</li>\n\t<li><a href='https://acoup.blog/2021/11/'>November 2021</a>&nbsp;(4)</li>\n\t<li><a href='https://acoup.blog/2021/10/'>October 2021</a>&nbsp;(5)</li>\n\t<li><a href='https://acoup.blog/2021/09/'>September 2021</a>&nbsp;(4)</li>\n\t<li><a href='https://acoup.blog/2021/08/'>August 2021</a>&nbsp;(4)</li>\n\t<li><a href='https://acoup.blog/2021/07/'>July 2021</a>&nbsp;(5)</li>\n\t<li><a href='https://acoup.blog/2021/06/'>June 2021</a>&nbsp;(4)</li>\n\t<li><a href='https://acoup.blog/2021/05/'>May 2021</a>&nbsp;(4)</li>\n\t<li><a href='https://acoup.blog/2021/04/'>April 2021</a>&nbsp;(5)</li>\n\t<li><a href='https://acoup.blog/2021/03/'>March 2021</a>&nbsp;(4)</li>\n\t<li><a href='https://acoup.blog/2021/02/'>February 2021</a>&nbsp;(4)</li>\n\t<li><a href='https://acoup.blog/2021/01/'>January 2021</a>&nbsp;(5)</li>\n\t<li><a href='https://acoup.blog/2020/12/'>December 2020</a>&nbsp;(3)</li>\n\t<li><a href='https://acoup.blog/2020/11/'>November 2020</a>&nbsp;(4)</li>\n\t<li><a href='https://acoup.blog/2020/10/'>October 2020</a>&nbsp;(5)</li>\n\t<li><a href='https://acoup.blog/2020/09/'>September 2020</a>&nbsp;(4)</li>\n\t<li><a href='https://acoup.blog/2020/08/'>August 2020</a>&nbsp;(4)</li>\n\t<li><a href='https://acoup.blog/2020/07/'>July 2020</a>&nbsp;(5)</li>\n\t<li><a href='https://acoup.blog/2020/06/'>June 2020</a>&nbsp;(4)</li>\n\t<li><a href='https://acoup.blog/2020/05/'>May 2020</a>&nbsp;(5)</li>\n\t<li><a href='https://acoup.blog/2020/04/'>April 2020</a>&nbsp;(4)</li>\n\t<li><a href='https://acoup.blog/2020/03/'>March 2020</a>&nbsp;(5)</li>\n\t<li><a href='https://acoup.blog/2020/02/'>February 2020</a>&nbsp;(4)</li>\n\t<li><a href='https://acoup.blog/2020/01/'>January 2020</a>&nbsp;(5)</li>\n\t<li><a href='https://acoup.blog/2019/12/'>December 2019</a>&nbsp;(4)</li>\n\t<li><a href='https://acoup.blog/2019/11/'>November 2019</a>&nbsp;(5)</li>\n\t<li><a href='https://acoup.blog/2019/10/'>October 2019</a>&nbsp;(5)</li>\n\t<li><a href='https://acoup.blog/2019/09/'>September 2019</a>&nbsp;(5)</li>\n\t<li><a href='https://acoup.blog/2019/08/'>August 2019</a>&nbsp;(6)</li>\n\t<li><a href='https://acoup.blog/2019/07/'>July 2019</a>&nbsp;(5)</li>\n\t<li><a href='https://acoup.blog/2019/06/'>June 2019</a>&nbsp;(6)</li>\n\t<li><a href='https://acoup.blog/2019/05/'>May 2019</a>&nbsp;(12)</li>\n\t\t\t</ul>\n\n\t\t\t</aside></div><!-- #secondary -->\n\n\t\t</div><!-- #content -->\n\n\t\t<footer id=\"colophon\" class=\"site-footer\" role=\"contentinfo\">\n\t\t\t\t\t\t<div class=\"site-info\">\n\t\t\t\t<a href=\"https://wordpress.com/?ref=footer_custom_powered\">Powered by WordPress.com</a>.\n\t\t\t\t\n\t\t\t\t\t\t\t</div><!-- .site-info -->\n\t\t</footer><!-- #colophon -->\n\t</div><!-- #content-wrapper -->\n</div><!-- #page -->\n\n<!--  -->\n<style>\n\t\t\t.sd-social-icon .sd-content ul li a.sd-button>span {\n\t\t\t\tmargin-left: 0;\n\t\t\t}\n\t\t</style><script defer id=\"bilmur\" data-provider=\"wordpress.com\" data-service=\"atomic\"  src=\"https://s0.wp.com/wp-content/js/bilmur.min.js?m=202317\"></script>\n\t<div style=\"display:none\">\n\t\t\t<div class=\"grofile-hash-map-3f4e8a2b40f543b00032bb1f567dea75\">\n\t\t</div>\n\t\t<div class=\"grofile-hash-map-1796998dbeaa1965634e99376c8eead2\">\n\t\t</div>\n\t\t<div class=\"grofile-hash-map-d73e540e747f9e36c4482be4e3f1c322\">\n\t\t</div>\n\t\t<div class=\"grofile-hash-map-a7811e71cce9fa8e4e6b04d36e90dab3\">\n\t\t</div>\n\t\t<div class=\"grofile-hash-map-3221a241dbd520e2f5fba940c104012e\">\n\t\t</div>\n\t\t<div class=\"grofile-hash-map-0079148a4f382623304a768a54a399ac\">\n\t\t</div>\n\t\t<div class=\"grofile-hash-map-0224cd3cbcf5f12befd576b4f3da316e\">\n\t\t</div>\n\t\t</div>\n\t\t\t\t<div id=\"jp-carousel-loading-overlay\">\n\t\t\t<div id=\"jp-carousel-loading-wrapper\">\n\t\t\t\t<span id=\"jp-carousel-library-loading\">&nbsp;</span>\n\t\t\t</div>\n\t\t</div>\n\t\t<div class=\"jp-carousel-overlay\" style=\"display: none;\">\n\n\t\t<div class=\"jp-carousel-container\">\n\t\t\t<!-- The Carousel Swiper -->\n\t\t\t<div\n\t\t\t\tclass=\"jp-carousel-wrap swiper-container jp-carousel-swiper-container jp-carousel-transitions\"\n\t\t\t\titemscope\n\t\t\t\titemtype=\"https://schema.org/ImageGallery\">\n\t\t\t\t<div class=\"jp-carousel swiper-wrapper\"></div>\n\t\t\t\t<div class=\"jp-swiper-button-prev swiper-button-prev\">\n\t\t\t\t\t<svg width=\"25\" height=\"24\" viewBox=\"0 0 25 24\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n\t\t\t\t\t\t<mask id=\"maskPrev\" mask-type=\"alpha\" maskUnits=\"userSpaceOnUse\" x=\"8\" y=\"6\" width=\"9\" height=\"12\">\n\t\t\t\t\t\t\t<path d=\"M16.2072 16.59L11.6496 12L16.2072 7.41L14.8041 6L8.8335 12L14.8041 18L16.2072 16.59Z\" fill=\"white\"/>\n\t\t\t\t\t\t</mask>\n\t\t\t\t\t\t<g mask=\"url(#maskPrev)\">\n\t\t\t\t\t\t\t<rect x=\"0.579102\" width=\"23.8823\" height=\"24\" fill=\"#FFFFFF\"/>\n\t\t\t\t\t\t</g>\n\t\t\t\t\t</svg>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"jp-swiper-button-next swiper-button-next\">\n\t\t\t\t\t<svg width=\"25\" height=\"24\" viewBox=\"0 0 25 24\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n\t\t\t\t\t\t<mask id=\"maskNext\" mask-type=\"alpha\" maskUnits=\"userSpaceOnUse\" x=\"8\" y=\"6\" width=\"8\" height=\"12\">\n\t\t\t\t\t\t\t<path d=\"M8.59814 16.59L13.1557 12L8.59814 7.41L10.0012 6L15.9718 12L10.0012 18L8.59814 16.59Z\" fill=\"white\"/>\n\t\t\t\t\t\t</mask>\n\t\t\t\t\t\t<g mask=\"url(#maskNext)\">\n\t\t\t\t\t\t\t<rect x=\"0.34375\" width=\"23.8822\" height=\"24\" fill=\"#FFFFFF\"/>\n\t\t\t\t\t\t</g>\n\t\t\t\t\t</svg>\n\t\t\t\t</div>\n\t\t\t</div>\n\t\t\t<!-- The main close buton -->\n\t\t\t<div class=\"jp-carousel-close-hint\">\n\t\t\t\t<svg width=\"25\" height=\"24\" viewBox=\"0 0 25 24\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n\t\t\t\t\t<mask id=\"maskClose\" mask-type=\"alpha\" maskUnits=\"userSpaceOnUse\" x=\"5\" y=\"5\" width=\"15\" height=\"14\">\n\t\t\t\t\t\t<path d=\"M19.3166 6.41L17.9135 5L12.3509 10.59L6.78834 5L5.38525 6.41L10.9478 12L5.38525 17.59L6.78834 19L12.3509 13.41L17.9135 19L19.3166 17.59L13.754 12L19.3166 6.41Z\" fill=\"white\"/>\n\t\t\t\t\t</mask>\n\t\t\t\t\t<g mask=\"url(#maskClose)\">\n\t\t\t\t\t\t<rect x=\"0.409668\" width=\"23.8823\" height=\"24\" fill=\"#FFFFFF\"/>\n\t\t\t\t\t</g>\n\t\t\t\t</svg>\n\t\t\t</div>\n\t\t\t<!-- Image info, comments and meta -->\n\t\t\t<div class=\"jp-carousel-info\">\n\t\t\t\t<div class=\"jp-carousel-info-footer\">\n\t\t\t\t\t<div class=\"jp-carousel-pagination-container\">\n\t\t\t\t\t\t<div class=\"jp-swiper-pagination swiper-pagination\"></div>\n\t\t\t\t\t\t<div class=\"jp-carousel-pagination\"></div>\n\t\t\t\t\t</div>\n\t\t\t\t\t<div class=\"jp-carousel-photo-title-container\">\n\t\t\t\t\t\t<h2 class=\"jp-carousel-photo-caption\"></h2>\n\t\t\t\t\t</div>\n\t\t\t\t\t<div class=\"jp-carousel-photo-icons-container\">\n\t\t\t\t\t\t<a href=\"#\" class=\"jp-carousel-icon-btn jp-carousel-icon-info\" aria-label=\"Toggle photo metadata visibility\">\n\t\t\t\t\t\t\t<span class=\"jp-carousel-icon\">\n\t\t\t\t\t\t\t\t<svg width=\"25\" height=\"24\" viewBox=\"0 0 25 24\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n\t\t\t\t\t\t\t\t\t<mask id=\"maskInfo\" mask-type=\"alpha\" maskUnits=\"userSpaceOnUse\" x=\"2\" y=\"2\" width=\"21\" height=\"20\">\n\t\t\t\t\t\t\t\t\t\t<path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M12.7537 2C7.26076 2 2.80273 6.48 2.80273 12C2.80273 17.52 7.26076 22 12.7537 22C18.2466 22 22.7046 17.52 22.7046 12C22.7046 6.48 18.2466 2 12.7537 2ZM11.7586 7V9H13.7488V7H11.7586ZM11.7586 11V17H13.7488V11H11.7586ZM4.79292 12C4.79292 16.41 8.36531 20 12.7537 20C17.142 20 20.7144 16.41 20.7144 12C20.7144 7.59 17.142 4 12.7537 4C8.36531 4 4.79292 7.59 4.79292 12Z\" fill=\"white\"/>\n\t\t\t\t\t\t\t\t\t</mask>\n\t\t\t\t\t\t\t\t\t<g mask=\"url(#maskInfo)\">\n\t\t\t\t\t\t\t\t\t\t<rect x=\"0.8125\" width=\"23.8823\" height=\"24\" fill=\"#FFFFFF\"/>\n\t\t\t\t\t\t\t\t\t</g>\n\t\t\t\t\t\t\t\t</svg>\n\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t</a>\n\t\t\t\t\t\t\t\t\t\t\t\t<a href=\"#\" class=\"jp-carousel-icon-btn jp-carousel-icon-comments\" aria-label=\"Toggle photo comments visibility\">\n\t\t\t\t\t\t\t<span class=\"jp-carousel-icon\">\n\t\t\t\t\t\t\t\t<svg width=\"25\" height=\"24\" viewBox=\"0 0 25 24\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n\t\t\t\t\t\t\t\t\t<mask id=\"maskComments\" mask-type=\"alpha\" maskUnits=\"userSpaceOnUse\" x=\"2\" y=\"2\" width=\"21\" height=\"20\">\n\t\t\t\t\t\t\t\t\t\t<path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M4.3271 2H20.2486C21.3432 2 22.2388 2.9 22.2388 4V16C22.2388 17.1 21.3432 18 20.2486 18H6.31729L2.33691 22V4C2.33691 2.9 3.2325 2 4.3271 2ZM6.31729 16H20.2486V4H4.3271V18L6.31729 16Z\" fill=\"white\"/>\n\t\t\t\t\t\t\t\t\t</mask>\n\t\t\t\t\t\t\t\t\t<g mask=\"url(#maskComments)\">\n\t\t\t\t\t\t\t\t\t\t<rect x=\"0.34668\" width=\"23.8823\" height=\"24\" fill=\"#FFFFFF\"/>\n\t\t\t\t\t\t\t\t\t</g>\n\t\t\t\t\t\t\t\t</svg>\n\n\t\t\t\t\t\t\t\t<span class=\"jp-carousel-has-comments-indicator\" aria-label=\"This image has comments.\"></span>\n\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t</a>\n\t\t\t\t\t\t\t\t\t\t\t</div>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"jp-carousel-info-extra\">\n\t\t\t\t\t<div class=\"jp-carousel-info-content-wrapper\">\n\t\t\t\t\t\t<div class=\"jp-carousel-photo-title-container\">\n\t\t\t\t\t\t\t<h2 class=\"jp-carousel-photo-title\"></h2>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t\t<div class=\"jp-carousel-comments-wrapper\">\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<div id=\"jp-carousel-comments-loading\">\n\t\t\t\t\t\t\t\t\t<span>Loading Comments...</span>\n\t\t\t\t\t\t\t\t</div>\n\t\t\t\t\t\t\t\t<div class=\"jp-carousel-comments\"></div>\n\t\t\t\t\t\t\t\t<div id=\"jp-carousel-comment-form-container\">\n\t\t\t\t\t\t\t\t\t<span id=\"jp-carousel-comment-form-spinner\">&nbsp;</span>\n\t\t\t\t\t\t\t\t\t<div id=\"jp-carousel-comment-post-results\"></div>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<form id=\"jp-carousel-comment-form\">\n\t\t\t\t\t\t\t\t\t\t\t\t<label for=\"jp-carousel-comment-form-comment-field\" class=\"screen-reader-text\">Write a Comment...</label>\n\t\t\t\t\t\t\t\t\t\t\t\t<textarea\n\t\t\t\t\t\t\t\t\t\t\t\t\tname=\"comment\"\n\t\t\t\t\t\t\t\t\t\t\t\t\tclass=\"jp-carousel-comment-form-field jp-carousel-comment-form-textarea\"\n\t\t\t\t\t\t\t\t\t\t\t\t\tid=\"jp-carousel-comment-form-comment-field\"\n\t\t\t\t\t\t\t\t\t\t\t\t\tplaceholder=\"Write a Comment...\"\n\t\t\t\t\t\t\t\t\t\t\t\t></textarea>\n\t\t\t\t\t\t\t\t\t\t\t\t<div id=\"jp-carousel-comment-form-submit-and-info-wrapper\">\n\t\t\t\t\t\t\t\t\t\t\t\t\t<div id=\"jp-carousel-comment-form-commenting-as\">\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<fieldset>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<label for=\"jp-carousel-comment-form-email-field\">Email (Required)</label>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<input type=\"text\" name=\"email\" class=\"jp-carousel-comment-form-field jp-carousel-comment-form-text-field\" id=\"jp-carousel-comment-form-email-field\" />\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</fieldset>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<fieldset>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<label for=\"jp-carousel-comment-form-author-field\">Name (Required)</label>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<input type=\"text\" name=\"author\" class=\"jp-carousel-comment-form-field jp-carousel-comment-form-text-field\" id=\"jp-carousel-comment-form-author-field\" />\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</fieldset>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<fieldset>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<label for=\"jp-carousel-comment-form-url-field\">Website</label>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<input type=\"text\" name=\"url\" class=\"jp-carousel-comment-form-field jp-carousel-comment-form-text-field\" id=\"jp-carousel-comment-form-url-field\" />\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</fieldset>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</div>\n\t\t\t\t\t\t\t\t\t\t\t\t\t<input\n\t\t\t\t\t\t\t\t\t\t\t\t\t\ttype=\"submit\"\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tname=\"submit\"\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tclass=\"jp-carousel-comment-form-button\"\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tid=\"jp-carousel-comment-form-button-submit\"\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tvalue=\"Post Comment\" />\n\t\t\t\t\t\t\t\t\t\t\t\t</div>\n\t\t\t\t\t\t\t\t\t\t\t</form>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</div>\n\t\t\t\t\t\t\t\t\t\t\t\t\t</div>\n\t\t\t\t\t\t<div class=\"jp-carousel-image-meta\">\n\t\t\t\t\t\t\t<div class=\"jp-carousel-title-and-caption\">\n\t\t\t\t\t\t\t\t<div class=\"jp-carousel-photo-info\">\n\t\t\t\t\t\t\t\t\t<h3 class=\"jp-carousel-caption\" itemprop=\"caption description\"></h3>\n\t\t\t\t\t\t\t\t</div>\n\n\t\t\t\t\t\t\t\t<div class=\"jp-carousel-photo-description\"></div>\n\t\t\t\t\t\t\t</div>\n\t\t\t\t\t\t\t<ul class=\"jp-carousel-image-exif\" style=\"display: none;\"></ul>\n\t\t\t\t\t\t\t<a class=\"jp-carousel-image-download\" target=\"_blank\" style=\"display: none;\">\n\t\t\t\t\t\t\t\t<svg width=\"25\" height=\"24\" viewBox=\"0 0 25 24\" fill=\"none\" xmlns=\"http://www.w3.org/2000/svg\">\n\t\t\t\t\t\t\t\t\t<mask id=\"mask0\" mask-type=\"alpha\" maskUnits=\"userSpaceOnUse\" x=\"3\" y=\"3\" width=\"19\" height=\"18\">\n\t\t\t\t\t\t\t\t\t\t<path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M5.84615 5V19H19.7775V12H21.7677V19C21.7677 20.1 20.8721 21 19.7775 21H5.84615C4.74159 21 3.85596 20.1 3.85596 19V5C3.85596 3.9 4.74159 3 5.84615 3H12.8118V5H5.84615ZM14.802 5V3H21.7677V10H19.7775V6.41L9.99569 16.24L8.59261 14.83L18.3744 5H14.802Z\" fill=\"white\"/>\n\t\t\t\t\t\t\t\t\t</mask>\n\t\t\t\t\t\t\t\t\t<g mask=\"url(#mask0)\">\n\t\t\t\t\t\t\t\t\t\t<rect x=\"0.870605\" width=\"23.8823\" height=\"24\" fill=\"#FFFFFF\"/>\n\t\t\t\t\t\t\t\t\t</g>\n\t\t\t\t\t\t\t\t</svg>\n\t\t\t\t\t\t\t\t<span class=\"jp-carousel-download-text\"></span>\n\t\t\t\t\t\t\t</a>\n\t\t\t\t\t\t\t<div class=\"jp-carousel-image-map\" style=\"display: none;\"></div>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t</div>\n\t\t\t\t</div>\n\t\t\t</div>\n\t\t</div>\n\n\t\t</div>\n\t\t\n\t<script type=\"text/javascript\">\n\t\twindow.WPCOM_sharing_counts = {\"https:\\/\\/acoup.blog\\/2023\\/02\\/17\\/collections-on-chatgpt\\/\":17368};\n\t</script>\n\t\t\t\t<link rel='stylesheet' id='all-css-07c6e08739ac402b712b726b42e84493' href='https://acoup.blog/_static/??-eJyVjEEOwiAQRS8kTGpiZWM8C9LRUGGGMkNIb69NdOHCRXc/7+e9XkxgUiSFktojksCMWnx4QuapJRQIvnITTCA9Fqzm1mhKaIPIoe+wP4f5gn8B9LKaO7MS69v3IqgCi8YC89KwrnbbNkfaV/ilm3vNl2E8H4eTc6N7AanYZWE=' type='text/css' media='all' />\n<link rel='stylesheet' id='dashicons-css' href='https://acoup.blog/wp-includes/css/dashicons.min.css?ver=6.2' media='all' />\n<script type='text/javascript'  src='https://acoup.blog/wp-content/plugins/jetpack/_inc/build/photon/photon.min.js?m=1638896208'></script>\n<script src='https://secure.gravatar.com/js/gprofiles.js?ver=202317' id='grofiles-cards-js'></script>\n<script id='wpgroho-js-extra'>\nvar WPGroHo = {\"my_hash\":\"\"};\n</script>\n<script id='jetpack-lazy-images-js-extra'>\nvar jetpackLazyImagesL10n = {\"loading_warning\":\"Images are still loading. Please cancel your print and try again.\"};\n</script>\n<script type='text/javascript'  src='https://acoup.blog/_static/??-eJytkN1OwzAMhV+ILAy0jRvEo0xp4rVu87fYadieHlcMgSoumMRNLMX+zjk6LSubIkNknX3tMZIegbOxkw7JVQ+kW+5LGtJmpIf2fc0DBFlidJBBnsgq184jDVDUkx5JRzNjbxhTvBulCbPyGCd1SraSOuH7TQOj9dUJLVc2hbDABbK/bALe6SNSmmzBzKpl0VrR6zqOy31X0TvNDZlFgzGApIRfvNf0bR5nCZKKNpVTMMxovzbKm+tFYTC9RHZILPnEg8AuDarUEZQZyv/b/Pj4ewMeJ+HPFSoMJjovwT47eAuv2/3L9rDbPx8ePwDL++aP'></script>\n<script defer src='https://stats.wp.com/e-202317.js' id='jetpack-stats-js'></script>\n<script id='jetpack-stats-js-after'>\n_stq = window._stq || [];\n_stq.push([ \"view\", {v:'ext',blog:'161773962',post:'17368',tz:'-4',srv:'acoup.blog',hp:'atomic',ac:'2',amp:'0',j:'1:12.1-a.7'} ]);\n_stq.push([ \"clickTrackerInit\", \"161773962\", \"17368\" ]);\n</script>\n<script id='jetpack-carousel-js-extra'>\nvar jetpackSwiperLibraryPath = {\"url\":\"https:\\/\\/acoup.blog\\/wp-content\\/plugins\\/jetpack\\/_inc\\/build\\/carousel\\/swiper-bundle.min.js\"};\nvar jetpackCarouselStrings = {\"widths\":[370,700,1000,1200,1400,2000],\"is_logged_in\":\"\",\"lang\":\"en\",\"ajaxurl\":\"https:\\/\\/acoup.blog\\/wp-admin\\/admin-ajax.php\",\"nonce\":\"c8ebb1618a\",\"display_exif\":\"1\",\"display_comments\":\"1\",\"single_image_gallery\":\"1\",\"single_image_gallery_media_file\":\"\",\"background_color\":\"black\",\"comment\":\"Comment\",\"post_comment\":\"Post Comment\",\"write_comment\":\"Write a Comment...\",\"loading_comments\":\"Loading Comments...\",\"download_original\":\"View full size <span class=\\\"photo-size\\\">{0}<span class=\\\"photo-size-times\\\">\\u00d7<\\/span>{1}<\\/span>\",\"no_comment_text\":\"Please be sure to submit some text with your comment.\",\"no_comment_email\":\"Please provide an email address to comment.\",\"no_comment_author\":\"Please provide your name to comment.\",\"comment_post_error\":\"Sorry, but there was an error posting your comment. Please try again later.\",\"comment_approved\":\"Your comment was approved.\",\"comment_unapproved\":\"Your comment is in moderation.\",\"camera\":\"Camera\",\"aperture\":\"Aperture\",\"shutter_speed\":\"Shutter Speed\",\"focal_length\":\"Focal Length\",\"copyright\":\"Copyright\",\"comment_registration\":\"0\",\"require_name_email\":\"1\",\"login_url\":\"https:\\/\\/acoup.blog\\/wp-login.php?redirect_to=https%3A%2F%2Facoup.blog%2F2023%2F02%2F17%2Fcollections-on-chatgpt%2F\",\"blog_id\":\"1\",\"meta_data\":[\"camera\",\"aperture\",\"shutter_speed\",\"focal_length\",\"copyright\"]};\n</script>\n<script type='text/javascript'  src='https://acoup.blog/_static/??-eJxljNsKwjAQRH/IdCtoqQ/ip0gua9h2cyGXBv/egC0IPs7MmdOi0MEX9AUiV0s+g609KkwWVCU2oDjoVTCpJNP7mzK8iBE2wjY48sOST+1ftGCJUq/wJK93l5Yp1Ix8bOIofjSd5mqw/zOQkxYzB2nQ7MjD3c/TPE7X8TZfPnRzRwE='></script>\n<script src='https://acoup.blog/wp-includes/js/jquery/jquery.min.js?ver=3.6.3' id='jquery-core-js'></script>\n<script type='text/javascript'  src='https://acoup.blog/_static/??-eJylj8EKwyAQRH+oKh6sp9JPKWI2YVNdjbsS8ve1JT32VBiYHZh9MHtVSDH1CdisQ1uHdpymMi4tCOiMpFe+7FXFQgIkpqa+ILGBwIeaSxEqMgiBGYTNJlhPhn7ffwNiSOkHIDyRM4h5jBnfoOb2aU3j555v9uqdt9469wIVeFpT'></script>\n<script id='sharing-js-js-extra'>\nvar sharing_js_options = {\"lang\":\"en\",\"counts\":\"1\",\"is_stats_active\":\"1\"};\n</script>\n<script src='https://acoup.blog/wp-content/plugins/jetpack/_inc/build/sharedaddy/sharing.min.js?ver=12.1-a.7' id='sharing-js-js'></script>\n<script id='sharing-js-js-after'>\nvar windowOpen;\n\t\t\t( function () {\n\t\t\t\tfunction matches( el, sel ) {\n\t\t\t\t\treturn !! (\n\t\t\t\t\t\tel.matches && el.matches( sel ) ||\n\t\t\t\t\t\tel.msMatchesSelector && el.msMatchesSelector( sel )\n\t\t\t\t\t);\n\t\t\t\t}\n\n\t\t\t\tdocument.body.addEventListener( 'click', function ( event ) {\n\t\t\t\t\tif ( ! event.target ) {\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\n\t\t\t\t\tvar el;\n\t\t\t\t\tif ( matches( event.target, 'a.share-twitter' ) ) {\n\t\t\t\t\t\tel = event.target;\n\t\t\t\t\t} else if ( event.target.parentNode && matches( event.target.parentNode, 'a.share-twitter' ) ) {\n\t\t\t\t\t\tel = event.target.parentNode;\n\t\t\t\t\t}\n\n\t\t\t\t\tif ( el ) {\n\t\t\t\t\t\tevent.preventDefault();\n\n\t\t\t\t\t\t// If there's another sharing window open, close it.\n\t\t\t\t\t\tif ( typeof windowOpen !== 'undefined' ) {\n\t\t\t\t\t\t\twindowOpen.close();\n\t\t\t\t\t\t}\n\t\t\t\t\t\twindowOpen = window.open( el.getAttribute( 'href' ), 'wpcomtwitter', 'menubar=1,resizable=1,width=600,height=350' );\n\t\t\t\t\t\treturn false;\n\t\t\t\t\t}\n\t\t\t\t} );\n\t\t\t} )();\nvar windowOpen;\n\t\t\t( function () {\n\t\t\t\tfunction matches( el, sel ) {\n\t\t\t\t\treturn !! (\n\t\t\t\t\t\tel.matches && el.matches( sel ) ||\n\t\t\t\t\t\tel.msMatchesSelector && el.msMatchesSelector( sel )\n\t\t\t\t\t);\n\t\t\t\t}\n\n\t\t\t\tdocument.body.addEventListener( 'click', function ( event ) {\n\t\t\t\t\tif ( ! event.target ) {\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\n\t\t\t\t\tvar el;\n\t\t\t\t\tif ( matches( event.target, 'a.share-facebook' ) ) {\n\t\t\t\t\t\tel = event.target;\n\t\t\t\t\t} else if ( event.target.parentNode && matches( event.target.parentNode, 'a.share-facebook' ) ) {\n\t\t\t\t\t\tel = event.target.parentNode;\n\t\t\t\t\t}\n\n\t\t\t\t\tif ( el ) {\n\t\t\t\t\t\tevent.preventDefault();\n\n\t\t\t\t\t\t// If there's another sharing window open, close it.\n\t\t\t\t\t\tif ( typeof windowOpen !== 'undefined' ) {\n\t\t\t\t\t\t\twindowOpen.close();\n\t\t\t\t\t\t}\n\t\t\t\t\t\twindowOpen = window.open( el.getAttribute( 'href' ), 'wpcomfacebook', 'menubar=1,resizable=1,width=600,height=400' );\n\t\t\t\t\t\treturn false;\n\t\t\t\t\t}\n\t\t\t\t} );\n\t\t\t} )();\n</script>\n\t<iframe src='https://widgets.wp.com/likes/master.html?ver=202317#ver=202317' scrolling='no' id='likes-master' name='likes-master' style='display:none;'></iframe>\n\t<div id='likes-other-gravatars'><div class=\"likes-text\"><span>%d</span> bloggers like this:</div><ul class=\"wpl-avatars sd-like-gravatars\"></ul></div>\n\t\n\t\t<!--[if IE]>\n\t\t<script type=\"text/javascript\">\n\t\t\tif ( 0 === window.location.hash.indexOf( '#comment-' ) ) {\n\t\t\t\t// window.location.reload() doesn't respect the Hash in IE\n\t\t\t\twindow.location.hash = window.location.hash;\n\t\t\t}\n\t\t</script>\n\t\t<![endif]-->\n\t\t<script type=\"text/javascript\">\n\t\t\t(function () {\n\t\t\t\tvar comm_par_el = document.getElementById( 'comment_parent' ),\n\t\t\t\t\tcomm_par = ( comm_par_el && comm_par_el.value ) ? comm_par_el.value : '',\n\t\t\t\t\tframe = document.getElementById( 'jetpack_remote_comment' ),\n\t\t\t\t\ttellFrameNewParent;\n\n\t\t\t\ttellFrameNewParent = function () {\n\t\t\t\t\tif ( comm_par ) {\n\t\t\t\t\t\tframe.src = \"https://jetpack.wordpress.com/jetpack-comment/?blogid=161773962&postid=17368&comment_registration=0&require_name_email=1&stc_enabled=1&stb_enabled=1&show_avatars=1&avatar_default=identicon&greeting=Leave+a+Reply&jetpack_comments_nonce=da56ad4845&greeting_reply=Leave+a+Reply+to+%25s&color_scheme=light&lang=en_US&jetpack_version=12.1-a.7&show_cookie_consent=10&has_cookie_consent=0&token_key=%3Bnormal%3B&sig=06477dd03300592e57fb15d97dd1099b24a76942#parent=https%3A%2F%2Facoup.blog%2F2023%2F02%2F17%2Fcollections-on-chatgpt%2F\" + '&replytocom=' + parseInt( comm_par, 10 ).toString();\n\t\t\t\t\t} else {\n\t\t\t\t\t\tframe.src = \"https://jetpack.wordpress.com/jetpack-comment/?blogid=161773962&postid=17368&comment_registration=0&require_name_email=1&stc_enabled=1&stb_enabled=1&show_avatars=1&avatar_default=identicon&greeting=Leave+a+Reply&jetpack_comments_nonce=da56ad4845&greeting_reply=Leave+a+Reply+to+%25s&color_scheme=light&lang=en_US&jetpack_version=12.1-a.7&show_cookie_consent=10&has_cookie_consent=0&token_key=%3Bnormal%3B&sig=06477dd03300592e57fb15d97dd1099b24a76942#parent=https%3A%2F%2Facoup.blog%2F2023%2F02%2F17%2Fcollections-on-chatgpt%2F\";\n\t\t\t\t\t}\n\t\t\t\t};\n\n\t\t\t\t\n\t\t\t\tif ( 'undefined' !== typeof addComment ) {\n\t\t\t\t\taddComment._Jetpack_moveForm = addComment.moveForm;\n\n\t\t\t\t\taddComment.moveForm = function ( commId, parentId, respondId, postId ) {\n\t\t\t\t\t\tvar returnValue = addComment._Jetpack_moveForm( commId, parentId, respondId, postId ),\n\t\t\t\t\t\t\tcancelClick, cancel;\n\n\t\t\t\t\t\tif ( false === returnValue ) {\n\t\t\t\t\t\t\tcancel = document.getElementById( 'cancel-comment-reply-link' );\n\t\t\t\t\t\t\tcancelClick = cancel.onclick;\n\t\t\t\t\t\t\tcancel.onclick = function () {\n\t\t\t\t\t\t\t\tvar cancelReturn = cancelClick.call( this );\n\t\t\t\t\t\t\t\tif ( false !== cancelReturn ) {\n\t\t\t\t\t\t\t\t\treturn cancelReturn;\n\t\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t\tif ( ! comm_par ) {\n\t\t\t\t\t\t\t\t\treturn cancelReturn;\n\t\t\t\t\t\t\t\t}\n\n\t\t\t\t\t\t\t\tcomm_par = 0;\n\n\t\t\t\t\t\t\t\ttellFrameNewParent();\n\n\t\t\t\t\t\t\t\treturn cancelReturn;\n\t\t\t\t\t\t\t};\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tif ( comm_par == parentId ) {\n\t\t\t\t\t\t\treturn returnValue;\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\tcomm_par = parentId;\n\n\t\t\t\t\t\ttellFrameNewParent();\n\n\t\t\t\t\t\treturn returnValue;\n\t\t\t\t\t};\n\t\t\t\t}\n\n\t\t\t\t\n\t\t\t\t// Do the post message bit after the dom has loaded.\n\t\t\t\tdocument.addEventListener( 'DOMContentLoaded', function () {\n\t\t\t\t\tvar iframe_url = \"https:\\/\\/jetpack.wordpress.com\";\n\t\t\t\t\tif ( window.postMessage ) {\n\t\t\t\t\t\tif ( document.addEventListener ) {\n\t\t\t\t\t\t\twindow.addEventListener( 'message', function ( event ) {\n\t\t\t\t\t\t\t\tvar origin = event.origin.replace( /^http:\\/\\//i, 'https://' );\n\t\t\t\t\t\t\t\tif ( iframe_url.replace( /^http:\\/\\//i, 'https://' ) !== origin ) {\n\t\t\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tframe.style.height = event.data + 'px';\n\t\t\t\t\t\t\t});\n\t\t\t\t\t\t} else if ( document.attachEvent ) {\n\t\t\t\t\t\t\twindow.attachEvent( 'message', function ( event ) {\n\t\t\t\t\t\t\t\tvar origin = event.origin.replace( /^http:\\/\\//i, 'https://' );\n\t\t\t\t\t\t\t\tif ( iframe_url.replace( /^http:\\/\\//i, 'https://' ) !== origin ) {\n\t\t\t\t\t\t\t\t\treturn;\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\tframe.style.height = event.data + 'px';\n\t\t\t\t\t\t\t});\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t})\n\n\t\t\t})();\n\t\t</script>\n\n\t\t\n</body>\n</html>\n","oembed":false,"readabilityObject":{"title":"Collections: On ChatGPT","content":"<div id=\"readability-page-1\" class=\"page\"><div>\n\t\t\n<p>So I stirred up a bit of conversation on Twitter last week when I noted that I had already been handed ChatGPT produced assignments.<span id=\"easy-footnote-1-17368\"></span><span><a href=\"#easy-footnote-bottom-1-17368\" title=\"And I should be clear right here ahead of time that nothing that follows is particular to any paper(s) I may have received.  Do not ask &amp;#8220;what happened to the student(s)?&amp;#8221; or &amp;#8220;how did you know?&amp;#8221; or &amp;#8220;what class was this in?&amp;#8221; because I can&amp;#8217;t tell you.  <a href=&quot;https://en.wikipedia.org/wiki/Family_Educational_Rights_and_Privacy_Act&quot; data-type=&quot;URL&quot; data-id=&quot;https://en.wikipedia.org/wiki/Family_Educational_Rights_and_Privacy_Act&quot;>Student privacy laws</a> in the United States protect that sort of information and it is a good thing they do.  The observations that follow are not based on student papers, instead they are based on a number of responses I had ChatGPT produce for me to get a sense of what such an effort at cheating might look like and how I might detect it.\"><sup>1</sup></a></span>  For those who are unaware, ChatGPT is an ‘AI’ chatbot that given a prompt can produce texts; it is one of most sophisticated bots of this sort yet devised, trained on a massive amount of writing (along with substantial human input in the training process, something we’ll come back to).  And its appearance has made a lot of waves and caused a fair bit of consternation.</p>\n\n\n\n<p>Now I should note at the outset that while I am going to argue that ChatGPT is – or at least ought to be – basically useless for doing college assignments, it is also <em>wrong</em> to use it for this purpose.  Functionally all university honor codes prohibit something like ‘unauthorized aid or assistance’ when completing an assignment.  Having a chatbot write an assignment – or any part of that assignment – <em>for you</em> pretty clearly meets that definition.  Consequently using ChatGPT on a college essay is pretty clearly an impermissible outside aid – that is to say, ‘cheating.’  At most universities, this sort of cheating is an offense that can lead to failing classes or expulsion.  So however irritating that paper may be, it is probably not worth getting thrown out of college, money wasted, without a degree.  Learn.  Don’t cheat.</p>\n\n\n\n<p>That said I want to move through a few of my basic issues: first, what ChatGPT <em>is</em> in contrast to what people seem to <em>think</em> it is.  Second, why I think that functionality serves little purpose in essay writing – or more correctly why I think folks that think it ‘solves’ essay writing misunderstand what essay writing is <em>for</em>.  Third, why I think that same functionality serves little purpose in my classroom – or more correctly why I think that folks that think is solves issues in the classroom fundamentally misunderstand what I am teaching and how.</p>\n\n\n\n<p>Now I do want to be clear at the outset that I am not saying that this technology has no viable uses (though I can’t say I’ve yet seen an example of a use I would consider <em>good</em> rather than merely economically viable for ChatGPT in particular) and I am certainly not saying that future machine-learning based products, be they large language models or other products, will not be useful (though I do think that boosters of this technology frequently <em>assume</em> applications in fields they do not understand). <strong> Machine learning products are, in fact, <em>already</em> useful and in common use in ways that are good</strong>.  But I think I will stipulate that much of the boosterism for ChatGPT amounts to what <a href=\"https://youtube.com/watch?v=YQ_xWvX1n9g&amp;feature=shares&amp;t=1408\" data-type=\"URL\" data-id=\"https://youtube.com/watch?v=YQ_xWvX1n9g&amp;feature=shares&amp;t=1408\">Dan Olsen (commenting on cryptocurrency) describes as</a>, “technofetishistic egotism,” a condition in which tech creators fall into the trap where, “They don’t understand anything about the ecosystems they’re trying to disrupt…and assume that because they understand one very complicated thing, [difficult programming challenges]…that all other complicated things must be lesser in complexity and naturally lower in the hierarchy of reality, nails easily driven by the hammer that they have created.”</p>\n\n\n\n<p>Of course that goes both ways which is why I am not going to say what capabilities machine learning may bring tomorrow.  It is evidently a potentially powerful technology and I am not able to assess what it may be able to do in the future.  But I <em>can</em> assess the observes capabilities of ChatGPT <em>right now</em> and talk about the implication those capabilities have in a classroom environment, which I do understand.<span id=\"easy-footnote-2-17368\"></span><span><a href=\"#easy-footnote-bottom-2-17368\" title=\"After all I may not have experience as a creator of large language models, but I am a fully qualified <em>end user</em>. I cannot and indeed will not critique how ChatGPT was created, but I am perfectly qualified to say, &amp;#8220;this product as delivered does not meet any of my needs.&amp;#8221;\"><sup>2</sup></a></span>  That means – and I should be clear on this – <strong>this is a post about the capabilities of ChatGPT in its current form; not some other machine learning tool or AI that one imagines might exist in the future</strong>.  And in that context what I see does not convince me that <em>this </em>technology is going to improve the learning experience; <strong>where it is disruptive it seems almost entirely negatively so and even then the disruption is less profound than one might think.</strong></p>\n\n\n\n<p>Now because I am not a chatbot but instead a living, breathing human who in theory needs to eat to survive, I should remind you that if you like what you are reading here you can help by sharing what I write (for I rely on word of mouth for my audience) and by supporting me on <a href=\"https://www.patreon.com/user?u=20122096\">Patreon</a>. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings, assuming there is still a Twitter by the time this post goes live.</p>\n\n\n\n\n\n\n<figure><img data-lazy-fallback=\"1\" data-attachment-id=\"17508\" data-permalink=\"https://acoup.blog/2023/02/17/collections-on-chatgpt/title-image-4/\" data-orig-file=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?fit=1561%2C1138&amp;ssl=1\" data-orig-size=\"1561,1138\" data-comments-opened=\"1\" data-image-meta=\"{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}\" data-image-title=\"title image\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?fit=300%2C219&amp;ssl=1\" data-large-file=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?fit=1024%2C747&amp;ssl=1\" decoding=\"async\" loading=\"lazy\" width=\"1024\" height=\"747\" src=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?resize=1024%2C747&amp;ssl=1\" alt=\"\" srcset=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?resize=1024%2C747&amp;ssl=1 1024w, https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?resize=300%2C219&amp;ssl=1 300w, https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?resize=768%2C560&amp;ssl=1 768w, https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?resize=1536%2C1120&amp;ssl=1 1536w, https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?resize=1200%2C875&amp;ssl=1 1200w, https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?resize=1100%2C802&amp;ssl=1 1100w, https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?w=1561&amp;ssl=1 1561w\" sizes=\"(max-width: 1024px) 100vw, 1024px\" data-recalc-dims=\"1\" data-lazy-srcset=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?resize=1024%2C747&amp;ssl=1 1024w, https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?resize=300%2C219&amp;ssl=1 300w, https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?resize=768%2C560&amp;ssl=1 768w, https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?resize=1536%2C1120&amp;ssl=1 1536w, https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?resize=1200%2C875&amp;ssl=1 1200w, https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?resize=1100%2C802&amp;ssl=1 1100w, https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?w=1561&amp;ssl=1 1561w\" data-lazy-src=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?resize=1024%2C747&amp;is-pending-load=1#038;ssl=1\" data-old-srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\"></figure>\n\n\n\n<h2>The Heck is a ChatGPT?</h2>\n\n\n\n<p>But I think we want to start by discussing what ChatGPT is and what it is <em>not</em>; it is the latter actually that is most important for this discussion.  <strong>The tricky part is that ChatGPT and chatbots like it are designed to make use of a very influential human cognitive bias that we all have: <a href=\"https://en.wikipedia.org/wiki/Anthropomorphism\" data-type=\"URL\" data-id=\"https://en.wikipedia.org/wiki/Anthropomorphism\">the tendency to view things which are not people as people or at least as being like people</a>.</strong>  We all do this; we imagine our pets understand more than they can, have emotions more similar to ours than they do,<span id=\"easy-footnote-3-17368\"></span><span><a href=\"#easy-footnote-bottom-3-17368\" title=\"Not that pets don&amp;#8217;t have emotions or some kind of understanding, but we anthropomorphize our pets <em>a lot</em> as a way of relating to them.\"><sup>3</sup></a></span> or that inanimate objects are not merely animate but <em>human</em> in their feelings, memories and so on.  We even imagine that the waves and winds are like people too and assign them attributes as divine beings with human-like emotions and often human-like appearances.  We beg and plead with the impersonal forces of the world like we would with <em>people</em> who might be moved by those emotions.</p>\n\n\n\n<p><strong>The way ChatGPT and other chatbots abuse that tendency is that they <em>pretend</em> to be like minds – like human minds.</strong>  But <strong>it is only pretend, <em>there is no mind there</em></strong> and that is the key to understanding what ChatGPT is (and thus what it is capable of).  Now I can’t claim to understand the complex computer science that produced this program (indeed, with machine learning programs, even the creators sometimes cannot truly understand ‘how’ the program comes to a specific result), but enough concerning how it functions has been discussed to get a sense of what it can and cannot do.  Moreover its limitations (demonstrated in its <em>use</em> and thus available for interrogation by the non-specialist) are illustrative of its capabilities.</p>\n\n\n\n<p><strong>ChatGPT is chatbot (a program designed to mimic human conversation) that uses a large language model (a giant model of probabilities of what words will appear and in what order).  </strong>That large language model was produced through a giant text base (<a href=\"https://www.sciencefocus.com/future-technology/gpt-3/\" data-type=\"URL\" data-id=\"https://www.sciencefocus.com/future-technology/gpt-3/\">some 570GB, reportedly</a>) though I can’t find that OpenAI has been transparent about what was and was not in that training base (though no part of that training data is post-2021, apparently).  <a href=\"https://www.assemblyai.com/blog/how-chatgpt-actually-works/\" data-type=\"URL\" data-id=\"https://www.assemblyai.com/blog/how-chatgpt-actually-works/\">The program was then trained</a> by human trainers who both gave the model a prompt and an appropriate output to that prompt (supervised fine tuning) or else had the model generate several responses to a prompt and then humans sorted those responses best to worst (the reward model).  At each stage the model is refined (<a href=\"https://youtube.com/watch?v=R9OHn5ZF4Uo&amp;feature=shares\" data-type=\"URL\" data-id=\"https://youtube.com/watch?v=R9OHn5ZF4Uo&amp;feature=shares\">CGP Grey has a very accessible description of how this works</a>) to produce results more in keeping with what the human trainers expect or desire.  This last step is really important whenever anyone suggests that it would be trivial to train ChatGPT on a large new dataset; <strong>a lot of human intervention was in fact required to get these results.</strong></p>\n\n\n\n<p>It is <em>crucial</em> to note, however,<strong> what the data is that is being collected and refined in the training system here: it is purely information about how words appear in relation to each other</strong>.  That is, how often words occur together, how closely, in what relative positions and so on.  It is not, as we do, storing <em>definitions</em> or associations between those words and their real world referents, nor is it storing a perfect copy of the training material for future reference.  ChatGPT does not sit atop a great library it can peer through at will; it has read every book in the library <em>once</em> and distilled the statistical relationships between the words in that library <em>and then burned the library</em>.</p>\n\n\n\n<p>ChatGPT does not understand the <em>logical</em> correlations of these words or the actual things that the words (as symbols) signify (their ‘referents’).  It does not know that water makes you wet, only that ‘water’ and ‘wet’ tend to appear together and humans sometimes say ‘water makes you wet’ (in that order) for reasons it does not and cannot understand.</p>\n\n\n\n<p>In that sense, ChatGPT’s greatest limitation is that it <em>doesn’t</em> <em>know anything about anything</em>; it isn’t storing definitions of words or a sense of their meanings or connections to real world objects or facts to reference about them.  <strong>ChatGPT is, in fact, incapable of knowing anything at all</strong>.  The assumption so many people make is that when they ask ChatGPT a question, it ‘researches’ the answer the way we would, perhaps by checking Wikipedia for the relevant information.  But ChatGPT doesn’t have ‘information’ in this sense; it has no discrete facts.  To put it one way, ChatGPT does not and cannot know that “World War I started in 1914.”  What it <em>does</em> know is that “World War I” “1914” and “start” (and its synonyms) tend to appear together in its training material, so when you ask, “when did WWI start?” it can give that answer.  <strong>But it can also give absolutely nonsensical or blatantly wrong answers with <em>exactly</em> the same kind of confidence because the language model has no space for <em>knowledge</em> as we understand it</strong>; it merely has a model of the statistical relationships between how words appear in its training material.</p>\n\n\n\n<p>In artificial intelligence studies, this habit of manufacturing false information gets called an “<a href=\"https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence)\" data-type=\"URL\" data-id=\"https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence)\">artificial hallucination</a>,” but I’ll be frank I think this sort of terminology begs the question.<span id=\"easy-footnote-4-17368\"></span><span><a href=\"#easy-footnote-bottom-4-17368\" title=\"Since I am going to use this phrase a lot I should be clear on its meaning.  To &amp;#8216;beg the question&amp;#8217; is not to ask someone to ask you something, but rather to ask your interlocutor in a debate or discussion to concede as a first step the very thesis you wanted to prove.  If we were, say, debating the value of Jane Austin&amp;#8217;s writing and I lead by saying, &amp;#8220;well, you must first concede she writes extremely well!&amp;#8221; that would be question begging.  It&amp;#8217;s more common to see actual question begging occur as a definitional exercise; an attorney that defines the defendant at a trial as a &amp;#8216;criminal&amp;#8217; has begged the question, assuming the guilt of the person whose guilt has not yet judged in the proceeding where that is the primary concern.\"><sup>4</sup></a></span>   ChatGPT gets called an artificial intelligence by some boosters (the company that makes it has the somewhat unearned name of ‘OpenAI’) but it is not some sort of synthetic mind so much as it is an extremely sophisticated form of the software on your phone that tries to guess what you will type next.  And ChatGPT isn’t suffering some form of hallucination – which is a distortion of sense-perception.  Even if we were to say that it can sense-perceive at all (and this is <em>also</em> question-begging), its sense-perception has worked just fine: it has absorbed its training materials with perfect accuracy, after all; it merely lacks the capacity to understand or verify those materials.  ChatGPT isn’t a mind suffering a disorder but a program functioning perfectly as it returns an undesired output.  When ChatGPT invents a title and author of a book that does not exist because you asked it to cite something, the program has not failed: it has done exactly what was asked of it, putting words together in a statistically probable relationship based on your prompt.  <strong>But calling this a hallucination is already ascribing mind-like qualities to something that <em>is not a mind</em> or even particularly mind-like in its function.</strong></p>\n\n\n\n<p>Now I should note the counter-argument here is that by associating words together ChatGPT can ‘know’ things in some sense because it can link those associations.  But there are some major differences here.  First, human minds assess the reliability of those associations: how often when asked a question does an answer pop into your mind that you realize quickly cannot be right or you realize you don’t know the answer at all and must look it up?  Part of that process, of course, is that the mental associations we make are ‘checked’ against the real world realities they describe.  In fancy terms, words are merely <em>symbols</em> of actual real things (their ‘<a href=\"https://en.wikipedia.org/wiki/Referent\" data-type=\"URL\" data-id=\"https://en.wikipedia.org/wiki/Referent\">referents</a>‘ – the things to which they refer) and so the truth value of words may be checked against the actual status of their referents.  For most people, this connection is very strong.  Chances are, if I say ‘wool blanket’ your mind is going to not merely play word association but also conjure up some memories of <em>actual</em> wool blankets – their sight, touch or smell.  ChatGPT lacks this capability; <em>all</em> it has are the statistical relationship between words stripped entirely of their referents.  It will thus invent descriptions for scientific phenomenon that aren’t real, embellish descriptions of books that do not exist and if asked to cite things it will invent works to cite, <strong>because none of those things is any more or less real to ChatGPT than <em>actual real existing things</em></strong>.</p>\n\n\n\n<p>All it knows, <em>all it knows</em> are the statistical relationships of how words appear together, refined by the responses that its human trainers prefer.  Thus the statement that ChatGPT doesn’t know anything about anything or more correctly it cannot know anything about the topics it is asked to write about.</p>\n\n\n\n<p>All of that is important to understand what ChatGPT is doing when you tell it to, say, write an essay.  It is not considering the topic, looking up references, thinking up the best answer and then mobilizing evidence for that answer.  <strong>Instead it is taking a great big pile of words, picking out the words which are most likely to be related to the prompt and putting those words together in the order-relationships (but not necessarily the <em>logical</em> relationships) that they most often have, modified by the training process it has gone through to produce ‘better’ results</strong>.  As one technical writer, Ted Chiang, has put it,<strong> <a href=\"https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web\" data-type=\"URL\" data-id=\"https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web\">the result is merely a ‘very lossy’ (that is, not very faithful) reproduction of its training materials, rather than anything new or based on any actual understanding of the underlying objects or ideas</a>.</strong>  But, because it is a chatbot, its can dole those words out in tremendous quantity, with flawless spelling and grammar and to follow whatever formula (more or less) the prompt asks for.  But it doesn’t know what those words mean; indeed coming from the chatbot, in a sense they mean nothing.</p>\n\n\n\n<p>I stress this functionality at the beginning because I want readers to understand that many of the mental processes – analysis, verification, logical organization – that we take for granted from a thinking person are things ChatGPT does not do and <em>is entirely incapable of</em> in the same way that an electric can-opener cannot also double as a cell phone.  Those capabilities are both entirely outside of the structure of the current iteration of ChatGPT and also entirely outside of the processes that the training procedures which produced ChatGPT will train.  Incremental improvements in the can-opener will not turn it into a cell phone either; the cell phone is an entirely different sort of machine.  Thus the confidence among some that the ‘hallucination’ problem will be inevitably solved seems premature to me.  It may well be solved, but it may well not; doing so will probably require the creation of an entirely new sort of machine of a type never before created.  That eventuality cannot be taken for granted; it is not even something that we know is <em>possible</em> (though it may well be!).  It most certainly will not happen on its own.</p>\n\n\n\n<h2>The Heck Is an Essay?</h2>\n\n\n\n<p>So that is what ChatGPT does: in response to a prompt, it puts together an answer that is composed of words in its training material organized based on the statistical probability that those words appear together and the degree to which they are related to the prompt (processed through an extremely complex language model).  It thus assembles words from its big bag of words in a way that looks like the assemblages of words it has seen in its training and which its human trainers have ranked highly.  And if all you want ChatGPT to do is precisely that: somewhat randomly assemble a bunch of words loosely related to a topic in a form that <em>resembles</em> communication, it can do that for you.  I’m not sure <em>why</em> you want it to do that, but that is the one and only thing it can do.</p>\n\n\n\n<p>But can ChatGPT write an essay?</p>\n\n\n\n<p>It has been suggested that this endangers or even makes obsolete the essay or particularly the ‘college essay,’ and I think this misunderstands what the purpose of an essay is.  Now the definition of an essay is somewhat nebulous, especially when it comes to length; essays are shorter than books but longer than notes but these too are nebulously defined.  Still we can have a useful definition:</p>\n\n\n\n<p><strong>An essay is a piece of relatively short writing designed to express an <em>argument</em> – that is, it asserts a truth about something real outside of the essay itself – by communicating the idea of argument itself (the <em>thesis</em>) and assembling <em>evidence</em> chosen to prove that argument to a reader</strong>.  Communication is thus <em>part</em> of writing an essay, but not the only part or even necessarily the most important.  Indeed, the communication element may come in entirely different forms from the traditional essay.  Consider video essays or photo essays: both have radically changed the form of communication but they remain essays because the important part – the argument asserting a truth about something supported by assembled evidence – remains the same, even as the nature of the evidence and communication has changed.</p>\n\n\n\n<p>Writing an essay thus involves a number of steps, of which communication is merely the last.  Ideally, the essay writer has first observed their subject, then drawn some sort of analytical conclusion about that subject,<span id=\"easy-footnote-5-17368\"></span><span><a href=\"#easy-footnote-bottom-5-17368\" title=\"In our previous definition this conclusion is an <em>argument</em>, but we could easily expand our definition to also include <em>descriptive</em> essays (which aim not to make a new conclusion about something but merely assemble a collection of generally accepted facts).  There is still an analytical process here because the writer must determine what facts to trust, which are important enough to include and how they ought to be arranged, even though no <em>explicit</em> argument is being made.  Indeed, such a descriptive essay (like a Wikipedia article) makes an <em>implicit</em> argument based on what it is considered important enough to be included (e.g. on Wikipedia, what exactly is &amp;#8216;notable&amp;#8217;).\"><sup>5</sup></a></span> then organized their evidence in a way that expresses the logical connections between various pieces of evidence, before finally communicating that to a reader in a way that is clear and persuasive.</p>\n\n\n\n<p>ChatGPT is entirely incapable of the first two steps (though it may <em>appear</em> to do either of them) and incompetent at the third; it’s capabilities are entirely on the last step (and even there generally inferior to a well-trained human writer at present).</p>\n\n\n\n<p>When it comes to observing a subject, as noted ChatGPT is not capable of research so the best it can do, to borrow Ted Chiang’s phrasing again, is provide a ‘lossy’ replica of the research of others and only if that research has somehow found its way into ChatGPT’s training materials.  Even when the necessary <em>information</em> is contained within the works in ChatGPT’s training material, it can’t actually <em>understand</em> those things, it can only reproduce them, so if they do not <em>explicitly</em> draw the conclusion it needs in as many words, ChatGPT can’t do so either.  We can demonstrate this by asking ChatGPT an almost trivially easy research question, like, “What is the relationship between Edward Luttwak’s <em>Grand Strategy of the Roman Empire</em> and Benjamin Isaac’s <em>The Limits of Empire</em>?”  And so we did:</p>\n\n\n\n<figure><img data-lazy-fallback=\"1\" data-attachment-id=\"17419\" data-permalink=\"https://acoup.blog/2023/02/17/collections-on-chatgpt/limits-of-empire-2/\" data-orig-file=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/limits-of-empire-2.png?fit=737%2C715&amp;ssl=1\" data-orig-size=\"737,715\" data-comments-opened=\"1\" data-image-meta=\"{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}\" data-image-title=\"limits-of-empire-2\" data-image-description=\"\" data-image-caption=\"\" data-medium-file=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/limits-of-empire-2.png?fit=300%2C291&amp;ssl=1\" data-large-file=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/limits-of-empire-2.png?fit=737%2C715&amp;ssl=1\" decoding=\"async\" loading=\"lazy\" width=\"737\" height=\"715\" src=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/limits-of-empire-2.png?resize=737%2C715&amp;ssl=1\" alt=\"\" srcset=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/limits-of-empire-2.png?w=737&amp;ssl=1 737w, https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/limits-of-empire-2.png?resize=300%2C291&amp;ssl=1 300w\" sizes=\"(max-width: 737px) 100vw, 737px\" data-recalc-dims=\"1\" data-lazy-srcset=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/limits-of-empire-2.png?w=737&amp;ssl=1 737w, https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/limits-of-empire-2.png?resize=300%2C291&amp;ssl=1 300w\" data-lazy-src=\"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/limits-of-empire-2.png?resize=737%2C715&amp;is-pending-load=1#038;ssl=1\" data-old-srcset=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\"></figure>\n\n\n\n<p>If you know nothing about either book, this answer almost sounds useful (it isn’t).<span id=\"easy-footnote-6-17368\"></span><span><a href=\"#easy-footnote-bottom-6-17368\" title=\"the description of <em>The Limits of Empire</em> in particular is poor and mostly misses the book&amp;#8217;s core argument that there was no Roman &amp;#8216;grand strategy&amp;#8217; because the Romans were <em>incapable</em> of conceiving of strategy in that way.\"><sup>6</sup></a></span>  Now this is a <em>trivial</em> research task; simply typing ‘the limits of empire review’ into Google and then clicking on the very first non-paywalled result (<a href=\"https://bmcr.brynmawr.edu/1990/1990.01.12/\" data-type=\"URL\" data-id=\"https://bmcr.brynmawr.edu/1990/1990.01.12/\">this review of the book by David Potter from 1990</a>) and reading <em><strong>the first paragraph</strong></em> makes almost immediately clear the correct answer is that Isaac’s book is an intentional and explicit <em>rebuttal</em> of Luttwak’s book, or as Potter puts it, “Ben Isaac’s <em>The Limits of Empire</em> offers a new and formidable challenge to Luttwack.”  A human being who <em>understands the words and what they mean</em> could immediately answer the question, but ChatGPT which doesn’t, cannot: it can only BS around the answer by describing both books and then lamely saying they “intersect in some ways.”  The <em>information</em> ChatGPT needed was clearly in its training materials (or it wouldn’t have a description of either book to make a lossy copy of),<span id=\"easy-footnote-7-17368\"></span><span><a href=\"#easy-footnote-bottom-7-17368\" title=\"I&amp;#8217;m pretty sure from the other responses I have seen (but cannot be 100% confident) that the BMCR, which is open and available to all, was included in ChatGPT&amp;#8217;s corpus.\"><sup>7</sup></a></span> but it lacks the capacity to understand that information <em>as information</em> (rather than as a statistically correlated sequence of words).<span id=\"easy-footnote-8-17368\"></span><span><a href=\"#easy-footnote-bottom-8-17368\" title=\"While we&amp;#8217;re here I should note that I think <em>The Limits of Empire</em> is hardly the last word on this question.  On why, you want to read E. Wheeler, &amp;#8220;Methodological Limits and the Mirage of Roman Strategy&amp;#8221; <em>JMH</em> 57.1 and 57.2 (1993); Wheeler systematically destroys nearly all of Isaac&amp;#8217;s arguments.  I also asked ChatGPT to tell me what Wheeler&amp;#8217;s critiques were, but since Wheeler isn&amp;#8217;t in its training corpus, it couldn&amp;#8217;t tell me.  When I asked for a list of Isaac&amp;#8217;s most prominent critics, it didn&amp;#8217;t list Wheeler because, I suppose, no one in its corpus discussed his article, despite it being (to the best of my knowledge) generally understood that Wheeler&amp;#8217;s critique has been the most influential, as for instance noted by J.E. Lendon<a href=&quot;https://www.jstor.org/stable/3298451&quot; data-type=&quot;URL&quot; data-id=&quot;https://www.jstor.org/stable/3298451&quot;> in this review of the topic</a> for <em>Classical Journal</em> back in 2002.  ChatGPT can&amp;#8217;t tell you any of that because it can only tell you things other people have already written in its training corpus.  Instead, it listed Adrian Goldsworthy, Jeremy Armstrong, John W.I. Lee and Christopher S. Mackay because they all wrote reviews of the book; none of these scholars (some of whom are <em>great </em>scholars) are particularly involved in the Roman strategy debate, so all of these answers are wrong.  The latest in this debate is James Lacey&amp;#8217;s <em>Rome: Strategy of Empire</em> (2022), which is a solid reiteration of the Luttwakian side of the debate (valuable if only because Luttwak himself is a poor interlocutor in all of this) but seems unlikely to end it.  It is possible I am working on trying to say something useful on this topic at some point in the future.\"><sup>8</sup></a></span>  Consequently it cannot draw the right conclusion and so talks around the question in a convincing, but erronous way.</p>\n\n\n\n<p>Note that no analysis was required for the above question!  It was a <em>pure</em> reading comprehension question that could be solved by merely recognizing that something in the training set already <em>said the answer</em> and <em>copying it</em>, but ChatGPT wasn’t even capable of that because while it has a big bag of words related to both books, it lacks the capability to understand and grab the <em>relevant</em> words.  This is an example of the not at all uncommon situation where Google is a far better research tool than ChatGPT, because Google can rely on your reading comprehension to understand the places it points you to which may have the answer you seek.</p>\n\n\n\n<p>So research and observation are out; what about analysis?  Well, if you have been following along you’ll realize that ChatGPT is incapable of doing that too.  What it can do is find something that <em>looks</em> like analysis (though it may not be analysis or it may be quite bad analysis) and then reproduce it (in a lossy form) for you.  But the point of analysis is to be able to provide novel insight, that is to either suggest a conclusion hitherto unconsidered for a given problem or equally importantly to come up with a conclusion for a problem that is only being encountered for the very first time.  ChatGPT, limited entirely to remixing <em>existing</em> writings, cannot do either.</p>\n\n\n\n<p>As a system to produce essays, this makes ChatGPT not very useful at all.  <strong>Generally when people want an essay, they don’t actually want <em>the essay</em>; the essay they are reading is instead a <em>container</em> for what they actually want which is the analysis and evidence.  An essay in this sense is a word-box that we put thoughts in so that we can give those thoughts to someone else</strong>.  But ChatGPT cannot <em>have</em> original thoughts, it can only remix writing that is already in its training material; it can only poorly copy writing someone else has already done <em>better</em> somewhere.<span id=\"easy-footnote-9-17368\"></span><span><a href=\"#easy-footnote-bottom-9-17368\" title=\"It also isn&amp;#8217;t very good at discoverability.  It can&amp;#8217;t tell you <em>who</em> or <em>where</em> that better idea is from if you find yourself wanting more explanation or context.  Once again, as a research tool, Google is pretty clearly superior.\"><sup>9</sup></a></span>  <strong>ChatGPT in this sense is like a friendly, if somewhat daft neighbor who noticed one day that every so often you get a box from Amazon and that you seem quite happy to get it and so decides to do you a favor by regularly ordering empty Amazon boxes to your house</strong>.  The poor fellow does not know and cannot understand that it was the <em>thing in the box</em> – in this case, the <em>thoughts</em> (original observations, analysis, evidence) in the essay – that you actually wanted.  ChatGPT doesn’t have any thoughts to give you (though it can somewhat garble someone else’s thoughts), but it sure can order you up a bunch of very OK boxes.</p>\n\n\n\n<p><strong>In a very real sense then, ChatGPT cannot write an essay. </strong> It can <em>imitate</em> an essay, but because it is incapable of the tasks which give an essay its actual use value (original thought and analysis), it can only produce inferior copies of other writing.  That quite a few people, including some journalists, have supposed that ChatGPT <em>can</em> write an essay suggests to me that they have an impoverished idea of what an essay <em>is</em>, viewing it only as ‘content’ rather than as a box that thoughts go into for delivery, or haven’t really scrutinized what ChatGPT outputs closely enough.</p>\n\n\n\n<p><strong>Now there are, in that previous analogy, box-sellers online: outlets who really do not care about the thoughts in the essay but merely want units of text to throw up to generate clicks</strong>.  Few reputable publications function this way – that’s why they have editors whose job is to try to figure out if your essay has a thought in it actually worth sharing and then if so to help guide you to the most effective presentation of that thought (that’s the editing process).  But there are a lot of content mills online which are really looking to just supply large amounts of vaguely relevant text at the lowest possible cost hoping to harvest views from gullible search engines.  <strong>For those content mills, ChatGPT potentially has a lot of value but those content mills provide almost no value to us, the consumer.  Far from it, they are one of the major reasons why folks <a href=\"https://freakonomics.com/podcast/is-google-getting-worse/\" data-type=\"URL\" data-id=\"https://freakonomics.com/podcast/is-google-getting-worse/\">report declining search engine quality</a>, as they crowd out actually useful content</strong>.<span id=\"easy-footnote-10-17368\"></span><span><a href=\"#easy-footnote-bottom-10-17368\" title=\"This is painfully obvious when it comes to trying to get information about video games.  In ye days of yore, Google would swiftly send you to the GameFaqs page (remember those!?) or the helpful fan Wiki, but more recently it becomes necessary to slog through a page or two of overly long (because Google prefers pages with at least a certain amount of text) answers to very simple questions in order to find what you are looking for (which usually ends up being a helpful response to someone&amp;#8217;s question on Reddit or a Steam guide or, because I still like to live in 2004, an actual GameFaqs page).\"><sup>10</sup></a></span></p>\n\n\n\n<p>That said I don’t want to rule out ChatGPT’s ability to produce functional formulaic documents entirely.  I’ve heard it suggested that it could massively reduce the cost of producing formula-driven legal and corporate documents and perhaps it can.  It’s also been suggested it could be trained to write code, though my understanding is that as of now, most of the code it produces looks good but does not work well.  I don’t write those sorts of things, though, so I can’t speak to the question.  I would be concerned though, because ChatGPT can make some very bad mistakes and has no way of catching those mistakes, so very high stakes legal or corporate documents seems like a risky use of ChatGPT.  ChatGPT can’t write a good essay, but a bad essay only wastes a few minutes of your time; a bad contract can cost a company millions and a single bad line of code can crash an entire program (or just cause it to fail to compile and in either case waste hours and hours of bug-hunting to determine what went wrong).</p>\n\n\n\n<p><strong>But the core work of the essay?  This ChatGPT cannot do</strong>.  And importantly it is not some capacity which merely requires iterative improvements on the product.  <strong>While ChatGPT can <em>fake</em> an original essay, the jump from faking that essay to writing an actually original thought certainly looks like it would require a completely different program, one capable of observing the real world, analyzing facts about it and then reaching conclusions</strong>.</p>\n\n\n\n<h2>The Heck is the Teaching Essay For?</h2>\n\n\n\n<p>That leaves the role of ChatGPT in the classroom.  And here some of the previous objections do indeed break down.  A classroom essay, after all, isn’t meant to be original; the instructor is often assigning an entire class to write essays on the same topic, producing a kaleidoscope of quite similar essays using similar sources.  Moreover classroom essays are far more likely to be about the kind of ‘Wikipedia-famous’ people and works which have enough of a presence in ChatGPT’s training materials for the program to be able to cobble together a workable response (by quietly taking a bunch of other such essays, putting them into the blender and handing out the result, a process which in the absence of citation we probably ought to understand as plagiarism).  In short, many students are often asked to write an essay that many hundreds of students have already written before them.  And so there were quite a few pronouncements that ChatGPT <a href=\"https://www.theatlantic.com/technology/archive/2022/12/chatgpt-ai-writing-college-student-essays/672371/\" data-type=\"URL\" data-id=\"https://www.theatlantic.com/technology/archive/2022/12/chatgpt-ai-writing-college-student-essays/672371/\">had ‘killed’ the college essay</a>. And indeed, in my own experience in the Twitter discourse around the system, one frequent line of argument was that ChatGPT was <em>going</em> to disrupt my classroom, so shouldn’t I just go ahead and get on board with the new technology?</p>\n\n\n\n<p><strong>This both misunderstands what the college essay is <em>for</em> as well as the role of disruption in the classroom</strong>.  Let’s start with the first question: what is the teaching essay (at any level of schooling) <em>for</em>?  It’s an important question and one that arises out of a consistent problem in how we teach students, which is that we rarely <em>explain our pedagogy</em> (our ‘teaching strategy’) to the students.  That tends to leave many assignments feeling arbitrary even when teachers have in fact put a great deal of thought into why they are assigning what they are and what skills they are supposed to train.  So let’s talk about why we assign essays, what those assignments are supposed to accomplish and why ChatGPT has little to offer in that realm.</p>\n\n\n\n<p><strong>In practice there are three things that I am aiming for an essay assignment to accomplish in a classroom.  The first and probably least important is to get students to think about a specific historical topic or idea, since they (in theory) must do this in order to write about it</strong>.  In my own planning I sometimes refer to these assignments as ‘pedagogical’ essays (not a perfect term) where the assignment – typically a ‘potted’ essay (short essay with pre-chosen sources handed to students, opposite of a ‘research’ essay) – is meant to have students ponder a specific question for the value of that question.  One example is an essay prompt I sometimes use in my ancient history survey asking students, “On what basis do we consider Alexander to be ‘great’?  Is this a sound basis to apply this title?”  Obviously I want students here to both understand something about Alexander but also to <em>think about the idea of greatness</em> and what that means; does successfully killing a lot of people and then failing to administer what remains qualify as greatness and if so what does that say about what we value?  Writing the essay forces them to ponder the question.  That value is obviously lost if they just let ChatGPT copy some other essay for them.</p>\n\n\n\n<p>That said this first sort of goal is often the least important.  While of course I think my course material matters, the fact is few students will need to be able to recall from memory the details of Alexander the Great at some point in their life.  They’ll be able to look him up and hopefully with the broad knowledge framework I’ve given them and the research and analysis skills, be able to reach for these same conclusions.  Which brings us to:</p>\n\n\n\n<p><strong>The second goal and middle in importance is training the student in how to write essays</strong>.  I’ve made this element of my approach more explicit in recent years, making the assignments more closely resemble the real world writing forms they train for.  Thus the classics 3-5 page paper becomes the c. 1000 word think-piece (though I do require a bit more citation than a print publication would in a ‘show your work’ sort of way), the sort paper becomes a 700-800 word op-ed, etc.  The idea here is to signal to students more clearly that they are training to write real things that exist in the world outside of the classroom.  That said, while a lot of students can imagine situations in which they might want to write an op-ed or a think piece or a short speech, many of them won’t ever write another formal essay after leaving college.</p>\n\n\n\n<p><strong>Thus the last and most important thing I am trying to train is not the form of the essay nor its content, but the basic skills of having a thought and putting it in a box that we outlined earlier</strong>.  Even if your job or hobbies do not involve formal writing, chances are (especially if your job requires a college degree) you are still expected to observe something real, make conclusions about it and then present those conclusions to someone else (boss, subordinates, co-workers, customers, etc.) in a clear way, supported by convincing evidence if challenged.  <strong>What we are practicing then is how to have good thoughts, put them in good boxes and then effectively hand that box to someone else</strong>.  That can be done in a formal written form (the essay), in informal writing (emails, memos, notes, Slack conversations), or verbally (speeches, but also arguments, debates and discussions).  The skills of having the idea, supporting it with evidence, organizing that evidence effectively to be understood and then communicating that effectively are transferable and the most important skills that are being practiced when a student writes an essay.</p>\n\n\n\n<p>Crucially – and somehow this point seems to be <em>missed</em> by many of ChatGPT’s boosters I encountered on social media – <strong>at no point in this process do I actually want the essays</strong>.  Yes, they have to be turned in to me and graded and commented because that feedback in turn is meant to both motivate students to improve but also to signal where they need to improve.<span id=\"easy-footnote-11-17368\"></span><span><a href=\"#easy-footnote-bottom-11-17368\" title=\"And thus, dear students, if you are not <em>reading the comments</em> you are not getting what you paid tens of thousands of dollars for when you paid tuition.  Read the comments.  You are in college to <em>learn things</em> not prove what you already know or how smart you already are.  We know you are smart, that&amp;#8217;s why you got admitted to college; the question now is about drive and willingness to <em>learn</em>.\"><sup>11</sup></a></span>  <strong>But I did not assign the project because I wanted the essays</strong>.  To indulge in an analogy, I am not asking my students to forge some nails because I want a whole bunch of nails – the nails they forge on early attempts will be quite bad <em>anyway</em>.  I am asking them to forge nails so that they <em>learn how to forge nails</em> (which is why I inspect the nails and explain their defects each time) and by extension also learn how to forge <em>other things</em> that are akin to nails.  <strong>I want students to learn how to analyze, organize ideas and communicate those ideas</strong>.</p>\n\n\n\n<p>What one can immediately see is that a student who simply uses ChatGPT to write their essay for them has simply cheated themselves out of the opportunity to learn (and also wasted my time in providing comments and grades).  As we’ve seen above, ChatGPT cannot effectively replace the actual core tasks we are training for, so this is not a case where the existence of spinning jennies renders most training at hand spinning obsolete.  And it certainly doesn’t fulfill the purpose of the assignment.</p>\n\n\n\n<p><strong>To which some boosters of the technology respond that what I should <em>really</em> be <a href=\"https://twitter.com/BradDFelix/status/1624094644043755541\" data-type=\"URL\" data-id=\"https://twitter.com/BradDFelix/status/1624094644043755541\">doing </a>is <a href=\"https://twitter.com/eranshir/status/1624340970492899332\" data-type=\"URL\" data-id=\"https://twitter.com/eranshir/status/1624340970492899332\">training </a><a href=\"https://twitter.com/shaun_harrison/status/1624006980183400449\" data-type=\"URL\" data-id=\"https://twitter.com/shaun_harrison/status/1624006980183400449\">students </a>on how to most effectively use ChatGPT as a tool</strong>.  But it is not clear to me that ChatGPT functions well as a tool for any part of this process.  One suggestion is to write an outline and then feed that into ChatGPT to generate a paper, but that fails to train the essential communication component of the assignment and in any case, ChatGPT is actually pretty bad at the nuts of and bolts of writing paragraphs.  Its tendency in particular to invent facts or invent non-existent sources to cite makes it an enormous liability here; it is a <em>very bad</em> research tool because it is unreliable.  Alternately the suggestion is that students could use ChatGPT to produce an essay they edit to fit or an outline they fill in; both problems run into the issue that the student is now trying to offload the most important part of the task for them to <em>learn</em>: the actual thinking and analysis.  <strong>And the crucial thing to note is that the skill that is not being trained in both cases is a skill that current large language models like ChatGPT cannot perform or perform very poorly</strong>.<span id=\"easy-footnote-12-17368\"></span><span><a href=\"#easy-footnote-bottom-12-17368\" title=\"There is thus a meaningful difference between this and the &amp;#8216;why did I need to learn math without a calculator&amp;#8217; example that gets reused here, in that a calculator can at least do basic math for you, but ChatGPT cannot think for you.  That said, I had quite a difficult time learning that sort of thing as a kid, but (with some extra effort from my parents) I did learn it and I&amp;#8217;ve found it tremendously useful in life.  Being able to calculate a tip in my head or compare the per-unit price of, say, 3-for-whatever sale on 12pack sodas vs. a 24pack of the same brand without having to plug it into my phone is really handy.  I thus find myself somewhat confused by folks I run into who are bitter they were forced to learn mathematics first without a calculator.\"><sup>12</sup></a></span></p>\n\n\n\n<p>I suspect this argument looks plausible to people because they are not thinking in terms of being trained to think about novel problems, but in terms of the assignment itself; they are thinking about the most efficient way to produce ‘one unit of essay.’   <strong>But what we’re actually doing is practicing a non-novel problem (by <em>treating</em> it as a novel problem for the purpose of the assignment), so that when we run into novel problems, we’ll be able to apply the same skills</strong>.  Consequently they imagine that ChatGPT, trained as it is on what seems to be an awful lot of mediocre student essays (it mimics the form of a bad student essay with <em>remarkable</em> accuracy), can perform the actual final task in question, but it cannot.</p>\n\n\n\n<h2>Conclusion: Preparing to Be ‘Disrupted.’</h2>\n\n\n\n<p>The reply that all of this gets has generally been some combination of how this technology is ‘the future,’ that it will make essay writing obsolete so I should focus on training for it,<span id=\"easy-footnote-13-17368\"></span><span><a href=\"#easy-footnote-bottom-13-17368\" title=\"A point we have already addressed.\"><sup>13</sup></a></span>, and most of all that the technology will soon be so good, if it is not already, that<a href=\"https://twitter.com/theobserver42/status/1624156895782273025\" data-type=\"URL\" data-id=\"https://twitter.com/theobserver42/status/1624156895782273025\"> any competent student will be able to use it to perfectly fake good papers</a>.  <strong>Thus, I am told, my classroom is doomed to be ‘disrupted’ by this technology so I should preemptively surrender and get on board.</strong></p>\n\n\n\n<p>And no.  No, I don’t think so.</p>\n\n\n\n<p>I do think there are classrooms that will be disrupted by ChatGPT, but those are classrooms where something is already broken.  <strong>Certainly for a history classroom, if ChatGPT can churn out a decent essay for your assignment, chances are the assignment is poorly designed</strong>.  ChatGPT after all cannot analyze a primary source (unless it is already been analyzed many times in its training materials), it struggles to cite scholarship (more often inventing fake sources) and it generally avoids specific evidence.  Well-designed assignments which demand proper citation, <em>specific</em> evidence to support claims (rather than general statements) and a clear thesis are going to be beyond ChatGPT and indeed require so much editing to produce from a ChatGPT framework as to make it hardly worth the effort to cheat.  <strong>If your essay prompt can be successfully answered using nothing but vague ChatGPT generated platitudes, it is a bad prompt</strong>.<span id=\"easy-footnote-14-17368\"></span><span><a href=\"#easy-footnote-bottom-14-17368\" title=\"The one exception here are online courses using &amp;#8216;closed book&amp;#8217; online essay tests.  That is an exam model which will be rendered difficult by this technology.  I think clever prompt writing (demand the students do things &amp;#8211;  be specific in evidence or reference specific works &amp;#8211; that ChatGPT is bad at) or use alternative assignments (a capstone project or essay instead).  For in-person classes, the entire problem is obviated by the written in-class essay.\"><sup>14</sup></a></span></p>\n\n\n\n<p>Meanwhile, ChatGPT responses seem to be actually pretty easy to spot once you know how to look for the limitations built into the system.  There are already programs designed to detect if a piece of writing is machine-written; they’re not fully reliable yet but I suspect they will become more reliable over time mostly because it is in the interests of both AI-developers (who do not want their models trained on non-human produced writing) and search engines (who want to be able to exclude from search results the veritable river of machine-produced content-mill garbage we all know is coming) to develop that capability.  But because of the ways ChatGPT is limited, a human grader should also be able to flag ChatGPT generated responses very quickly too.</p>\n\n\n\n<p>It should be trivially easy, for instance, for a grader to confirm if the sources a paper cites exist.<span id=\"easy-footnote-15-17368\"></span><span><a href=\"#easy-footnote-bottom-15-17368\" title=\"And if they <em>don&amp;#8217;t</em>, that&amp;#8217;s academic dishonestly regardless of who wrote the paper.\"><sup>15</sup></a></span>  A paper with a bunch of convincing sounding but entirely invented sources is probably machine-written because humans don’t tend to make that mistake.  If instead, as is its wont, the paper refers merely vaguely to works written by a given author or on a given topic, insist the student produce those works (and <em>require citation on all papers</em>) – this will be very hard for the student with the ChatGPT paper as those works will not, in fact, exist.<span id=\"easy-footnote-16-17368\"></span><span><a href=\"#easy-footnote-bottom-16-17368\" title=\"And a student that cannot or will not cite their sources has plagiarized, regardless of who wrote their paper.  ChatGPT is such a mess of academic dishonesty that it isn&amp;#8217;t even necessary to prove its products were machine-written because the machine <em>also</em> does the sort of things which can get you kicked out of college.\"><sup>16</sup></a></span>  ChatGPT also has a habit of mistaking non-famous people for famous people with similar names; again for a grader familiar with the material this should be quite obvious.</p>\n\n\n\n<p>And then of course there are the errors.  ChatGPT makes a lot of factual mistakes, especially as it gets into more technical questions where the amount of material for it to be trained on is less.  While the text it produces often <em>looks</em> authoritative to someone with minimal knowledge in that field, in theory the person grading the paper should have enough grounding to spot some of the obvious howlers that are bound to sneak in over the course of a longer research paper.<span id=\"easy-footnote-17-17368\"></span><span><a href=\"#easy-footnote-bottom-17-17368\" title=\"And if the student has gone back and done the research to be able to correct those errors and rewrite those sentences in advance&amp;#8230;at this point why not just write the paper honestly and not risk being thrown out of college?\"><sup>17</sup></a></span>  By way of example, I asked ChatGPT to write  on, “the causes of Roman military success in the third and second centuries BCE.”  Hardly a niche topic.<span id=\"easy-footnote-18-17368\"></span><span><a href=\"#easy-footnote-bottom-18-17368\" title=\"In the event I asked for 8,000 words because I wanted to see how it would handle organizing a larger piece of writing.  Now in the free version it can&amp;#8217;t write that many words before it runs out of &amp;#8216;tokens,&amp;#8217; but I wanted to see how the introduction would set up the organization for the bits it wouldn&amp;#8217;t get to.  In practice it set up an essay in three or four chunks the first of which was 224 words; ChatGPT doesn&amp;#8217;t seem to be able to even set up a larger and more complex piece of writing.  It also doesn&amp;#8217;t plan for a number of words limited by how many it can get to before running out of tokens either, in case anyone thinks that&amp;#8217;s what it was doing: to get to the end of the essay with all of the components it laid out in the introduction I had to jog it twice.\"><sup>18</sup></a></span>   The whole thing was sufficiently full of problems and errors that I’m just going to include an annotated word document pointing them all out here:</p>\n\n\n\n\n\n\n\n<p>Needless to say, this would not be a passing (C or higher) paper in my class.  Exact counting here will vary but I identified 38 factual claims, of which 7 were correct, 7 were badly distorted and 24 were simply wrong.  A trainwreck this bad would absolutely have me meeting with a student and raising questions which – if the paper was machine written – might be very hard for the student to answer.  Indeed, a research paper with just three or four of these errors would probably prompt a meeting with a student to talk about their research methods.  This is certainly then also an error rate which is going to draw my attention and now cause me to ask questions about who exactly wrote the essay and how.<span id=\"easy-footnote-19-17368\"></span><span><a href=\"#easy-footnote-bottom-19-17368\" title=\"Of course if the student has just tried honestly and failed, they&amp;#8217;ll be able to document that process quite easily, with the works they read and where each wrong fact came from, whereas the student who has cheated using ChatGPT will be incapable of doing so.\"><sup>19</sup></a></span></p>\n\n\n\n<p>And that’s the thing: in a free market, a competitor cannot simply exclude a disruptive new technology.  But in a <em>classroom</em>, we can <em>absolutely</em> do this thing.  I am one of those professors who doesn’t allow laptops for note-taking (unless it is a disability accommodation, of course) because there’s <a href=\"https://blueprintlabs.mit.edu/research/the-impact-of-computer-usage-on-academic-performance-evidence-from-a-randomized-trial-at-the-united-states-military-academy/\" data-type=\"URL\" data-id=\"https://blueprintlabs.mit.edu/research/the-impact-of-computer-usage-on-academic-performance-evidence-from-a-randomized-trial-at-the-united-states-military-academy/\">quite a bit</a> <a href=\"https://journals.sagepub.com/doi/10.1177/0956797614524581\" data-type=\"URL\" data-id=\"https://journals.sagepub.com/doi/10.1177/0956797614524581\">of evidence</a> that laptops as note-taking devices lower student performance (quite apart from their potential to distract) and my goal is to maximize learning.  This isn’t me being a luddite; I would ban, say, classroom firecrackers or a live jazz band for the same reason and if laptops <em>improved</em> learning outcomes somehow (again, the research suggests they don’t), I’d immediately permit them.  <strong>Given that detecting machine-writing isn’t particularly hard and that designing assignments that focus on the skills humans can learn that the machines cannot (and struggle to fake) is good pedagogical practice anyway, excluding the technology from my classroom is not only <em>possible</em> it is indeed <em>necessary</em></strong>.</p>\n\n\n\n<p>Now will this disrupt some classrooms?  Yes.  Overworked or indifferent graders will probably be fooled by these papers or more correctly they will not care who wrote the paper because those instructors or graders are either not very much invested in learning outcomes or not given the time and resources <em>to invest</em> however much they might wish to.  I think schools are going to need to think particularly about the workload on adjuncts and TAs who are sometimes asked to grade through absurdly high amounts of papers in relatively little time and thus will simply lack the time read carefully enough.  Of course given how much students are <em>paying</em> for this, one would assume that resources could be made available to allow for the bare minimum of scrutiny these assignments deserve.  Schools may also need to rethink the tradeoffs of hiring indifferent teachers ‘for their research’ or for the prestige of their PhD institutions because the gap between good, dedicated teachers and bad, indifferent ones is going to grow wider as a result of this technology.</p>\n\n\n\n<p>Likewise, poorly designed assignments will be easier for students to cheat on, but that simply calls on all of us to be more careful and intentional with our assignment design (though in practice in my experience most professors, at least in history and classics, generally are).  I will confess every time I see a news story about how ChatGPT supposedly passed this or that exam, I find myself more than a little baffled and quite concerned about the level of work being expected in those programs.  <a href=\"https://www.cnn.com/2023/01/26/tech/chatgpt-passes-exams/index.html\" data-type=\"URL\" data-id=\"https://www.cnn.com/2023/01/26/tech/chatgpt-passes-exams/index.html\">If ChatGPT can pass business school</a>, that might say something rather concerning about business school (or at least the bar they set for passing).</p>\n\n\n\n<p>The final argument I hear is that while ChatGPT or large language models like it may not make my job obsolete <em>now</em>, they will <em>inevitably</em> do so in the future, that these programs are inevitably going to improve to the point where all of the limitations I’ve outlined will be surpassed.  And I’ll admit some of that is <em>possible</em> but I do not think it is by any means <em>certain</em>.  Of the processes we’ve laid out here, observing, analyzing those observations, arranging evidence to support conclusions and then communicating all of that, ChatGPT only does (or pretends to do) the last task.  As I noted above, an <em>entirely new machine</em> would be necessary for these other processes and it is not certain that such a machine is possible within the limits of the computing power now available to us.  I rather <em>suspect</em> it is, but it doesn’t seem certain that it is.</p>\n\n\n\n<p>More broadly, as far as I can tell it seems that a lot of AI research (I actually dislike a lot of these terms which seem to me to imply that what we’ve achieved is a lot closer to a synthetic mind than it really is, at least for now) has proceeded on a ‘fake it till you make it’ model.  <strong>It makes sense as a strategy: want to produce a mind, but we don’t <em>really</em> know how a mind works at full complexity, so we’ve chosen instead to try to create machines which can convincingly <em>fake</em> being a mind in the hopes that a maximally convincing fake will turn out to <em>be a mind</em> of some sort</strong>.  I have no trouble imagining that strategy <em>could</em> work, but what I think AI-boosters need to consider is that it also may not.  It may in fact turn out that the sort of machine learning we are doing is a dead end.</p>\n\n\n\n<p>It wouldn’t be the first time!  <a href=\"https://en.wikipedia.org/wiki/Alchemy\" data-type=\"URL\" data-id=\"https://en.wikipedia.org/wiki/Alchemy\">Early alchemists</a> spent a lot of time trying to transmute lead into gold; they ended up pioneering a lot of chemistry, exploring chemical reactions to try to achieve that result.  Important things were learned, but you know what no amount of alchemical proto-chemistry was ever going to do?  Turn lead into gold.  As a means of <em>making gold</em> those experiments were dead ends; if you want to turn lead into gold you have to figure out some way of <a href=\"https://en.wikipedia.org/wiki/Nuclear_transmutation\" data-type=\"URL\" data-id=\"https://en.wikipedia.org/wiki/Nuclear_transmutation\">ripping three protons off of a lead atom</a> which purely chemical reactions cannot do.  The alchemist who devised chemical reactions aiming to produce progressively more convincing fakes of gold until he at last managed the perfect fake that would be the real thing was bound to fail because that final step turns out to be impossible.  The problem was that the alchemist had to experiment without knowing what made some things (<a href=\"https://en.wikipedia.org/wiki/Chemical_compound\" data-type=\"URL\" data-id=\"https://en.wikipedia.org/wiki/Chemical_compound\">compounds</a>) different from other things (<a href=\"https://en.wikipedia.org/wiki/Chemical_element\" data-type=\"URL\" data-id=\"https://en.wikipedia.org/wiki/Chemical_element\">elements</a>) and so couldn’t know that while compounds could be altered in chemical reactions, elements could not.</p>\n\n\n\n<p>In short, just as the alchemist labored without really knowing what gold <em>was</em> or how it <em>worked</em>, but was only able to observe its outward qualities, so too our AI engineers are forced to work without really knowing what a mind <em>is</em> or how it <em>works</em>.  This present research may turn out to be the way that we end up learning what a mind really is and how it really works, or it may be a dead end.  We may never turn ChatGPT into gold.  It may be impossible to do so.  Hopefully even if that is the case, we’ll have developed some useful tools along the way, just like those alchemists pioneered much of chemistry in the pursuit of things chemistry was incapable of doing.</p>\n\n\n\n<p><strong>In the meantime, I am asking our tech pioneers to please be more alive to the consequences of the machines you create</strong>.  Just because something <em>can</em> be done doesn’t mean it <em>should</em> be done.  We <em>could</em> decide to empirically test if 2,000 nuclear detonations will actually produce a nuclear winter,<span id=\"easy-footnote-20-17368\"></span><span><a href=\"#easy-footnote-bottom-20-17368\" title=\"a hotly debated topic, actually!\"><sup>20</sup></a></span> <em>but we shouldn’t</em>.  Some inventions – say, <a href=\"https://acoup.blog/2020/03/20/collections-why-dont-we-use-chemical-weapons-anymore/\" data-type=\"URL\" data-id=\"https://acoup.blog/2020/03/20/collections-why-dont-we-use-chemical-weapons-anymore/\">sarin gas</a> – <em>shouldn’t be used</em>.  <strong>Discovering what we <em>can</em> do is always laudable; <em>doing it</em> is not always so</strong>.  And yet again and again these new machines are created and deployed with vanishingly little concern about what their impacts might be.  Will ChatGPT improve society, <a href=\"https://twitter.com/Roelkonijn/status/1626292591980433408\" data-type=\"URL\" data-id=\"https://twitter.com/Roelkonijn/status/1626292591980433408\">or just clutter the internet with more junk that will take real humans more time to sort through</a>?  Is this a tool for learning or just a tool to disrupt the market in cheating?</p>\n\n\n\n<figure><div>\n<blockquote data-width=\"550\" data-dnt=\"true\"><div lang=\"en\" dir=\"ltr\"><p>Sci-Fi Author: In my book I invented the Torment Nexus as a cautionary tale</p><p>Tech Company: At long last, we have created the Torment Nexus from classic sci-fi novel Don't Create The Torment Nexus</p></div>— Alex Blechman (@AlexBlechman) <a href=\"https://twitter.com/AlexBlechman/status/1457842724128833538?ref_src=twsrc%5Etfw\">November 8, 2021</a></blockquote>\n</div></figure>\n\n\n\n<p>Too often the response to these questions is, “well if it can be done, someone will do it, so I might as well do it first (and become famous or rich),” which is both an immorally self-serving justification but also a suicidal rule of conduct to adopt for a species which has the capacity to fatally irradiate its only biosphere.  <strong>The amount of power our species has to create and destroy <em>long ago</em> exceeded the point where we could survive on that basis</strong>.</p>\n\n\n\n<p>And that problem – that we need to think hard about the ethics of our inventions before we let them escape our labs – that is a thinking problem and thus one in which ChatGPT is entirely powerless to help us.</p>\n<ol><li><span id=\"easy-footnote-bottom-1-17368\"></span>And I should be clear right here ahead of time that nothing that follows is particular to any paper(s) I may have received.  Do not ask “what happened to the student(s)?” or “how did you know?” or “what class was this in?” because I can’t tell you.  <a href=\"https://en.wikipedia.org/wiki/Family_Educational_Rights_and_Privacy_Act\" data-type=\"URL\" data-id=\"https://en.wikipedia.org/wiki/Family_Educational_Rights_and_Privacy_Act\">Student privacy laws</a> in the United States protect that sort of information and it is a good thing they do.  The observations that follow are not based on student papers, instead they are based on a number of responses I had ChatGPT produce for me to get a sense of what such an effort at cheating might look like and how I might detect it.<a href=\"#easy-footnote-1-17368\"></a></li><li><span id=\"easy-footnote-bottom-2-17368\"></span>After all I may not have experience as a creator of large language models, but I am a fully qualified <em>end user</em>. I cannot and indeed will not critique how ChatGPT was created, but I am perfectly qualified to say, “this product as delivered does not meet any of my needs.”<a href=\"#easy-footnote-2-17368\"></a></li><li><span id=\"easy-footnote-bottom-3-17368\"></span>Not that pets don’t have emotions or some kind of understanding, but we anthropomorphize our pets <em>a lot</em> as a way of relating to them.<a href=\"#easy-footnote-3-17368\"></a></li><li><span id=\"easy-footnote-bottom-4-17368\"></span>Since I am going to use this phrase a lot I should be clear on its meaning.  To ‘beg the question’ is not to ask someone to ask you something, but rather to ask your interlocutor in a debate or discussion to concede as a first step the very thesis you wanted to prove.  If we were, say, debating the value of Jane Austin’s writing and I lead by saying, “well, you must first concede she writes extremely well!” that would be question begging.  It’s more common to see actual question begging occur as a definitional exercise; an attorney that defines the defendant at a trial as a ‘criminal’ has begged the question, assuming the guilt of the person whose guilt has not yet judged in the proceeding where that is the primary concern.<a href=\"#easy-footnote-4-17368\"></a></li><li><span id=\"easy-footnote-bottom-5-17368\"></span>In our previous definition this conclusion is an <em>argument</em>, but we could easily expand our definition to also include <em>descriptive</em> essays (which aim not to make a new conclusion about something but merely assemble a collection of generally accepted facts).  There is still an analytical process here because the writer must determine what facts to trust, which are important enough to include and how they ought to be arranged, even though no <em>explicit</em> argument is being made.  Indeed, such a descriptive essay (like a Wikipedia article) makes an <em>implicit</em> argument based on what it is considered important enough to be included (e.g. on Wikipedia, what exactly is ‘notable’).<a href=\"#easy-footnote-5-17368\"></a></li><li><span id=\"easy-footnote-bottom-6-17368\"></span>the description of <em>The Limits of Empire</em> in particular is poor and mostly misses the book’s core argument that there was no Roman ‘grand strategy’ because the Romans were <em>incapable</em> of conceiving of strategy in that way.<a href=\"#easy-footnote-6-17368\"></a></li><li><span id=\"easy-footnote-bottom-7-17368\"></span>I’m pretty sure from the other responses I have seen (but cannot be 100% confident) that the BMCR, which is open and available to all, was included in ChatGPT’s corpus.<a href=\"#easy-footnote-7-17368\"></a></li><li><span id=\"easy-footnote-bottom-8-17368\"></span>While we’re here I should note that I think <em>The Limits of Empire</em> is hardly the last word on this question.  On why, you want to read E. Wheeler, “Methodological Limits and the Mirage of Roman Strategy” <em>JMH</em> 57.1 and 57.2 (1993); Wheeler systematically destroys nearly all of Isaac’s arguments.  I also asked ChatGPT to tell me what Wheeler’s critiques were, but since Wheeler isn’t in its training corpus, it couldn’t tell me.  When I asked for a list of Isaac’s most prominent critics, it didn’t list Wheeler because, I suppose, no one in its corpus discussed his article, despite it being (to the best of my knowledge) generally understood that Wheeler’s critique has been the most influential, as for instance noted by J.E. Lendon<a href=\"https://www.jstor.org/stable/3298451\" data-type=\"URL\" data-id=\"https://www.jstor.org/stable/3298451\"> in this review of the topic</a> for <em>Classical Journal</em> back in 2002.  ChatGPT can’t tell you any of that because it can only tell you things other people have already written in its training corpus.  Instead, it listed Adrian Goldsworthy, Jeremy Armstrong, John W.I. Lee and Christopher S. Mackay because they all wrote reviews of the book; none of these scholars (some of whom are <em>great </em>scholars) are particularly involved in the Roman strategy debate, so all of these answers are wrong.  The latest in this debate is James Lacey’s <em>Rome: Strategy of Empire</em> (2022), which is a solid reiteration of the Luttwakian side of the debate (valuable if only because Luttwak himself is a poor interlocutor in all of this) but seems unlikely to end it.  It is possible I am working on trying to say something useful on this topic at some point in the future.<a href=\"#easy-footnote-8-17368\"></a></li><li><span id=\"easy-footnote-bottom-9-17368\"></span>It also isn’t very good at discoverability.  It can’t tell you <em>who</em> or <em>where</em> that better idea is from if you find yourself wanting more explanation or context.  Once again, as a research tool, Google is pretty clearly superior.<a href=\"#easy-footnote-9-17368\"></a></li><li><span id=\"easy-footnote-bottom-10-17368\"></span>This is painfully obvious when it comes to trying to get information about video games.  In ye days of yore, Google would swiftly send you to the GameFaqs page (remember those!?) or the helpful fan Wiki, but more recently it becomes necessary to slog through a page or two of overly long (because Google prefers pages with at least a certain amount of text) answers to very simple questions in order to find what you are looking for (which usually ends up being a helpful response to someone’s question on Reddit or a Steam guide or, because I still like to live in 2004, an actual GameFaqs page).<a href=\"#easy-footnote-10-17368\"></a></li><li><span id=\"easy-footnote-bottom-11-17368\"></span>And thus, dear students, if you are not <em>reading the comments</em> you are not getting what you paid tens of thousands of dollars for when you paid tuition.  Read the comments.  You are in college to <em>learn things</em> not prove what you already know or how smart you already are.  We know you are smart, that’s why you got admitted to college; the question now is about drive and willingness to <em>learn</em>.<a href=\"#easy-footnote-11-17368\"></a></li><li><span id=\"easy-footnote-bottom-12-17368\"></span>There is thus a meaningful difference between this and the ‘why did I need to learn math without a calculator’ example that gets reused here, in that a calculator can at least do basic math for you, but ChatGPT cannot think for you.  That said, I had quite a difficult time learning that sort of thing as a kid, but (with some extra effort from my parents) I did learn it and I’ve found it tremendously useful in life.  Being able to calculate a tip in my head or compare the per-unit price of, say, 3-for-whatever sale on 12pack sodas vs. a 24pack of the same brand without having to plug it into my phone is really handy.  I thus find myself somewhat confused by folks I run into who are bitter they were forced to learn mathematics first without a calculator.<a href=\"#easy-footnote-12-17368\"></a></li><li><span id=\"easy-footnote-bottom-13-17368\"></span>A point we have already addressed.<a href=\"#easy-footnote-13-17368\"></a></li><li><span id=\"easy-footnote-bottom-14-17368\"></span>The one exception here are online courses using ‘closed book’ online essay tests.  That is an exam model which will be rendered difficult by this technology.  I think clever prompt writing (demand the students do things –  be specific in evidence or reference specific works – that ChatGPT is bad at) or use alternative assignments (a capstone project or essay instead).  For in-person classes, the entire problem is obviated by the written in-class essay.<a href=\"#easy-footnote-14-17368\"></a></li><li><span id=\"easy-footnote-bottom-15-17368\"></span>And if they <em>don’t</em>, that’s academic dishonestly regardless of who wrote the paper.<a href=\"#easy-footnote-15-17368\"></a></li><li><span id=\"easy-footnote-bottom-16-17368\"></span>And a student that cannot or will not cite their sources has plagiarized, regardless of who wrote their paper.  ChatGPT is such a mess of academic dishonesty that it isn’t even necessary to prove its products were machine-written because the machine <em>also</em> does the sort of things which can get you kicked out of college.<a href=\"#easy-footnote-16-17368\"></a></li><li><span id=\"easy-footnote-bottom-17-17368\"></span>And if the student has gone back and done the research to be able to correct those errors and rewrite those sentences in advance…at this point why not just write the paper honestly and not risk being thrown out of college?<a href=\"#easy-footnote-17-17368\"></a></li><li><span id=\"easy-footnote-bottom-18-17368\"></span>In the event I asked for 8,000 words because I wanted to see how it would handle organizing a larger piece of writing.  Now in the free version it can’t write that many words before it runs out of ‘tokens,’ but I wanted to see how the introduction would set up the organization for the bits it wouldn’t get to.  In practice it set up an essay in three or four chunks the first of which was 224 words; ChatGPT doesn’t seem to be able to even set up a larger and more complex piece of writing.  It also doesn’t plan for a number of words limited by how many it can get to before running out of tokens either, in case anyone thinks that’s what it was doing: to get to the end of the essay with all of the components it laid out in the introduction I had to jog it twice.<a href=\"#easy-footnote-18-17368\"></a></li><li><span id=\"easy-footnote-bottom-19-17368\"></span>Of course if the student has just tried honestly and failed, they’ll be able to document that process quite easily, with the works they read and where each wrong fact came from, whereas the student who has cheated using ChatGPT will be incapable of doing so.<a href=\"#easy-footnote-19-17368\"></a></li><li><span id=\"easy-footnote-bottom-20-17368\"></span>a hotly debated topic, actually!<a href=\"#easy-footnote-20-17368\"></a></li></ol>\t</div></div>","textContent":"\n\t\t\nSo I stirred up a bit of conversation on Twitter last week when I noted that I had already been handed ChatGPT produced assignments.1  For those who are unaware, ChatGPT is an ‘AI’ chatbot that given a prompt can produce texts; it is one of most sophisticated bots of this sort yet devised, trained on a massive amount of writing (along with substantial human input in the training process, something we’ll come back to).  And its appearance has made a lot of waves and caused a fair bit of consternation.\n\n\n\nNow I should note at the outset that while I am going to argue that ChatGPT is – or at least ought to be – basically useless for doing college assignments, it is also wrong to use it for this purpose.  Functionally all university honor codes prohibit something like ‘unauthorized aid or assistance’ when completing an assignment.  Having a chatbot write an assignment – or any part of that assignment – for you pretty clearly meets that definition.  Consequently using ChatGPT on a college essay is pretty clearly an impermissible outside aid – that is to say, ‘cheating.’  At most universities, this sort of cheating is an offense that can lead to failing classes or expulsion.  So however irritating that paper may be, it is probably not worth getting thrown out of college, money wasted, without a degree.  Learn.  Don’t cheat.\n\n\n\nThat said I want to move through a few of my basic issues: first, what ChatGPT is in contrast to what people seem to think it is.  Second, why I think that functionality serves little purpose in essay writing – or more correctly why I think folks that think it ‘solves’ essay writing misunderstand what essay writing is for.  Third, why I think that same functionality serves little purpose in my classroom – or more correctly why I think that folks that think is solves issues in the classroom fundamentally misunderstand what I am teaching and how.\n\n\n\nNow I do want to be clear at the outset that I am not saying that this technology has no viable uses (though I can’t say I’ve yet seen an example of a use I would consider good rather than merely economically viable for ChatGPT in particular) and I am certainly not saying that future machine-learning based products, be they large language models or other products, will not be useful (though I do think that boosters of this technology frequently assume applications in fields they do not understand).  Machine learning products are, in fact, already useful and in common use in ways that are good.  But I think I will stipulate that much of the boosterism for ChatGPT amounts to what Dan Olsen (commenting on cryptocurrency) describes as, “technofetishistic egotism,” a condition in which tech creators fall into the trap where, “They don’t understand anything about the ecosystems they’re trying to disrupt…and assume that because they understand one very complicated thing, [difficult programming challenges]…that all other complicated things must be lesser in complexity and naturally lower in the hierarchy of reality, nails easily driven by the hammer that they have created.”\n\n\n\nOf course that goes both ways which is why I am not going to say what capabilities machine learning may bring tomorrow.  It is evidently a potentially powerful technology and I am not able to assess what it may be able to do in the future.  But I can assess the observes capabilities of ChatGPT right now and talk about the implication those capabilities have in a classroom environment, which I do understand.2  That means – and I should be clear on this – this is a post about the capabilities of ChatGPT in its current form; not some other machine learning tool or AI that one imagines might exist in the future.  And in that context what I see does not convince me that this technology is going to improve the learning experience; where it is disruptive it seems almost entirely negatively so and even then the disruption is less profound than one might think.\n\n\n\nNow because I am not a chatbot but instead a living, breathing human who in theory needs to eat to survive, I should remind you that if you like what you are reading here you can help by sharing what I write (for I rely on word of mouth for my audience) and by supporting me on Patreon. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings, assuming there is still a Twitter by the time this post goes live.\n\n\n\n\n\n\n\n\n\n\nThe Heck is a ChatGPT?\n\n\n\nBut I think we want to start by discussing what ChatGPT is and what it is not; it is the latter actually that is most important for this discussion.  The tricky part is that ChatGPT and chatbots like it are designed to make use of a very influential human cognitive bias that we all have: the tendency to view things which are not people as people or at least as being like people.  We all do this; we imagine our pets understand more than they can, have emotions more similar to ours than they do,3 or that inanimate objects are not merely animate but human in their feelings, memories and so on.  We even imagine that the waves and winds are like people too and assign them attributes as divine beings with human-like emotions and often human-like appearances.  We beg and plead with the impersonal forces of the world like we would with people who might be moved by those emotions.\n\n\n\nThe way ChatGPT and other chatbots abuse that tendency is that they pretend to be like minds – like human minds.  But it is only pretend, there is no mind there and that is the key to understanding what ChatGPT is (and thus what it is capable of).  Now I can’t claim to understand the complex computer science that produced this program (indeed, with machine learning programs, even the creators sometimes cannot truly understand ‘how’ the program comes to a specific result), but enough concerning how it functions has been discussed to get a sense of what it can and cannot do.  Moreover its limitations (demonstrated in its use and thus available for interrogation by the non-specialist) are illustrative of its capabilities.\n\n\n\nChatGPT is chatbot (a program designed to mimic human conversation) that uses a large language model (a giant model of probabilities of what words will appear and in what order).  That large language model was produced through a giant text base (some 570GB, reportedly) though I can’t find that OpenAI has been transparent about what was and was not in that training base (though no part of that training data is post-2021, apparently).  The program was then trained by human trainers who both gave the model a prompt and an appropriate output to that prompt (supervised fine tuning) or else had the model generate several responses to a prompt and then humans sorted those responses best to worst (the reward model).  At each stage the model is refined (CGP Grey has a very accessible description of how this works) to produce results more in keeping with what the human trainers expect or desire.  This last step is really important whenever anyone suggests that it would be trivial to train ChatGPT on a large new dataset; a lot of human intervention was in fact required to get these results.\n\n\n\nIt is crucial to note, however, what the data is that is being collected and refined in the training system here: it is purely information about how words appear in relation to each other.  That is, how often words occur together, how closely, in what relative positions and so on.  It is not, as we do, storing definitions or associations between those words and their real world referents, nor is it storing a perfect copy of the training material for future reference.  ChatGPT does not sit atop a great library it can peer through at will; it has read every book in the library once and distilled the statistical relationships between the words in that library and then burned the library.\n\n\n\nChatGPT does not understand the logical correlations of these words or the actual things that the words (as symbols) signify (their ‘referents’).  It does not know that water makes you wet, only that ‘water’ and ‘wet’ tend to appear together and humans sometimes say ‘water makes you wet’ (in that order) for reasons it does not and cannot understand.\n\n\n\nIn that sense, ChatGPT’s greatest limitation is that it doesn’t know anything about anything; it isn’t storing definitions of words or a sense of their meanings or connections to real world objects or facts to reference about them.  ChatGPT is, in fact, incapable of knowing anything at all.  The assumption so many people make is that when they ask ChatGPT a question, it ‘researches’ the answer the way we would, perhaps by checking Wikipedia for the relevant information.  But ChatGPT doesn’t have ‘information’ in this sense; it has no discrete facts.  To put it one way, ChatGPT does not and cannot know that “World War I started in 1914.”  What it does know is that “World War I” “1914” and “start” (and its synonyms) tend to appear together in its training material, so when you ask, “when did WWI start?” it can give that answer.  But it can also give absolutely nonsensical or blatantly wrong answers with exactly the same kind of confidence because the language model has no space for knowledge as we understand it; it merely has a model of the statistical relationships between how words appear in its training material.\n\n\n\nIn artificial intelligence studies, this habit of manufacturing false information gets called an “artificial hallucination,” but I’ll be frank I think this sort of terminology begs the question.4   ChatGPT gets called an artificial intelligence by some boosters (the company that makes it has the somewhat unearned name of ‘OpenAI’) but it is not some sort of synthetic mind so much as it is an extremely sophisticated form of the software on your phone that tries to guess what you will type next.  And ChatGPT isn’t suffering some form of hallucination – which is a distortion of sense-perception.  Even if we were to say that it can sense-perceive at all (and this is also question-begging), its sense-perception has worked just fine: it has absorbed its training materials with perfect accuracy, after all; it merely lacks the capacity to understand or verify those materials.  ChatGPT isn’t a mind suffering a disorder but a program functioning perfectly as it returns an undesired output.  When ChatGPT invents a title and author of a book that does not exist because you asked it to cite something, the program has not failed: it has done exactly what was asked of it, putting words together in a statistically probable relationship based on your prompt.  But calling this a hallucination is already ascribing mind-like qualities to something that is not a mind or even particularly mind-like in its function.\n\n\n\nNow I should note the counter-argument here is that by associating words together ChatGPT can ‘know’ things in some sense because it can link those associations.  But there are some major differences here.  First, human minds assess the reliability of those associations: how often when asked a question does an answer pop into your mind that you realize quickly cannot be right or you realize you don’t know the answer at all and must look it up?  Part of that process, of course, is that the mental associations we make are ‘checked’ against the real world realities they describe.  In fancy terms, words are merely symbols of actual real things (their ‘referents‘ – the things to which they refer) and so the truth value of words may be checked against the actual status of their referents.  For most people, this connection is very strong.  Chances are, if I say ‘wool blanket’ your mind is going to not merely play word association but also conjure up some memories of actual wool blankets – their sight, touch or smell.  ChatGPT lacks this capability; all it has are the statistical relationship between words stripped entirely of their referents.  It will thus invent descriptions for scientific phenomenon that aren’t real, embellish descriptions of books that do not exist and if asked to cite things it will invent works to cite, because none of those things is any more or less real to ChatGPT than actual real existing things.\n\n\n\nAll it knows, all it knows are the statistical relationships of how words appear together, refined by the responses that its human trainers prefer.  Thus the statement that ChatGPT doesn’t know anything about anything or more correctly it cannot know anything about the topics it is asked to write about.\n\n\n\nAll of that is important to understand what ChatGPT is doing when you tell it to, say, write an essay.  It is not considering the topic, looking up references, thinking up the best answer and then mobilizing evidence for that answer.  Instead it is taking a great big pile of words, picking out the words which are most likely to be related to the prompt and putting those words together in the order-relationships (but not necessarily the logical relationships) that they most often have, modified by the training process it has gone through to produce ‘better’ results.  As one technical writer, Ted Chiang, has put it, the result is merely a ‘very lossy’ (that is, not very faithful) reproduction of its training materials, rather than anything new or based on any actual understanding of the underlying objects or ideas.  But, because it is a chatbot, its can dole those words out in tremendous quantity, with flawless spelling and grammar and to follow whatever formula (more or less) the prompt asks for.  But it doesn’t know what those words mean; indeed coming from the chatbot, in a sense they mean nothing.\n\n\n\nI stress this functionality at the beginning because I want readers to understand that many of the mental processes – analysis, verification, logical organization – that we take for granted from a thinking person are things ChatGPT does not do and is entirely incapable of in the same way that an electric can-opener cannot also double as a cell phone.  Those capabilities are both entirely outside of the structure of the current iteration of ChatGPT and also entirely outside of the processes that the training procedures which produced ChatGPT will train.  Incremental improvements in the can-opener will not turn it into a cell phone either; the cell phone is an entirely different sort of machine.  Thus the confidence among some that the ‘hallucination’ problem will be inevitably solved seems premature to me.  It may well be solved, but it may well not; doing so will probably require the creation of an entirely new sort of machine of a type never before created.  That eventuality cannot be taken for granted; it is not even something that we know is possible (though it may well be!).  It most certainly will not happen on its own.\n\n\n\nThe Heck Is an Essay?\n\n\n\nSo that is what ChatGPT does: in response to a prompt, it puts together an answer that is composed of words in its training material organized based on the statistical probability that those words appear together and the degree to which they are related to the prompt (processed through an extremely complex language model).  It thus assembles words from its big bag of words in a way that looks like the assemblages of words it has seen in its training and which its human trainers have ranked highly.  And if all you want ChatGPT to do is precisely that: somewhat randomly assemble a bunch of words loosely related to a topic in a form that resembles communication, it can do that for you.  I’m not sure why you want it to do that, but that is the one and only thing it can do.\n\n\n\nBut can ChatGPT write an essay?\n\n\n\nIt has been suggested that this endangers or even makes obsolete the essay or particularly the ‘college essay,’ and I think this misunderstands what the purpose of an essay is.  Now the definition of an essay is somewhat nebulous, especially when it comes to length; essays are shorter than books but longer than notes but these too are nebulously defined.  Still we can have a useful definition:\n\n\n\nAn essay is a piece of relatively short writing designed to express an argument – that is, it asserts a truth about something real outside of the essay itself – by communicating the idea of argument itself (the thesis) and assembling evidence chosen to prove that argument to a reader.  Communication is thus part of writing an essay, but not the only part or even necessarily the most important.  Indeed, the communication element may come in entirely different forms from the traditional essay.  Consider video essays or photo essays: both have radically changed the form of communication but they remain essays because the important part – the argument asserting a truth about something supported by assembled evidence – remains the same, even as the nature of the evidence and communication has changed.\n\n\n\nWriting an essay thus involves a number of steps, of which communication is merely the last.  Ideally, the essay writer has first observed their subject, then drawn some sort of analytical conclusion about that subject,5 then organized their evidence in a way that expresses the logical connections between various pieces of evidence, before finally communicating that to a reader in a way that is clear and persuasive.\n\n\n\nChatGPT is entirely incapable of the first two steps (though it may appear to do either of them) and incompetent at the third; it’s capabilities are entirely on the last step (and even there generally inferior to a well-trained human writer at present).\n\n\n\nWhen it comes to observing a subject, as noted ChatGPT is not capable of research so the best it can do, to borrow Ted Chiang’s phrasing again, is provide a ‘lossy’ replica of the research of others and only if that research has somehow found its way into ChatGPT’s training materials.  Even when the necessary information is contained within the works in ChatGPT’s training material, it can’t actually understand those things, it can only reproduce them, so if they do not explicitly draw the conclusion it needs in as many words, ChatGPT can’t do so either.  We can demonstrate this by asking ChatGPT an almost trivially easy research question, like, “What is the relationship between Edward Luttwak’s Grand Strategy of the Roman Empire and Benjamin Isaac’s The Limits of Empire?”  And so we did:\n\n\n\n\n\n\n\nIf you know nothing about either book, this answer almost sounds useful (it isn’t).6  Now this is a trivial research task; simply typing ‘the limits of empire review’ into Google and then clicking on the very first non-paywalled result (this review of the book by David Potter from 1990) and reading the first paragraph makes almost immediately clear the correct answer is that Isaac’s book is an intentional and explicit rebuttal of Luttwak’s book, or as Potter puts it, “Ben Isaac’s The Limits of Empire offers a new and formidable challenge to Luttwack.”  A human being who understands the words and what they mean could immediately answer the question, but ChatGPT which doesn’t, cannot: it can only BS around the answer by describing both books and then lamely saying they “intersect in some ways.”  The information ChatGPT needed was clearly in its training materials (or it wouldn’t have a description of either book to make a lossy copy of),7 but it lacks the capacity to understand that information as information (rather than as a statistically correlated sequence of words).8  Consequently it cannot draw the right conclusion and so talks around the question in a convincing, but erronous way.\n\n\n\nNote that no analysis was required for the above question!  It was a pure reading comprehension question that could be solved by merely recognizing that something in the training set already said the answer and copying it, but ChatGPT wasn’t even capable of that because while it has a big bag of words related to both books, it lacks the capability to understand and grab the relevant words.  This is an example of the not at all uncommon situation where Google is a far better research tool than ChatGPT, because Google can rely on your reading comprehension to understand the places it points you to which may have the answer you seek.\n\n\n\nSo research and observation are out; what about analysis?  Well, if you have been following along you’ll realize that ChatGPT is incapable of doing that too.  What it can do is find something that looks like analysis (though it may not be analysis or it may be quite bad analysis) and then reproduce it (in a lossy form) for you.  But the point of analysis is to be able to provide novel insight, that is to either suggest a conclusion hitherto unconsidered for a given problem or equally importantly to come up with a conclusion for a problem that is only being encountered for the very first time.  ChatGPT, limited entirely to remixing existing writings, cannot do either.\n\n\n\nAs a system to produce essays, this makes ChatGPT not very useful at all.  Generally when people want an essay, they don’t actually want the essay; the essay they are reading is instead a container for what they actually want which is the analysis and evidence.  An essay in this sense is a word-box that we put thoughts in so that we can give those thoughts to someone else.  But ChatGPT cannot have original thoughts, it can only remix writing that is already in its training material; it can only poorly copy writing someone else has already done better somewhere.9  ChatGPT in this sense is like a friendly, if somewhat daft neighbor who noticed one day that every so often you get a box from Amazon and that you seem quite happy to get it and so decides to do you a favor by regularly ordering empty Amazon boxes to your house.  The poor fellow does not know and cannot understand that it was the thing in the box – in this case, the thoughts (original observations, analysis, evidence) in the essay – that you actually wanted.  ChatGPT doesn’t have any thoughts to give you (though it can somewhat garble someone else’s thoughts), but it sure can order you up a bunch of very OK boxes.\n\n\n\nIn a very real sense then, ChatGPT cannot write an essay.  It can imitate an essay, but because it is incapable of the tasks which give an essay its actual use value (original thought and analysis), it can only produce inferior copies of other writing.  That quite a few people, including some journalists, have supposed that ChatGPT can write an essay suggests to me that they have an impoverished idea of what an essay is, viewing it only as ‘content’ rather than as a box that thoughts go into for delivery, or haven’t really scrutinized what ChatGPT outputs closely enough.\n\n\n\nNow there are, in that previous analogy, box-sellers online: outlets who really do not care about the thoughts in the essay but merely want units of text to throw up to generate clicks.  Few reputable publications function this way – that’s why they have editors whose job is to try to figure out if your essay has a thought in it actually worth sharing and then if so to help guide you to the most effective presentation of that thought (that’s the editing process).  But there are a lot of content mills online which are really looking to just supply large amounts of vaguely relevant text at the lowest possible cost hoping to harvest views from gullible search engines.  For those content mills, ChatGPT potentially has a lot of value but those content mills provide almost no value to us, the consumer.  Far from it, they are one of the major reasons why folks report declining search engine quality, as they crowd out actually useful content.10\n\n\n\nThat said I don’t want to rule out ChatGPT’s ability to produce functional formulaic documents entirely.  I’ve heard it suggested that it could massively reduce the cost of producing formula-driven legal and corporate documents and perhaps it can.  It’s also been suggested it could be trained to write code, though my understanding is that as of now, most of the code it produces looks good but does not work well.  I don’t write those sorts of things, though, so I can’t speak to the question.  I would be concerned though, because ChatGPT can make some very bad mistakes and has no way of catching those mistakes, so very high stakes legal or corporate documents seems like a risky use of ChatGPT.  ChatGPT can’t write a good essay, but a bad essay only wastes a few minutes of your time; a bad contract can cost a company millions and a single bad line of code can crash an entire program (or just cause it to fail to compile and in either case waste hours and hours of bug-hunting to determine what went wrong).\n\n\n\nBut the core work of the essay?  This ChatGPT cannot do.  And importantly it is not some capacity which merely requires iterative improvements on the product.  While ChatGPT can fake an original essay, the jump from faking that essay to writing an actually original thought certainly looks like it would require a completely different program, one capable of observing the real world, analyzing facts about it and then reaching conclusions.\n\n\n\nThe Heck is the Teaching Essay For?\n\n\n\nThat leaves the role of ChatGPT in the classroom.  And here some of the previous objections do indeed break down.  A classroom essay, after all, isn’t meant to be original; the instructor is often assigning an entire class to write essays on the same topic, producing a kaleidoscope of quite similar essays using similar sources.  Moreover classroom essays are far more likely to be about the kind of ‘Wikipedia-famous’ people and works which have enough of a presence in ChatGPT’s training materials for the program to be able to cobble together a workable response (by quietly taking a bunch of other such essays, putting them into the blender and handing out the result, a process which in the absence of citation we probably ought to understand as plagiarism).  In short, many students are often asked to write an essay that many hundreds of students have already written before them.  And so there were quite a few pronouncements that ChatGPT had ‘killed’ the college essay. And indeed, in my own experience in the Twitter discourse around the system, one frequent line of argument was that ChatGPT was going to disrupt my classroom, so shouldn’t I just go ahead and get on board with the new technology?\n\n\n\nThis both misunderstands what the college essay is for as well as the role of disruption in the classroom.  Let’s start with the first question: what is the teaching essay (at any level of schooling) for?  It’s an important question and one that arises out of a consistent problem in how we teach students, which is that we rarely explain our pedagogy (our ‘teaching strategy’) to the students.  That tends to leave many assignments feeling arbitrary even when teachers have in fact put a great deal of thought into why they are assigning what they are and what skills they are supposed to train.  So let’s talk about why we assign essays, what those assignments are supposed to accomplish and why ChatGPT has little to offer in that realm.\n\n\n\nIn practice there are three things that I am aiming for an essay assignment to accomplish in a classroom.  The first and probably least important is to get students to think about a specific historical topic or idea, since they (in theory) must do this in order to write about it.  In my own planning I sometimes refer to these assignments as ‘pedagogical’ essays (not a perfect term) where the assignment – typically a ‘potted’ essay (short essay with pre-chosen sources handed to students, opposite of a ‘research’ essay) – is meant to have students ponder a specific question for the value of that question.  One example is an essay prompt I sometimes use in my ancient history survey asking students, “On what basis do we consider Alexander to be ‘great’?  Is this a sound basis to apply this title?”  Obviously I want students here to both understand something about Alexander but also to think about the idea of greatness and what that means; does successfully killing a lot of people and then failing to administer what remains qualify as greatness and if so what does that say about what we value?  Writing the essay forces them to ponder the question.  That value is obviously lost if they just let ChatGPT copy some other essay for them.\n\n\n\nThat said this first sort of goal is often the least important.  While of course I think my course material matters, the fact is few students will need to be able to recall from memory the details of Alexander the Great at some point in their life.  They’ll be able to look him up and hopefully with the broad knowledge framework I’ve given them and the research and analysis skills, be able to reach for these same conclusions.  Which brings us to:\n\n\n\nThe second goal and middle in importance is training the student in how to write essays.  I’ve made this element of my approach more explicit in recent years, making the assignments more closely resemble the real world writing forms they train for.  Thus the classics 3-5 page paper becomes the c. 1000 word think-piece (though I do require a bit more citation than a print publication would in a ‘show your work’ sort of way), the sort paper becomes a 700-800 word op-ed, etc.  The idea here is to signal to students more clearly that they are training to write real things that exist in the world outside of the classroom.  That said, while a lot of students can imagine situations in which they might want to write an op-ed or a think piece or a short speech, many of them won’t ever write another formal essay after leaving college.\n\n\n\nThus the last and most important thing I am trying to train is not the form of the essay nor its content, but the basic skills of having a thought and putting it in a box that we outlined earlier.  Even if your job or hobbies do not involve formal writing, chances are (especially if your job requires a college degree) you are still expected to observe something real, make conclusions about it and then present those conclusions to someone else (boss, subordinates, co-workers, customers, etc.) in a clear way, supported by convincing evidence if challenged.  What we are practicing then is how to have good thoughts, put them in good boxes and then effectively hand that box to someone else.  That can be done in a formal written form (the essay), in informal writing (emails, memos, notes, Slack conversations), or verbally (speeches, but also arguments, debates and discussions).  The skills of having the idea, supporting it with evidence, organizing that evidence effectively to be understood and then communicating that effectively are transferable and the most important skills that are being practiced when a student writes an essay.\n\n\n\nCrucially – and somehow this point seems to be missed by many of ChatGPT’s boosters I encountered on social media – at no point in this process do I actually want the essays.  Yes, they have to be turned in to me and graded and commented because that feedback in turn is meant to both motivate students to improve but also to signal where they need to improve.11  But I did not assign the project because I wanted the essays.  To indulge in an analogy, I am not asking my students to forge some nails because I want a whole bunch of nails – the nails they forge on early attempts will be quite bad anyway.  I am asking them to forge nails so that they learn how to forge nails (which is why I inspect the nails and explain their defects each time) and by extension also learn how to forge other things that are akin to nails.  I want students to learn how to analyze, organize ideas and communicate those ideas.\n\n\n\nWhat one can immediately see is that a student who simply uses ChatGPT to write their essay for them has simply cheated themselves out of the opportunity to learn (and also wasted my time in providing comments and grades).  As we’ve seen above, ChatGPT cannot effectively replace the actual core tasks we are training for, so this is not a case where the existence of spinning jennies renders most training at hand spinning obsolete.  And it certainly doesn’t fulfill the purpose of the assignment.\n\n\n\nTo which some boosters of the technology respond that what I should really be doing is training students on how to most effectively use ChatGPT as a tool.  But it is not clear to me that ChatGPT functions well as a tool for any part of this process.  One suggestion is to write an outline and then feed that into ChatGPT to generate a paper, but that fails to train the essential communication component of the assignment and in any case, ChatGPT is actually pretty bad at the nuts of and bolts of writing paragraphs.  Its tendency in particular to invent facts or invent non-existent sources to cite makes it an enormous liability here; it is a very bad research tool because it is unreliable.  Alternately the suggestion is that students could use ChatGPT to produce an essay they edit to fit or an outline they fill in; both problems run into the issue that the student is now trying to offload the most important part of the task for them to learn: the actual thinking and analysis.  And the crucial thing to note is that the skill that is not being trained in both cases is a skill that current large language models like ChatGPT cannot perform or perform very poorly.12\n\n\n\nI suspect this argument looks plausible to people because they are not thinking in terms of being trained to think about novel problems, but in terms of the assignment itself; they are thinking about the most efficient way to produce ‘one unit of essay.’   But what we’re actually doing is practicing a non-novel problem (by treating it as a novel problem for the purpose of the assignment), so that when we run into novel problems, we’ll be able to apply the same skills.  Consequently they imagine that ChatGPT, trained as it is on what seems to be an awful lot of mediocre student essays (it mimics the form of a bad student essay with remarkable accuracy), can perform the actual final task in question, but it cannot.\n\n\n\nConclusion: Preparing to Be ‘Disrupted.’\n\n\n\nThe reply that all of this gets has generally been some combination of how this technology is ‘the future,’ that it will make essay writing obsolete so I should focus on training for it,13, and most of all that the technology will soon be so good, if it is not already, that any competent student will be able to use it to perfectly fake good papers.  Thus, I am told, my classroom is doomed to be ‘disrupted’ by this technology so I should preemptively surrender and get on board.\n\n\n\nAnd no.  No, I don’t think so.\n\n\n\nI do think there are classrooms that will be disrupted by ChatGPT, but those are classrooms where something is already broken.  Certainly for a history classroom, if ChatGPT can churn out a decent essay for your assignment, chances are the assignment is poorly designed.  ChatGPT after all cannot analyze a primary source (unless it is already been analyzed many times in its training materials), it struggles to cite scholarship (more often inventing fake sources) and it generally avoids specific evidence.  Well-designed assignments which demand proper citation, specific evidence to support claims (rather than general statements) and a clear thesis are going to be beyond ChatGPT and indeed require so much editing to produce from a ChatGPT framework as to make it hardly worth the effort to cheat.  If your essay prompt can be successfully answered using nothing but vague ChatGPT generated platitudes, it is a bad prompt.14\n\n\n\nMeanwhile, ChatGPT responses seem to be actually pretty easy to spot once you know how to look for the limitations built into the system.  There are already programs designed to detect if a piece of writing is machine-written; they’re not fully reliable yet but I suspect they will become more reliable over time mostly because it is in the interests of both AI-developers (who do not want their models trained on non-human produced writing) and search engines (who want to be able to exclude from search results the veritable river of machine-produced content-mill garbage we all know is coming) to develop that capability.  But because of the ways ChatGPT is limited, a human grader should also be able to flag ChatGPT generated responses very quickly too.\n\n\n\nIt should be trivially easy, for instance, for a grader to confirm if the sources a paper cites exist.15  A paper with a bunch of convincing sounding but entirely invented sources is probably machine-written because humans don’t tend to make that mistake.  If instead, as is its wont, the paper refers merely vaguely to works written by a given author or on a given topic, insist the student produce those works (and require citation on all papers) – this will be very hard for the student with the ChatGPT paper as those works will not, in fact, exist.16  ChatGPT also has a habit of mistaking non-famous people for famous people with similar names; again for a grader familiar with the material this should be quite obvious.\n\n\n\nAnd then of course there are the errors.  ChatGPT makes a lot of factual mistakes, especially as it gets into more technical questions where the amount of material for it to be trained on is less.  While the text it produces often looks authoritative to someone with minimal knowledge in that field, in theory the person grading the paper should have enough grounding to spot some of the obvious howlers that are bound to sneak in over the course of a longer research paper.17  By way of example, I asked ChatGPT to write  on, “the causes of Roman military success in the third and second centuries BCE.”  Hardly a niche topic.18   The whole thing was sufficiently full of problems and errors that I’m just going to include an annotated word document pointing them all out here:\n\n\n\n\n\n\n\nNeedless to say, this would not be a passing (C or higher) paper in my class.  Exact counting here will vary but I identified 38 factual claims, of which 7 were correct, 7 were badly distorted and 24 were simply wrong.  A trainwreck this bad would absolutely have me meeting with a student and raising questions which – if the paper was machine written – might be very hard for the student to answer.  Indeed, a research paper with just three or four of these errors would probably prompt a meeting with a student to talk about their research methods.  This is certainly then also an error rate which is going to draw my attention and now cause me to ask questions about who exactly wrote the essay and how.19\n\n\n\nAnd that’s the thing: in a free market, a competitor cannot simply exclude a disruptive new technology.  But in a classroom, we can absolutely do this thing.  I am one of those professors who doesn’t allow laptops for note-taking (unless it is a disability accommodation, of course) because there’s quite a bit of evidence that laptops as note-taking devices lower student performance (quite apart from their potential to distract) and my goal is to maximize learning.  This isn’t me being a luddite; I would ban, say, classroom firecrackers or a live jazz band for the same reason and if laptops improved learning outcomes somehow (again, the research suggests they don’t), I’d immediately permit them.  Given that detecting machine-writing isn’t particularly hard and that designing assignments that focus on the skills humans can learn that the machines cannot (and struggle to fake) is good pedagogical practice anyway, excluding the technology from my classroom is not only possible it is indeed necessary.\n\n\n\nNow will this disrupt some classrooms?  Yes.  Overworked or indifferent graders will probably be fooled by these papers or more correctly they will not care who wrote the paper because those instructors or graders are either not very much invested in learning outcomes or not given the time and resources to invest however much they might wish to.  I think schools are going to need to think particularly about the workload on adjuncts and TAs who are sometimes asked to grade through absurdly high amounts of papers in relatively little time and thus will simply lack the time read carefully enough.  Of course given how much students are paying for this, one would assume that resources could be made available to allow for the bare minimum of scrutiny these assignments deserve.  Schools may also need to rethink the tradeoffs of hiring indifferent teachers ‘for their research’ or for the prestige of their PhD institutions because the gap between good, dedicated teachers and bad, indifferent ones is going to grow wider as a result of this technology.\n\n\n\nLikewise, poorly designed assignments will be easier for students to cheat on, but that simply calls on all of us to be more careful and intentional with our assignment design (though in practice in my experience most professors, at least in history and classics, generally are).  I will confess every time I see a news story about how ChatGPT supposedly passed this or that exam, I find myself more than a little baffled and quite concerned about the level of work being expected in those programs.  If ChatGPT can pass business school, that might say something rather concerning about business school (or at least the bar they set for passing).\n\n\n\nThe final argument I hear is that while ChatGPT or large language models like it may not make my job obsolete now, they will inevitably do so in the future, that these programs are inevitably going to improve to the point where all of the limitations I’ve outlined will be surpassed.  And I’ll admit some of that is possible but I do not think it is by any means certain.  Of the processes we’ve laid out here, observing, analyzing those observations, arranging evidence to support conclusions and then communicating all of that, ChatGPT only does (or pretends to do) the last task.  As I noted above, an entirely new machine would be necessary for these other processes and it is not certain that such a machine is possible within the limits of the computing power now available to us.  I rather suspect it is, but it doesn’t seem certain that it is.\n\n\n\nMore broadly, as far as I can tell it seems that a lot of AI research (I actually dislike a lot of these terms which seem to me to imply that what we’ve achieved is a lot closer to a synthetic mind than it really is, at least for now) has proceeded on a ‘fake it till you make it’ model.  It makes sense as a strategy: want to produce a mind, but we don’t really know how a mind works at full complexity, so we’ve chosen instead to try to create machines which can convincingly fake being a mind in the hopes that a maximally convincing fake will turn out to be a mind of some sort.  I have no trouble imagining that strategy could work, but what I think AI-boosters need to consider is that it also may not.  It may in fact turn out that the sort of machine learning we are doing is a dead end.\n\n\n\nIt wouldn’t be the first time!  Early alchemists spent a lot of time trying to transmute lead into gold; they ended up pioneering a lot of chemistry, exploring chemical reactions to try to achieve that result.  Important things were learned, but you know what no amount of alchemical proto-chemistry was ever going to do?  Turn lead into gold.  As a means of making gold those experiments were dead ends; if you want to turn lead into gold you have to figure out some way of ripping three protons off of a lead atom which purely chemical reactions cannot do.  The alchemist who devised chemical reactions aiming to produce progressively more convincing fakes of gold until he at last managed the perfect fake that would be the real thing was bound to fail because that final step turns out to be impossible.  The problem was that the alchemist had to experiment without knowing what made some things (compounds) different from other things (elements) and so couldn’t know that while compounds could be altered in chemical reactions, elements could not.\n\n\n\nIn short, just as the alchemist labored without really knowing what gold was or how it worked, but was only able to observe its outward qualities, so too our AI engineers are forced to work without really knowing what a mind is or how it works.  This present research may turn out to be the way that we end up learning what a mind really is and how it really works, or it may be a dead end.  We may never turn ChatGPT into gold.  It may be impossible to do so.  Hopefully even if that is the case, we’ll have developed some useful tools along the way, just like those alchemists pioneered much of chemistry in the pursuit of things chemistry was incapable of doing.\n\n\n\nIn the meantime, I am asking our tech pioneers to please be more alive to the consequences of the machines you create.  Just because something can be done doesn’t mean it should be done.  We could decide to empirically test if 2,000 nuclear detonations will actually produce a nuclear winter,20 but we shouldn’t.  Some inventions – say, sarin gas – shouldn’t be used.  Discovering what we can do is always laudable; doing it is not always so.  And yet again and again these new machines are created and deployed with vanishingly little concern about what their impacts might be.  Will ChatGPT improve society, or just clutter the internet with more junk that will take real humans more time to sort through?  Is this a tool for learning or just a tool to disrupt the market in cheating?\n\n\n\n\nSci-Fi Author: In my book I invented the Torment Nexus as a cautionary taleTech Company: At long last, we have created the Torment Nexus from classic sci-fi novel Don't Create The Torment Nexus— Alex Blechman (@AlexBlechman) November 8, 2021\n\n\n\n\nToo often the response to these questions is, “well if it can be done, someone will do it, so I might as well do it first (and become famous or rich),” which is both an immorally self-serving justification but also a suicidal rule of conduct to adopt for a species which has the capacity to fatally irradiate its only biosphere.  The amount of power our species has to create and destroy long ago exceeded the point where we could survive on that basis.\n\n\n\nAnd that problem – that we need to think hard about the ethics of our inventions before we let them escape our labs – that is a thinking problem and thus one in which ChatGPT is entirely powerless to help us.\nAnd I should be clear right here ahead of time that nothing that follows is particular to any paper(s) I may have received.  Do not ask “what happened to the student(s)?” or “how did you know?” or “what class was this in?” because I can’t tell you.  Student privacy laws in the United States protect that sort of information and it is a good thing they do.  The observations that follow are not based on student papers, instead they are based on a number of responses I had ChatGPT produce for me to get a sense of what such an effort at cheating might look like and how I might detect it.After all I may not have experience as a creator of large language models, but I am a fully qualified end user. I cannot and indeed will not critique how ChatGPT was created, but I am perfectly qualified to say, “this product as delivered does not meet any of my needs.”Not that pets don’t have emotions or some kind of understanding, but we anthropomorphize our pets a lot as a way of relating to them.Since I am going to use this phrase a lot I should be clear on its meaning.  To ‘beg the question’ is not to ask someone to ask you something, but rather to ask your interlocutor in a debate or discussion to concede as a first step the very thesis you wanted to prove.  If we were, say, debating the value of Jane Austin’s writing and I lead by saying, “well, you must first concede she writes extremely well!” that would be question begging.  It’s more common to see actual question begging occur as a definitional exercise; an attorney that defines the defendant at a trial as a ‘criminal’ has begged the question, assuming the guilt of the person whose guilt has not yet judged in the proceeding where that is the primary concern.In our previous definition this conclusion is an argument, but we could easily expand our definition to also include descriptive essays (which aim not to make a new conclusion about something but merely assemble a collection of generally accepted facts).  There is still an analytical process here because the writer must determine what facts to trust, which are important enough to include and how they ought to be arranged, even though no explicit argument is being made.  Indeed, such a descriptive essay (like a Wikipedia article) makes an implicit argument based on what it is considered important enough to be included (e.g. on Wikipedia, what exactly is ‘notable’).the description of The Limits of Empire in particular is poor and mostly misses the book’s core argument that there was no Roman ‘grand strategy’ because the Romans were incapable of conceiving of strategy in that way.I’m pretty sure from the other responses I have seen (but cannot be 100% confident) that the BMCR, which is open and available to all, was included in ChatGPT’s corpus.While we’re here I should note that I think The Limits of Empire is hardly the last word on this question.  On why, you want to read E. Wheeler, “Methodological Limits and the Mirage of Roman Strategy” JMH 57.1 and 57.2 (1993); Wheeler systematically destroys nearly all of Isaac’s arguments.  I also asked ChatGPT to tell me what Wheeler’s critiques were, but since Wheeler isn’t in its training corpus, it couldn’t tell me.  When I asked for a list of Isaac’s most prominent critics, it didn’t list Wheeler because, I suppose, no one in its corpus discussed his article, despite it being (to the best of my knowledge) generally understood that Wheeler’s critique has been the most influential, as for instance noted by J.E. Lendon in this review of the topic for Classical Journal back in 2002.  ChatGPT can’t tell you any of that because it can only tell you things other people have already written in its training corpus.  Instead, it listed Adrian Goldsworthy, Jeremy Armstrong, John W.I. Lee and Christopher S. Mackay because they all wrote reviews of the book; none of these scholars (some of whom are great scholars) are particularly involved in the Roman strategy debate, so all of these answers are wrong.  The latest in this debate is James Lacey’s Rome: Strategy of Empire (2022), which is a solid reiteration of the Luttwakian side of the debate (valuable if only because Luttwak himself is a poor interlocutor in all of this) but seems unlikely to end it.  It is possible I am working on trying to say something useful on this topic at some point in the future.It also isn’t very good at discoverability.  It can’t tell you who or where that better idea is from if you find yourself wanting more explanation or context.  Once again, as a research tool, Google is pretty clearly superior.This is painfully obvious when it comes to trying to get information about video games.  In ye days of yore, Google would swiftly send you to the GameFaqs page (remember those!?) or the helpful fan Wiki, but more recently it becomes necessary to slog through a page or two of overly long (because Google prefers pages with at least a certain amount of text) answers to very simple questions in order to find what you are looking for (which usually ends up being a helpful response to someone’s question on Reddit or a Steam guide or, because I still like to live in 2004, an actual GameFaqs page).And thus, dear students, if you are not reading the comments you are not getting what you paid tens of thousands of dollars for when you paid tuition.  Read the comments.  You are in college to learn things not prove what you already know or how smart you already are.  We know you are smart, that’s why you got admitted to college; the question now is about drive and willingness to learn.There is thus a meaningful difference between this and the ‘why did I need to learn math without a calculator’ example that gets reused here, in that a calculator can at least do basic math for you, but ChatGPT cannot think for you.  That said, I had quite a difficult time learning that sort of thing as a kid, but (with some extra effort from my parents) I did learn it and I’ve found it tremendously useful in life.  Being able to calculate a tip in my head or compare the per-unit price of, say, 3-for-whatever sale on 12pack sodas vs. a 24pack of the same brand without having to plug it into my phone is really handy.  I thus find myself somewhat confused by folks I run into who are bitter they were forced to learn mathematics first without a calculator.A point we have already addressed.The one exception here are online courses using ‘closed book’ online essay tests.  That is an exam model which will be rendered difficult by this technology.  I think clever prompt writing (demand the students do things –  be specific in evidence or reference specific works – that ChatGPT is bad at) or use alternative assignments (a capstone project or essay instead).  For in-person classes, the entire problem is obviated by the written in-class essay.And if they don’t, that’s academic dishonestly regardless of who wrote the paper.And a student that cannot or will not cite their sources has plagiarized, regardless of who wrote their paper.  ChatGPT is such a mess of academic dishonesty that it isn’t even necessary to prove its products were machine-written because the machine also does the sort of things which can get you kicked out of college.And if the student has gone back and done the research to be able to correct those errors and rewrite those sentences in advance…at this point why not just write the paper honestly and not risk being thrown out of college?In the event I asked for 8,000 words because I wanted to see how it would handle organizing a larger piece of writing.  Now in the free version it can’t write that many words before it runs out of ‘tokens,’ but I wanted to see how the introduction would set up the organization for the bits it wouldn’t get to.  In practice it set up an essay in three or four chunks the first of which was 224 words; ChatGPT doesn’t seem to be able to even set up a larger and more complex piece of writing.  It also doesn’t plan for a number of words limited by how many it can get to before running out of tokens either, in case anyone thinks that’s what it was doing: to get to the end of the essay with all of the components it laid out in the introduction I had to jog it twice.Of course if the student has just tried honestly and failed, they’ll be able to document that process quite easily, with the works they read and where each wrong fact came from, whereas the student who has cheated using ChatGPT will be incapable of doing so.a hotly debated topic, actually!\t","length":55008,"excerpt":"So I stirred up a bit of conversation on Twitter last week when I noted that I had already been handed ChatGPT produced assignments. For those who are unaware, ChatGPT is an ‘AI’ chatbo…","byline":"Bret Devereaux","dir":null,"siteName":"A Collection of Unmitigated Pedantry","lang":"en-US"},"finalizedMeta":{"title":"Collections: On ChatGPT","description":"So I stirred up a bit of conversation on Twitter last week when I noted that I had already been handed ChatGPT produced assignments. For those who are unaware, ChatGPT is an ‘AI’ chatbo…","author":false,"creator":"","publisher":false,"date":"2023-02-17T22:47:59+00:00","topics":[]},"jsonLd":{"@type":false,"headline":false,"description":false,"image":[],"mainEntityOfPage":{"@type":false,"@id":false},"datePublished":false,"dateModified":false,"isAccessibleForFree":false,"isPartOf":{"@type":[],"name":false,"productID":false},"discussionUrl":false,"license":false,"author":{"@type":false,"name":false,"description":false,"sameAs":false,"image":{"@type":false,"url":false},"givenName":false,"familyName":false,"alternateName":false,"publishingPrinciples":false},"publisher":{"@type":false,"name":false,"description":false,"sameAs":false,"logo":{"@type":false,"url":false},"publishingPrinciples":false},"editor":{"@type":false,"name":false,"description":false,"sameAs":false,"image":{"@type":false,"url":false},"givenName":false,"familyName":false,"alternateName":false,"publishingPrinciples":false}},"twitterObj":false,"status":200,"metadata":{"author":false,"title":"Collections: On ChatGPT – A Collection of Unmitigated Pedantry","description":"So I stirred up a bit of conversation on Twitter last week when I noted that I had already been handed ChatGPT produced assignments. For those who are unaware, ChatGPT is an 'AI' chatbot that given a prompt can produce texts; it is one of most sophisticated bots of this sort yet devised, trained on…","canonical":"https://acoup.blog/2023/02/17/collections-on-chatgpt/","keywords":[],"image":"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?resize=1024%2C747&ssl=1","firstParagraph":"A Collection of Unmitigated Pedantry"},"dublinCore":{},"opengraph":{"title":"Collections: On ChatGPT","description":"So I stirred up a bit of conversation on Twitter last week when I noted that I had already been handed ChatGPT produced assignments. For those who are unaware, ChatGPT is an ‘AI’ chatbo…","url":"https://acoup.blog/2023/02/17/collections-on-chatgpt/","site_name":"A Collection of Unmitigated Pedantry","locale":"en_US","type":"article","typeObject":{"published_time":"2023-02-17T06:44:30+00:00","modified_time":"2023-02-17T22:47:59+00:00","author":false,"publisher":false,"section":false,"tag":[]},"image":"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?fit=1200%2C875&ssl=1","image:width":"1200","image:height":"875","image:alt":""},"twitter":{"site":false,"description":false,"card":"summary_large_image","creator":false,"title":false,"image":"https://i0.wp.com/acoup.blog/wp-content/uploads/2023/02/title-image-1.png?fit=1200%2C875&ssl=1&w=640","text:title":"Collections: On ChatGPT"},"archivedData":{"link":"https://web.archive.org/web/20230425140625/https://acoup.blog/2023/02/17/collections-on-chatgpt/","wayback":"https://web.archive.org/web/20230425140625/https://acoup.blog/2023/02/17/collections-on-chatgpt/"}}}