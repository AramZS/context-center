{"initialLink":"https://www.scientificamerican.com/article/the-ai-boom-could-use-a-shocking-amount-of-electricity/","sanitizedLink":"https://www.scientificamerican.com/article/the-ai-boom-could-use-a-shocking-amount-of-electricity/","finalLink":"https://www.scientificamerican.com/article/the-ai-boom-could-use-a-shocking-amount-of-electricity/","htmlEmbed":"<script>window.contexterSetup=window.contexterSetup||function(){window.contexterSetupComplete=!0;class ContexterLink extends HTMLAnchorElement{constructor(){super()}connectedCallback(){this.setAttribute(\"target\",\"_blank\")}}customElements.define(\"contexter-link\",ContexterLink,{extends:\"a\"}),customElements.define(\"contexter-inner\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__inner\"}}),customElements.define(\"contexter-thumbnail\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__thumbnail\"}}),customElements.define(\"contexter-byline\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__byline\"}}),customElements.define(\"contexter-keywordset\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__keywordset\"}}),customElements.define(\"contexter-linkset\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__linkset\"}}),customElements.define(\"contexter-meta\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__meta\"}}),customElements.define(\"contexter-summary\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"p-summary entry-summary\"}}),customElements.define(\"contexter-box-head\",class extends HTMLElement{constructor(){super()}connectedCallback(){this.className=\"contexter-box__head\"}}),customElements.define(\"contexter-box-inner\",class extends HTMLElement{constructor(){super()}connectedCallback(){}});class ContexterBox extends HTMLElement{constructor(){super(),this.first=!0,this.shadow=this.attachShadow({mode:\"open\"})}connectedCallback(){if(this.first){this.first=!1;var style=document.createElement(\"style\"),lightDomStyle=(style.innerHTML=`:host {--background: #f5f6f7;--border: darkblue;--blue: #0000ee;--font-color: black;--inner-border: black;font-family: Franklin,Arial,Helvetica,sans-serif;font-size: 14px;background: var(--background);width: 600px;color: var(--font-color);min-height: 90px;display: block;padding: 8px;border: 1px solid var(--border);cursor: pointer;box-sizing: border-box;margin: 6px;contain: content;margin: 6px auto;}// can only select top-level nodes with slotted::slotted(*) {max-width: 100%;display:block;}::slotted([slot=thumbnail]) {max-width: 100%;display:block;}::slotted([slot=header]) {width: 100%;font-size: 1.25rem;font-weight: bold;display:block;margin-bottom: 6px;}::slotted([slot=author]) {max-width: 50%;font-size: 12px;display:inline-block;float: left;}::slotted([slot=time]) {max-width: 50%;font-size: 12px;display:inline-block;float: right;}::slotted([slot=summary]) {width: 100%;margin-top: 6px;padding: 10px 2px;border-top: 1px solid var(--inner-border);font-size: 15px;display:inline-block;margin-bottom: 6px;}contexter-meta {height: auto;margin-bottom: 4px;width: 100%;display: grid;position: relative;min-height: 16px;grid-template-columns: repeat(2, 1fr);}::slotted([slot=keywords]) {width: 80%;padding: 2px 4px;border-top: 1px solid var(--inner-border);font-size: 11px;display: block;float: right;font-style: italic;text-align: right;grid-column: 2/2;grid-row: 1;align-self: end;justify-self: end;}::slotted([slot=keywords]):empty {border-top: 0px solid var(--inner-border);}::slotted([slot=archive-link]) {font-size: 1em;display: inline;}::slotted([slot=archive-link])::after {content: \"|\";display: inline;color: var(--font-color);text-decoration: none;margin: 0 .5em;}::slotted([slot=read-link]) {font-size: 1em;display: inline;}contexter-linkset {width: 80%;padding: 2px 4px;font-size: 13px;float: left;font-weight: bold;grid-row: 1;grid-column: 1/2;align-self: end;justify-self: start;}/* Extra small devices (phones, 600px and down) */@media only screen and (max-width: 600px) {:host {width: 310px;}}/* Small devices (portrait tablets and large phones, 600px and up) */@media only screen and (min-width: 600px) {...}/* Medium devices (landscape tablets, 768px and up) */@media only screen and (min-width: 768px) {...}/* Large devices (laptops/desktops, 992px and up) */@media only screen and (min-width: 992px) {...}/* Extra large devices (large laptops and desktops, 1200px and up) */@media only screen and (min-width: 1200px) {...}@media (prefers-color-scheme: dark){:host {--background: #354150;--border: #1f2b37;--blue: #55b0ff;--font-color: #ffffff;--inner-border: #787a7c;background: var(--background);border: 1px solid var(--border)}}`,document.createElement(\"style\"));lightDomStyle.innerHTML=`contexter-box {contain: content;}contexter-box .read-link {font-weight: bold;}contexter-box a {color: #0000ee;}contexter-box img {width: 100%;border: 0;padding: 0;margin: 0;}/* Extra small devices (phones, 600px and down) */@media only screen and (max-width: 600px) {...}/* Small devices (portrait tablets and large phones, 600px and up) */@media only screen and (min-width: 600px) {...}/* Medium devices (landscape tablets, 768px and up) */@media only screen and (min-width: 768px) {...}/* Large devices (laptops/desktops, 992px and up) */@media only screen and (min-width: 992px) {...}/* Extra large devices (large laptops and desktops, 1200px and up) */@media only screen and (min-width: 1200px) {...}@media (prefers-color-scheme: dark){contexter-box a {color: #55b0ff;}}`,this.appendChild(lightDomStyle),this.shadow.appendChild(style);const innerContainer=document.createElement(\"contexter-box-inner\"),innerSlotThumbnail=(this.shadow.appendChild(innerContainer),document.createElement(\"slot\")),innerSlotHeader=(innerSlotThumbnail.name=\"thumbnail\",innerContainer.appendChild(innerSlotThumbnail),document.createElement(\"slot\")),innerSlotAuthor=(innerSlotHeader.name=\"header\",innerContainer.appendChild(innerSlotHeader),document.createElement(\"slot\")),innerSlotTime=(innerSlotAuthor.name=\"author\",innerContainer.appendChild(innerSlotAuthor),document.createElement(\"slot\")),innerSlotSummary=(innerSlotTime.name=\"time\",innerContainer.appendChild(innerSlotTime),document.createElement(\"slot\")),metaContainer=(innerSlotSummary.name=\"summary\",innerContainer.appendChild(innerSlotSummary),document.createElement(\"contexter-meta\")),innerSlotInfo=(innerContainer.appendChild(metaContainer),document.createElement(\"slot\")),linkContainer=(innerSlotInfo.name=\"keywords\",metaContainer.appendChild(innerSlotInfo),document.createElement(\"contexter-linkset\")),innerSlotArchiveLink=(metaContainer.appendChild(linkContainer),document.createElement(\"slot\")),innerSlotReadLink=(innerSlotArchiveLink.name=\"archive-link\",linkContainer.appendChild(innerSlotArchiveLink),document.createElement(\"slot\"));innerSlotReadLink.name=\"read-link\",linkContainer.appendChild(innerSlotReadLink),this.className=\"contexter-box\",this.onclick=e=>{if(!e.target.className.includes(\"read-link\")&&!e.target.className.includes(\"title-link\")){const mainLinks=this.querySelectorAll(\"a.main-link\");mainLinks[0].click()}}}}}customElements.define(\"contexter-box\",ContexterBox)},window.contexterSetupComplete||window.contexterSetup();</script><contexter-box class=\"link-card h-entry hentry\" itemscope=\"\" itemtype=\"https://schema.org/CreativeWork\"><contexter-thumbnail class=\"thumbnail\" slot=\"thumbnail\"><img src=\"https://static.scientificamerican.com/sciam/cache/file/AE1CFA10-BB53-41CF-9D9F713DA1BA26B4_source.jpg?w=1200\" alt=\"\" itemprop=\"image\" /></contexter-thumbnail><contexter-box-head slot=\"header\" class=\"p-name entry-title\" itemprop=\"headline\"><contexter-box-head slot=\"header\" class=\"p-name entry-title\" itemprop=\"headline\"><a is=\"contexter-link\" href=\"https://www.scientificamerican.com/article/the-ai-boom-could-use-a-shocking-amount-of-electricity/\" itemprop=\"url\">The AI Boom Could Use a Shocking Amount of Electricity</a></contexter-box-head></contexter-box-head><contexter-byline class=\"p-author author\" slot=\"author\"><span class=\"p-name byline\" rel=\"author\" itemprop=\"author\">Lauren Leffer</span></contexter-byline><time class=\"dt-published published\" slot=\"time\" itemprop=\"datePublished\" datetime=\"2023-10-13T11:00:00.000Z\">10/13/2023</time><contexter-summary class=\"p-summary entry-summary\" itemprop=\"abstract\" slot=\"summary\"><p>Powering artificial intelligence models takes a lot of energy. A new analysis demonstrates just how big the problem could become</p></contexter-summary><contexter-keywordset itemprop=\"keywords\" slot=\"keywords\"></contexter-keywordset><a href=\"https://web.archive.org/web/20240625095137/https://www.scientificamerican.com/article/the-ai-boom-could-use-a-shocking-amount-of-electricity/\" is=\"contexter-link\" target=\"_blank\" rel=\"timemap\" class=\"read-link archive-link\" itemprop=\"archivedAt\" slot=\"archive-link\">Archived</a><a is=\"contexter-link\" href=\"https://www.scientificamerican.com/article/the-ai-boom-could-use-a-shocking-amount-of-electricity/\" class=\"read-link main-link\" itemprop=\"sameAs\" slot=\"read-link\">Read</a></contexter-box>","linkId":"ba6668f8c17a86aa38496d6b3f4324503ef324d1","data":{"originalLink":"https://www.scientificamerican.com/article/the-ai-boom-could-use-a-shocking-amount-of-electricity/","sanitizedLink":"https://www.scientificamerican.com/article/the-ai-boom-could-use-a-shocking-amount-of-electricity/","canonical":"https://www.scientificamerican.com/article/the-ai-boom-could-use-a-shocking-amount-of-electricity/","htmlText":"<!DOCTYPE html>\n<html lang=\"en\">\n  <head>\n    <meta charset=\"utf-8\" />\n    <title>The AI Boom Could Use a Shocking Amount of Electricity | Scientific American</title>\n    <link rel=\"canonical\" href=\"https://www.scientificamerican.com/article/the-ai-boom-could-use-a-shocking-amount-of-electricity/\">\n    <meta name=\"theme-color\" content=\"#fff\"/>\n    <meta name=\"robots\" content=\"max-image-preview:large\"/>\n    <link rel=\"image_src\" src=\"https://static.scientificamerican.com/sciam/cache/file/AE1CFA10-BB53-41CF-9D9F713DA1BA26B4_source.jpg?w=1200\">\n    <meta property=og:url content=\"https://www.scientificamerican.com/article/the-ai-boom-could-use-a-shocking-amount-of-electricity/\"/>\n    <meta property=og:image content=\"https://static.scientificamerican.com/sciam/cache/file/AE1CFA10-BB53-41CF-9D9F713DA1BA26B4_source.jpg?w=1200\"/>\n    <meta name=twitter:image content=\"https://static.scientificamerican.com/sciam/cache/file/AE1CFA10-BB53-41CF-9D9F713DA1BA26B4_source.jpg?w=1200\"/>\n    <meta name=author content=\"Lauren Leffer\"/>\n    <meta name=description content=\"Powering artificial intelligence models takes a lot of energy. A new analysis demonstrates just how big the problem could become\"/>\n    <meta property=og:title content=\"The AI Boom Could Use a Shocking Amount of Electricity\"/>\n    <meta property=og:description content=\"Powering artificial intelligence models takes a lot of energy. A new analysis demonstrates just how big the problem could become\"/>\n    <meta property=og:site_name content=\"Scientific American\"/>\n    <meta property=og:image:alt content=\"Equipment in server room\"/>\n    <meta property=og:type content=\"article\"/>\n    <meta name=twitter:title content=\"The AI Boom Could Use a Shocking Amount of Electricity\"/>\n    <meta name=twitter:description content=\"Powering artificial intelligence models takes a lot of energy. A new analysis demonstrates just how big the problem could become\"/>\n    <meta name=twitter:image:alt content=\"Equipment in server room\"/>\n    <meta property=og:locale content=\"en_US\"/>\n    <meta name=twitter:site content=\"@sciam\"/>\n    <meta name=twitter:domain content=\"scientificamerican.com\"/>\n    <meta name=twitter:card content=\"summary_large_image\"/>\n    <script type=\"application/ld+json\">{\"@context\":\"https://schema.org\",\"@type\":\"NewsArticle\",\"mainEntityOfPage\":{\"@type\":\"WebPage\",\"@id\":\"https://www.scientificamerican.com/article/the-ai-boom-could-use-a-shocking-amount-of-electricity/\",\"breadcrumb\":{\"@type\":\"BreadcrumbList\",\"itemListElement\":[{\"@type\":\"ListItem\",\"position\":1,\"name\":\"Energy\",\"item\":\"https://www.scientificamerican.com/energy/\"},{\"@type\":\"ListItem\",\"position\":2,\"name\":\"The AI Boom Could Use a Shocking Amount of Electricity\",\"item\":\"https://www.scientificamerican.com/article/the-ai-boom-could-use-a-shocking-amount-of-electricity/\"}]}},\"headline\":\"The AI Boom Could Use a Shocking Amount of Electricity\",\"alternativeHeadline\":\"The AI Boom Could Use a Shocking Amount of Electricity\",\"description\":\"Powering artificial intelligence models takes a lot of energy. A new analysis demonstrates just how big the problem could become\",\"url\":\"https://www.scientificamerican.com/article/the-ai-boom-could-use-a-shocking-amount-of-electricity/\",\"thumbnailUrl\":\"https://static.scientificamerican.com/sciam/cache/file/AE1CFA10-BB53-41CF-9D9F713DA1BA26B4_source.jpg?w=1200\",\"image\":[\"https://static.scientificamerican.com/sciam/cache/file/AE1CFA10-BB53-41CF-9D9F713DA1BA26B4_source.jpg?w=1200\",\"https://static.scientificamerican.com/sciam/cache/file/AE1CFA10-BB53-41CF-9D9F713DA1BA26B4_source.jpg?crop=16%3A9%2Csmart&w=1920\",\"https://static.scientificamerican.com/sciam/cache/file/AE1CFA10-BB53-41CF-9D9F713DA1BA26B4_source.jpg?crop=4%3A3%2Csmart&w=1200\",\"https://static.scientificamerican.com/sciam/cache/file/AE1CFA10-BB53-41CF-9D9F713DA1BA26B4_source.jpg?crop=1%3A1%2Csmart&w=1000\"],\"datePublished\":\"2023-10-13T11:00:00+00:00\",\"dateModified\":\"2024-02-20T11:46:41.809000+00:00\",\"author\":[{\"@type\":\"Person\",\"name\":\"Lauren Leffer\",\"url\":\"https://www.scientificamerican.com/author/lauren-leffer/\"}],\"isAccessibleForFree\":false,\"publisher\":{\"@id\":\"https://www.scientificamerican.com/#publisher\",\"name\":\"Scientific American\"},\"copyrightHolder\":{\"@id\":\"https://www.scientificamerican.com/#publisher\",\"name\":\"Scientific American\"}}</script>\n    <script type=\"application/ld+json\">{\"@context\":\"https://schema.org\",\"@type\":\"NewsMediaOrganization\",\"@id\":\"https://www.scientificamerican.com/#publisher\",\"name\":\"Scientific American\",\"alternateName\":\"SciAm\",\"legalName\":\"Scientific American, a Division of Springer Nature America, Inc.\",\"description\":\"Scientific American is the essential guide to the most awe-inspiring advances in science and technology, explaining how they change our understanding of the world and shape our lives.\",\"foundingDate\":\"1845-08-28\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https://www.scientificamerican.com/static/sciam.svg\"},\"url\":\"https://www.scientificamerican.com/\",\"masthead\":\"https://www.scientificamerican.com/masthead/\",\"sameAs\":[\"https://en.wikipedia.org/wiki/Scientific_American\",\"https://www.wikidata.org/wiki/Q39379\",\"https://www.jstor.org/publisher/sciamerican\",\"https://x.com/sciam\",\"https://www.youtube.com/user/SciAmerican\",\"https://www.tiktok.com/@scientificamerican\",\"https://www.threads.net/@scientific_american\",\"https://www.facebook.com/ScientificAmerican/\"],\"address\":{\"@type\":\"PostalAddress\",\"streetAddress\":\"1 New York Plaza\",\"addressLocality\":\"New York\",\"addressRegion\":\"NY\",\"postalCode\":\"10004\",\"addressCountry\":\"US\"}}</script>\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n    <link rel=\"icon shortcut\" href=\"https://www.scientificamerican.com/account/sciam-favicon.ico\" />\n    <link\n      rel=\"alternate\"\n      type=\"application/rss+xml\"\n      title=\"RSS\"\n      href=\"https://www.scientificamerican.com/platform/syndication/rss/\"\n    />\n    <script data-layer=\"critical\">;performance.mark('app-load-start');((d,ael,dcl,unl,cxl,log,onunl)=>{log('[readyState]',d.readyState);d[ael]('readystatechange',()=>log('[readyState]',d.readyState));d[ael](dcl,()=>log(dcl));d[ael](unl,onunl);window.onload=()=>{d.removeEventListener(unl,onunl);log('windowloaded')};})(document,'addEventListener','DOMContentLoaded','beforeunload','cancelled',(...msg)=>console.log('[dev]',...msg),()=>{window[cxl]=true;log(cxl)})</script>\n    <script type=\"module\" crossorigin src=\"/static/bundle.e9cca81f.js\"></script>\n    <link rel=\"modulepreload\" crossorigin href=\"/static/chunks/preload-helper-4b76a383.js\">\n    <link rel=\"modulepreload\" crossorigin href=\"/static/chunks/vendor-react-fc923b03.js\">\n    <link rel=\"modulepreload\" crossorigin href=\"/static/chunks/sciam-553c800f.js\">\n    <link rel=\"modulepreload\" crossorigin href=\"/static/chunks/datalayer-344da07f.js\">\n    <link rel=\"modulepreload\" crossorigin href=\"/static/chunks/use-page-df39437b.js\">\n    <link rel=\"modulepreload\" crossorigin href=\"/static/chunks/useOverlay-fde5367b.js\">\n    <link rel=\"stylesheet\" href=\"/static/assets/bundle-90d4e9d4.css\">\n    \n    <link rel=\"stylesheet\" href=\"/static/assets/Header-04186c49.css\">\n    <link rel=\"stylesheet\" href=\"/static/assets/Input-b967ce2c.css\">\n    <link rel=\"stylesheet\" href=\"/static/assets/index-73c5d4bd.css\">\n    <link rel=\"stylesheet\" href=\"/static/assets/ArticleDisplay-4dd85516.css\">\n    <link rel=\"stylesheet\" href=\"/static/assets/ArticleFooter-48e5f28a.css\">\n    <link rel=\"stylesheet\" href=\"/static/assets/6d1b2284.css\">\n    <link rel=\"stylesheet\" href=\"/static/assets/Article-a01e443c.css\">\n    <link rel=\"stylesheet\" href=\"/static/assets/DefaultLayout-4266d6e7.css\">\n    <link rel=\"stylesheet\" href=\"/static/assets/article-0798e3cc.css\">\n    <link rel=\"modulepreload\" href=\"/static/article.fe263603.js\" crossorigin fetchpriority=\"auto\">\n    <link rel=\"preload\" href=\"https://cdn.cookielaw.org/scripttemplates/otSDKStub.js\" as=\"script\" fetchpriority=\"auto\">\n    <link rel=\"preload\" href=\"https://www.googletagmanager.com/gtm.js?id=GTM-5FLM662\" as=\"script\" fetchpriority=\"auto\">\n    <link rel=\"preload\" href=\"https://www.scientificamerican.com/sciads/sciads.js\" as=\"script\" fetchpriority=\"auto\">\n    <link rel=\"preload\" href=\"https://cdn.tp.scientificamerican.com/api/tinypass.min.js\" as=\"script\" fetchpriority=\"low\">\n    <link rel=\"preconnect\" href=\"https://cdn.cxense.com/cx.cce.js\" as=\"script\">\n  </head>\n  <body>\n    <div id=\"app\"><header class=\"headerContainer-8KxQ5\"><a href=\"#main\" id=\"skipToMain\" class=\"skiptocontent sr-only-focusable sr-only\">Skip to main content</a><div class=\"header-1t1JE flex-aYeiI\"><div class=\"left-ajw3c flex-aYeiI\"><a href=\"/\" aria-label=\"Link to homepage\" class=\"logoLink-Wt3sq\"><span class=\"sr-only\">Scientific American</span><svg width=\"1em\" height=\"1em\" viewBox=\"0 0 120.79 128.39\" fill=\"currentColor\" role=\"img\" aria-label=\"Scientific American\"><path d=\"M7.98 58.19c2.3 0 5.24 3.18 14.53 3.18 13.66 0 21.75-8.57 21.75-17.86 0-7.86-3.73-12.94-11.43-17.23l-9.37-5.24c-4.05-2.3-7.46-5.32-7.46-9.92 0-4.92 3.73-7.7 9.69-7.7s11.35 4.21 13.02 13.26h1.98V.95h-1.83c-.16 1.43-.87 2.06-1.75 2.06-2.06 0-4.53-2.94-12.62-2.94C13.85.08 5.12 6.51 5.12 16.35c0 7.3 3.26 11.83 9.77 15.56l9.61 5.48c5.48 3.18 7.7 6.19 7.7 10.72 0 5.64-3.18 9.77-10.64 9.77-9.29 0-13.58-5.08-15.32-16.2H4.1V60.5h1.98c.16-1.67.95-2.3 1.91-2.3Zm65.97 3.26c11.11-.03 19.13-8.81 20.4-20.72l-2.22-.64c-2.54 8.26-7.22 12.46-13.97 12.46-12.23 0-16.04-14.93-16.04-27.87 0-15.56 6.11-21.28 14.13-21.28 5.72 0 11.83 5.72 14.45 16.59h2.06V.95h-1.91c-.16 1.27-.87 2.06-2.14 2.06-1.91 0-5.72-3.02-11.83-3.02-14.85 0-28.66 12.07-28.66 32.39 0 17.39 10.96 29.1 25.72 29.06Zm14.53 42.72L76.49 68.84H56.24v1.75c3.33.16 4.76.95 4.76 5.95v42c0 6.03-1.67 8.1-5.32 8.1-2.54 0-4.53-1.91-6.51-6.91L29.11 68.12h-2.7L6.35 119.89c-2.17 5.72-4.3 6.75-6.35 6.75v1.75h18.02v-1.75c-5.8-.24-8.65-2.7-5.8-10.48l2.05-5.4h17.88l3.45 8.97c2.3 5.72.64 6.91-3.73 6.91v1.75h39.62v-1.75c-4.13 0-6.27-1.19-6.27-8.02l.48-42.08 17.07 51.29h2.14l17.63-51.05v43.9c0 5.48-1.75 5.95-5.08 5.95v1.75h23.34v-1.75c-3.33 0-4.76-.48-4.76-5.95V76.54c0-5.56 1.43-5.95 4.76-5.95v-1.75h-19.85l-12.46 35.33Zm-72.88 3.1 7.56-19.85 7.63 19.85H15.6ZM120.79 2.7V.95h-23.1V2.7c3.33 0 4.84.32 4.84 5.95v44.14c0 5.48-1.51 5.95-4.84 5.95v1.75h23.1v-1.75c-3.33 0-4.76-.48-4.76-5.95V8.65c0-5.64 1.43-5.95 4.76-5.95Z\"></path></svg></a></div><div class=\"center-oMgM8 flex-aYeiI\"></div><div class=\"right-4LP3J flex-aYeiI\"><div class=\"profileIconDropdownContainer-DM-LM\"><button type=\"button\" class=\"profileIconLoggedOutBtn-F9aJJ\"><span class=\"sr-only\">Sign in</span><svg width=\"1em\" height=\"1em\" viewBox=\"0 0 472 472\" fill=\"currentColor\" role=\"img\" aria-label=\"User\" class=\"profileIconLoggedOutImg-UUxUk\"><path d=\"M403 69a235 235 0 0 0-334 0 235 235 0 0 0 0 334 235 235 0 0 0 334 0 235 235 0 0 0 0-334ZM118 412a122 122 0 0 1 237 0 211 211 0 0 1-237 0Zm41-197a77 77 0 1 1 155 0 77 77 0 0 1-155 0Zm216 181c-14-43-48-77-91-92a101 101 0 1 0-96 0c-43 15-77 49-91 92a212 212 0 1 1 278 0Z\"></path></svg></button></div></div></div></header><article class=\"article-GDG-h\"><div class=\"article__header-a5-f7\"><div class=\"article_date_and_read_time-NVTxn\"><p class=\"article_pub_date-mp61W\">October 13, 2023</p><p class=\"article_read_time-k3gXv\">5<!-- --> min read</p></div><h1 class=\"article_hed-LDnzF\"><p>The AI Boom Could Use a Shocking Amount of Electricity</p></h1><div class=\"article_dek-VydJj\"><p>Powering artificial intelligence models takes a lot of energy. A new analysis demonstrates just how big the problem could become</p></div><p class=\"article_authors-OZP24\">By <a class=\"article_authors__link-M7PNB\" href=\"/author/lauren-leffer/\">Lauren Leffer</a></p><figure class=\"lead_image-3nDcx\" data-disable-apple-news=\"true\"><img src=\"https://static.scientificamerican.com/sciam/cache/file/AE1CFA10-BB53-41CF-9D9F713DA1BA26B4_source.jpg?w=600\" alt=\"Equipment in server room\" srcSet=\"https://static.scientificamerican.com/sciam/cache/file/AE1CFA10-BB53-41CF-9D9F713DA1BA26B4_source.jpg?w=600 600w, https://static.scientificamerican.com/sciam/cache/file/AE1CFA10-BB53-41CF-9D9F713DA1BA26B4_source.jpg?w=900 900w, https://static.scientificamerican.com/sciam/cache/file/AE1CFA10-BB53-41CF-9D9F713DA1BA26B4_source.jpg?w=1000 1000w, https://static.scientificamerican.com/sciam/cache/file/AE1CFA10-BB53-41CF-9D9F713DA1BA26B4_source.jpg?w=1200 1200w, https://static.scientificamerican.com/sciam/cache/file/AE1CFA10-BB53-41CF-9D9F713DA1BA26B4_source.jpg?w=1350 1350w\" sizes=\"(min-width: 900px) 900px, (min-resolution: 2dppx) 75vw, (min-resolution: 2.1dppx) 50vw, 100vw\" class=\"lead_image__img-e3fpf\" style=\"--w:5123;--h:3415\" fetchpriority=\"high\"/><figcaption class=\"lead_image__figcaption-Y9Y9T\"> <div class=\"lead_image__credit-jEB44\"><p><a href=\"https://www.gettyimages.com/detail/photo/equipment-in-server-room-royalty-free-image/885294104\">Erik Isakson/Getty Images</a></p></div></figcaption></figure><div class=\"article_eyebrows-1uGmS\"><div class=\"eyebrows_container-QeE5W\"></div></div></div><div class=\"article__content-24wun\"><p class=\"article__block-KZIY9\" data-block=\"sciam/paragraph\">Every online interaction relies on a scaffolding of information stored in remote servers&mdash;and those machines, stacked together in data centers worldwide, require a lot of energy. Around the globe, data centers currently account for about <a href=\"https://www.iea.org/energy-system/buildings/data-centres-and-data-transmission-networks#overview\">1 to 1.5 percent of global electricity use</a>, according to the International Energy Agency. And the world&rsquo;s still-exploding boom in artificial intelligence could drive that number up a lot&mdash;and fast.</p><p class=\"article__block-KZIY9\" data-block=\"sciam/paragraph\">Researchers have been raising general alarms about <a href=\"https://www.scientificamerican.com/article/a-computer-scientist-breaks-down-generative-ais-hefty-carbon-footprint/\">AI&rsquo;s hefty energy requirements</a> over the past few months. But a peer-reviewed analysis published this week in <i>Joule</i> is one of the first to quantify the demand that is quickly materializing. A continuation of the current trends in AI capacity and adoption are set to lead to NVIDIA shipping 1.5 million AI server units per year by 2027. These 1.5 million servers, running at full capacity, would <a href=\"https://www.cell.com/joule/fulltext/S2542-4351(23)00365-3\">consume at least 85.4 terawatt-hours of electricity annually</a>&mdash;more than what many small countries use in a year, according to the new assessment.</p><p class=\"article__block-KZIY9\" data-block=\"sciam/paragraph\">The analysis was conducted by Alex de Vries, a data scientist at the central bank of the Netherlands and a Ph.D. candidate at Vrije University Amsterdam, where he studies the energy costs of emerging technologies. Earlier de Vries gained prominence for sounding the alarm on the <a href=\"https://www.scientificamerican.com/article/cryptocurrencies-and-nfts-are-a-buyer-beware-market/\">enormous energy costs of cryptocurrency</a> mining and transactions. Now he has turned his attention to the latest tech fad. <i>Scientific American</i> spoke with him about AI&rsquo;s shocking appetite for electricity.</p><hr/><h2 class=\"article__block-KZIY9\">On supporting science journalism</h2><p class=\"article__block-KZIY9\">If you&#x27;re enjoying this article, consider supporting our award-winning journalism by<!-- --> <a href=\"/getsciam/\">subscribing</a>. By purchasing a subscription you are helping to ensure the future of impactful stories about the discoveries and ideas shaping our world today.</p><hr/><p class=\"article__block-KZIY9\" data-block=\"sciam/paragraph\">[<i>An edited and condensed transcript of the interview follows.</i>]</p><p class=\"article__block-KZIY9\" data-block=\"sciam/paragraph\"><b>Why do you think it&rsquo;s important to examine the energy consumption of artificial intelligence?</b></p><p class=\"article__block-KZIY9\" data-block=\"sciam/paragraph\">Because AI is energy-intensive. I put one example of this in my research article: I highlighted that if you were to fully turn Google&rsquo;s search engine into something like ChatGPT, and everyone used it that way&mdash;so you would have nine billion chatbot interactions instead of nine billion regular searches per day&mdash;then the energy use of Google would spike. Google would need as much power as Ireland just to run its search engine.</p><p class=\"article__block-KZIY9\" data-block=\"sciam/paragraph\">Now, it&rsquo;s not going to happen like that because Google would also have to invest $100 billion in hardware to make that possible. And even if [the company] had the money to invest, the supply chain couldn&rsquo;t deliver all those servers right away. But I still think it&rsquo;s useful to illustrate that if you&rsquo;re going to be using generative AI in applications [such as a search engine], that has the potential to make every online interaction much more resource-heavy.</p><p class=\"article__block-KZIY9\" data-block=\"sciam/paragraph\">I think it&rsquo;s healthy to at least include sustainability when we talk about the risk of AI. When we talk about the potential risk of errors, the unknowns of the black box, or AI discrimination bias, we should be including sustainability as a risk factor as well. I hope that my article will at least encourage the thought process in that direction. If we&rsquo;re going to be using AI, is it going to help? Can we do it in a responsible way? Do we really need to be using this technology in the first place? What is it that an end user wants and needs, and how do we best help them? If AI is part of that solution, okay, go ahead. But if it&rsquo;s not, then don&rsquo;t put it in.</p><p class=\"article__block-KZIY9\" data-block=\"sciam/paragraph\"><b>What parts of AI&rsquo;s processes are using all that energy?</b></p><p class=\"article__block-KZIY9\" data-block=\"sciam/paragraph\">You generally have two big phases when it comes to AI. One is a training phase, which is where you&rsquo;re setting up and getting the model to teach itself how to behave. And then you have an inference phase, where you just put the model into a live operation and start feeding it prompts so it can produce original responses. Both phases are very energy-intensive, and we don&rsquo;t really know what the energy ratio there is. Historically, with Google, the balance was 60 percent inference, 40 percent training. But then with ChatGPT that kind of broke down&mdash;because training ChatGPT took comparatively very little energy consumption, compared with applying the model.</p><p class=\"article__block-KZIY9\" data-block=\"sciam/paragraph\">It&rsquo;s dependent on a lot of factors, such as how much data are included in these models. I mean, these large language models that ChatGPT is powered by are notorious for using huge data sets and having billions of parameters. And of course, making these models larger is a factor that contributes to them just needing more power&mdash;but it is also how companies make their models more robust.</p><p class=\"article__block-KZIY9\" data-block=\"sciam/paragraph\"><b>What are some of the other variables to consider when thinking about AI energy usage?</b></p><p class=\"article__block-KZIY9\" data-block=\"sciam/paragraph\">Cooling is not included in my article, but if there were any data to go on, it would have been. A big unknown is where those servers are going to end up. That matters a whole lot, because if they&rsquo;re at Google, then the additional cooling energy use is going to be somewhere in the range of a 10 percent increase. But global data centers, on average, will add 50 percent to the energy cost just to keep the machines cool. There are data centers that perform even worse than that.</p><p class=\"article__block-KZIY9\" data-block=\"sciam/paragraph\">What type of hardware you&rsquo;re using also matters. The latest servers are more efficient than older ones. What you&rsquo;re going to be using the AI technology for matters, too. The more complicated a request, and the longer the servers are working to fulfill it, the more power is consumed.</p><p class=\"article__block-KZIY9\" data-block=\"sciam/paragraph\"><b>In your assessment, you outline a few different energy-use scenarios from worst- to best-case. Which is the most likely?</b></p><p class=\"article__block-KZIY9\" data-block=\"sciam/paragraph\">In the worst-case scenario, if we decide we&rsquo;re going to do everything on AI, then every data center is going to experience effectively a 10-fold increase in energy consumption. That would be a massive explosion in global electricity consumption because data centers, not including cryptocurrency mining, are already responsible for consuming about 1 percent of global electricity. Now, again, that&rsquo;s not going to happen&mdash;that&rsquo;s not realistic at all. It&rsquo;s a useful example to illustrate that AI is very energy-intensive.</p><p class=\"article__block-KZIY9\" data-block=\"sciam/paragraph\">On the opposite end, you have this idea of no growth&mdash;zero. You have people saying that the growth in demand will be completely offset by improving efficiency, but that&rsquo;s a very optimistic take that doesn&rsquo;t include what we understand about demand and efficiency. Every time a major new technology makes a process more efficient, it actually leads to more people demanding whatever is being produced. Efficiency boosts demand, so boosting efficiency is not really saving energy in the end.</p><p class=\"article__block-KZIY9\" data-block=\"sciam/paragraph\">What do I think is the most likely path going forward? I think the answer is that there&rsquo;s going to be a growth in AI-related electricity consumption. At least initially, it&rsquo;s going to be somewhat slow. But there&rsquo;s the possibility that it accelerates in a couple of years as server production increases. Knowing this gives us some time to think about what we&rsquo;re doing.</p><p class=\"article__block-KZIY9\" data-block=\"sciam/paragraph\"><b>What additional research or other steps might be needed?</b></p><p class=\"article__block-KZIY9\" data-block=\"sciam/paragraph\">We need a higher quality of data. We need to know where these servers are going. We need to know the source of the energy itself. Carbon emissions are the real numbers that we care about when it comes to environmental impact. Energy demand is one thing, but is it coming from renewables? Is it coming from fossil fuels?</p><p class=\"article__block-KZIY9\" data-block=\"sciam/paragraph\">Maybe regulators should start requiring energy use disclosures from AI developers because there&rsquo;s just very little information to go on. It was really hard to do this analysis&mdash;anyone who is trying to work on AI at the moment is facing the same challenges, where information is limited. I think it would help if there was more transparency. And if that transparency doesn&rsquo;t come naturally, which it hasn&rsquo;t so far, then we should think about giving it a little bit of a push.</p></div><footer class=\"footer-u1I4n\"><div class=\"divide-L7a-x\"><div class=\"rights-Y0o9k\"><a target=\"_blank\" href=\"https://s100.copyright.com/AppDispatchServlet?publisherName=sciam&amp;publication=sciam&amp;title=The+AI+Boom+Could+Use+a+Shocking+Amount+of+Electricity&amp;publicationDate=2023-10-13&amp;contentID=C93BCC54-1548-4994-9FAC38153FF07F03&amp;orderBeanReset=true&amp;author=Lauren+Leffer&amp;copyright=Copyright+2023+Scientific+American%2C+Inc.\">Rights &amp; Permissions</a></div></div><div class=\"divide-L7a-x\"></div><div class=\"divide-L7a-x\"><div class=\"subdivide-5Zp4J\"><div class=\"bio-LnT3Q\"><p><b><a class=\"bioLink-kqdDv\" href=\"/author/lauren-leffer/\">Lauren Leffer</a></b> is a contributing writer and former tech reporting fellow at <i>Scientific American</i>. She covers many subjects, including artificial intelligence, climate and weird biology, because she's curious to a fault. Follow her on X <a href=\"https://twitter.com/lauren_leffer\">@lauren_leffer</a> and on Bluesky <a href=\"https://bsky.app/profile/did:plc:2s3v2ytoofduo2ssame5netd\">@laurenleffer.bsky.social</a></p></div><a href=\"/author/lauren-leffer/\">More by <span>Lauren Leffer</span></a></div></div><div class=\"divide-L7a-x\"></div></footer><div class=\"breakoutContainer-8fsaw\"><gpt-ad class=\"ad-G8iDN\" unitpath=\"injector\" style=\"--margin:20px 0\" sizes-from-0=\"320x450,300x250,300x50,320x50,fluid\" sizes-from-745=\"320x450,728x90,300x250,fluid\" sizes-from-1000=\"970x350,970x250,970x90,728x90,300x250,fluid\" targeting-pos=\"article-footer\"></gpt-ad></div></article><div class=\"articleList-R10iq root-fREBs\"><div class=\"articleListGrid-N4wvY grid-PoVrj containerHideLastItemIfNativeLoads-PffoX\"></div></div><footer class=\"footer-VfsmT\"><div class=\"footerContainer-pfbjC\"><h2 class=\"footerMainText-wQ3og\">Expand Your World with Science</h2></div><div class=\"footerFlexContainer-XKe5g footerContainer-pfbjC\"><div class=\"footerLinks-m1THn\"><p class=\"footerText-PzHcy\">Learn and share the most exciting discoveries, innovations and ideas shaping our world today.</p><a class=\"footerLink-uRzI4\" href=\"https://www.scientificamerican.com/getsciam/\">Subscribe</a><a class=\"footerLink-uRzI4\" href=\"https://www.scientificamerican.com/newsletter-signup/\">Sign up for our newsletters</a><a class=\"footerLink-uRzI4\" href=\"https://www.scientificamerican.com/\">See the latest stories</a><a class=\"footerLink-uRzI4\" href=\"https://www.scientificamerican.com/latest-issue/\">Read the latest issue</a><a class=\"footerLink-uRzI4\" href=\"https://www.scientificamerican.com/getsciam/gift/\">Give a Gift Subscription</a><p class=\"footerSocialMedia-7KIIV\">Follow Us:<a href=\"https://www.instagram.com/scientific_american/?hl=en\" alt=\"Instagram link\" title=\"Instagram\"><svg class=\"footerSocialIcon-UQyIx\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 448 512\"><path d=\"M224.1 141c-63.6 0-114.9 51.3-114.9 114.9s51.3 114.9 114.9 114.9S339 319.5 339 255.9 287.7 141 224.1 141zm0 189.6c-41.1 0-74.7-33.5-74.7-74.7s33.5-74.7 74.7-74.7 74.7 33.5 74.7 74.7-33.6 74.7-74.7 74.7zm146.4-194.3c0 14.9-12 26.8-26.8 26.8-14.9 0-26.8-12-26.8-26.8s12-26.8 26.8-26.8 26.8 12 26.8 26.8zm76.1 27.2c-1.7-35.9-9.9-67.7-36.2-93.9-26.2-26.2-58-34.4-93.9-36.2-37-2.1-147.9-2.1-184.9 0-35.8 1.7-67.6 9.9-93.9 36.1s-34.4 58-36.2 93.9c-2.1 37-2.1 147.9 0 184.9 1.7 35.9 9.9 67.7 36.2 93.9s58 34.4 93.9 36.2c37 2.1 147.9 2.1 184.9 0 35.9-1.7 67.7-9.9 93.9-36.2 26.2-26.2 34.4-58 36.2-93.9 2.1-37 2.1-147.8 0-184.8zM398.8 388c-7.8 19.6-22.9 34.7-42.6 42.6-29.5 11.7-99.5 9-132.1 9s-102.7 2.6-132.1-9c-19.6-7.8-34.7-22.9-42.6-42.6-11.7-29.5-9-99.5-9-132.1s-2.6-102.7 9-132.1c7.8-19.6 22.9-34.7 42.6-42.6 29.5-11.7 99.5-9 132.1-9s102.7-2.6 132.1 9c19.6 7.8 34.7 22.9 42.6 42.6 11.7 29.5 9 99.5 9 132.1s2.7 102.7-9 132.1z\"></path></svg></a><a href=\"https://www.youtube.com/user/SciAmerican\" alt=\"YouTube link\" title=\"YouTube\"><svg class=\"footerSocialIcon-UQyIx\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 576 512\"><path d=\"M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z\"></path></svg></a><a href=\"https://twitter.com/sciam\" alt=\"Twitter link\" title=\"Twitter\"><svg class=\"footerSocialIcon-UQyIx\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 512 512\"><path d=\"M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z\"></path></svg></a><a href=\"https://www.facebook.com/ScientificAmerican\" alt=\"Facebook link\" title=\"Facebook\"><svg class=\"footerSocialIcon-UQyIx\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 320 512\"><path d=\"M279.14 288l14.22-92.66h-88.91v-60.13c0-25.35 12.42-50.06 52.24-50.06h40.42V6.26S260.43 0 225.36 0c-73.22 0-121.08 44.38-121.08 124.72v70.62H22.89V288h81.39v224h100.17V288z\"></path></svg></a><a href=\"/platform/syndication/rss/\" alt=\"RSS feed\" title=\"RSS feed\"><svg class=\"footerSocialIcon-UQyIx\" xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 448 512\"><path d=\"M0 64C0 46.3 14.3 32 32 32c229.8 0 416 186.2 416 416c0 17.7-14.3 32-32 32s-32-14.3-32-32C384 253.6 226.4 96 32 96C14.3 96 0 81.7 0 64zM0 416a64 64 0 1 1 128 0A64 64 0 1 1 0 416zM32 160c159.1 0 288 128.9 288 288c0 17.7-14.3 32-32 32s-32-14.3-32-32c0-123.7-100.3-224-224-224c-17.7 0-32-14.3-32-32s14.3-32 32-32z\"></path></svg></a></p></div><div class=\"footerImageContainer-omuef\"><img class=\"footerImage-fMFhw\" src=\"/static/assets/footerProductImg-f6732134.png\" alt=\"Scientific American publications in print &amp; digital formats\" as=\"image\" loading=\"lazy\"/></div></div><div class=\"grid-c0--6 footerContainer-pfbjC\"><div><ul><li><a class=\"footerSmallLink-tZvCu\" href=\"https://www.scientificamerican.com/page/return-refund-policy/\">Return &amp; Refund Policy</a></li><li><a class=\"footerSmallLink-tZvCu\" href=\"https://www.scientificamerican.com/page/about-scientific-american/\">About</a></li><li><a class=\"footerSmallLink-tZvCu\" href=\"https://www.scientificamerican.com/pressroom/\">Press Room</a></li></ul></div><div><ul class=\"footer-links\"><li><a class=\"footerSmallLink-tZvCu\" href=\"/page/frequently-asked-questions/subscriptions-products/\">FAQs</a></li><li><a class=\"footerSmallLink-tZvCu\" href=\"https://www.scientificamerican.com/page/contact-us/customer-service/\">Contact Us</a></li><li><a class=\"footerSmallLink-tZvCu\" href=\"https://www.scientificamerican.com/page/international/\">International Editions</a></li></ul></div><div><ul class=\"footer-links\"><li><a class=\"footerSmallLink-tZvCu\" href=\"https://www.scientificamerican.com/mediakit/\">Advertise</a></li><li><a class=\"footerSmallLink-tZvCu\" href=\"https://www.scientificamerican.com/accessibility-statement/\">Accessibility Statement</a></li><li><a class=\"footerSmallLink-tZvCu\" href=\"https://www.scientificamerican.com/page/terms-of-use/\">Terms of Use</a></li></ul></div><div><ul class=\"footer-links\"><li><a class=\"footerSmallLink-tZvCu\" href=\"https://www.scientificamerican.com/page/privacy-policy/\">Privacy Policy</a></li><li><a class=\"footerSmallLink-tZvCu\" href=\"https://www.scientificamerican.com/page/california-consumer-privacy-statement/\">California Consumer Privacy Statement</a></li><li><a class=\"footerSmallLink-tZvCu\" href=\"#\">Use of cookies/Do not sell my data</a></li></ul></div></div><div class=\"footerContainer-pfbjC\"><p>Scientific American is part of Springer Nature, which owns or has commercial relations with thousands of scientific publications (many of them can be found at www.springernature.com/us). Scientific American maintains a strict policy of editorial independence in reporting developments in science to our readers.</p><p>© 2024 SCIENTIFIC AMERICAN, A DIVISION OF SPRINGER NATURE AMERICA, INC.<br/>ALL RIGHTS RESERVED.</p></div></footer></div>\n    <script id=\"__DATA__\">window.__DATA__=JSON.parse(`{\"initialData\":{\"article\":{\"id\":1305790,\"contentful_id\":\"246IYwSU7ld4TrLQrYNkcZ\",\"mura_id\":\"2E3A3B5B-9E02-4E59-B1587E097C3381E5\",\"mura_contentid\":\"C93BCC54-1548-4994-9FAC38153FF07F03\",\"title\":\"The AI Boom Could Use a Shocking Amount of Electricity\",\"display_title\":\"<p>The AI Boom Could Use a Shocking Amount of Electricity</p>\",\"share_title\":null,\"display_category\":\"Energy\",\"display_category_slug\":\"energy\",\"display_date\":null,\"slug\":\"the-ai-boom-could-use-a-shocking-amount-of-electricity\",\"summary\":\"<p>Powering artificial intelligence models takes a lot of energy. A new analysis demonstrates just how big the problem could become</p>\",\"why_box\":\"\",\"content\":[{\"tag\":\"p\",\"type\":\"paragraph\",\"attributes\":{},\"content\":\"Every online interaction relies on a scaffolding of information stored in remote servers&mdash;and those machines, stacked together in data centers worldwide, require a lot of energy. Around the globe, data centers currently account for about <a href=\\\\\"https://www.iea.org/energy-system/buildings/data-centres-and-data-transmission-networks#overview\\\\\">1 to 1.5 percent of global electricity use</a>, according to the International Energy Agency. And the world&rsquo;s still-exploding boom in artificial intelligence could drive that number up a lot&mdash;and fast.\"},{\"tag\":\"p\",\"type\":\"paragraph\",\"attributes\":{},\"content\":\"Researchers have been raising general alarms about <a href=\\\\\"https://www.scientificamerican.com/article/a-computer-scientist-breaks-down-generative-ais-hefty-carbon-footprint/\\\\\">AI&rsquo;s hefty energy requirements</a> over the past few months. But a peer-reviewed analysis published this week in <i>Joule</i> is one of the first to quantify the demand that is quickly materializing. A continuation of the current trends in AI capacity and adoption are set to lead to NVIDIA shipping 1.5 million AI server units per year by 2027. These 1.5 million servers, running at full capacity, would <a href=\\\\\"https://www.cell.com/joule/fulltext/S2542-4351(23)00365-3\\\\\">consume at least 85.4 terawatt-hours of electricity annually</a>&mdash;more than what many small countries use in a year, according to the new assessment.\"},{\"tag\":\"p\",\"type\":\"paragraph\",\"attributes\":{},\"content\":\"The analysis was conducted by Alex de Vries, a data scientist at the central bank of the Netherlands and a Ph.D. candidate at Vrije University Amsterdam, where he studies the energy costs of emerging technologies. Earlier de Vries gained prominence for sounding the alarm on the <a href=\\\\\"https://www.scientificamerican.com/article/cryptocurrencies-and-nfts-are-a-buyer-beware-market/\\\\\">enormous energy costs of cryptocurrency</a> mining and transactions. Now he has turned his attention to the latest tech fad. <i>Scientific American</i> spoke with him about AI&rsquo;s shocking appetite for electricity.\"},{\"tag\":\"p\",\"type\":\"paragraph\",\"attributes\":{},\"content\":\"[<i>An edited and condensed transcript of the interview follows.</i>]\"},{\"tag\":\"p\",\"type\":\"paragraph\",\"attributes\":{},\"content\":\"<b>Why do you think it&rsquo;s important to examine the energy consumption of artificial intelligence?</b>\"},{\"tag\":\"p\",\"type\":\"paragraph\",\"attributes\":{},\"content\":\"Because AI is energy-intensive. I put one example of this in my research article: I highlighted that if you were to fully turn Google&rsquo;s search engine into something like ChatGPT, and everyone used it that way&mdash;so you would have nine billion chatbot interactions instead of nine billion regular searches per day&mdash;then the energy use of Google would spike. Google would need as much power as Ireland just to run its search engine.\"},{\"tag\":\"p\",\"type\":\"paragraph\",\"attributes\":{},\"content\":\"Now, it&rsquo;s not going to happen like that because Google would also have to invest $100 billion in hardware to make that possible. And even if [the company] had the money to invest, the supply chain couldn&rsquo;t deliver all those servers right away. But I still think it&rsquo;s useful to illustrate that if you&rsquo;re going to be using generative AI in applications [such as a search engine], that has the potential to make every online interaction much more resource-heavy.\"},{\"tag\":\"p\",\"type\":\"paragraph\",\"attributes\":{},\"content\":\"I think it&rsquo;s healthy to at least include sustainability when we talk about the risk of AI. When we talk about the potential risk of errors, the unknowns of the black box, or AI discrimination bias, we should be including sustainability as a risk factor as well. I hope that my article will at least encourage the thought process in that direction. If we&rsquo;re going to be using AI, is it going to help? Can we do it in a responsible way? Do we really need to be using this technology in the first place? What is it that an end user wants and needs, and how do we best help them? If AI is part of that solution, okay, go ahead. But if it&rsquo;s not, then don&rsquo;t put it in.\"},{\"tag\":\"p\",\"type\":\"paragraph\",\"attributes\":{},\"content\":\"<b>What parts of AI&rsquo;s processes are using all that energy?</b>\"},{\"tag\":\"p\",\"type\":\"paragraph\",\"attributes\":{},\"content\":\"You generally have two big phases when it comes to AI. One is a training phase, which is where you&rsquo;re setting up and getting the model to teach itself how to behave. And then you have an inference phase, where you just put the model into a live operation and start feeding it prompts so it can produce original responses. Both phases are very energy-intensive, and we don&rsquo;t really know what the energy ratio there is. Historically, with Google, the balance was 60 percent inference, 40 percent training. But then with ChatGPT that kind of broke down&mdash;because training ChatGPT took comparatively very little energy consumption, compared with applying the model.\"},{\"tag\":\"p\",\"type\":\"paragraph\",\"attributes\":{},\"content\":\"It&rsquo;s dependent on a lot of factors, such as how much data are included in these models. I mean, these large language models that ChatGPT is powered by are notorious for using huge data sets and having billions of parameters. And of course, making these models larger is a factor that contributes to them just needing more power&mdash;but it is also how companies make their models more robust.\"},{\"tag\":\"p\",\"type\":\"paragraph\",\"attributes\":{},\"content\":\"<b>What are some of the other variables to consider when thinking about AI energy usage?</b>\"},{\"tag\":\"p\",\"type\":\"paragraph\",\"attributes\":{},\"content\":\"Cooling is not included in my article, but if there were any data to go on, it would have been. A big unknown is where those servers are going to end up. That matters a whole lot, because if they&rsquo;re at Google, then the additional cooling energy use is going to be somewhere in the range of a 10 percent increase. But global data centers, on average, will add 50 percent to the energy cost just to keep the machines cool. There are data centers that perform even worse than that.\"},{\"tag\":\"p\",\"type\":\"paragraph\",\"attributes\":{},\"content\":\"What type of hardware you&rsquo;re using also matters. The latest servers are more efficient than older ones. What you&rsquo;re going to be using the AI technology for matters, too. The more complicated a request, and the longer the servers are working to fulfill it, the more power is consumed.\"},{\"tag\":\"p\",\"type\":\"paragraph\",\"attributes\":{},\"content\":\"<b>In your assessment, you outline a few different energy-use scenarios from worst- to best-case. Which is the most likely?</b>\"},{\"tag\":\"p\",\"type\":\"paragraph\",\"attributes\":{},\"content\":\"In the worst-case scenario, if we decide we&rsquo;re going to do everything on AI, then every data center is going to experience effectively a 10-fold increase in energy consumption. That would be a massive explosion in global electricity consumption because data centers, not including cryptocurrency mining, are already responsible for consuming about 1 percent of global electricity. Now, again, that&rsquo;s not going to happen&mdash;that&rsquo;s not realistic at all. It&rsquo;s a useful example to illustrate that AI is very energy-intensive.\"},{\"tag\":\"p\",\"type\":\"paragraph\",\"attributes\":{},\"content\":\"On the opposite end, you have this idea of no growth&mdash;zero. You have people saying that the growth in demand will be completely offset by improving efficiency, but that&rsquo;s a very optimistic take that doesn&rsquo;t include what we understand about demand and efficiency. Every time a major new technology makes a process more efficient, it actually leads to more people demanding whatever is being produced. Efficiency boosts demand, so boosting efficiency is not really saving energy in the end.\"},{\"tag\":\"p\",\"type\":\"paragraph\",\"attributes\":{},\"content\":\"What do I think is the most likely path going forward? I think the answer is that there&rsquo;s going to be a growth in AI-related electricity consumption. At least initially, it&rsquo;s going to be somewhat slow. But there&rsquo;s the possibility that it accelerates in a couple of years as server production increases. Knowing this gives us some time to think about what we&rsquo;re doing.\"},{\"tag\":\"p\",\"type\":\"paragraph\",\"attributes\":{},\"content\":\"<b>What additional research or other steps might be needed?</b>\"},{\"tag\":\"p\",\"type\":\"paragraph\",\"attributes\":{},\"content\":\"We need a higher quality of data. We need to know where these servers are going. We need to know the source of the energy itself. Carbon emissions are the real numbers that we care about when it comes to environmental impact. Energy demand is one thing, but is it coming from renewables? Is it coming from fossil fuels?\"},{\"tag\":\"p\",\"type\":\"paragraph\",\"attributes\":{},\"content\":\"Maybe regulators should start requiring energy use disclosures from AI developers because there&rsquo;s just very little information to go on. It was really hard to do this analysis&mdash;anyone who is trying to work on AI at the moment is facing the same challenges, where information is limited. I think it would help if there was more transparency. And if that transparency doesn&rsquo;t come naturally, which it hasn&rsquo;t so far, then we should think about giving it a little bit of a push.\"}],\"authors\":[{\"mura_id\":\"8575CDD7-515C-47F1-A6C41AACA3FE59C1\",\"url\":\"/author/lauren-leffer/\",\"contentful_id\":\"7hVz0b87JKK9TWoPbko9ti\",\"name\":\"Lauren Leffer\",\"slug\":\"lauren-leffer\",\"biography\":\"<p><b>Lauren Leffer</b> is a contributing writer and former tech reporting fellow at <i>Scientific American</i>. She covers many subjects, including artificial intelligence, climate and weird biology, because she's curious to a fault. Follow her on X <a href=\\\\\"https://twitter.com/lauren_leffer\\\\\">@lauren_leffer</a> and on Bluesky <a href=\\\\\"https://bsky.app/profile/did:plc:2s3v2ytoofduo2ssame5netd\\\\\">@laurenleffer.bsky.social</a></p>\",\"picture_file\":null,\"contacts\":[]}],\"editors\":[{\"mura_id\":\"851A9547-D637-4842-808853D625701931\",\"url\":\"/author/sophie-bushwick/\",\"contentful_id\":\"1kN6x2EquH4W9oNsI8LRMv\",\"name\":\"Sophie Bushwick\",\"slug\":\"sophie-bushwick\",\"biography\":\"<p><b>Sophie Bushwick</b> is tech editor at <i>Scientific American</i>. She runs the daily technology news coverage for the website, writes about everything from artificial intelligence to jumping robots for both digital and print publication, records YouTube and TikTok videos and hosts the podcast <i>Tech, Quickly</i>. Bushwick also makes frequent appearances on radio shows such as <i>Science Friday</i> and television networks, including CBS, MSNBC and National Geographic. She has more than a decade of experience as a science journalist based in New York City and previously worked at outlets such as <i>Popular Science,</i><i>Discover</i> and Gizmodo. Follow Bushwick on X (formerly Twitter) <a href=\\\\\"https://twitter.com/sophiebushwick\\\\\">@sophiebushwick</a></p>\",\"picture_file\":null,\"contacts\":[]}],\"image_url\":\"https://static.scientificamerican.com/sciam/cache/file/AE1CFA10-BB53-41CF-9D9F713DA1BA26B4_source.jpg\",\"image_width\":5123,\"image_height\":3415,\"image_alt_text\":\"Equipment in server room\",\"image_caption\":null,\"image_credits\":\"<p><a href=\\\\\"https://www.gettyimages.com/detail/photo/equipment-in-server-room-royalty-free-image/885294104\\\\\">Erik Isakson/Getty Images</a></p>\",\"image_desktop_url\":null,\"image_desktop_width\":0,\"image_desktop_height\":0,\"image_block_syndication\":true,\"release_date\":\"2023-10-13T11:00:00+00:00\",\"primary_category\":\"Technology\",\"primary_category_slug\":\"technology\",\"subcategory\":\"Energy\",\"subcategory_slug\":\"energy\",\"subtype\":\"news\",\"column\":null,\"digital_column\":null,\"digital_column_slug\":null,\"digital_column_frequency\":null,\"digital_column_description\":null,\"digital_column_newsletter_id\":null,\"partner_title\":null,\"partner_url\":null,\"partner_end_note\":null,\"article_doi\":null,\"categories\":[\"Artificial Intelligence\",\"Computing\",\"Energy\",\"Environment\",\"Machine learning\",\"Power grid\",\"Technology\"],\"contains_media\":null,\"is_partner\":false,\"is_resalable\":true,\"is_syndicated\":true,\"is_opinion\":false,\"journal_issue_name\":null,\"keywords\":[],\"media_url\":null,\"media_type\":null,\"podcast_series_name\":null,\"podcast_series_slug\":null,\"published_at_date\":\"2023-10-13\",\"published_at_date_time\":\"2023-10-13T11:00:00+00:00\",\"published_at_time\":\"11:00:00\",\"tags\":[],\"type\":\"Article\",\"updated_at_date_time\":\"2024-02-20T11:46:41.809000+00:00\",\"paywall_exempt\":false,\"page_number\":null,\"print_title\":null,\"print_dek\":\"\",\"canonical_url\":null,\"url\":\"/article/the-ai-boom-could-use-a-shocking-amount-of-electricity/\",\"footnote\":\"\",\"content_modeling\":null,\"content_difficulty\":null,\"sentiment\":null,\"durability\":null,\"layout\":\"default\"},\"issue\":null,\"persistentHeaderTitle\":\"The AI Boom Could Use a Shocking Amount of Electricity\",\"dataLayerContent\":{\"content\":{\"articleDoi\":\"\",\"authors\":[\"Lauren Leffer\"],\"categories\":\"Artificial Intelligence,Computing,Energy,Environment,Machine learning,Power grid,Technology\",\"collectionId\":\"\",\"collectionName\":\"\",\"column\":\"\",\"containsMedia\":\"\",\"contentfulId\":\"246IYwSU7ld4TrLQrYNkcZ\",\"contentId\":\"C93BCC54-1548-4994-9FAC38153FF07F03\",\"contentDifficulty\":\"\",\"contentModeling\":[],\"durability\":\"\",\"editors\":[\"Sophie Bushwick\"],\"isOpinion\":false,\"isPartner\":false,\"isResalable\":true,\"isSyndicated\":true,\"journalIssueName\":\"\",\"language\":\"en\",\"partnerName\":\"\",\"platform\":\"hopper\",\"paywallExempt\":null,\"podcastSeries\":\"\",\"primaryCategory\":\"Technology\",\"printDek\":\"\",\"printTitle\":\"\",\"publishedAtDate\":\"2023-10-13\",\"publishedAtDateTime\":\"2023-10-13T11:00:00+00:00\",\"publishedAtTime\":\"11:00:00\",\"sentiment\":\"\",\"subCategory\":\"Energy\",\"title\":\"The AI Boom Could Use a Shocking Amount of Electricity\",\"type\":\"news\",\"updatedAtDateTime\":\"2024-02-20T11:46:41.809000+00:00\",\"wordCount\":1280,\"advertiser\":\"\",\"campaign\":\"\",\"isSponsored\":false},\"game\":{\"gameId\":\"\",\"puzzleType\":\"\",\"set\":\"\",\"dek\":\"\"}},\"meta\":{\"title\":\"The AI Boom Could Use a Shocking Amount of Electricity\",\"canonicalUrl\":\"https://www.scientificamerican.com/article/the-ai-boom-could-use-a-shocking-amount-of-electricity/\",\"image\":\"https://static.scientificamerican.com/sciam/cache/file/AE1CFA10-BB53-41CF-9D9F713DA1BA26B4_source.jpg?w=1200\",\"imageWidth\":5123,\"imageBlockSyndication\":true,\"tags\":{\"author\":\"Lauren Leffer\",\"description\":\"Powering artificial intelligence models takes a lot of energy. A new analysis demonstrates just how big the problem could become\",\"og:title\":\"The AI Boom Could Use a Shocking Amount of Electricity\",\"og:description\":\"Powering artificial intelligence models takes a lot of energy. A new analysis demonstrates just how big the problem could become\",\"og:site_name\":\"Scientific American\",\"og:image\":\"https://static.scientificamerican.com/sciam/cache/file/AE1CFA10-BB53-41CF-9D9F713DA1BA26B4_source.jpg?w=1200\",\"og:image:alt\":\"Equipment in server room\",\"og:type\":\"article\",\"og:url\":\"https://www.scientificamerican.com/article/the-ai-boom-could-use-a-shocking-amount-of-electricity/\",\"twitter:title\":\"The AI Boom Could Use a Shocking Amount of Electricity\",\"twitter:description\":\"Powering artificial intelligence models takes a lot of energy. A new analysis demonstrates just how big the problem could become\",\"twitter:image\":\"https://static.scientificamerican.com/sciam/cache/file/AE1CFA10-BB53-41CF-9D9F713DA1BA26B4_source.jpg?w=1200\",\"twitter:image:alt\":\"Equipment in server room\"},\"jsonLD\":{\"@context\":\"https://schema.org\",\"@type\":\"NewsArticle\",\"mainEntityOfPage\":{\"@type\":\"WebPage\",\"@id\":\"https://www.scientificamerican.com/article/the-ai-boom-could-use-a-shocking-amount-of-electricity/\",\"breadcrumb\":{\"@type\":\"BreadcrumbList\",\"itemListElement\":[{\"@type\":\"ListItem\",\"position\":1,\"name\":\"Energy\",\"item\":\"https://www.scientificamerican.com/energy/\"},{\"@type\":\"ListItem\",\"position\":2,\"name\":\"The AI Boom Could Use a Shocking Amount of Electricity\",\"item\":\"https://www.scientificamerican.com/article/the-ai-boom-could-use-a-shocking-amount-of-electricity/\"}]}},\"headline\":\"The AI Boom Could Use a Shocking Amount of Electricity\",\"alternativeHeadline\":\"The AI Boom Could Use a Shocking Amount of Electricity\",\"description\":\"Powering artificial intelligence models takes a lot of energy. A new analysis demonstrates just how big the problem could become\",\"url\":\"https://www.scientificamerican.com/article/the-ai-boom-could-use-a-shocking-amount-of-electricity/\",\"thumbnailUrl\":\"https://static.scientificamerican.com/sciam/cache/file/AE1CFA10-BB53-41CF-9D9F713DA1BA26B4_source.jpg?w=1200\",\"image\":[\"https://static.scientificamerican.com/sciam/cache/file/AE1CFA10-BB53-41CF-9D9F713DA1BA26B4_source.jpg?w=1200\",\"https://static.scientificamerican.com/sciam/cache/file/AE1CFA10-BB53-41CF-9D9F713DA1BA26B4_source.jpg?crop=16%3A9%2Csmart&w=1920\",\"https://static.scientificamerican.com/sciam/cache/file/AE1CFA10-BB53-41CF-9D9F713DA1BA26B4_source.jpg?crop=4%3A3%2Csmart&w=1200\",\"https://static.scientificamerican.com/sciam/cache/file/AE1CFA10-BB53-41CF-9D9F713DA1BA26B4_source.jpg?crop=1%3A1%2Csmart&w=1000\"],\"datePublished\":\"2023-10-13T11:00:00+00:00\",\"dateModified\":\"2024-02-20T11:46:41.809000+00:00\",\"author\":[{\"@type\":\"Person\",\"name\":\"Lauren Leffer\",\"url\":\"https://www.scientificamerican.com/author/lauren-leffer/\"}],\"isAccessibleForFree\":false,\"publisher\":{\"@id\":\"https://www.scientificamerican.com/#publisher\",\"name\":\"Scientific American\"},\"copyrightHolder\":{\"@id\":\"https://www.scientificamerican.com/#publisher\",\"name\":\"Scientific American\"}}},\"adsConfig\":{\"unitpath\":\"/270604982/sciam/article\",\"targeting\":{\"title\":\"The AI Boom Could Use a Shocking Amount of Electricity\",\"cat\":[\"Artificial Intelligence\",\"Computing\",\"Energy\",\"Environment\",\"Machine learning\",\"Power grid\",\"Technology\"],\"subject\":\"Technology\",\"authors\":[\"Lauren Leffer\"],\"podcast\":null,\"version\":\"hopper\"}},\"podcastSeriesInfo\":null,\"readTime\":5,\"isPreview\":false},\"bundle\":\"article\"}`)</script>\n    <script data-layer=\"footer\">;OptanonWrapper=()=>{};consentQueue=[];tp=[];pdl={requireConsent:'v2'};window.dataLayer=[];;window.__ads=[];_sf_async_config={};_cbq=[]</script>\n  </body>\n</html>\n","oembed":false,"readabilityObject":{"title":"The AI Boom Could Use a Shocking Amount of Electricity","content":"<div id=\"readability-page-1\" class=\"page\"><div><p data-block=\"sciam/paragraph\">Every online interaction relies on a scaffolding of information stored in remote servers—and those machines, stacked together in data centers worldwide, require a lot of energy. Around the globe, data centers currently account for about <a href=\"https://www.iea.org/energy-system/buildings/data-centres-and-data-transmission-networks#overview\">1 to 1.5 percent of global electricity use</a>, according to the International Energy Agency. And the world’s still-exploding boom in artificial intelligence could drive that number up a lot—and fast.</p><p data-block=\"sciam/paragraph\">Researchers have been raising general alarms about <a href=\"https://www.scientificamerican.com/article/a-computer-scientist-breaks-down-generative-ais-hefty-carbon-footprint/\">AI’s hefty energy requirements</a> over the past few months. But a peer-reviewed analysis published this week in <i>Joule</i> is one of the first to quantify the demand that is quickly materializing. A continuation of the current trends in AI capacity and adoption are set to lead to NVIDIA shipping 1.5 million AI server units per year by 2027. These 1.5 million servers, running at full capacity, would <a href=\"https://www.cell.com/joule/fulltext/S2542-4351(23)00365-3\">consume at least 85.4 terawatt-hours of electricity annually</a>—more than what many small countries use in a year, according to the new assessment.</p><p data-block=\"sciam/paragraph\">The analysis was conducted by Alex de Vries, a data scientist at the central bank of the Netherlands and a Ph.D. candidate at Vrije University Amsterdam, where he studies the energy costs of emerging technologies. Earlier de Vries gained prominence for sounding the alarm on the <a href=\"https://www.scientificamerican.com/article/cryptocurrencies-and-nfts-are-a-buyer-beware-market/\">enormous energy costs of cryptocurrency</a> mining and transactions. Now he has turned his attention to the latest tech fad. <i>Scientific American</i> spoke with him about AI’s shocking appetite for electricity.</p><hr><h2>On supporting science journalism</h2><p>If you're enjoying this article, consider supporting our award-winning journalism by<!-- --> <a href=\"/getsciam/\">subscribing</a>. By purchasing a subscription you are helping to ensure the future of impactful stories about the discoveries and ideas shaping our world today.</p><hr><p data-block=\"sciam/paragraph\">[<i>An edited and condensed transcript of the interview follows.</i>]</p><p data-block=\"sciam/paragraph\"><b>Why do you think it’s important to examine the energy consumption of artificial intelligence?</b></p><p data-block=\"sciam/paragraph\">Because AI is energy-intensive. I put one example of this in my research article: I highlighted that if you were to fully turn Google’s search engine into something like ChatGPT, and everyone used it that way—so you would have nine billion chatbot interactions instead of nine billion regular searches per day—then the energy use of Google would spike. Google would need as much power as Ireland just to run its search engine.</p><p data-block=\"sciam/paragraph\">Now, it’s not going to happen like that because Google would also have to invest $100 billion in hardware to make that possible. And even if [the company] had the money to invest, the supply chain couldn’t deliver all those servers right away. But I still think it’s useful to illustrate that if you’re going to be using generative AI in applications [such as a search engine], that has the potential to make every online interaction much more resource-heavy.</p><p data-block=\"sciam/paragraph\">I think it’s healthy to at least include sustainability when we talk about the risk of AI. When we talk about the potential risk of errors, the unknowns of the black box, or AI discrimination bias, we should be including sustainability as a risk factor as well. I hope that my article will at least encourage the thought process in that direction. If we’re going to be using AI, is it going to help? Can we do it in a responsible way? Do we really need to be using this technology in the first place? What is it that an end user wants and needs, and how do we best help them? If AI is part of that solution, okay, go ahead. But if it’s not, then don’t put it in.</p><p data-block=\"sciam/paragraph\"><b>What parts of AI’s processes are using all that energy?</b></p><p data-block=\"sciam/paragraph\">You generally have two big phases when it comes to AI. One is a training phase, which is where you’re setting up and getting the model to teach itself how to behave. And then you have an inference phase, where you just put the model into a live operation and start feeding it prompts so it can produce original responses. Both phases are very energy-intensive, and we don’t really know what the energy ratio there is. Historically, with Google, the balance was 60 percent inference, 40 percent training. But then with ChatGPT that kind of broke down—because training ChatGPT took comparatively very little energy consumption, compared with applying the model.</p><p data-block=\"sciam/paragraph\">It’s dependent on a lot of factors, such as how much data are included in these models. I mean, these large language models that ChatGPT is powered by are notorious for using huge data sets and having billions of parameters. And of course, making these models larger is a factor that contributes to them just needing more power—but it is also how companies make their models more robust.</p><p data-block=\"sciam/paragraph\"><b>What are some of the other variables to consider when thinking about AI energy usage?</b></p><p data-block=\"sciam/paragraph\">Cooling is not included in my article, but if there were any data to go on, it would have been. A big unknown is where those servers are going to end up. That matters a whole lot, because if they’re at Google, then the additional cooling energy use is going to be somewhere in the range of a 10 percent increase. But global data centers, on average, will add 50 percent to the energy cost just to keep the machines cool. There are data centers that perform even worse than that.</p><p data-block=\"sciam/paragraph\">What type of hardware you’re using also matters. The latest servers are more efficient than older ones. What you’re going to be using the AI technology for matters, too. The more complicated a request, and the longer the servers are working to fulfill it, the more power is consumed.</p><p data-block=\"sciam/paragraph\"><b>In your assessment, you outline a few different energy-use scenarios from worst- to best-case. Which is the most likely?</b></p><p data-block=\"sciam/paragraph\">In the worst-case scenario, if we decide we’re going to do everything on AI, then every data center is going to experience effectively a 10-fold increase in energy consumption. That would be a massive explosion in global electricity consumption because data centers, not including cryptocurrency mining, are already responsible for consuming about 1 percent of global electricity. Now, again, that’s not going to happen—that’s not realistic at all. It’s a useful example to illustrate that AI is very energy-intensive.</p><p data-block=\"sciam/paragraph\">On the opposite end, you have this idea of no growth—zero. You have people saying that the growth in demand will be completely offset by improving efficiency, but that’s a very optimistic take that doesn’t include what we understand about demand and efficiency. Every time a major new technology makes a process more efficient, it actually leads to more people demanding whatever is being produced. Efficiency boosts demand, so boosting efficiency is not really saving energy in the end.</p><p data-block=\"sciam/paragraph\">What do I think is the most likely path going forward? I think the answer is that there’s going to be a growth in AI-related electricity consumption. At least initially, it’s going to be somewhat slow. But there’s the possibility that it accelerates in a couple of years as server production increases. Knowing this gives us some time to think about what we’re doing.</p><p data-block=\"sciam/paragraph\"><b>What additional research or other steps might be needed?</b></p><p data-block=\"sciam/paragraph\">We need a higher quality of data. We need to know where these servers are going. We need to know the source of the energy itself. Carbon emissions are the real numbers that we care about when it comes to environmental impact. Energy demand is one thing, but is it coming from renewables? Is it coming from fossil fuels?</p><p data-block=\"sciam/paragraph\">Maybe regulators should start requiring energy use disclosures from AI developers because there’s just very little information to go on. It was really hard to do this analysis—anyone who is trying to work on AI at the moment is facing the same challenges, where information is limited. I think it would help if there was more transparency. And if that transparency doesn’t come naturally, which it hasn’t so far, then we should think about giving it a little bit of a push.</p></div></div>","textContent":"Every online interaction relies on a scaffolding of information stored in remote servers—and those machines, stacked together in data centers worldwide, require a lot of energy. Around the globe, data centers currently account for about 1 to 1.5 percent of global electricity use, according to the International Energy Agency. And the world’s still-exploding boom in artificial intelligence could drive that number up a lot—and fast.Researchers have been raising general alarms about AI’s hefty energy requirements over the past few months. But a peer-reviewed analysis published this week in Joule is one of the first to quantify the demand that is quickly materializing. A continuation of the current trends in AI capacity and adoption are set to lead to NVIDIA shipping 1.5 million AI server units per year by 2027. These 1.5 million servers, running at full capacity, would consume at least 85.4 terawatt-hours of electricity annually—more than what many small countries use in a year, according to the new assessment.The analysis was conducted by Alex de Vries, a data scientist at the central bank of the Netherlands and a Ph.D. candidate at Vrije University Amsterdam, where he studies the energy costs of emerging technologies. Earlier de Vries gained prominence for sounding the alarm on the enormous energy costs of cryptocurrency mining and transactions. Now he has turned his attention to the latest tech fad. Scientific American spoke with him about AI’s shocking appetite for electricity.On supporting science journalismIf you're enjoying this article, consider supporting our award-winning journalism by subscribing. By purchasing a subscription you are helping to ensure the future of impactful stories about the discoveries and ideas shaping our world today.[An edited and condensed transcript of the interview follows.]Why do you think it’s important to examine the energy consumption of artificial intelligence?Because AI is energy-intensive. I put one example of this in my research article: I highlighted that if you were to fully turn Google’s search engine into something like ChatGPT, and everyone used it that way—so you would have nine billion chatbot interactions instead of nine billion regular searches per day—then the energy use of Google would spike. Google would need as much power as Ireland just to run its search engine.Now, it’s not going to happen like that because Google would also have to invest $100 billion in hardware to make that possible. And even if [the company] had the money to invest, the supply chain couldn’t deliver all those servers right away. But I still think it’s useful to illustrate that if you’re going to be using generative AI in applications [such as a search engine], that has the potential to make every online interaction much more resource-heavy.I think it’s healthy to at least include sustainability when we talk about the risk of AI. When we talk about the potential risk of errors, the unknowns of the black box, or AI discrimination bias, we should be including sustainability as a risk factor as well. I hope that my article will at least encourage the thought process in that direction. If we’re going to be using AI, is it going to help? Can we do it in a responsible way? Do we really need to be using this technology in the first place? What is it that an end user wants and needs, and how do we best help them? If AI is part of that solution, okay, go ahead. But if it’s not, then don’t put it in.What parts of AI’s processes are using all that energy?You generally have two big phases when it comes to AI. One is a training phase, which is where you’re setting up and getting the model to teach itself how to behave. And then you have an inference phase, where you just put the model into a live operation and start feeding it prompts so it can produce original responses. Both phases are very energy-intensive, and we don’t really know what the energy ratio there is. Historically, with Google, the balance was 60 percent inference, 40 percent training. But then with ChatGPT that kind of broke down—because training ChatGPT took comparatively very little energy consumption, compared with applying the model.It’s dependent on a lot of factors, such as how much data are included in these models. I mean, these large language models that ChatGPT is powered by are notorious for using huge data sets and having billions of parameters. And of course, making these models larger is a factor that contributes to them just needing more power—but it is also how companies make their models more robust.What are some of the other variables to consider when thinking about AI energy usage?Cooling is not included in my article, but if there were any data to go on, it would have been. A big unknown is where those servers are going to end up. That matters a whole lot, because if they’re at Google, then the additional cooling energy use is going to be somewhere in the range of a 10 percent increase. But global data centers, on average, will add 50 percent to the energy cost just to keep the machines cool. There are data centers that perform even worse than that.What type of hardware you’re using also matters. The latest servers are more efficient than older ones. What you’re going to be using the AI technology for matters, too. The more complicated a request, and the longer the servers are working to fulfill it, the more power is consumed.In your assessment, you outline a few different energy-use scenarios from worst- to best-case. Which is the most likely?In the worst-case scenario, if we decide we’re going to do everything on AI, then every data center is going to experience effectively a 10-fold increase in energy consumption. That would be a massive explosion in global electricity consumption because data centers, not including cryptocurrency mining, are already responsible for consuming about 1 percent of global electricity. Now, again, that’s not going to happen—that’s not realistic at all. It’s a useful example to illustrate that AI is very energy-intensive.On the opposite end, you have this idea of no growth—zero. You have people saying that the growth in demand will be completely offset by improving efficiency, but that’s a very optimistic take that doesn’t include what we understand about demand and efficiency. Every time a major new technology makes a process more efficient, it actually leads to more people demanding whatever is being produced. Efficiency boosts demand, so boosting efficiency is not really saving energy in the end.What do I think is the most likely path going forward? I think the answer is that there’s going to be a growth in AI-related electricity consumption. At least initially, it’s going to be somewhat slow. But there’s the possibility that it accelerates in a couple of years as server production increases. Knowing this gives us some time to think about what we’re doing.What additional research or other steps might be needed?We need a higher quality of data. We need to know where these servers are going. We need to know the source of the energy itself. Carbon emissions are the real numbers that we care about when it comes to environmental impact. Energy demand is one thing, but is it coming from renewables? Is it coming from fossil fuels?Maybe regulators should start requiring energy use disclosures from AI developers because there’s just very little information to go on. It was really hard to do this analysis—anyone who is trying to work on AI at the moment is facing the same challenges, where information is limited. I think it would help if there was more transparency. And if that transparency doesn’t come naturally, which it hasn’t so far, then we should think about giving it a little bit of a push.","length":7764,"excerpt":"Powering artificial intelligence models takes a lot of energy. A new analysis demonstrates just how big the problem could become","byline":"Lauren Leffer","dir":null,"siteName":"Scientific American","lang":"en"},"finalizedMeta":{"title":"The AI Boom Could Use a Shocking Amount of Electricity","description":"Powering artificial intelligence models takes a lot of energy. A new analysis demonstrates just how big the problem could become","author":"Lauren Leffer","creator":"Lauren Leffer","publisher":"Scientific American","date":"2024-02-20T11:46:41.809000+00:00","image":"https://static.scientificamerican.com/sciam/cache/file/AE1CFA10-BB53-41CF-9D9F713DA1BA26B4_source.jpg?w=1200","topics":[]},"jsonLd":{"@type":"NewsArticle","headline":"The AI Boom Could Use a Shocking Amount of Electricity","description":"Powering artificial intelligence models takes a lot of energy. A new analysis demonstrates just how big the problem could become","image":["https://static.scientificamerican.com/sciam/cache/file/AE1CFA10-BB53-41CF-9D9F713DA1BA26B4_source.jpg?w=1200","https://static.scientificamerican.com/sciam/cache/file/AE1CFA10-BB53-41CF-9D9F713DA1BA26B4_source.jpg?crop=16%3A9%2Csmart&w=1920","https://static.scientificamerican.com/sciam/cache/file/AE1CFA10-BB53-41CF-9D9F713DA1BA26B4_source.jpg?crop=4%3A3%2Csmart&w=1200","https://static.scientificamerican.com/sciam/cache/file/AE1CFA10-BB53-41CF-9D9F713DA1BA26B4_source.jpg?crop=1%3A1%2Csmart&w=1000"],"mainEntityOfPage":{"@type":"WebPage","@id":"https://www.scientificamerican.com/article/the-ai-boom-could-use-a-shocking-amount-of-electricity/","breadcrumb":{"@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Energy","item":"https://www.scientificamerican.com/energy/"},{"@type":"ListItem","position":2,"name":"The AI Boom Could Use a Shocking Amount of Electricity","item":"https://www.scientificamerican.com/article/the-ai-boom-could-use-a-shocking-amount-of-electricity/"}]}},"datePublished":"2023-10-13T11:00:00+00:00","dateModified":"2024-02-20T11:46:41.809000+00:00","isAccessibleForFree":false,"isPartOf":{"@type":[],"name":false,"productID":false},"discussionUrl":false,"license":false,"author":[{"@type":"Person","name":"Lauren Leffer","url":"https://www.scientificamerican.com/author/lauren-leffer/"}],"publisher":{"@id":"https://www.scientificamerican.com/#publisher","name":"Scientific American"},"editor":{"@type":false,"name":false,"description":false,"sameAs":false,"image":{"@type":false,"url":false},"givenName":false,"familyName":false,"alternateName":false,"publishingPrinciples":false},"@context":"https://schema.org","alternativeHeadline":"The AI Boom Could Use a Shocking Amount of Electricity","url":"https://www.scientificamerican.com/article/the-ai-boom-could-use-a-shocking-amount-of-electricity/","thumbnailUrl":"https://static.scientificamerican.com/sciam/cache/file/AE1CFA10-BB53-41CF-9D9F713DA1BA26B4_source.jpg?w=1200","copyrightHolder":{"@id":"https://www.scientificamerican.com/#publisher","name":"Scientific American"}},"twitterObj":false,"status":200,"metadata":{"author":"Lauren Leffer","title":"The AI Boom Could Use a Shocking Amount of Electricity | Scientific American","description":"Powering artificial intelligence models takes a lot of energy. A new analysis demonstrates just how big the problem could become","canonical":"https://www.scientificamerican.com/article/the-ai-boom-could-use-a-shocking-amount-of-electricity/","keywords":[],"image":"https://static.scientificamerican.com/sciam/cache/file/AE1CFA10-BB53-41CF-9D9F713DA1BA26B4_source.jpg?w=600","firstParagraph":"October 13, 2023"},"dublinCore":{},"opengraph":{"title":"The AI Boom Could Use a Shocking Amount of Electricity","description":"Powering artificial intelligence models takes a lot of energy. A new analysis demonstrates just how big the problem could become","url":"https://www.scientificamerican.com/article/the-ai-boom-could-use-a-shocking-amount-of-electricity/","site_name":"Scientific American","locale":"en_US","type":"article","typeObject":{"published_time":false,"modified_time":false,"author":false,"publisher":false,"section":false,"tag":[]},"image":"https://static.scientificamerican.com/sciam/cache/file/AE1CFA10-BB53-41CF-9D9F713DA1BA26B4_source.jpg?w=1200","image:alt":"Equipment in server room"},"twitter":{"site":"@sciam","description":"Powering artificial intelligence models takes a lot of energy. A new analysis demonstrates just how big the problem could become","card":"summary_large_image","creator":false,"title":"The AI Boom Could Use a Shocking Amount of Electricity","image":"https://static.scientificamerican.com/sciam/cache/file/AE1CFA10-BB53-41CF-9D9F713DA1BA26B4_source.jpg?w=1200","image:alt":"Equipment in server room","domain":"scientificamerican.com"},"archivedData":{"link":"https://web.archive.org/web/20240625095137/https://www.scientificamerican.com/article/the-ai-boom-could-use-a-shocking-amount-of-electricity/","wayback":"https://web.archive.org/web/20240625095137/https://www.scientificamerican.com/article/the-ai-boom-could-use-a-shocking-amount-of-electricity/"}}}