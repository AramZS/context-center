{"initialLink":"https://www.theverge.com/features/23764584/ai-artificial-intelligence-data-notation-labor-scale-surge-remotasks-openai-chatbots","sanitizedLink":"https://www.theverge.com/features/23764584/ai-artificial-intelligence-data-notation-labor-scale-surge-remotasks-openai-chatbots","finalLink":"https://www.theverge.com/features/23764584/ai-artificial-intelligence-data-notation-labor-scale-surge-remotasks-openai-chatbots","htmlEmbed":"<script>window.contexterSetup=window.contexterSetup||function(){window.contexterSetupComplete=!0;class ContexterLink extends HTMLAnchorElement{constructor(){super()}connectedCallback(){this.setAttribute(\"target\",\"_blank\")}}customElements.define(\"contexter-link\",ContexterLink,{extends:\"a\"}),customElements.define(\"contexter-inner\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__inner\"}}),customElements.define(\"contexter-thumbnail\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__thumbnail\"}}),customElements.define(\"contexter-byline\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__byline\"}}),customElements.define(\"contexter-keywordset\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__keywordset\"}}),customElements.define(\"contexter-linkset\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__linkset\"}}),customElements.define(\"contexter-meta\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__meta\"}}),customElements.define(\"contexter-summary\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"p-summary entry-summary\"}}),customElements.define(\"contexter-box-head\",class extends HTMLElement{constructor(){super()}connectedCallback(){this.className=\"contexter-box__head\"}}),customElements.define(\"contexter-box-inner\",class extends HTMLElement{constructor(){super()}connectedCallback(){}});class ContexterBox extends HTMLElement{constructor(){super(),this.first=!0,this.shadow=this.attachShadow({mode:\"open\"})}connectedCallback(){if(this.first){this.first=!1;var style=document.createElement(\"style\"),lightDomStyle=(style.innerHTML=`:host {--background: #f5f6f7;--border: darkblue;--blue: #0000ee;--font-color: black;--inner-border: black;font-family: Franklin,Arial,Helvetica,sans-serif;font-size: 14px;background: var(--background);width: 600px;color: var(--font-color);min-height: 90px;display: block;padding: 8px;border: 1px solid var(--border);cursor: pointer;box-sizing: border-box;margin: 6px;contain: content;margin: 6px auto;}// can only select top-level nodes with slotted::slotted(*) {max-width: 100%;display:block;}::slotted([slot=thumbnail]) {max-width: 100%;display:block;}::slotted([slot=header]) {width: 100%;font-size: 1.25rem;font-weight: bold;display:block;margin-bottom: 6px;}::slotted([slot=author]) {max-width: 50%;font-size: 12px;display:inline-block;float: left;}::slotted([slot=time]) {max-width: 50%;font-size: 12px;display:inline-block;float: right;}::slotted([slot=summary]) {width: 100%;margin-top: 6px;padding: 10px 2px;border-top: 1px solid var(--inner-border);font-size: 15px;display:inline-block;margin-bottom: 6px;}contexter-meta {height: auto;margin-bottom: 4px;width: 100%;display: grid;position: relative;min-height: 16px;grid-template-columns: repeat(2, 1fr);}::slotted([slot=keywords]) {width: 80%;padding: 2px 4px;border-top: 1px solid var(--inner-border);font-size: 11px;display: block;float: right;font-style: italic;text-align: right;grid-column: 2/2;grid-row: 1;align-self: end;justify-self: end;}::slotted([slot=keywords]):empty {border-top: 0px solid var(--inner-border);}::slotted([slot=archive-link]) {font-size: 1em;display: inline;}::slotted([slot=archive-link])::after {content: \"|\";display: inline;color: var(--font-color);text-decoration: none;margin: 0 .5em;}::slotted([slot=read-link]) {font-size: 1em;display: inline;}contexter-linkset {width: 80%;padding: 2px 4px;font-size: 13px;float: left;font-weight: bold;grid-row: 1;grid-column: 1/2;align-self: end;justify-self: start;}/* Extra small devices (phones, 600px and down) */@media only screen and (max-width: 600px) {:host {width: 310px;}}/* Small devices (portrait tablets and large phones, 600px and up) */@media only screen and (min-width: 600px) {...}/* Medium devices (landscape tablets, 768px and up) */@media only screen and (min-width: 768px) {...}/* Large devices (laptops/desktops, 992px and up) */@media only screen and (min-width: 992px) {...}/* Extra large devices (large laptops and desktops, 1200px and up) */@media only screen and (min-width: 1200px) {...}@media (prefers-color-scheme: dark){:host {--background: #354150;--border: #1f2b37;--blue: #55b0ff;--font-color: #ffffff;--inner-border: #787a7c;background: var(--background);border: 1px solid var(--border)}}`,document.createElement(\"style\"));lightDomStyle.innerHTML=`contexter-box {contain: content;}contexter-box .read-link {font-weight: bold;}contexter-box a {color: #0000ee;}contexter-box img {width: 100%;border: 0;padding: 0;margin: 0;}/* Extra small devices (phones, 600px and down) */@media only screen and (max-width: 600px) {...}/* Small devices (portrait tablets and large phones, 600px and up) */@media only screen and (min-width: 600px) {...}/* Medium devices (landscape tablets, 768px and up) */@media only screen and (min-width: 768px) {...}/* Large devices (laptops/desktops, 992px and up) */@media only screen and (min-width: 992px) {...}/* Extra large devices (large laptops and desktops, 1200px and up) */@media only screen and (min-width: 1200px) {...}@media (prefers-color-scheme: dark){contexter-box a {color: #55b0ff;}}`,this.appendChild(lightDomStyle),this.shadow.appendChild(style);const innerContainer=document.createElement(\"contexter-box-inner\"),innerSlotThumbnail=(this.shadow.appendChild(innerContainer),document.createElement(\"slot\")),innerSlotHeader=(innerSlotThumbnail.name=\"thumbnail\",innerContainer.appendChild(innerSlotThumbnail),document.createElement(\"slot\")),innerSlotAuthor=(innerSlotHeader.name=\"header\",innerContainer.appendChild(innerSlotHeader),document.createElement(\"slot\")),innerSlotTime=(innerSlotAuthor.name=\"author\",innerContainer.appendChild(innerSlotAuthor),document.createElement(\"slot\")),innerSlotSummary=(innerSlotTime.name=\"time\",innerContainer.appendChild(innerSlotTime),document.createElement(\"slot\")),metaContainer=(innerSlotSummary.name=\"summary\",innerContainer.appendChild(innerSlotSummary),document.createElement(\"contexter-meta\")),innerSlotInfo=(innerContainer.appendChild(metaContainer),document.createElement(\"slot\")),linkContainer=(innerSlotInfo.name=\"keywords\",metaContainer.appendChild(innerSlotInfo),document.createElement(\"contexter-linkset\")),innerSlotArchiveLink=(metaContainer.appendChild(linkContainer),document.createElement(\"slot\")),innerSlotReadLink=(innerSlotArchiveLink.name=\"archive-link\",linkContainer.appendChild(innerSlotArchiveLink),document.createElement(\"slot\"));innerSlotReadLink.name=\"read-link\",linkContainer.appendChild(innerSlotReadLink),this.className=\"contexter-box\",this.onclick=e=>{if(!e.target.className.includes(\"read-link\")&&!e.target.className.includes(\"title-link\")){const mainLinks=this.querySelectorAll(\"a.main-link\");mainLinks[0].click()}}}}}customElements.define(\"contexter-box\",ContexterBox)},window.contexterSetupComplete||window.contexterSetup();</script><contexter-box class=\"link-card h-entry hentry\" itemscope=\"\" itemtype=\"https://schema.org/CreativeWork\"><contexter-thumbnail class=\"thumbnail\" slot=\"thumbnail\"></contexter-thumbnail><contexter-box-head slot=\"header\" class=\"p-name entry-title\" itemprop=\"headline\"><contexter-box-head slot=\"header\" class=\"p-name entry-title\" itemprop=\"headline\"><a is=\"contexter-link\" href=\"https://www.theverge.com/features/23764584/ai-artificial-intelligence-data-notation-labor-scale-surge-remotasks-openai-chatbots\" itemprop=\"url\">Inside the AI Factory: the humans that make tech seem human</a></contexter-box-head></contexter-box-head><contexter-byline class=\"p-author author\" slot=\"author\"><span class=\"p-name byline\" rel=\"author\" itemprop=\"author\">The Verge</span></contexter-byline><time class=\"dt-published published\" slot=\"time\" itemprop=\"datePublished\" datetime=\"2023-06-20T12:05:00.000Z\">6/20/2023</time><contexter-summary class=\"p-summary entry-summary\" itemprop=\"abstract\" slot=\"summary\"><p>How many humans does it take to make tech seem human? Millions to support OpenAI, Google, Meta, and every other major tech company. As AI becomes ubiquitous, a vast tasker underclass is emerging — and not going anywhere.</p></contexter-summary><contexter-keywordset itemprop=\"keywords\" slot=\"keywords\"></contexter-keywordset><a is=\"contexter-link\" href=\"https://www.theverge.com/features/23764584/ai-artificial-intelligence-data-notation-labor-scale-surge-remotasks-openai-chatbots\" class=\"read-link main-link\" itemprop=\"sameAs\" slot=\"read-link\">Read</a></contexter-box>","linkId":"00a7fcd7a40294fa9205a531cf481db4765a8373","data":{"originalLink":"https://www.theverge.com/features/23764584/ai-artificial-intelligence-data-notation-labor-scale-surge-remotasks-openai-chatbots","sanitizedLink":"https://www.theverge.com/features/23764584/ai-artificial-intelligence-data-notation-labor-scale-surge-remotasks-openai-chatbots","canonical":"https://www.theverge.com/features/23764584/ai-artificial-intelligence-data-notation-labor-scale-surge-remotasks-openai-chatbots","htmlText":"<!DOCTYPE html><html lang=\"en-US\"><head><meta charSet=\"utf-8\"/><meta name=\"twitter:card\" content=\"summary_large_image\"/><meta name=\"twitter:site\" content=\"@verge\"/><meta property=\"fb:app_id\" content=\"549923288395304\"/><meta property=\"og:site_name\" content=\"The Verge\"/><meta name=\"viewport\" content=\"width=device-width, initial-scale=1, shrink-to-fit=no\"/><meta name=\"apple-mobile-web-app-title\" content=\"Verge\"/><meta name=\"google-site-verification\" content=\"IucFf_TKtbFFH8_YeFyEteQIwYPdANM1R46_U9DpAr4\"/><link rel=\"alternate\" type=\"application/rss+xml\" title=\"The Verge\" href=\"/rss/index.xml\"/><title>Inside the AI Factory: the humans that make tech seem human - The Verge</title><meta name=\"robots\" content=\"index,follow,max-image-preview:large\"/><meta name=\"description\" content=\"How many humans does it take to make tech seem human? Millions to support OpenAI, Google, Meta, and every other major tech company. As AI becomes ubiquitous, a vast tasker underclass is emerging — and not going anywhere.\"/><meta property=\"og:title\" content=\"Inside the AI Factory\"/><meta property=\"og:description\" content=\"How many humans does it take to make tech seem human? Millions.\"/><meta property=\"og:url\" content=\"https://www.theverge.com/features/23764584/ai-artificial-intelligence-data-notation-labor-scale-surge-remotasks-openai-chatbots\"/><meta property=\"og:type\" content=\"article\"/><meta property=\"article:published_time\" content=\"2023-06-20T12:05:00.000Z\"/><meta property=\"article:modified_time\" content=\"2023-06-20T12:05:00.000Z\"/><meta property=\"og:image\" content=\"https://cdn.vox-cdn.com/thumbor/v9wxGGbTW0yvHsZtt1mg8laUnOA=/0x0:2048x1365/1200x628/filters:focal(1024x683:1025x684)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg\"/><meta property=\"og:image:type\" content=\"image/jpeg\"/><meta property=\"og:image:width\" content=\"1200\"/><meta property=\"og:image:height\" content=\"628\"/><link rel=\"canonical\" href=\"https://www.theverge.com/features/23764584/ai-artificial-intelligence-data-notation-labor-scale-surge-remotasks-openai-chatbots\"/><meta property=\"author\" content=\"Josh Dzieza\"/><script type=\"application/ld+json\">{\"@context\":\"http://schema.org/\",\"@type\":\"NewsArticle\",\"headline\":\"Inside the AI Factory: the humans that make tech seem human\",\"description\":\"How many humans does it take to make tech seem human? Millions to support OpenAI, Google, Meta, and every other major tech company. As AI becomes ubiquitous, a vast tasker underclass is emerging — and not going anywhere.\",\"datePublished\":\"2023-06-20T12:05:00.000Z\",\"dateModified\":\"2023-06-20T12:05:00.000Z\",\"thumbnailUrl\":\"https://cdn.vox-cdn.com/thumbor/MFiURNjiF1enowJ5t0oyd0gkPlU=/0x0:2048x1365/1400x788/filters:focal(1024x683:1025x684)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg\",\"author\":[{\"@type\":\"Person\",\"name\":\"Josh Dzieza\",\"url\":\"https://www.theverge.com/authors/josh-dzieza\"}],\"publisher\":{\"@type\":\"Organization\",\"name\":\"The Verge\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https://cdn.vox-cdn.com/uploads/chorus_asset/file/24015294/verge_duet_google_news.png\",\"width\":250,\"height\":50}},\"image\":[{\"@type\":\"ImageObject\",\"url\":\"https://cdn.vox-cdn.com/thumbor/MFiURNjiF1enowJ5t0oyd0gkPlU=/0x0:2048x1365/1400x788/filters:focal(1024x683:1025x684)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg\",\"width\":1400,\"height\":788},{\"@type\":\"ImageObject\",\"url\":\"https://cdn.vox-cdn.com/thumbor/aD8beUZUaAWE-Xp9Nxghr39hEc8=/0x0:2048x1365/1400x1050/filters:focal(1024x683:1025x684)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg\",\"width\":1400,\"height\":1050},{\"@type\":\"ImageObject\",\"url\":\"https://cdn.vox-cdn.com/thumbor/3DumuHSwStBgrpK3v23C-ipMVRE=/0x0:2048x1365/1400x1400/filters:focal(1024x683:1025x684)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg\",\"width\":1400,\"height\":1400}],\"url\":\"https://www.theverge.com/features/23764584/ai-artificial-intelligence-data-notation-labor-scale-surge-remotasks-openai-chatbots\",\"articleBody\":\"This article is a collaboration between New York Magazine and The Verge.\\n\\n---\\n\\nA few months after graduating from college in Nairobi, a 30-year-old I’ll call Joe got a job as an annotator — the tedious work of processing the raw information used to train artificial intelligence. AI learns by finding patterns in enormous quantities of data, but first that data has to be sorted and tagged by people, a vast workforce mostly hidden behind the machines. In Joe’s case, he was labeling footage for self-driving cars — identifying every vehicle, pedestrian, cyclist, anything a driver needs to be aware of — frame by frame and from every possible camera angle. It’s difficult and repetitive work. A several-second blip of footage took eight hours to annotate, for which Joe was paid about $10.\\n\\nThen, in 2019, an opportunity arose: Joe could make four times as much running an annotation boot camp for a new company that was hungry for labelers. Every two weeks, 50 new recruits would file into an office building in Nairobi to begin their apprenticeships. There seemed to be limitless demand for the work. They would be asked to categorize clothing seen in mirror selfies, look through the eyes of robot vacuum cleaners to determine which rooms they were in, and draw squares around lidar scans of motorcycles. Over half of Joe’s students usually dropped out before the boot camp was finished. “Some people don’t know how to stay in one place for long,” he explained with gracious understatement. Also, he acknowledged, “it is very boring.”\\n\\n---\\n[Image: https://cdn.vox-cdn.com/thumbor/bqRhb5A3myLSYGiXMDOshxcrXCE=/0x0:2400x3000/2400x3000/filters:focal(1200x1500:1201x1501)/cdn.vox-cdn.com/uploads/chorus_asset/file/24734352/1323Cov4x5_AI_Factory.jpg]\\n\\nThis article is a collaboration between New York Magazine and The Verge.\\n---\\n\\nBut it was a job in a place where jobs were scarce, and Joe turned out hundreds of graduates. After boot camp, they went home to work alone in their bedrooms and kitchens, forbidden from telling anyone what they were working on, which wasn’t really a problem because they rarely knew themselves. Labeling objects for self-driving cars was obvious, but what about categorizing whether snippets of distorted dialogue were spoken by a robot or a human? Uploading photos of yourself staring into a webcam with a blank expression, then with a grin, then wearing a motorcycle helmet? Each project was such a small component of some larger process that it was difficult to say what they were actually training AI to do. Nor did the names of the projects offer any clues: Crab Generation, Whale Segment, Woodland Gyro, and Pillbox Bratwurst. They were non sequitur code names for non sequitur work.\\n\\nAs for the company employing them, most knew it only as Remotasks, a website offering work to anyone fluent in English. Like most of the annotators I spoke with, Joe was unaware until I told him that Remotasks is the worker-facing subsidiary of a company called Scale AI, a multibillion-dollar Silicon Valley data vendor that counts OpenAI and the U.S. military among its customers. Neither Remotasks’ or Scale’s website mentions the other.\\n\\nMuch of the public response to language models like OpenAI’s ChatGPT has focused on all the jobs they appear poised to automate. But behind even the most impressive AI system are people — huge numbers of people labeling data to train it and clarifying data when it gets confused. Only the companies that can afford to buy this data can compete, and those that get it are highly motivated to keep it secret. The result is that, with few exceptions, little is known about the information shaping these systems’ behavior, and even less is known about the people doing the shaping.\\n\\nFor Joe’s students, it was work stripped of all its normal trappings: a schedule, colleagues, knowledge of what they were working on or whom they were working for. In fact, they rarely called it work at all — just “tasking.” They were taskers.\\n\\nThe anthropologist David Graeber defines “bullshit jobs” as employment without meaning or purpose, work that should be automated but for reasons of bureaucracy or status or inertia is not. These AI jobs are their bizarro twin: work that people want to automate, and often think is already automated, yet still requires a human stand-in. The jobs have a purpose; it’s just that workers often have no idea what it is.\\n\\n---\\n\\nThe current AI boom — the convincingly human-sounding chatbots, the artwork that can be generated from simple prompts, and the multibillion-dollar valuations of the companies behind these technologies — began with an unprecedented feat of tedious and repetitive labor.\\n\\nIn 2007, the AI researcher Fei-Fei Li, then a professor at Princeton, suspected the key to improving image-recognition neural networks, a method of machine learning that had been languishing for years, was training on more data — millions of labeled images rather than tens of thousands. The problem was that it would take decades and millions of dollars for her team of undergrads to label that many photos.\\n\\nLi found thousands of workers on Mechanical Turk, Amazon’s crowdsourcing platform where people around the world complete small tasks for cheap. The resulting annotated dataset, called ImageNet, enabled breakthroughs in machine learning that revitalized the field and ushered in a decade of progress.\\n\\nAnnotation remains a foundational part of making AI, but there is often a sense among engineers that it’s a passing, inconvenient prerequisite to the more glamorous work of building models. You collect as much labeled data as you can get as cheaply as possible to train your model, and if it works, at least in theory, you no longer need the annotators. But annotation is never really finished. Machine-learning systems are what researchers call “brittle,” prone to fail when encountering something that isn’t well represented in their training data. These failures, called “edge cases,” can have serious consequences. In 2018, an Uber self-driving test car killed a woman because, though it was programmed to avoid cyclists and pedestrians, it didn’t know what to make of someone walking a bike across the street. The more AI systems are put out into the world to dispense legal advice and medical help, the more edge cases they will encounter and the more humans will be needed to sort them. Already, this has given rise to a global industry staffed by people like Joe who use their uniquely human faculties to help the machines.\\n\\n\\\"Is that a red shirt with white stripes or a white shirt with red stripes? Is a wicker bowl a “decorative bowl” if it’s full of apples? What color is leopard print?\\\"\\n\\nOver the past six months, I spoke with more than two dozen annotators from around the world, and while many of them were training cutting-edge chatbots, just as many were doing the mundane manual labor required to keep AI running. There are people classifying the emotional content of TikTok videos, new variants of email spam, and the precise sexual provocativeness of online ads. Others are looking at credit-card transactions and figuring out what sort of purchase they relate to or checking e-commerce recommendations and deciding whether that shirt is really something you might like after buying that other shirt. Humans are correcting customer-service chatbots, listening to Alexa requests, and categorizing the emotions of people on video calls. They are labeling food so that smart refrigerators don’t get confused by new packaging, checking automated security cameras before sounding alarms, and identifying corn for baffled autonomous tractors.\\n\\n“There’s an entire supply chain,” said Sonam Jindal, the program and research lead of the nonprofit Partnership on AI. “The general perception in the industry is that this work isn’t a critical part of development and isn’t going to be needed for long. All the excitement is around building artificial intelligence, and once we build that, it won’t be needed anymore, so why think about it? But it’s infrastructure for AI. Human intelligence is the basis of artificial intelligence, and we need to be valuing these as real jobs in the AI economy that are going to be here for a while.”\\n\\nThe data vendors behind familiar names like OpenAI, Google, and Microsoft come in different forms. There are private outsourcing companies with call-center-like offices, such as the Kenya- and Nepal-based CloudFactory, where Joe annotated for $1.20 an hour before switching to Remotasks. There are also “crowdworking” sites like Mechanical Turk and Clickworker where anyone can sign up to perform tasks. In the middle are services like Scale AI. Anyone can sign up, but everyone has to pass qualification exams and training courses and undergo performance monitoring. Annotation is big business. Scale, founded in 2016 by then-19-year-old Alexandr Wang, was valued in 2021 at $7.3 billion, making him what Forbes called “the youngest self-made billionaire,” though the magazine noted in a recent profile that his stake has fallen on secondary markets since then.\\n\\n[Image: https://cdn.vox-cdn.com/thumbor/tzXNAIWOaBlv7KbHabZQPNgOKvU=/0x0:2048x1500/2048x1500/filters:focal(1024x750:1025x751)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg]\\n\\nThis tangled supply chain is deliberately hard to map. According to people in the industry, the companies buying the data demand strict confidentiality. (This is the reason Scale cited to explain why Remotasks has a different name.) Annotation reveals too much about the systems being developed, and the huge number of workers required makes leaks difficult to prevent. Annotators are warned repeatedly not to tell anyone about their jobs, not even their friends and co-workers, but corporate aliases, project code names, and, crucially, the extreme division of labor ensure they don’t have enough information about them to talk even if they wanted to. (Most workers requested pseudonyms for fear of being booted from the platforms.) Consequently, there are no granular estimates of the number of people who work in annotation, but it is a lot, and it is growing. A recent Google Research paper gave an order-of-magnitude figure of “millions” with the potential to become “billions.”\\n\\nAutomation often unfolds in unexpected ways. Erik Duhaime, CEO of medical-data-annotation company Centaur Labs, recalled how, several years ago, prominent machine-learning engineers were predicting AI would make the job of radiologist obsolete. When that didn’t happen, conventional wisdom shifted to radiologists using AI as a tool. Neither of those is quite what he sees occurring. AI is very good at specific tasks, Duhaime said, and that leads work to be broken up and distributed across a system of specialized algorithms and to equally specialized humans. An AI system might be capable of spotting cancer, he said, giving a hypothetical example, but only in a certain type of imagery from a certain type of machine; so now, you need a human to check that the AI is being fed the right type of data and maybe another human who checks its work before passing it to another AI that writes a report, which goes to another human, and so on. “AI doesn’t replace work,” he said. “But it does change how work is organized.”\\n\\nYou might miss this if you believe AI is a brilliant, thinking machine. But if you pull back the curtain even a little, it looks more familiar, the latest iteration of a particularly Silicon Valley division of labor, in which the futuristic gleam of new technologies hides a sprawling manufacturing apparatus and the people who make it run. Duhaime reached back farther for a comparison, a digital version of the transition from craftsmen to industrial manufacturing: coherent processes broken into tasks and arrayed along assembly lines with some steps done by machines and some by humans but none resembling what came before.\\n\\nWorries about AI-driven disruption are often countered with the argument that AI automates tasks, not jobs, and that these tasks will be the dull ones, leaving people to pursue more fulfilling and human work. But just as likely, the rise of AI will look like past labor-saving technologies, maybe like the telephone or typewriter, which vanquished the drudgery of message delivering and handwriting but generated so much new correspondence, commerce, and paperwork that new offices staffed by new types of workers — clerks, accountants, typists — were required to manage it. When AI comes for your job, you may not lose it, but it might become more alien, more isolating, more tedious.\\n\\n---\\n\\nEarlier this year, I signed up for Scale AI’s Remotasks. The process was straightforward. After entering my computer specs, internet speed, and some basic contact information, I found myself in the “training center.” To access a paying task, I first had to complete an associated (unpaid) intro course.\\n\\nThe training center displayed a range of courses with inscrutable names like Glue Swimsuit and Poster Macadamia. I clicked on something called GFD Chunking, which revealed itself to be labeling clothing in social-media photos.\\n\\nThe instructions, however, were odd. For one, they basically consisted of the same direction reiterated in the idiosyncratically colored and capitalized typography of a collaged bomb threat.\\n\\n“DO LABEL items that are real and can be worn by humans or are intended to be worn by real people,” it read.\\n\\n“All items below SHOULD be labeled because they are real and can be worn by real-life humans,” it reiterated above photos of an Air Jordans ad, someone in a Kylo Ren helmet, and mannequins in dresses, over which was a lime-green box explaining, once again, “DO Label real items that can be worn by real people.”\\n\\n[Image: Remotasks instructions for labeling clothing. https://cdn.vox-cdn.com/thumbor/MHHrTeYM1ECpMGl9kVhgPdVy6QM=/0x0:2083x2083/2083x2083/filters:focal(1042x1042:1043x1043)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg]\\n\\nI skimmed to the bottom of the manual, where the instructor had written in the large bright-red font equivalent of grabbing someone by the shoulders and shaking them, “THE FOLLOWING ITEMS SHOULD NOT BE LABELED because a human could not actually put wear any of these items!” above a photo of C-3PO, Princess Jasmine from Aladdin, and a cartoon shoe with eyeballs.\\n\\nFeeling confident in my ability to distinguish between real clothes that can be worn by real people and not-real clothes that cannot, I proceeded to the test. Right away, it threw an ontological curveball: a picture of a magazine depicting photos of women in dresses. Is a photograph of clothing real clothing? No, I thought, because a human cannot wear a photograph of clothing. Wrong! As far as AI is concerned, photos of real clothes are real clothes. Next came a photo of a woman in a dimly lit bedroom taking a selfie before a full-length mirror. The blouse and shorts she’s wearing are real. What about their reflection? Also real! Reflections of real clothes are also real clothes.\\n\\nAfter an embarrassing amount of trial and error, I made it to the actual work, only to make the horrifying discovery that the instructions I’d been struggling to follow had been updated and clarified so many times that they were now a full 43 printed pages of directives: Do NOT label open suitcases full of clothes; DO label shoes but do NOT label flippers; DO label leggings but do NOT label tights; do NOT label towels even if someone is wearing it; label costumes but do NOT label armor. And so on.\\n\\nThere has been general instruction disarray across the industry, according to Milagros Miceli, a researcher at the Weizenbaum Institute in Germany who studies data work. It is in part a product of the way machine-learning systems learn. Where a human would get the concept of “shirt” with a few examples, machine-learning programs need thousands, and they need to be categorized with perfect consistency yet varied enough (polo shirts, shirts being worn outdoors, shirts hanging on a rack) that the very literal system can handle the diversity of the real world. “Imagine simplifying complex realities into something that is readable for a machine that is totally dumb,” she said.\\n\\n\\\"Once, Victor stayed up 36 hours straight labeling elbows and knees and heads in photographs of crowds — he has no idea why.\\\"\\n\\nThe act of simplifying reality for a machine results in a great deal of complexity for the human. Instruction writers must come up with rules that will get humans to categorize the world with perfect consistency. To do so, they often create categories no human would use. A human asked to tag all the shirts in a photo probably wouldn’t tag the reflection of a shirt in a mirror because they would know it is a reflection and not real. But to the AI, which has no understanding of the world, it’s all just pixels and the two are perfectly identical. Fed a dataset with some shirts labeled and other (reflected) shirts unlabeled, the model won’t work. So the engineer goes back to the vendor with an update: DO label reflections of shirts. Soon, you have a 43-page guide descending into red all-caps.\\n\\n“When you start off, the rules are relatively simple,” said a former Scale employee who requested anonymity because of an NDA. “Then they get back a thousand images and then they’re like, Wait a second, and then you have multiple engineers and they start to argue with each other. It’s very much a human thing.”\\n\\nThe job of the annotator often involves putting human understanding aside and following instructions very, very literally — to think, as one annotator said, like a robot. It’s a strange mental space to inhabit, doing your best to follow nonsensical but rigorous rules, like taking a standardized test while on hallucinogens. Annotators invariably end up confronted with confounding questions like, Is that a red shirt with white stripes or a white shirt with red stripes? Is a wicker bowl a “decorative bowl” if it’s full of apples? What color is leopard print? When instructors said to label traffic-control directors, did they also mean to label traffic-control directors eating lunch on the sidewalk? Every question must be answered, and a wrong guess could get you banned and booted to a new, totally different task with its own baffling rules.\\n\\n[Image: https://cdn.vox-cdn.com/thumbor/kQBljfwrhkJGYtW8XWVY30BSM1k=/0x0:2048x1737/2048x1737/filters:focal(1024x869:1025x870)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg]\\n\\nMost of the work on Remotasks is paid at a piece rate with a single task earning anywhere from a few cents to several dollars. Because tasks can take seconds or hours, wages are hard to predict. When Remotasks first arrived in Kenya, annotators said it paid relatively well — averaging about $5 to $10 per hour depending on the task — but the amount fell as time went on.\\n\\nScale AI spokesperson Anna Franko said that the company’s economists analyze the specifics of a project, the skills required, the regional cost of living, and other factors “to ensure fair and competitive compensation.” Former Scale employees also said pay is determined through a surge-pricing-like mechanism that adjusts for how many annotators are available and how quickly the data is needed.\\n\\nAccording to workers I spoke with and job listings, U.S.-based Remotasks annotators generally earn between $10 and $25 per hour, though some subject-matter experts can make more. By the beginning of this year, pay for the Kenyan annotators I spoke with had dropped to between $1 and $3 per hour.\\n\\nThat is, when they were making any money at all. The most common complaint about Remotasks work is its variability; it’s steady enough to be a full-time job for long stretches but too unpredictable to rely on. Annotators spend hours reading instructions and completing unpaid trainings only to do a dozen tasks and then have the project end. There might be nothing new for days, then, without warning, a totally different task appears and could last anywhere from a few hours to weeks. Any task could be their last, and they never know when the next one will come.\\n\\nThis boom-and-bust cycle results from the cadence of AI development, according to engineers and data vendors. Training a large model requires an enormous amount of annotation followed by more iterative updates, and engineers want it all as fast as possible so they can hit their target launch date. There may be monthslong demand for thousands of annotators, then for only a few hundred, then for a dozen specialists of a certain type, and then thousands again. “The question is, Who bears the cost for these fluctuations?” said Jindal of Partnership on AI. “Because right now, it’s the workers.”\\n\\n\\\"“I really am wasting my life here if I made somebody a billionaire and I’m earning a couple of bucks a week.”\\\"\\n\\nTo succeed, annotators work together. When I told Victor, who started working for Remotasks while at university in Nairobi, about my struggles with the traffic-control-directors task, he told me everyone knew to stay away from that one: too tricky, bad pay, not worth it. Like a lot of annotators, Victor uses unofficial WhatsApp groups to spread the word when a good task drops. When he figures out a new one, he starts impromptu Google Meets to show others how it’s done. Anyone can join and work together for a time, sharing tips. “It’s a culture we have developed of helping each other because we know when on your own, you can’t know all the tricks,” he said.\\n\\nBecause work appears and vanishes without warning, taskers always need to be on alert. Victor has found that projects pop up very late at night, so he is in the habit of waking every three hours or so to check his queue. When a task is there, he’ll stay awake as long as he can to work. Once, he stayed up 36 hours straight labeling elbows and knees and heads in photographs of crowds — he has no idea why. Another time, he stayed up so long his mother asked him what was wrong with his eyes. He looked in the mirror to discover they were swollen.\\n\\nAnnotators generally know only that they are training AI for companies located vaguely elsewhere, but sometimes the veil of anonymity drops — instructions mentioning a brand or a chatbot say too much. “I read and I Googled and found I am working for a 25-year-old billionaire,” said one worker, who, when we spoke, was labeling the emotions of people calling to order Domino’s pizza. “I really am wasting my life here if I made somebody a billionaire and I’m earning a couple of bucks a week.”\\n\\nVictor is a self-proclaimed “fanatic” about AI and started annotating because he wants to help bring about a fully automated post-work future. But earlier this year, someone dropped a Time story into one of his WhatsApp groups about workers training ChatGPT to recognize toxic content who were getting paid less than $2 an hour by the vendor Sama AI. “People were angry that these companies are so profitable but paying so poorly,” Victor said. He was unaware until I told him about Remotasks’ connection to Scale. Instructions for one of the tasks he worked on were nearly identical to those used by OpenAI, which meant he had likely been training ChatGPT as well, for approximately $3 per hour.\\n\\n“I remember that someone posted that we will be remembered in the future,” he said. “And somebody else replied, ‘We are being treated worse than foot soldiers. We will be remembered nowhere in the future.’ I remember that very well. Nobody will recognize the work we did or the effort we put in.”\\n\\n---\\n\\nIdentifying clothing and labeling customer-service conversations are just some of the annotation gigs available. Lately, the hottest on the market has been chatbot trainer. Because it demands specific areas of expertise or language fluency and wages are often adjusted regionally, this job tends to pay better. Certain types of specialist annotation can go for $50 or more per hour.\\n\\nA woman I’ll call Anna was searching for a job in Texas when she stumbled across a generic listing for online work and applied. It was Remotasks, and after passing an introductory exam, she was brought into a Slack room of 1,500 people who were training a project code-named Dolphin, which she later discovered to be Google DeepMind’s chatbot, Sparrow, one of the many bots competing with ChatGPT. Her job is to talk with it all day. At about $14 an hour, plus bonuses for high productivity, “it definitely beats getting paid $10 an hour at the local Dollar General store,” she said.\\n\\nAlso, she enjoys it. She has discussed science-fiction novels, mathematical paradoxes, children’s riddles, and TV shows. Sometimes the bot’s responses make her laugh; other times, she runs out of things to talk about. “Some days, my brain is just like, I literally have no idea what on earth to ask it now,” she said. “So I have a little notebook, and I’ve written about two pages of things — I just Google interesting topics — so I think I’ll be good for seven hours today, but that’s not always the case.”\\n\\nEach time Anna prompts Sparrow, it delivers two responses and she picks the best one, thereby creating something called “human-feedback data.” When ChatGPT debuted late last year, its impressively natural-seeming conversational style was credited to its having been trained on troves of internet data. But the language that fuels ChatGPT and its competitors is filtered through several rounds of human annotation. One group of contractors writes examples of how the engineers want the bot to behave, creating questions followed by correct answers, descriptions of computer programs followed by functional code, and requests for tips on committing crimes followed by polite refusals. After the model is trained on these examples, yet more contractors are brought in to prompt it and rank its responses. This is what Anna is doing with Sparrow. Exactly which criteria the raters are told to use varies — honesty, or helpfulness, or just personal preference. The point is that they are creating data on human taste, and once there’s enough of it, engineers can train a second model to mimic their preferences at scale, automating the ranking process and training their AI to act in ways humans approve of. The result is a remarkably human-seeming bot that mostly declines harmful requests and explains its AI nature with seeming self-awareness.\\n\\nPut another way, ChatGPT seems so human because it was trained by an AI that was mimicking humans who were rating an AI that was mimicking humans who were pretending to be a better version of an AI that was trained on human writing.\\n\\n[Image: https://cdn.vox-cdn.com/thumbor/BJ1voW9GJtnRC0ZSvYAl9KHBH-c=/0x0:2048x1514/2048x1514/filters:focal(1024x757:1025x758)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg]\\n\\nThis circuitous technique is called “reinforcement learning from human feedback,” or RLHF, and it’s so effective that it’s worth pausing to fully register what it doesn’t do. When annotators teach a model to be accurate, for example, the model isn’t learning to check answers against logic or external sources or about what accuracy as a concept even is. The model is still a text-prediction machine mimicking patterns in human writing, but now its training corpus has been supplemented with bespoke examples, and the model has been weighted to favor them. Maybe this results in the model extracting patterns from the part of its linguistic map labeled as accurate and producing text that happens to align with the truth, but it can also result in it mimicking the confident style and expert jargon of the accurate text while writing things that are totally wrong. There is no guarantee that the text the labelers marked as accurate is in fact accurate, and when it is, there is no guarantee that the model learns the right patterns from it.\\n\\nThis dynamic makes chatbot annotation a delicate process. It has to be rigorous and consistent because sloppy feedback, like marking material that merely sounds correct as accurate, risks training models to be even more convincing bullshitters. An early OpenAI and DeepMind joint project using RLHF, in this case to train a virtual robot hand to grab an item, resulted in also training the robot to position its hand between the object and its raters and wiggle around such that it only appeared to its human overseers to grab the item. Ranking a language model’s responses is always going to be somewhat subjective because it’s language. A text of any length will have multiple elements that could be right or wrong or, taken together, misleading. OpenAI researchers ran into this obstacle in another early RLHF paper. Trying to get their model to summarize text, the researchers found they agreed only 60 percent of the time that a summary was good. “Unlike many tasks in [machine learning] our queries do not have unambiguous ground truth,” they lamented.\\n\\nWhen Anna rates Sparrow’s responses, she’s supposed to be looking at their accuracy, helpfulness, and harmlessness while also checking that the model isn’t giving medical or financial advice or anthropomorphizing itself or running afoul of other criteria. To be useful training data, the model’s responses have to be quantifiably ranked against one another: Is a bot that helpfully tells you how to make a bomb “better” than a bot that’s so harmless it refuses to answer any questions? In one DeepMind paper, when Sparrow’s makers took a turn annotating, four researchers wound up debating whether their bot had assumed the gender of a user who asked it for relationship advice. According to Geoffrey Irving, one of DeepMind’s research scientists, the company’s researchers hold weekly annotation meetings in which they rerate data themselves and discuss ambiguous cases, consulting with ethical or subject-matter experts when a case is particularly tricky.\\n\\n\\\"There are people classifying the emotional content of TikTok videos, new variants of email spam, and the precise sexual provocativeness of online ads.\\\"\\n\\nAnna often finds herself having to choose between two bad options. “Even if they’re both absolutely, ridiculously wrong, you still have to figure out which one is better and then write words explaining why,” she said. Sometimes, when both responses are bad, she’s encouraged to write a better response herself, which she does about half the time.\\n\\nBecause feedback data is difficult to collect, it fetches a higher price. Basic preferences of the sort Anna is producing sell for about $1 each, according to people with knowledge of the industry. But if you want to train a model to do legal research, you need someone with training in law, and this gets expensive. Everyone involved is reluctant to say how much they’re spending, but in general, specialized written examples can go for hundreds of dollars, while expert ratings can cost $50 or more. One engineer told me about buying examples of Socratic dialogues for up to $300 a pop. Another told me about paying $15 for a “darkly funny limerick about a goldfish.”\\n\\nOpenAI, Microsoft, Meta, and Anthropic did not comment about how many people contribute annotations to their models, how much they are paid, or where in the world they are located. Irving of DeepMind, which is a subsidiary of Google, said the annotators working on Sparrow are paid “at least the hourly living wage” based on their location. Anna knows “absolutely nothing” about Remotasks, but Sparrow has been more open. She wasn’t the only annotator I spoke with who got more information from the AI they were training than from their employer; several others learned whom they were working for by asking their AI for its company’s terms of service. “I literally asked it, ‘What is your purpose, Sparrow?’” Anna said. It pulled up a link to DeepMind’s website and explained that it’s an AI assistant and that its creators trained it using RLHF to be helpful and safe.\\n\\n---\\n\\nUntil recently, it was relatively easy to spot bad output from a language model. It looked like gibberish. But this gets harder as the models get better — a problem called “scalable oversight.” Google inadvertently demonstrated how hard it is to catch the errors of a modern-language model when one made it into the splashy debut of its AI assistant, Bard. (It stated confidently that the James Webb Space Telescope “took the very first pictures of a planet outside of our own solar system,” which is wrong.) This trajectory means annotation increasingly requires specific skills and expertise.\\n\\nLast year, someone I’ll call Lewis was working on Mechanical Turk when, after completing a task, he received a message inviting him to apply for a platform he hadn’t heard of. It was called Taskup.ai, and its website was remarkably basic: just a navy background with text reading GET PAID FOR TASKS ON DEMAND. He applied.\\n\\nThe work paid far better than anything he had tried before, often around $30 an hour. It was more challenging, too: devising complex scenarios to trick chatbots into giving dangerous advice, testing a model’s ability to stay in character, and having detailed conversations about scientific topics so technical they required extensive research. He found the work “satisfying and stimulating.” While checking one model’s attempts to code in Python, Lewis was learning too. He couldn’t work for more than four hours at a stretch, lest he risk becoming mentally drained and making mistakes, and he wanted to keep the job.\\n\\n“If there was one thing I could change, I would just like to have more information about what happens on the other end,” he said. “We only know as much as we need to know to get work done, but if I could know more, then maybe I could get more established and perhaps pursue this as a career.”\\n\\nI spoke with eight other workers, most based in the U.S., who had similar experiences of answering surveys or completing tasks on other platforms and finding themselves recruited for Taskup.ai or several similarly generic sites, such as DataAnnotation.tech or Gethybrid.io. Often their work involved training chatbots, though with higher-quality expectations and more specialized purposes than other sites they had worked for. One was demonstrating spreadsheet macros. Another was just supposed to have conversations and rate responses according to whatever criteria she wanted. She often asked the chatbot things that had come up in conversations with her 7-year-old daughter, like “What is the largest dinosaur?” and “Write a story about a tiger.” “I haven’t fully gotten my head around what they’re trying to do with it,” she told me.\\n\\nTaskup.ai, DataAnnotation.tech, and Gethybrid.io all appear to be owned by the same company: Surge AI. Its CEO, Edwin Chen, would neither confirm nor deny the connection, but he was willing to talk about his company and how he sees annotation evolving.\\n\\n“I’ve always felt the annotation landscape is overly simplistic,” Chen said over a video call from Surge’s office. He founded Surge in 2020 after working on AI at Google, Facebook, and Twitter convinced him that crowdsourced labeling was inadequate. “We want AI to tell jokes or write really good marketing copy or help me out when I need therapy or whatnot,” Chen said. “You can’t ask five people to independently come up with a joke and combine it into a majority answer. Not everybody can tell a joke or solve a Python program. The annotation landscape needs to shift from this low-quality, low-skill mind-set to something that’s much richer and captures the range of human skills and creativity and values that we want AI systems to possess.”\\n\\n[Image: https://cdn.vox-cdn.com/thumbor/Qe4htQ4VivRXnS0BWZowjTY8hE8=/0x0:2048x1572/2048x1572/filters:focal(1024x786:1025x787)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg]\\n\\nLast year, Surge relabeled Google’s dataset classifying Reddit posts by emotion. Google had stripped each post of context and sent them to workers in India for labeling. Surge employees familiar with American internet culture found that 30 percent of the labels were wrong. Posts like “hell yeah my brother” had been classified as annoyance and “Yay, cold McDonald’s. My favorite” as love.\\n\\nSurge claims to vet its workers for qualifications — that people doing creative-writing tasks have experience with creative writing, for example — but exactly how Surge finds workers is “proprietary,” Chen said. As with Remotasks, workers often have to complete training courses, though unlike Remotasks, they are paid for it, according to the annotators I spoke with. Having fewer, better-trained workers producing higher-quality data allows Surge to compensate better than its peers, Chen said, though he declined to elaborate, saying only that people are paid “fair and ethical wages.” The workers I spoke with earned between $15 and $30 per hour, but they are a small sample of all the annotators, a group Chen said now consists of 100,000 people. The secrecy, he explained, stems from clients’ demands for confidentiality.\\n\\nSurge’s customers include OpenAI, Google, Microsoft, Meta, and Anthropic. Surge specializes in feedback and language annotation, and after ChatGPT launched, it got an influx of requests, Chen said: “I thought everybody knew the power of RLHF, but I guess people just didn’t viscerally understand.”\\n\\nThe new models are so impressive they’ve inspired another round of predictions that annotation is about to be automated. Given the costs involved, there is significant financial pressure to do so. Anthropic, Meta, and other companies have recently made strides in using AI to drastically reduce the amount of human annotation needed to guide models, and other developers have started using GPT-4 to generate training data. However, a recent paper found that GPT-4-trained models may be learning to mimic GPT’s authoritative style with even less accuracy, and so far, when improvements in AI have made one form of annotation obsolete, demand for other, more sophisticated types of labeling has gone up. This debate spilled into the open earlier this year, when Scale’s CEO, Wang, tweeted that he predicted AI labs will soon be spending as many billions of dollars on human data as they do on computing power; OpenAI’s CEO, Sam Altman, responded that data needs will decrease as AI improves.\\n\\n\\\"“I mean, what it can do is amazing,” she said of the chatbot. “But it still does some really weird shit.”\\\"\\n\\nChen is skeptical AI will reach a point where human feedback is no longer needed, but he does see annotation becoming more difficult as models improve. Like many researchers, he believes the path forward will involve AI systems helping humans oversee other AI. Surge recently collaborated with Anthropic on a proof of concept, having human labelers answer questions about a lengthy text with the help of an unreliable AI assistant, on the theory that the humans would have to feel out the weaknesses of their AI assistant and collaborate to reason their way to the correct answer. Another possibility has two AIs debating each other and a human rendering the final verdict on which is correct. “We still have yet to see really good practical implementations of this stuff, but it’s starting to become necessary because it’s getting really hard for labelers to keep up with the models,” said OpenAI research scientist John Schulman in a recent talk at Berkeley.\\n\\n“I think you always need a human to monitor what AIs are doing just because they are this kind of alien entity,” Chen said. Machine-learning systems are just too strange ever to fully trust. The most impressive models today have what, to a human, seems like bizarre weaknesses, he added, pointing out that though GPT-4 can generate complex and convincing prose, it can’t pick out which words are adjectives: “Either that or models get so good that they’re better than humans at all things, in which case, you reach your utopia and who cares?”\\n\\n---\\n\\nAs 2022 ended, Joe started hearing from his students that their task queues were often empty. Then he got an email informing him the boot camps in Kenya were closing. He continued training taskers online, but he began to worry about the future.\\n\\n“There were signs that it was not going to last long,” he said. Annotation was leaving Kenya. From colleagues he had met online, he heard tasks were going to Nepal, India, and the Philippines. “The companies shift from one region to another,” Joe said. “They don’t have infrastructure locally, so it makes them flexible to shift to regions that favor them in terms of operation cost.”\\n\\nOne way the AI industry differs from manufacturers of phones and cars is in its fluidity. The work is constantly changing, constantly getting automated away and replaced with new needs for new types of data. It’s an assembly line but one that can be endlessly and instantly reconfigured, moving to wherever there is the right combination of skills, bandwidth, and wages.\\n\\nLately, the best-paying work is in the U.S. In May, Scale started listing annotation jobs on its own website, soliciting people with experience in practically every field AI is predicted to conquer. There were listings for AI trainers with expertise in health coaching, human resources, finance, economics, data science, programming, computer science, chemistry, biology, accounting, taxes, nutrition, physics, travel, K-12 education, sports journalism, and self-help. You can make $45 an hour teaching robots law or make $25 an hour teaching them poetry. There were also listings for people with security clearance, presumably to help train military AI. Scale recently launched a defense-oriented language model called Donovan, which Wang called “ammunition in the AI war,” and won a contract to work on the Army’s robotic-combat-vehicle program.\\n\\nAnna is still training chatbots in Texas. Colleagues have been turned into reviewers and Slack admins — she isn’t sure why, but it has given her hope that the gig could be a longer-term career. One thing she isn’t worried about is being automated out of a job. “I mean, what it can do is amazing,” she said of the chatbot. “But it still does some really weird shit.”\\n\\nWhen Remotasks first arrived in Kenya, Joe thought annotation could be a good career. Even after the work moved elsewhere, he was determined to make it one. There were thousands of people in Nairobi who knew how to do the work, he reasoned — he had trained many of them, after all. Joe rented office space in the city and began sourcing contracts: a job annotating blueprints for a construction company, another labeling fruits despoiled by insects for some sort of agricultural project, plus the usual work of annotating for self-driving cars and e-commerce.\\n\\nBut he has found his vision difficult to achieve. He has just one full-time employee, down from two. “We haven’t been having a consistent flow of work,” he said. There are weeks with nothing to do because customers are still collecting data, and when they’re done, he has to bring in short-term contractors to meet their deadlines: “Clients don’t care whether we have consistent work or not. So long as the datasets have been completed, then that’s the end of that.”\\n\\nRather than let their skills go to waste, other taskers decided to chase the work wherever it went. They rented proxy servers to disguise their locations and bought fake IDs to pass security checks so they could pretend to work from Singapore, the Netherlands, Mississippi, or wherever the tasks were flowing. It’s a risky business. Scale has become increasingly aggressive about suspending accounts caught disguising their location, according to multiple taskers. It was during one of these crackdowns that my account got banned, presumably because I had been using a VPN to see what workers in other countries were seeing, and all $1.50 or so of my earnings were seized.\\n\\n“These days, we have become a bit cunning because we noticed that in other countries they are paying well,” said Victor, who was earning double the Kenyan rate by tasking in Malaysia. “You do it cautiously.”\\n\\nAnother Kenyan annotator said that after his account got suspended for mysterious reasons, he decided to stop playing by the rules. Now, he runs multiple accounts in multiple countries, tasking wherever the pay is best. He works fast and gets high marks for quality, he said, thanks to ChatGPT. The bot is wonderful, he said, letting him speed through $10 tasks in a matter of minutes. When we spoke, he was having it rate another chatbot’s responses according to seven different criteria, one AI training the other.\\n\"}</script><meta name=\"parsely-type\" content=\"post\"/><meta name=\"parsely-title\" content=\"AI Is a Lot of Work\"/><meta name=\"parsely-link\" content=\"https://www.theverge.com/features/23764584/ai-artificial-intelligence-data-notation-labor-scale-surge-remotasks-openai-chatbots\"/><meta name=\"parsely-image-url\" content=\"https://cdn.vox-cdn.com/thumbor/v9wxGGbTW0yvHsZtt1mg8laUnOA=/0x0:2048x1365/1200x628/filters:focal(1024x683:1025x684)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg\"/><meta name=\"parsely-pub-date\" content=\"2023-06-20T12:05:00.000Z\"/><meta name=\"parsely-section\" content=\"features\"/><meta name=\"parsely-tags\" content=\"verge,front-page,features,ai-artificial-intelligence,tech,featured-story\"/><meta name=\"parsely-author\" content=\"Josh Dzieza\"/><link rel=\"preload\" as=\"image\" imageSrcSet=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/376x376/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/384x384/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/415x415/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/480x480/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/540x540/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/640x640/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/750x750/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/828x828/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/1080x1080/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/1200x1200/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/1440x1440/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/1920x1920/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/2048x2048/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/2400x2400/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 2400w\" imageSizes=\"100vw\"/><link rel=\"preload\" as=\"image\" imageSrcSet=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/376x251/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/384x256/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/415x277/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/480x320/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/540x360/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/640x427/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/750x500/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/828x552/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/1080x720/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/1200x800/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/1440x960/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/1920x1280/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/2048x1365/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/2400x1600/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 2400w\" imageSizes=\"(max-width: 768px) 100vw, (max-width: 1180px) 700px, 1100px\"/><meta name=\"next-head-count\" content=\"35\"/><link rel=\"shortcut icon\" href=\"/icons/favicon.ico\"/><link rel=\"apple-touch-icon\" sizes=\"180x180\" href=\"/icons/apple_touch_icon.png\"/><link rel=\"icon\" type=\"image/png\" sizes=\"32x32\" href=\"/icons/favicon_32x32.png\"/><link rel=\"icon\" type=\"image/png\" sizes=\"96x96\" href=\"/icons/favicon_96x96.png\"/><link rel=\"icon\" type=\"image/png\" sizes=\"16x16\" href=\"/icons/favicon_16x16.png\"/><link rel=\"mask-icon\" href=\"/icons/safari_pinned_tab.svg\" color=\"#5200ff\"/><link rel=\"icon\" type=\"image/png\" href=\"/icons/android_chrome_192x192.png\" sizes=\"192x192\"/><link rel=\"icon\" type=\"image/png\" href=\"/icons/android_chrome_512x512.png\" sizes=\"512x512\"/><link rel=\"dns-prefetch\" href=\"https://pagead2.googlesyndication.com\"/><link rel=\"dns-prefetch\" href=\"https://micro.rubiconproject.com/prebid/dynamic/7470.js\"/><link rel=\"dns-prefetch\" href=\"https://securepubads.g.doubleclick.net\"/><link rel=\"dns-prefetch\" href=\"https://stats.g.doubleclick.net\"/><link rel=\"dns-prefetch\" href=\"https://www.google-analytics.com\"/><link rel=\"dns-prefetch\" href=\"https://cdn.permutive.com\"/><link rel=\"dns-prefetch\" href=\"https://mb.moatads.com\"/><link rel=\"preload\" href=\"/_next/static/media/b61d461e2e1d8573-s.p.woff2\" as=\"font\" type=\"font/woff2\" crossorigin=\"anonymous\" data-next-font=\"size-adjust\"/><link rel=\"preload\" href=\"/_next/static/media/af51b8e80b7e5b97-s.p.woff2\" as=\"font\" type=\"font/woff2\" crossorigin=\"anonymous\" data-next-font=\"size-adjust\"/><link rel=\"preload\" href=\"/_next/static/media/4c161430243654b9-s.p.woff2\" as=\"font\" type=\"font/woff2\" crossorigin=\"anonymous\" data-next-font=\"size-adjust\"/><link rel=\"preload\" href=\"/_next/static/media/faa4a7ab7fe4ff34-s.p.woff2\" as=\"font\" type=\"font/woff2\" crossorigin=\"anonymous\" data-next-font=\"size-adjust\"/><link rel=\"preload\" href=\"/_next/static/media/e0d450417c4fcdb2-s.p.woff2\" as=\"font\" type=\"font/woff2\" crossorigin=\"anonymous\" data-next-font=\"size-adjust\"/><link rel=\"preload\" href=\"/_next/static/media/c6806ee6b9a6284f-s.p.woff2\" as=\"font\" type=\"font/woff2\" crossorigin=\"anonymous\" data-next-font=\"size-adjust\"/><link rel=\"preload\" href=\"/_next/static/media/167de315d6f8820c-s.p.woff2\" as=\"font\" type=\"font/woff2\" crossorigin=\"anonymous\" data-next-font=\"size-adjust\"/><link rel=\"preload\" href=\"/_next/static/media/c32d4f9e62509b70-s.p.woff2\" as=\"font\" type=\"font/woff2\" crossorigin=\"anonymous\" data-next-font=\"size-adjust\"/><link rel=\"preload\" href=\"/_next/static/media/8314bd48671746e7-s.p.woff2\" as=\"font\" type=\"font/woff2\" crossorigin=\"anonymous\" data-next-font=\"size-adjust\"/><link rel=\"preload\" href=\"/_next/static/media/1acdcb23bd60cdf8-s.p.woff2\" as=\"font\" type=\"font/woff2\" crossorigin=\"anonymous\" data-next-font=\"size-adjust\"/><link rel=\"preload\" href=\"/_next/static/media/e334064d2786be51-s.p.woff2\" as=\"font\" type=\"font/woff2\" crossorigin=\"anonymous\" data-next-font=\"size-adjust\"/><link rel=\"preload\" href=\"/_next/static/media/dbe24bfb7e9bcd79-s.p.woff2\" as=\"font\" type=\"font/woff2\" crossorigin=\"anonymous\" data-next-font=\"size-adjust\"/><link rel=\"preload\" href=\"/_next/static/media/caa65695070c604f-s.p.woff2\" as=\"font\" type=\"font/woff2\" crossorigin=\"anonymous\" data-next-font=\"size-adjust\"/><link rel=\"preload\" href=\"/_next/static/media/7f8638c9585902a6-s.p.woff2\" as=\"font\" type=\"font/woff2\" crossorigin=\"anonymous\" data-next-font=\"size-adjust\"/><link rel=\"preload\" href=\"/_next/static/media/d2cd5f6e542bad4c-s.p.woff2\" as=\"font\" type=\"font/woff2\" crossorigin=\"anonymous\" data-next-font=\"size-adjust\"/><link rel=\"preload\" href=\"/_next/static/media/857aa1a339c7fe20-s.p.woff2\" as=\"font\" type=\"font/woff2\" crossorigin=\"anonymous\" data-next-font=\"size-adjust\"/><link rel=\"preload\" href=\"/_next/static/media/516340c748fee9da-s.p.woff2\" as=\"font\" type=\"font/woff2\" crossorigin=\"anonymous\" data-next-font=\"size-adjust\"/><link rel=\"preload\" href=\"/_next/static/media/70754f98ca969379-s.p.woff2\" as=\"font\" type=\"font/woff2\" crossorigin=\"anonymous\" data-next-font=\"size-adjust\"/><link rel=\"preload\" href=\"/_next/static/media/afa7a955b67174eb-s.p.woff2\" as=\"font\" type=\"font/woff2\" crossorigin=\"anonymous\" data-next-font=\"size-adjust\"/><link rel=\"preload\" href=\"/_next/static/media/d2ddd5a6c0493c79-s.p.woff2\" as=\"font\" type=\"font/woff2\" crossorigin=\"anonymous\" data-next-font=\"size-adjust\"/><link rel=\"preload\" href=\"/_next/static/media/60369a8d37d9d5b8-s.p.woff2\" as=\"font\" type=\"font/woff2\" crossorigin=\"anonymous\" data-next-font=\"size-adjust\"/><link rel=\"preload\" href=\"/_next/static/media/96fec850ad729c00-s.p.woff2\" as=\"font\" type=\"font/woff2\" crossorigin=\"anonymous\" data-next-font=\"size-adjust\"/><link rel=\"preload\" href=\"/_next/static/css/c25c64127db0ccec.css\" as=\"style\"/><link rel=\"stylesheet\" href=\"/_next/static/css/c25c64127db0ccec.css\" data-n-g=\"\"/><link rel=\"preload\" href=\"/_next/static/css/160a271db319eda1.css\" as=\"style\"/><link rel=\"stylesheet\" href=\"/_next/static/css/160a271db319eda1.css\" data-n-p=\"\"/><link rel=\"preload\" href=\"/_next/static/css/7b43d7d4dad5f1b8.css\" as=\"style\"/><link rel=\"stylesheet\" href=\"/_next/static/css/7b43d7d4dad5f1b8.css\" data-n-p=\"\"/><noscript data-n-css=\"\"></noscript><script defer=\"\" nomodule=\"\" src=\"/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js\"></script><script src=\"https://www.googletagservices.com/tag/js/gpt.js\" async=\"\" defer=\"\" data-nscript=\"beforeInteractive\"></script><script src=\"https://cdn.concert.io/lib/concert-ads/v2-latest/concert_ads.js\" async=\"\" defer=\"\" data-nscript=\"beforeInteractive\"></script><script src=\"https://z.moatads.com/voxprebidheader841653991752/moatheader.js\" async=\"\" defer=\"\" data-nscript=\"beforeInteractive\"></script><script src=\"https://cdn.concert.io/lib/concert-concierge.2.10.1.min.js\" async=\"\" defer=\"\" data-nscript=\"beforeInteractive\"></script><script src=\"https://polyfill.io/v3/polyfill.min.js?features=AbortController,Array.prototype.entries,Array.prototype.keys,Array.prototype.sort,Array.prototype.values,ArrayBuffer,ArrayBuffer.isView,AudioContext,Blob,console,console.error,console.log,console.warn,CustomEvent,DataView,document,Document,DocumentFragment,DocumentFragment.prototype.append,DOMRect,DOMTokenList,DOMTokenList.prototype.forEach,DOMTokenList.prototype.replace,Element,Element.prototype.after,Element.prototype.append,Element.prototype.before,Element.prototype.classList,Element.prototype.closest,Element.prototype.matches,Element.prototype.previousElementSibling,Element.prototype.remove,Element.prototype.scroll,Element.prototype.scrollIntoView,Event,EventSource,Float32Array,Float64Array,getComputedStyle,globalThis,HTMLDocument,HTMLPictureElement,HTMLTemplateElement,Int16Array,Int32Array,Int8Array,IntersectionObserver,IntersectionObserverEntry,Intl,Intl.DateTimeFormat,Intl.RelativeTimeFormat,JSON,location.origin,Math.clz32,Math.sign,modernizr:es6string,MutationObserver,Node.prototype.contains,NodeList.prototype.forEach,Object.getOwnPropertySymbols,Object.isExtensible,Object.isFrozen,Object.preventExtensions,Object.setPrototypeOf,queueMicrotask,Reflect.construct,Reflect.defineProperty,Reflect.get,Reflect.set,RegExp.prototype.flags,requestAnimationFrame,ResizeObserver,String.prototype.link,String.prototype.normalize,String.prototype.sub,Symbol.for,Symbol.iterator,Symbol.prototype.description,Symbol.toPrimitive,Symbol.toStringTag,TextDecoder,TextEncoder,Uint16Array,Uint32Array,Uint8Array,Uint8ClampedArray,Window,XMLHttpRequest,Intl.RelativeTimeFormat,Intl.RelativeTimeFormat.~locale.en\" defer=\"\" data-nscript=\"beforeInteractive\"></script><script src=\"/_next/static/chunks/webpack-abf244886dc6664e.js\" defer=\"\"></script><script src=\"/_next/static/chunks/framework-0203d16360ddbf38.js\" defer=\"\"></script><script src=\"/_next/static/chunks/main-13c38246c2e34fff.js\" defer=\"\"></script><script src=\"/_next/static/chunks/pages/_app-79aac6c7af547c6f.js\" defer=\"\"></script><script src=\"/_next/static/chunks/9760-4dbe1414c3390323.js\" defer=\"\"></script><script src=\"/_next/static/chunks/5833-5ad65b6eeff676da.js\" defer=\"\"></script><script src=\"/_next/static/chunks/171-bb4fcfbb2ea91d84.js\" defer=\"\"></script><script src=\"/_next/static/chunks/5271-0b6507b5cd11c8de.js\" defer=\"\"></script><script src=\"/_next/static/chunks/6962-9f9bedbafd14cb86.js\" defer=\"\"></script><script src=\"/_next/static/chunks/1347-ca3ab2ac5649e02c.js\" defer=\"\"></script><script src=\"/_next/static/chunks/9680-36ef207c1b3d5423.js\" defer=\"\"></script><script src=\"/_next/static/chunks/771-a84aef2182d521df.js\" defer=\"\"></script><script src=\"/_next/static/chunks/5098-4e767fb37510e036.js\" defer=\"\"></script><script src=\"/_next/static/chunks/1679-59baa0172bedb306.js\" defer=\"\"></script><script src=\"/_next/static/chunks/5328-cda10f36d8bc02f6.js\" defer=\"\"></script><script src=\"/_next/static/chunks/8239-acf66f57c3e493c1.js\" defer=\"\"></script><script src=\"/_next/static/chunks/6810-f0fd221c960db467.js\" defer=\"\"></script><script src=\"/_next/static/chunks/9997-d2e43bfa85bc6230.js\" defer=\"\"></script><script src=\"/_next/static/chunks/pages/entry/feature/%5Buid%5D-591d7d8ac5cb8473.js\" defer=\"\"></script><script src=\"/_next/static/wU_WuKX-JRgzsS4AEFUjj/_buildManifest.js\" defer=\"\"></script><script src=\"/_next/static/wU_WuKX-JRgzsS4AEFUjj/_ssgManifest.js\" defer=\"\"></script><style id=\"__jsx-1365922493\">:root{--font-fkroman:'__fkRomanStandard_6e52d0', '__fkRomanStandard_Fallback_6e52d0', Georgia, serif;--font-manuka:'__manuka_2fb8fc', '__manuka_Fallback_2fb8fc', Impact, Helvetica, sans-serif;--font-polysans:'__polySans_25d750', '__polySans_Fallback_25d750', Helvetica, Arial, sans-serif;--font-polysans-mono:'__polySansMono_e0ca51', '__polySansMono_Fallback_e0ca51', Courier New, Courier, monospace}</style></head><body class=\"antialiased qksc1b0\"><div id=\"__next\"><style>\n        *, *::before, *::after {\n          transition: none!important;\n        }\n      </style><div class=\"jsx-1365922493 duet--app\"><a class=\"text-2xl text-pink-500 border-b-pink-500 focus:outline-pink-500 sr-only z-50 block border-8 bg-white p-7 text-center opacity-0 transition-opacity focus:visible focus:static focus:h-auto focus:w-full focus:overflow-auto focus:opacity-100  focus:outline-dotted\" href=\"#content\">Skip to main content</a><div class=\"\"><div class=\"duet--navigation--navigation\"><div class=\"absolute h-[64px] w-full overflow-x-hidden md:h-[150px]\"><div class=\"relative h-[64px] w-full max-w-container-lg md:left-1/2 md:h-[150px] md:-translate-x-1/2\"><a href=\"/\"><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 309 70\" role=\"img\" class=\"absolute left-[-16px] top-[-3px] z-0 h-[64px] w-[282px] md:h-[174px] md:w-[769px] md:left-[-200px] md:top-[-24px] fill-black/30\" width=\"100%\" height=\"100%\" fill=\"none\"><title>The Verge</title><desc>The Verge logo.</desc><path d=\"m231.196 17.897-.302 9.071c-10.592-.726-13.618 1.996-13.618 10.885V39h-9.078V18.441h9.078v5.866c2.724-4.777 6.416-6.954 13.92-6.41ZM15.131 54.786h9.078V19.71h-9.078v35.075Zm44.968-36.828c-6.355 0-10.228 2.842-12.286 5.986V4.593H0v8.466h39.34V39h8.654c0-7.438 4.298-12.697 9.563-12.697 4.54 0 6.597 2.237 6.597 10.28v18.203h9.078V33.318c0-10.28-5.265-15.36-13.133-15.36ZM95.807 47.83c-5.507 0-9.078-3.326-9.683-8.829H77.59c.847 9.676 7.202 16.51 18.157 16.51 8.473 0 13.254-3.81 15.736-9.555l-7.687-3.387c-1.15 3.447-3.268 5.261-7.989 5.261Zm-.363-29.692a19.226 19.226 0 0 0-9.32 2.177l4.357 6.168c1.634-.846 3.39-1.27 5.266-1.21 5.084 0 7.686 3.327 8.049 7.68H95.02v6.048h17.31c.121-.907.182-1.754.182-2.66.06-13.184-8.655-18.203-17.068-18.203ZM185.32 47.83c-5.507 0-9.078-3.326-9.683-8.829h-8.534c.847 9.676 7.202 16.51 18.157 16.51 8.473 0 13.254-3.81 15.736-9.555l-7.687-3.387c-1.21 3.447-3.328 5.261-7.989 5.261Zm-.302-29.692a19.226 19.226 0 0 0-9.321 2.177l4.358 6.168c1.634-.846 3.389-1.27 5.265-1.21 5.084 0 7.687 3.327 8.05 7.68h-8.776v6.048h17.31c.121-.907.181-1.754.181-2.66.061-13.184-8.655-18.203-17.067-18.203ZM291.416 47.83c-5.507 0-9.078-3.326-9.683-8.829h-8.534c.847 9.676 7.202 16.51 18.157 16.51 8.473 0 13.254-3.81 15.736-9.555l-7.687-3.387c-1.21 3.447-3.328 5.261-7.989 5.261Zm-.484-29.692a19.225 19.225 0 0 0-9.32 2.177l4.357 6.168c1.635-.846 3.39-1.27 5.266-1.21 5.084 0 7.686 3.327 8.049 7.68h-8.775v6.048h17.309c.121-.907.182-1.754.182-2.66.06-13.184-8.655-18.203-17.068-18.203ZM117.172.299 133.5 39h9.926L130.971 8.221h16.099V.36L117.172.3Zm48.418.06L146.888 47.71l-2.784 7.076h9.502L176.06.36h-10.47Zm83.461 53.58c3.873 0 7.081-1.089 9.32-2.963l-3.631-5.745c-1.15.484-2.421.665-3.692.665-4.963 0-7.808-2.963-8.776-6.894h-8.897c1.211 8.406 7.263 14.937 15.676 14.937Zm11.196-30.418c-2.057-3.265-6.234-5.624-12.044-5.624-5.689-.06-10.954 3.024-13.738 8.043l7.565 4.838c1.392-2.903 4.116-4.838 8.292-4.838 5.931 0 9.925 4.596 9.925 10.038 0 1.029-.121 2.057-.423 3.024h9.502v-20.5h-9.079v5.019Zm-8.775 38.642c-5.871 0-8.05-2.842-8.474-6.168h-8.654c.181 6.35 4.418 13.304 17.309 13.304 8.715 0 14.404-4.354 16.765-10.885l-8.171-2.842c-1.15 4.233-4.297 6.591-8.775 6.591Z\"></path></svg></a><a class=\"absolute left-0 top-0 z-10 h-[60px] w-[265px] md:hidden\" href=\"/\"><span class=\"sr-only\">The Verge homepage</span></a></div></div><div class=\"md:px-34 pointer-events-none relative mx-auto mb-16 flex h-[48px] w-full max-w-container-lg items-end px-20 font-polysans text-15 md:mb-80 md:h-80 md:text-20 lg:px-0\"><nav class=\"pointer-events-auto relative ml-auto border-b pb-6 md:pb-8 text-white\"><ul class=\"flex items-end font-light\"><li class=\"hidden md:flex\"><a href=\"/\"><span class=\"sr-only\">The Verge homepage</span><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 309 70\" role=\"img\" class=\"h-[28px] w-[117px] hover:opacity-60 hover:transition-all hover:ease-in-out md:translate-y-2 fill-white\" width=\"100%\" height=\"100%\" fill=\"none\"><title>The Verge</title><desc>The Verge logo.</desc><path d=\"m231.196 17.897-.302 9.071c-10.592-.726-13.618 1.996-13.618 10.885V39h-9.078V18.441h9.078v5.866c2.724-4.777 6.416-6.954 13.92-6.41ZM15.131 54.786h9.078V19.71h-9.078v35.075Zm44.968-36.828c-6.355 0-10.228 2.842-12.286 5.986V4.593H0v8.466h39.34V39h8.654c0-7.438 4.298-12.697 9.563-12.697 4.54 0 6.597 2.237 6.597 10.28v18.203h9.078V33.318c0-10.28-5.265-15.36-13.133-15.36ZM95.807 47.83c-5.507 0-9.078-3.326-9.683-8.829H77.59c.847 9.676 7.202 16.51 18.157 16.51 8.473 0 13.254-3.81 15.736-9.555l-7.687-3.387c-1.15 3.447-3.268 5.261-7.989 5.261Zm-.363-29.692a19.226 19.226 0 0 0-9.32 2.177l4.357 6.168c1.634-.846 3.39-1.27 5.266-1.21 5.084 0 7.686 3.327 8.049 7.68H95.02v6.048h17.31c.121-.907.182-1.754.182-2.66.06-13.184-8.655-18.203-17.068-18.203ZM185.32 47.83c-5.507 0-9.078-3.326-9.683-8.829h-8.534c.847 9.676 7.202 16.51 18.157 16.51 8.473 0 13.254-3.81 15.736-9.555l-7.687-3.387c-1.21 3.447-3.328 5.261-7.989 5.261Zm-.302-29.692a19.226 19.226 0 0 0-9.321 2.177l4.358 6.168c1.634-.846 3.389-1.27 5.265-1.21 5.084 0 7.687 3.327 8.05 7.68h-8.776v6.048h17.31c.121-.907.181-1.754.181-2.66.061-13.184-8.655-18.203-17.067-18.203ZM291.416 47.83c-5.507 0-9.078-3.326-9.683-8.829h-8.534c.847 9.676 7.202 16.51 18.157 16.51 8.473 0 13.254-3.81 15.736-9.555l-7.687-3.387c-1.21 3.447-3.328 5.261-7.989 5.261Zm-.484-29.692a19.225 19.225 0 0 0-9.32 2.177l4.357 6.168c1.635-.846 3.39-1.27 5.266-1.21 5.084 0 7.686 3.327 8.049 7.68h-8.775v6.048h17.309c.121-.907.182-1.754.182-2.66.06-13.184-8.655-18.203-17.068-18.203ZM117.172.299 133.5 39h9.926L130.971 8.221h16.099V.36L117.172.3Zm48.418.06L146.888 47.71l-2.784 7.076h9.502L176.06.36h-10.47Zm83.461 53.58c3.873 0 7.081-1.089 9.32-2.963l-3.631-5.745c-1.15.484-2.421.665-3.692.665-4.963 0-7.808-2.963-8.776-6.894h-8.897c1.211 8.406 7.263 14.937 15.676 14.937Zm11.196-30.418c-2.057-3.265-6.234-5.624-12.044-5.624-5.689-.06-10.954 3.024-13.738 8.043l7.565 4.838c1.392-2.903 4.116-4.838 8.292-4.838 5.931 0 9.925 4.596 9.925 10.038 0 1.029-.121 2.057-.423 3.024h9.502v-20.5h-9.079v5.019Zm-8.775 38.642c-5.871 0-8.05-2.842-8.474-6.168h-8.654c.181 6.35 4.418 13.304 17.309 13.304 8.715 0 14.404-4.354 16.765-10.885l-8.171-2.842c-1.15 4.233-4.297 6.591-8.775 6.591Z\"></path></svg></a><span aria-hidden=\"true\" class=\"hidden px-16 md:inline\">/</span></li><li class=\"hidden md:inline\"><a href=\"/tech\" class=\"hover:opacity-50 hover:transition-all hover:ease-in-out\">Tech</a><span aria-hidden=\"true\" class=\"hidden px-16 md:inline\">/</span></li><li class=\"hidden md:inline\"><a href=\"/reviews\" class=\"hover:opacity-50 hover:transition-all hover:ease-in-out\">Reviews</a><span aria-hidden=\"true\" class=\"hidden px-16 md:inline\">/</span></li><li class=\"hidden md:inline\"><a href=\"/science\" class=\"hover:opacity-50 hover:transition-all hover:ease-in-out\">Science</a><span aria-hidden=\"true\" class=\"hidden px-16 md:inline\">/</span></li><li class=\"hidden md:inline\"><a href=\"/entertainment\" class=\"hover:opacity-50 hover:transition-all hover:ease-in-out\">Entertainment</a><span aria-hidden=\"true\" class=\"hidden px-16 md:inline\">/</span></li><li><button class=\"flex cursor-pointer flex-nowrap items-center hover:opacity-50 hover:transition-all hover:ease-in-out\"><span class=\"hidden md:inline\">More</span><span class=\"md:hidden\">Menu</span><svg width=\"100%\" height=\"100%\" viewBox=\"0 0 28 28\" xmlns=\"http://www.w3.org/2000/svg\" class=\"ml-8 inline-block h-18 w-18 md:mt-2 md:h-[22px] md:w-[22px] fill-white\"><title>Expand</title><path d=\"M28 11.76H16.24V0h-4.48v11.76H0v4.48h11.76V28h4.48V16.24H28v-4.48Z\"></path></svg></button></li></ul></nav></div></div><div class=\"duet--navigation--sticky-nav fixed inset-x-0 top-0 z-40 w-full bg-white drop-shadow-sticky-nav transition-opacity duration-200 pointer-events-none opacity-0\"><div class=\"mx-auto flex h-50 w-full max-w-container-lg items-center justify-between justify-self-start px-12 lg:px-0\"><a class=\"flex\" href=\"/\" aria-label=\"The Verge logo. Click to visit the homepage\" tabindex=\"-1\"><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 309 70\" role=\"img\" class=\"w-[141px] fill-black hover:opacity-60 hover:transition-all hover:ease-in-out\" width=\"100%\" height=\"100%\" fill=\"none\"><title>The Verge</title><desc>The Verge logo.</desc><path d=\"m231.196 17.897-.302 9.071c-10.592-.726-13.618 1.996-13.618 10.885V39h-9.078V18.441h9.078v5.866c2.724-4.777 6.416-6.954 13.92-6.41ZM15.131 54.786h9.078V19.71h-9.078v35.075Zm44.968-36.828c-6.355 0-10.228 2.842-12.286 5.986V4.593H0v8.466h39.34V39h8.654c0-7.438 4.298-12.697 9.563-12.697 4.54 0 6.597 2.237 6.597 10.28v18.203h9.078V33.318c0-10.28-5.265-15.36-13.133-15.36ZM95.807 47.83c-5.507 0-9.078-3.326-9.683-8.829H77.59c.847 9.676 7.202 16.51 18.157 16.51 8.473 0 13.254-3.81 15.736-9.555l-7.687-3.387c-1.15 3.447-3.268 5.261-7.989 5.261Zm-.363-29.692a19.226 19.226 0 0 0-9.32 2.177l4.357 6.168c1.634-.846 3.39-1.27 5.266-1.21 5.084 0 7.686 3.327 8.049 7.68H95.02v6.048h17.31c.121-.907.182-1.754.182-2.66.06-13.184-8.655-18.203-17.068-18.203ZM185.32 47.83c-5.507 0-9.078-3.326-9.683-8.829h-8.534c.847 9.676 7.202 16.51 18.157 16.51 8.473 0 13.254-3.81 15.736-9.555l-7.687-3.387c-1.21 3.447-3.328 5.261-7.989 5.261Zm-.302-29.692a19.226 19.226 0 0 0-9.321 2.177l4.358 6.168c1.634-.846 3.389-1.27 5.265-1.21 5.084 0 7.687 3.327 8.05 7.68h-8.776v6.048h17.31c.121-.907.181-1.754.181-2.66.061-13.184-8.655-18.203-17.067-18.203ZM291.416 47.83c-5.507 0-9.078-3.326-9.683-8.829h-8.534c.847 9.676 7.202 16.51 18.157 16.51 8.473 0 13.254-3.81 15.736-9.555l-7.687-3.387c-1.21 3.447-3.328 5.261-7.989 5.261Zm-.484-29.692a19.225 19.225 0 0 0-9.32 2.177l4.357 6.168c1.635-.846 3.39-1.27 5.266-1.21 5.084 0 7.686 3.327 8.049 7.68h-8.775v6.048h17.309c.121-.907.182-1.754.182-2.66.06-13.184-8.655-18.203-17.068-18.203ZM117.172.299 133.5 39h9.926L130.971 8.221h16.099V.36L117.172.3Zm48.418.06L146.888 47.71l-2.784 7.076h9.502L176.06.36h-10.47Zm83.461 53.58c3.873 0 7.081-1.089 9.32-2.963l-3.631-5.745c-1.15.484-2.421.665-3.692.665-4.963 0-7.808-2.963-8.776-6.894h-8.897c1.211 8.406 7.263 14.937 15.676 14.937Zm11.196-30.418c-2.057-3.265-6.234-5.624-12.044-5.624-5.689-.06-10.954 3.024-13.738 8.043l7.565 4.838c1.392-2.903 4.116-4.838 8.292-4.838 5.931 0 9.925 4.596 9.925 10.038 0 1.029-.121 2.057-.423 3.024h9.502v-20.5h-9.079v5.019Zm-8.775 38.642c-5.871 0-8.05-2.842-8.474-6.168h-8.654c.181 6.35 4.418 13.304 17.309 13.304 8.715 0 14.404-4.354 16.765-10.885l-8.171-2.842c-1.15 4.233-4.297 6.591-8.775 6.591Z\"></path></svg></a><div class=\"group flex flex-nowrap\"><button class=\"cursor-pointer items-center font-polysans text-15 flex\"><span class=\"group-hover:opacity-60\">Menu</span><svg width=\"100%\" height=\"100%\" viewBox=\"0 0 28 28\" xmlns=\"http://www.w3.org/2000/svg\" class=\"ml-8 inline-block h-18 w-18 fill-black group-hover:opacity-60 md:mt-2 md:h-[22px] md:w-[22px]\"><title>Expand</title><path d=\"M28 11.76H16.24V0h-4.48v11.76H0v4.48h11.76V28h4.48V16.24H28v-4.48Z\"></path></svg></button></div></div></div></div><div class=\"duet--page-layout--feature-article _6ytxv90\"><style>\nmain .md\\:hidden figure {\n\tbackground-image: url('https://cdn.vox-cdn.com/uploads/chorus_asset/file/24738362/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_Square_min.jpeg');\n  background-position: center center;\n  background-size: cover;\n}\n\nmain .md\\:hidden figure img {\n\topacity: 0;\n}</style><div style=\"position:fixed;top:1px;left:1px;width:1px;height:0;padding:0;margin:-1px;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border-width:0;display:none\"></div><div style=\"position:fixed;top:1px;left:1px;width:1px;height:0;padding:0;margin:-1px;overflow:hidden;clip:rect(0, 0, 0, 0);white-space:nowrap;border-width:0;display:none\"></div><main class=\"feature px-20\"><article class=\"mx-auto w-full max-w-container-lg\"><div class=\"duet--article--lede duet--article--lede-headline-above-blurple mx-auto md:max-w-container-md lg:max-w-none\"><div class=\"flex flex-col lg:flex-row-reverse lg:justify-end [&amp;_a]:text-black text-white [&amp;_a]:text-white\"><div class=\"lg:mb-32\"><div class=\"mb-18 md:mb-24\"><ul class=\"lg:px-0 article-groups leading-100 mb-8\"><li class=\"inline font-polysans-mono text-12 font-medium uppercase tracking-12 text-blurple\"><a class=\"hover:shadow-underline-inherit\" href=\"/ai-artificial-intelligence\">Artificial Intelligence</a></li></ul><div class=\"mb-8\"><h1 class=\"duet--article--feature-headline sticky-nav-trigger relative bg-[length:1px_1.04em] pb-8 font-polysans text-45 font-medium leading-[1.04] -tracking-2 before:w-full lg:text-65 bg-repeating-lines-light\">AI Is a Lot of Work</h1></div><h2 class=\"duet--article--dangerously-set-cms-markup duet--article--feature-dek font-polysans text-22 font-light leading-110 lg:text-26\">As the technology becomes ubiquitous, a vast tasker underclass is emerging — and not going anywhere.</h2></div><div class=\"mb-2 flex w-full justify-between\"><div><p class=\"duet--article--article-byline max-w-[550px] font-polysans text-12 leading-120\"><span>By</span> <span><span class=\"duet--article-byline-and\"></span> <span class=\"font-medium\"><a class=\"hover:shadow-underline-inherit\" href=\"/authors/josh-dzieza\">Josh Dzieza</a></span><span class=\"text-white\">, <span class=\"duet--article--dangerously-set-cms-markup\">an investigations editor covering tech, business, and climate change. Since joining The Verge in 2014, he’s won a Loeb Award for feature writing, among others.</span></span></span></p><p class=\"duet--article--dangerously-set-cms-markup mt-2 w-full font-polysans text-12 leading-120 [&amp;_a:hover]:underline [&amp;_a]:font-medium\">Illustrations by Richard Parry for The Verge</p></div><div class=\"hidden -translate-y-2 lg:block\"><div style=\"margin:0;min-height:40px;min-width:200px;transform:translateY(-4px)\" class=\"mx-auto hidden lg:block\" data-concert=\"article_sponsorship_headline_above_desktop\"></div></div></div></div><div class=\"&amp;&amp; lg:mr-32 lg:w-full lg:max-w-[170px] lg:pt-36\"><div class=\"duet--article--date-and-comments mb-18 font-polysans text-12\"><span class=\"mb-4 [&amp;&gt;time]:leading-120 [&amp;&gt;time]:lg:block\"><time dateTime=\"2023-06-20T12:05:00.000Z\" class=\"duet--article--timestamp font-polysans text-12\"> <!-- -->Jun 20, 2023, 12:05 PM UTC</time></span><span class=\"mx-8 hidden md:inline lg:hidden\">|</span><span class=\"lg:block\"><button title=\"Go to comments\" class=\"duet--article--comments-link block md:inline\"><svg class=\"mr-4 inline\" width=\"12\" height=\"12\" fill=\"none\" viewBox=\"0 0 12 12\" stroke-width=\"1px\" xmlns=\"http://www.w3.org/2000/svg\"><title>Comments</title><path d=\"M2.4 9.1h-.207l-.147.146L.5 10.793V1.2c0-.384.316-.7.7-.7h9.6c.384 0 .7.316.7.7v7.2c0 .384-.316.7-.7.7H2.4Z\" stroke=\"currentColor\"></path></svg><span class=\"font-polysans text-12 underline\"><span class=\"coral-count\" data-coral-id=\"e6a44b77-f363-473b-9651-3e323f6f4fd9\"></span></span></button></span></div><div class=\"mb-18 md:mb-28 lg:mb-36\"><div class=\"flex justify-between\"><div><h2 class=\"sr-only\">Share this story</h2><ul class=\"duet--article--share-buttons flex leading-[0]\"><li class=\"mr-8\"><button aria-label=\"Share on Twitter\" class=\"rounded-full bg-white transition hover:bg-black\"><svg width=\"30\" height=\"30\" class=\"fill-black transition hover:fill-white\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M20.608 13.49c.008.108.008.216.008.326 0 3.336-2.44 7.184-6.9 7.184v-.002A6.667 6.667 0 0 1 10 19.866c.192.024.384.036.577.037a4.747 4.747 0 0 0 3.011-1.083c-1.037-.02-1.947-.725-2.265-1.754.364.073.738.058 1.095-.043-1.131-.238-1.945-1.273-1.945-2.475v-.032c.337.195.714.304 1.1.316-1.065-.742-1.393-2.218-.75-3.371 1.231 1.577 3.047 2.536 4.997 2.637a2.594 2.594 0 0 1 .701-2.412 2.36 2.36 0 0 1 3.431.11 4.75 4.75 0 0 0 1.54-.613 2.518 2.518 0 0 1-1.066 1.396c.48-.059.95-.193 1.392-.397-.325.508-.735.95-1.21 1.307Z\"></path></svg></button></li><li class=\"mr-8\"><button aria-label=\"Share on Facebook\" class=\"rounded-full bg-white transition hover:bg-black\"><svg width=\"30\" height=\"30\" class=\"fill-black transition hover:fill-white\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"m18.393 16.258.355-2.335H16.53v-1.515c0-.639.31-1.262 1.303-1.262h1.01V9.158S17.926 9 17.051 9c-1.827 0-3.021 1.118-3.021 3.143v1.78H12v2.335h2.031v5.644a7.944 7.944 0 0 0 2.499 0v-5.644h1.863Z\"></path></svg></button></li><li><div class=\"relative flex items-center\"><button aria-label=\"Copy link\" class=\"rounded-full bg-white transition hover:bg-black\"><svg width=\"30\" height=\"30\" class=\"fill-black transition hover:fill-white\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M14.187 21.112a3.044 3.044 0 0 1-4.299 0 3.044 3.044 0 0 1 0-4.299l2.388-2.388a3.044 3.044 0 0 1 4.299 0 .507.507 0 1 1-.717.717c-.8-.8-2.065-.8-2.865 0l-2.388 2.388c-.8.8-.8 2.065 0 2.865.8.8 2.065.8 2.865 0l2.269-2.268a.507.507 0 1 1 .716.716l-2.268 2.269Zm4.537-4.537a3.044 3.044 0 0 1-4.299 0 .506.506 0 1 1 .717-.717c.8.8 2.065.8 2.865 0l2.388-2.388c.8-.8.8-2.065 0-2.865-.8-.8-2.065-.8-2.865 0l-2.269 2.268a.507.507 0 1 1-.716-.716l2.268-2.269a3.044 3.044 0 0 1 4.299 0 3.044 3.044 0 0 1 0 4.299l-2.388 2.388Z\"></path></svg></button></div></li></ul></div><div class=\"lg:hidden\"><div style=\"margin:0;min-height:40px;min-width:200px\" class=\"mx-auto block lg:hidden\" data-concert=\"article_sponsorship_headline_above_mobile_and_tablet\"></div></div></div></div></div></div><div class=\"relative lg:min-w-[37.5rem]\"><div class=\"duet--article--lede-background fullbleed absolute bottom-[75%] -z-20 h-[10000px] md:bottom-[66%] lg:bottom-[50%] bg-blurple\"></div><div class=\"md:hidden\"><figure class=\"duet--article--lede-image w-full\"><span style=\"box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative\"><span style=\"box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;padding-top:100%\"></span><img alt=\"\" sizes=\"100vw\" srcSet=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/376x376/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/384x384/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/415x415/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/480x480/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/540x540/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/640x640/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/750x750/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/828x828/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/1080x1080/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/1200x1200/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/1440x1440/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/1920x1920/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/2048x2048/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/2400x2400/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 2400w\" src=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/2400x2400/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg\" decoding=\"async\" data-nimg=\"responsive\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\"/></span></figure></div><div class=\"hidden md:block\"><figure class=\"duet--article--lede-image w-full\"><span style=\"box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative\"><span style=\"box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;padding-top:66.63636363636364%\"></span><img alt=\"\" sizes=\"(max-width: 768px) 100vw, (max-width: 1180px) 700px, 1100px\" srcSet=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/376x251/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/384x256/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/415x277/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/480x320/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/540x360/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/640x427/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/750x500/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/828x552/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/1080x720/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/1200x800/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/1440x960/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/1920x1280/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/2048x1365/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/2400x1600/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg 2400w\" src=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/2400x1600/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg\" decoding=\"async\" data-nimg=\"responsive\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\"/></span></figure></div></div></div><div class=\"relative mt-28 md:mx-auto md:flex md:max-w-container-md lg:mt-36 lg:max-w-none\"><div class=\"duet--article--article-body-component-container sm:ml-auto md:ml-100 md:max-w-article-body lg:mx-100\"><div id=\"content\" class=\"clearfix\"><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\"><small><em>This article is a collaboration between </em></small><a href=\"https://nymag.com/intelligencer/article/ai-artificial-intelligence-humans-technology-business-factory.html\"><small>New York Magazine</small></a><small><em> and The Verge.</em></small></p></div><div class=\"duet--article--article-body-component\"><hr class=\"duet--layout--standard-divider my-36 border-0 border-b border-gray-94\"/></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup mb-20 font-fkroman text-22 leading-150 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-franklin first-letter:float-left first-letter:mr-18 first-letter:font-polysans-mono first-letter:text-[117px] first-letter:font-medium first-letter:leading-[.72] dark:first-letter:text-franklin\"><strong>A few months</strong> after graduating from college in Nairobi, a 30-year-old I’ll call Joe got a job as an annotator — the tedious work of processing the raw information used to train artificial intelligence. AI learns by finding patterns in enormous quantities of data, but first that data has to be sorted and tagged by people, a vast workforce mostly hidden behind the machines. In Joe’s case, he was labeling footage for self-driving cars — identifying every vehicle, pedestrian, cyclist, anything a driver needs to be aware of — frame by frame and from every possible camera angle. It’s difficult and repetitive work. A several-second blip of footage took eight hours to annotate, for which Joe was paid about $10.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">Then, in 2019, an opportunity arose: Joe could make four times as much running an annotation boot camp for a new company that was hungry for labelers. Every two weeks, 50 new recruits would file into an office building in Nairobi to begin their apprenticeships. There seemed to be limitless demand for the work. They would be asked to categorize clothing seen in mirror selfies, look through the eyes of robot vacuum cleaners to determine which rooms they were in, and draw squares around lidar scans of motorcycles. Over half of Joe’s students usually dropped out before the boot camp was finished. “Some people don’t know how to stay in one place for long,” he explained with gracious understatement. Also, he acknowledged, “it is very boring.”</p></div><div class=\"duet--article--article-body-component clear-both block md:float-left md:mr-30 md:w-[320px] lg:-ml-100\"><div class=\"duet--article--sidebar bg-gray-200 mb-20 w-full rounded-sm bg-[#F8F5FF] p-20 [&amp;&gt;*:last-child&gt;*:last-child]:mb-0\"><div class=\"my-9\"><div class=\"transition-all duration-300 ease-in-out\"><div class=\"fixed inset-0 h-[110vh] w-full bg-white transition-all duration-300 ease-in-out z-[-1] cursor-default opacity-0\"></div><div role=\"button\" aria-label=\"Zoom\" tabindex=\"0\" class=\"visible z-30 w-full origin-center transition-all duration-300 ease-in-out cursor-zoom-in\"><figure class=\"transition-all duration-300 ease-in-out lg:mx-0\"><div><div class=\"duet--media--content-warning relative\" style=\"padding-top:125%\"><span style=\"box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0\"><img alt=\"“Inside the AI Factory” on the cover of New York Magazine\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\"/><noscript><img alt=\"“Inside the AI Factory” on the cover of New York Magazine\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\" sizes=\"(max-width: 1023px) 100vw, 744px\" srcSet=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x3000/376x470/filters:focal(1200x1500:1201x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24734352/1323Cov4x5_AI_Factory.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x3000/384x480/filters:focal(1200x1500:1201x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24734352/1323Cov4x5_AI_Factory.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x3000/415x519/filters:focal(1200x1500:1201x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24734352/1323Cov4x5_AI_Factory.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x3000/480x600/filters:focal(1200x1500:1201x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24734352/1323Cov4x5_AI_Factory.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x3000/540x675/filters:focal(1200x1500:1201x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24734352/1323Cov4x5_AI_Factory.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x3000/640x800/filters:focal(1200x1500:1201x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24734352/1323Cov4x5_AI_Factory.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x3000/750x938/filters:focal(1200x1500:1201x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24734352/1323Cov4x5_AI_Factory.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x3000/828x1035/filters:focal(1200x1500:1201x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24734352/1323Cov4x5_AI_Factory.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x3000/1080x1350/filters:focal(1200x1500:1201x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24734352/1323Cov4x5_AI_Factory.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x3000/1200x1500/filters:focal(1200x1500:1201x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24734352/1323Cov4x5_AI_Factory.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x3000/1440x1800/filters:focal(1200x1500:1201x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24734352/1323Cov4x5_AI_Factory.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x3000/1920x2400/filters:focal(1200x1500:1201x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24734352/1323Cov4x5_AI_Factory.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x3000/2048x2560/filters:focal(1200x1500:1201x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24734352/1323Cov4x5_AI_Factory.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x3000/2400x3000/filters:focal(1200x1500:1201x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24734352/1323Cov4x5_AI_Factory.jpg 2400w\" src=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x3000/2400x3000/filters:focal(1200x1500:1201x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24734352/1323Cov4x5_AI_Factory.jpg\"/></noscript></span></div></div></figure></div><div class=\"z-1 w-full hidden\"><figure class=\"transition-all duration-300 ease-in-out lg:mx-0\"><div><div class=\"duet--media--content-warning relative\" style=\"padding-top:125%\"><span style=\"box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0\"><img alt=\"“Inside the AI Factory” on the cover of New York Magazine\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\"/><noscript><img alt=\"“Inside the AI Factory” on the cover of New York Magazine\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\" sizes=\"(max-width: 1023px) 100vw, 744px\" srcSet=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x3000/376x470/filters:focal(1200x1500:1201x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24734352/1323Cov4x5_AI_Factory.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x3000/384x480/filters:focal(1200x1500:1201x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24734352/1323Cov4x5_AI_Factory.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x3000/415x519/filters:focal(1200x1500:1201x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24734352/1323Cov4x5_AI_Factory.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x3000/480x600/filters:focal(1200x1500:1201x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24734352/1323Cov4x5_AI_Factory.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x3000/540x675/filters:focal(1200x1500:1201x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24734352/1323Cov4x5_AI_Factory.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x3000/640x800/filters:focal(1200x1500:1201x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24734352/1323Cov4x5_AI_Factory.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x3000/750x938/filters:focal(1200x1500:1201x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24734352/1323Cov4x5_AI_Factory.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x3000/828x1035/filters:focal(1200x1500:1201x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24734352/1323Cov4x5_AI_Factory.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x3000/1080x1350/filters:focal(1200x1500:1201x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24734352/1323Cov4x5_AI_Factory.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x3000/1200x1500/filters:focal(1200x1500:1201x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24734352/1323Cov4x5_AI_Factory.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x3000/1440x1800/filters:focal(1200x1500:1201x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24734352/1323Cov4x5_AI_Factory.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x3000/1920x2400/filters:focal(1200x1500:1201x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24734352/1323Cov4x5_AI_Factory.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x3000/2048x2560/filters:focal(1200x1500:1201x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24734352/1323Cov4x5_AI_Factory.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x3000/2400x3000/filters:focal(1200x1500:1201x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24734352/1323Cov4x5_AI_Factory.jpg 2400w\" src=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2400x3000/2400x3000/filters:focal(1200x1500:1201x1501):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24734352/1323Cov4x5_AI_Factory.jpg\"/></noscript></span></div></div></figure></div></div></div><div class=\"[&amp;_p]:font-polysans [&amp;_p]:text-16 [&amp;_p]:font-light [&amp;_p]:leading-130\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\"><small><em>This article is a collaboration between </em></small><a href=\"https://nymag.com/intelligencer/article/ai-artificial-intelligence-humans-technology-business-factory.html\"><small>New York Magazine</small></a><small><em> and The Verge.</em></small></p></div></div></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">But it was a job in a place where jobs were scarce, and Joe turned out hundreds of graduates. After boot camp, they went home to work alone in their bedrooms and kitchens, forbidden from telling anyone what they were working on, which wasn’t really a problem because they rarely knew themselves. Labeling objects for self-driving cars was obvious, but what about categorizing whether snippets of distorted dialogue were spoken by a robot or a human? Uploading photos of yourself staring into a webcam with a blank expression, then with a grin, then wearing a motorcycle helmet? Each project was such a small component of some larger process that it was difficult to say what they were actually training AI to do. Nor did the names of the projects offer any clues: Crab Generation, Whale Segment, Woodland Gyro, and Pillbox Bratwurst. They were non sequitur code names for non sequitur work.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">As for the company employing them, most knew it only as Remotasks, a website offering work to anyone fluent in English. Like most of the annotators I spoke with, Joe was unaware until I told him that Remotasks is the worker-facing subsidiary of a company called Scale AI, a multibillion-dollar Silicon Valley data vendor that counts OpenAI and the U.S. military among its customers. Neither Remotasks’ or Scale’s website mentions the other.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">Much of the public response to language models like OpenAI’s ChatGPT has focused on all the jobs they appear poised to automate. But behind even the most impressive AI system are people — huge numbers of people labeling data to train it and clarifying data when it gets confused. Only the companies that can afford to buy this data can compete, and those that get it are highly motivated to keep it secret. The result is that, with few exceptions, little is known about the information shaping these systems’ behavior, and even less is known about the people doing the shaping.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">For Joe’s students, it was work stripped of all its normal trappings: a schedule, colleagues, knowledge of what they were working on or whom they were working for. In fact, they rarely called it work at all — just “tasking.” They were taskers.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">The anthropologist David Graeber defines “bullshit jobs” as employment without meaning or purpose, work that should be automated but for reasons of bureaucracy or status or inertia is not. These AI jobs are their bizarro twin: work that people want to automate, and often think is already automated, yet still requires a human stand-in. The jobs have a purpose; it’s just that workers often have no idea what it is.</p></div><div class=\"duet--article--article-body-component\"><hr class=\"duet--layout--standard-divider my-36 border-0 border-b border-gray-94\"/></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white min-h-[80px] first-letter:float-left first-letter:mr-18 first-letter:font-polysans-mono first-letter:text-100 first-letter:font-medium first-letter:leading-[.72]  first-letter:selection:bg-franklin-20 dark:first-letter:text-franklin\">The current AI boom — the convincingly human-sounding chatbots, the artwork that can be generated from simple prompts, and the multibillion-dollar valuations of the companies behind these technologies — began with an unprecedented feat of tedious and repetitive labor.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">In 2007, the AI researcher Fei-Fei Li, then a professor at Princeton, suspected the key to improving image-recognition neural networks, a method of machine learning that had been languishing for years, was training on more data — millions of labeled images rather than tens of thousands. The problem was that it would take decades and millions of dollars for her team of undergrads to label that many photos.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">Li found thousands of workers on Mechanical Turk, Amazon’s crowdsourcing platform where people around the world complete small tasks for cheap. The resulting annotated dataset, called ImageNet, enabled breakthroughs in machine learning that revitalized the field and ushered in a decade of progress.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">Annotation remains a foundational part of making AI, but there is often a sense among engineers that it’s a passing, inconvenient prerequisite to the more glamorous work of building models. You collect as much labeled data as you can get as cheaply as possible to train your model, and if it works, at least in theory, you no longer need the annotators. But annotation is never really finished. Machine-learning systems are what researchers call “brittle,” prone to fail when encountering something that isn’t well represented in their training data. These failures, called “edge cases,” can have serious consequences. In 2018, an Uber self-driving test car killed a woman because, though it was programmed to avoid cyclists and pedestrians, it didn’t know what to make of someone walking a bike across the street. The more AI systems are put out into the world to dispense legal advice and medical help, the more edge cases they will encounter and the more humans will be needed to sort them. Already, this has given rise to a global industry staffed by people like Joe who use their uniquely human faculties to help the machines.</p></div><div class=\"duet--article--article-body-component clear-both block md:float-left md:mr-30 md:w-[320px] lg:-ml-100\"><div class=\"duet--article--article-pullquote mb-20\"><div class=\"mb-10 h-[22px] w-[65px] bg-franklin\"></div><p class=\"duet--article--dangerously-set-cms-markup relative bg-repeating-lines-dark bg-[length:1px_1.2em] pb-8 font-polysans text-28 font-medium leading-120 tracking-1 selection:bg-franklin-20  dark:bg-repeating-lines-light dark:text-white dark:selection:bg-blurple\">Is that a red shirt with white stripes or a white shirt with red stripes? Is a wicker bowl a “decorative bowl” if it’s full of apples? What color is leopard print?</p></div></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">Over the past six months, I spoke with more than two dozen annotators from around the world, and while many of them were training cutting-edge chatbots, just as many were doing the mundane manual labor required to keep AI running. There are people classifying the emotional content of TikTok videos, new variants of email spam, and the precise sexual provocativeness of online ads. Others are looking at credit-card transactions and figuring out what sort of purchase they relate to or checking e-commerce recommendations and deciding whether that shirt is really something you might like after buying that other shirt. Humans are correcting customer-service chatbots, listening to Alexa requests, and categorizing the emotions of people on video calls. They are labeling food so that smart refrigerators don’t get confused by new packaging, checking automated security cameras before sounding alarms, and identifying corn for baffled autonomous tractors.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">“There’s an entire supply chain,” said Sonam Jindal, the program and research lead of the nonprofit Partnership on AI. “The general perception in the industry is that this work isn’t a critical part of development and isn’t going to be needed for long. All the excitement is around building artificial intelligence, and once we build that, it won’t be needed anymore, so why think about it? But it’s infrastructure for AI. Human intelligence is the basis of artificial intelligence, and we need to be valuing these as real jobs in the AI economy that are going to be here for a while.”</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">The data vendors behind familiar names like OpenAI, Google, and Microsoft come in different forms. There are private outsourcing companies with call-center-like offices, such as the Kenya- and Nepal-based CloudFactory, where Joe annotated for $1.20 an hour before switching to Remotasks. There are also “crowdworking” sites like Mechanical Turk and Clickworker where anyone can sign up to perform tasks. In the middle are services like Scale AI. Anyone can sign up, but everyone has to pass qualification exams and training courses and undergo performance monitoring. Annotation is big business. Scale, founded in 2016 by then-19-year-old Alexandr Wang, was valued in 2021 at $7.3 billion, making him what <em>Forbes</em> called “the youngest self-made billionaire,” though the magazine noted in a recent profile that his stake has fallen on secondary markets since then.</p></div><div class=\"duet--article--article-body-component clear-both block w-full md:ml-[-100px] md:w-outdent\"><div class=\"my-9\"><div class=\"transition-all duration-300 ease-in-out\"><div class=\"fixed inset-0 h-[110vh] w-full bg-white transition-all duration-300 ease-in-out z-[-1] cursor-default opacity-0\"></div><div role=\"button\" aria-label=\"Zoom\" tabindex=\"0\" class=\"visible z-30 w-full origin-center transition-all duration-300 ease-in-out cursor-zoom-in\"><figure class=\"transition-all duration-300 ease-in-out lg:mx-0\"><div><div class=\"duet--media--content-warning relative\" style=\"padding-top:73.2421875%\"><span style=\"box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0\"><img alt=\"\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\"/><noscript><img alt=\"\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\" sizes=\"(max-width: 1023px) 100vw, 744px\" srcSet=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/376x275/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/384x281/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/415x304/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/480x352/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/540x396/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/640x469/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/750x549/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/828x606/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/1080x791/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/1200x879/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/1440x1055/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/1920x1406/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/2048x1500/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/2400x1758/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 2400w\" src=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/2400x1758/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg\"/></noscript></span></div></div></figure></div><div class=\"z-1 w-full hidden\"><figure class=\"transition-all duration-300 ease-in-out lg:mx-0\"><div><div class=\"duet--media--content-warning relative\" style=\"padding-top:73.2421875%\"><span style=\"box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0\"><img alt=\"\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\"/><noscript><img alt=\"\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\" sizes=\"(max-width: 1023px) 100vw, 744px\" srcSet=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/376x275/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/384x281/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/415x304/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/480x352/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/540x396/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/640x469/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/750x549/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/828x606/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/1080x791/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/1200x879/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/1440x1055/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/1920x1406/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/2048x1500/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/2400x1758/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 2400w\" src=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/2400x1758/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg\"/></noscript></span></div></div></figure></div></div></div></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">This tangled supply chain is deliberately hard to map. According to people in the industry, the companies buying the data demand strict confidentiality. (This is the reason Scale cited to explain why Remotasks has a different name.) Annotation reveals too much about the systems being developed, and the huge number of workers required makes leaks difficult to prevent. Annotators are warned repeatedly not to tell anyone about their jobs, not even their friends and co-workers, but corporate aliases, project code names, and, crucially, the extreme division of labor ensure they don’t have enough information about them to talk even if they wanted to. (Most workers requested pseudonyms for fear of being booted from the platforms.) Consequently, there are no granular estimates of the number of people who work in annotation, but it is a lot, and it is growing. A recent Google Research paper gave an order-of-magnitude figure of “millions” with the potential to become “billions.”</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">Automation often unfolds in unexpected ways. Erik Duhaime, CEO of medical-data-annotation company Centaur Labs, recalled how, several years ago, prominent machine-learning engineers were predicting AI would make the job of radiologist obsolete. When that didn’t happen, conventional wisdom shifted to radiologists using AI as a tool. Neither of those is quite what he sees occurring. AI is very good at specific tasks, Duhaime said, and that leads work to be broken up and distributed across a system of specialized algorithms and to equally specialized humans. An AI system might be capable of spotting cancer, he said, giving a hypothetical example, but only in a certain type of imagery from a certain type of machine; so now, you need a human to check that the AI is being fed the right type of data and maybe another human who checks its work before passing it to another AI that writes a report, which goes to another human, and so on. “AI doesn’t replace work,” he said. “But it does change how work is organized.”</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">You might miss this if you believe AI is a brilliant, thinking machine. But if you pull back the curtain even a little, it looks more familiar, the latest iteration of a particularly Silicon Valley division of labor, in which the futuristic gleam of new technologies hides a sprawling manufacturing apparatus and the people who make it run. Duhaime reached back farther for a comparison, a digital version of the transition from craftsmen to industrial manufacturing: coherent processes broken into tasks and arrayed along assembly lines with some steps done by machines and some by humans but none resembling what came before.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">Worries about AI-driven disruption are often countered with the argument that AI automates tasks, not jobs, and that these tasks will be the dull ones, leaving people to pursue more fulfilling and human work. But just as likely, the rise of AI will look like past labor-saving technologies, maybe like the telephone or typewriter, which vanquished the drudgery of message delivering and handwriting but generated so much new correspondence, commerce, and paperwork that new offices staffed by new types of workers — clerks, accountants, typists — were required to manage it. When AI comes for your job, you may not lose it, but it might become more alien, more isolating, more tedious.</p></div><div class=\"duet--article--article-body-component\"><hr class=\"duet--layout--standard-divider my-36 border-0 border-b border-gray-94\"/></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white min-h-[80px] first-letter:float-left first-letter:mr-18 first-letter:font-polysans-mono first-letter:text-100 first-letter:font-medium first-letter:leading-[.72]  first-letter:selection:bg-franklin-20 dark:first-letter:text-franklin\">Earlier this year, I signed up for Scale AI’s Remotasks. The process was straightforward. After entering my computer specs, internet speed, and some basic contact information, I found myself in the “training center.” To access a paying task, I first had to complete an associated (unpaid) intro course.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">The training center displayed a range of courses with inscrutable names like Glue Swimsuit and Poster Macadamia. I clicked on something called GFD Chunking, which revealed itself to be labeling clothing in social-media photos.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">The instructions, however, were odd. For one, they basically consisted of the same direction reiterated in the idiosyncratically colored and capitalized typography of a collaged bomb threat.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">“DO LABEL items that are real and can be worn by humans or are intended to be worn by real people,” it read.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">“All items below SHOULD be labeled because they are real and can be worn by real-life humans,” it reiterated above photos of an Air Jordans ad, someone in a Kylo Ren helmet, and mannequins in dresses, over which was a lime-green box explaining, once again, “DO Label real items that can be worn by real people.”</p></div><div class=\"duet--article--article-body-component clear-both block\"><div class=\"my-9\"><div class=\"transition-all duration-300 ease-in-out\"><div class=\"fixed inset-0 h-[110vh] w-full bg-white transition-all duration-300 ease-in-out z-[-1] cursor-default opacity-0\"></div><div role=\"button\" aria-label=\"Zoom\" tabindex=\"0\" class=\"visible z-30 w-full origin-center transition-all duration-300 ease-in-out cursor-zoom-in\"><figure class=\"transition-all duration-300 ease-in-out lg:mx-0\"><div><div class=\"duet--media--content-warning relative\" style=\"padding-top:100%\"><span style=\"box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0\"><img alt=\"Remotasks instructions for labeling clothing.&amp;nbsp;\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\"/><noscript><img alt=\"Remotasks instructions for labeling clothing.&amp;nbsp;\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\" sizes=\"(max-width: 1023px) 100vw, 744px\" srcSet=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/376x376/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/384x384/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/415x415/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/480x480/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/540x540/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/640x640/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/750x750/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/828x828/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/1080x1080/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/1200x1200/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/1440x1440/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/1920x1920/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/2048x2048/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/2400x2400/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 2400w\" src=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/2400x2400/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg\"/></noscript></span></div></div></figure></div><div class=\"z-1 w-full hidden\"><figure class=\"transition-all duration-300 ease-in-out lg:mx-0\"><div><div class=\"duet--media--content-warning relative\" style=\"padding-top:100%\"><span style=\"box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0\"><img alt=\"Remotasks instructions for labeling clothing.&amp;nbsp;\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\"/><noscript><img alt=\"Remotasks instructions for labeling clothing.&amp;nbsp;\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\" sizes=\"(max-width: 1023px) 100vw, 744px\" srcSet=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/376x376/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/384x384/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/415x415/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/480x480/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/540x540/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/640x640/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/750x750/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/828x828/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/1080x1080/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/1200x1200/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/1440x1440/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/1920x1920/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/2048x2048/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/2400x2400/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 2400w\" src=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/2400x2400/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg\"/></noscript></span></div></div></figure></div></div><div class=\"duet--media--caption pt-6 font-polysans-mono text-12 font-light leading-130 tracking-1\"><figcaption class=\"duet--article--dangerously-set-cms-markup inline text-gray-13 dark:text-gray-e9 [&amp;&gt;a:hover]:text-black [&amp;&gt;a:hover]:shadow-underline-black dark:[&amp;&gt;a:hover]:text-gray-e9 dark:[&amp;&gt;a:hover]:shadow-underline-gray-63 [&amp;&gt;a]:shadow-underline-gray-13 dark:[&amp;&gt;a]:shadow-underline-gray-63\">Remotasks instructions for labeling clothing.</figcaption></div></div></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">I skimmed to the bottom of the manual, where the instructor had written in the large bright-red font equivalent of grabbing someone by the shoulders and shaking them, “THE FOLLOWING ITEMS SHOULD NOT BE LABELED because a human could not actually put wear any of these items!” above a photo of C-3PO, Princess Jasmine from <em>Aladdin, </em>and a cartoon shoe with eyeballs.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">Feeling confident in my ability to distinguish between real clothes that can be worn by real people and not-real clothes that cannot, I proceeded to the test. Right away, it threw an ontological curveball: a picture of a magazine depicting photos of women in dresses. Is a photograph of clothing real clothing? <em>No,</em> I thought, <em>because a human cannot wear a photograph of clothing.</em> Wrong! As far as AI is concerned, photos of real clothes are real clothes. Next came a photo of a woman in a dimly lit bedroom taking a selfie before a full-length mirror. The blouse and shorts she’s wearing are real. What about their reflection? Also real! Reflections of real clothes are also real clothes.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">After an embarrassing amount of trial and error, I made it to the actual work, only to make the horrifying discovery that the instructions I’d been struggling to follow had been updated and clarified so many times that they were now a full 43 printed pages of directives: Do NOT label open suitcases full of clothes; DO label shoes but do NOT label flippers; DO label leggings but do NOT label tights; do NOT label towels even if someone is wearing it; label costumes but do NOT label armor. And so on.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">There has been general instruction disarray across the industry, according to Milagros Miceli, a researcher at the Weizenbaum Institute in Germany who studies data work. It is in part a product of the way machine-learning systems learn. Where a human would get the concept of “shirt” with a few examples, machine-learning programs need thousands, and they need to be categorized with perfect consistency yet varied enough (polo shirts, shirts being worn outdoors, shirts hanging on a rack) that the very literal system can handle the diversity of the real world. “Imagine simplifying complex realities into something that is readable for a machine that is totally dumb,” she said.</p></div><div class=\"duet--article--article-body-component clear-both block md:float-left md:mr-30 md:w-[320px] lg:-ml-100\"><div class=\"duet--article--article-pullquote mb-20\"><div class=\"mb-10 h-[22px] w-[65px] bg-franklin\"></div><p class=\"duet--article--dangerously-set-cms-markup relative bg-repeating-lines-dark bg-[length:1px_1.2em] pb-8 font-polysans text-28 font-medium leading-120 tracking-1 selection:bg-franklin-20  dark:bg-repeating-lines-light dark:text-white dark:selection:bg-blurple\">Once, Victor stayed up 36 hours straight labeling elbows and knees and heads in photographs of crowds — he has no idea why.</p></div></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">The act of simplifying reality for a machine results in a great deal of complexity for the human. Instruction writers must come up with rules that will get humans to categorize the world with perfect consistency. To do so, they often create categories no human would use. A human asked to tag all the shirts in a photo probably wouldn’t tag the reflection of a shirt in a mirror because they would know it is a reflection and not real. But to the AI, which has no understanding of the world, it’s all just pixels and the two are perfectly identical. Fed a dataset with some shirts labeled and other (reflected) shirts unlabeled, the model won’t work. So the engineer goes back to the vendor with an update: DO label reflections of shirts. Soon, you have a 43-page guide descending into red all-caps.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">“When you start off, the rules are relatively simple,” said a former Scale employee who requested anonymity because of an NDA. “Then they get back a thousand images and then they’re like, <em>Wait a second, </em>and then you have multiple engineers and they start to argue with each other. It’s very much a human thing.”</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">The job of the annotator often involves putting human understanding aside and following instructions very, <em>very</em> literally — to think, as one annotator said, like a robot. It’s a strange mental space to inhabit, doing your best to follow nonsensical but rigorous rules, like taking a standardized test while on hallucinogens. Annotators invariably end up confronted with confounding questions like, Is that a red shirt with white stripes or a white shirt with red stripes? Is a wicker bowl a “decorative bowl” if it’s full of apples? What color is leopard print? When instructors said to label traffic-control directors, did they also mean to label traffic-control directors eating lunch on the sidewalk? Every question must be answered, and a wrong guess could get you banned and booted to a new, totally different task with its own baffling rules.</p></div><div class=\"duet--article--article-body-component clear-both block w-full md:ml-[-100px] md:w-outdent\"><div class=\"my-9\"><div class=\"transition-all duration-300 ease-in-out\"><div class=\"fixed inset-0 h-[110vh] w-full bg-white transition-all duration-300 ease-in-out z-[-1] cursor-default opacity-0\"></div><div role=\"button\" aria-label=\"Zoom\" tabindex=\"0\" class=\"visible z-30 w-full origin-center transition-all duration-300 ease-in-out cursor-zoom-in\"><figure class=\"transition-all duration-300 ease-in-out lg:mx-0\"><div><div class=\"duet--media--content-warning relative\" style=\"padding-top:84.814453125%\"><span style=\"box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0\"><img alt=\"\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\"/><noscript><img alt=\"\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\" sizes=\"(max-width: 1023px) 100vw, 744px\" srcSet=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/376x319/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/384x326/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/415x352/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/480x407/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/540x458/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/640x543/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/750x636/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/828x702/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/1080x916/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/1200x1018/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/1440x1221/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/1920x1628/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/2048x1737/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/2400x2036/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 2400w\" src=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/2400x2036/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg\"/></noscript></span></div></div></figure></div><div class=\"z-1 w-full hidden\"><figure class=\"transition-all duration-300 ease-in-out lg:mx-0\"><div><div class=\"duet--media--content-warning relative\" style=\"padding-top:84.814453125%\"><span style=\"box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0\"><img alt=\"\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\"/><noscript><img alt=\"\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\" sizes=\"(max-width: 1023px) 100vw, 744px\" srcSet=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/376x319/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/384x326/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/415x352/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/480x407/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/540x458/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/640x543/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/750x636/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/828x702/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/1080x916/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/1200x1018/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/1440x1221/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/1920x1628/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/2048x1737/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/2400x2036/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 2400w\" src=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/2400x2036/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg\"/></noscript></span></div></div></figure></div></div></div></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">Most of the work on Remotasks is paid at a piece rate with a single task earning anywhere from a few cents to several dollars. Because tasks can take seconds or hours, wages are hard to predict. When Remotasks first arrived in Kenya, annotators said it paid relatively well — averaging about $5 to $10 per hour depending on the task — but the amount fell as time went on.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">Scale AI spokesperson Anna Franko said that the company’s economists analyze the specifics of a project, the skills required, the regional cost of living, and other factors “to ensure fair and competitive compensation.” Former Scale employees also said pay is determined through a surge-pricing-like mechanism that adjusts for how many annotators are available and how quickly the data is needed.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">According to workers I spoke with and job listings, U.S.-based Remotasks annotators generally earn between $10 and $25 per hour, though some subject-matter experts can make more. By the beginning of this year, pay for the Kenyan annotators I spoke with had dropped to between $1 and $3 per hour.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">That is, when they were making any money at all. The most common complaint about Remotasks work is its variability; it’s steady enough to be a full-time job for long stretches but too unpredictable to rely on. Annotators spend hours reading instructions and completing unpaid trainings only to do a dozen tasks and then have the project end. There might be nothing new for days, then, without warning, a totally different task appears and could last anywhere from a few hours to weeks. Any task could be their last, and they never know when the next one will come.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">This boom-and-bust cycle results from the cadence of AI development, according to engineers and data vendors. Training a large model requires an enormous amount of annotation followed by more iterative updates, and engineers want it all as fast as possible so they can hit their target launch date. There may be monthslong demand for thousands of annotators, then for only a few hundred, then for a dozen specialists of a certain type, and then thousands again. “The question is, Who bears the cost for these fluctuations?” said Jindal of Partnership on AI. “Because right now, it’s the workers.”</p></div><div class=\"duet--article--article-body-component clear-both block md:float-left md:mr-30 md:w-[320px] lg:-ml-100\"><div class=\"duet--article--article-pullquote mb-20\"><div class=\"mb-10 h-[22px] w-[65px] bg-franklin\"></div><p class=\"duet--article--dangerously-set-cms-markup relative bg-repeating-lines-dark bg-[length:1px_1.2em] pb-8 font-polysans text-28 font-medium leading-120 tracking-1 selection:bg-franklin-20  dark:bg-repeating-lines-light dark:text-white dark:selection:bg-blurple\">“I really am wasting my life here if I made somebody a billionaire and I’m earning a couple of bucks a week.”</p></div></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">To succeed, annotators work together. When I told Victor, who started working for Remotasks while at university in Nairobi, about my struggles with the traffic-control-directors task, he told me everyone knew to stay away from that one: too tricky, bad pay, not worth it. Like a lot of annotators, Victor uses unofficial WhatsApp groups to spread the word when a good task drops. When he figures out a new one, he starts impromptu Google Meets to show others how it’s done. Anyone can join and work together for a time, sharing tips. “It’s a culture we have developed of helping each other because we know when on your own, you can’t know all the tricks,” he said.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">Because work appears and vanishes without warning, taskers always need to be on alert. Victor has found that projects pop up very late at night, so he is in the habit of waking every three hours or so to check his queue. When a task is there, he’ll stay awake as long as he can to work. Once, he stayed up 36 hours straight labeling elbows and knees and heads in photographs of crowds — he has no idea why. Another time, he stayed up so long his mother asked him what was wrong with his eyes. He looked in the mirror to discover they were swollen.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">Annotators generally know only that they are training AI for companies located vaguely elsewhere, but sometimes the veil of anonymity drops — instructions mentioning a brand or a chatbot say too much. “I read and I Googled and found I am working for a 25-year-old billionaire,” said one worker, who, when we spoke, was labeling the emotions of people calling to order Domino’s pizza. “I really am wasting my life here if I made somebody a billionaire and I’m earning a couple of bucks a week.”</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">Victor is a self-proclaimed “fanatic” about AI and started annotating because he wants to help bring about a fully automated post-work future. But earlier this year, someone dropped a <em>Time</em> story into one of his WhatsApp groups about workers training ChatGPT to recognize toxic content who were getting paid less than $2 an hour by the vendor Sama AI. “People were angry that these companies are so profitable but paying so poorly,” Victor said. He was unaware until I told him about Remotasks’ connection to Scale. Instructions for one of the tasks he worked on were nearly identical to those used by OpenAI, which meant he had likely been training ChatGPT as well, for approximately $3 per hour.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">“I remember that someone posted that we will be remembered in the future,” he said. “And somebody else replied, ‘We are being treated worse than foot soldiers. We will be remembered nowhere in the future.’ I remember that very well. Nobody will recognize the work we did or the effort we put in.”</p></div><div class=\"duet--article--article-body-component\"><hr class=\"duet--layout--standard-divider my-36 border-0 border-b border-gray-94\"/></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white min-h-[80px] first-letter:float-left first-letter:mr-18 first-letter:font-polysans-mono first-letter:text-100 first-letter:font-medium first-letter:leading-[.72]  first-letter:selection:bg-franklin-20 dark:first-letter:text-franklin\">Identifying clothing and labeling customer-service conversations are just some of the annotation gigs available. Lately, the hottest on the market has been chatbot trainer. Because it demands specific areas of expertise or language fluency and wages are often adjusted regionally, this job tends to pay better. Certain types of specialist annotation can go for $50 or more per hour.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">A woman I’ll call Anna was searching for a job in Texas when she stumbled across a generic listing for online work and applied. It was Remotasks, and after passing an introductory exam, she was brought into a Slack room of 1,500 people who were training a project code-named Dolphin, which she later discovered to be Google DeepMind’s chatbot, Sparrow, one of the many bots competing with ChatGPT. Her job is to talk with it all day. At about $14 an hour, plus bonuses for high productivity, “it definitely beats getting paid $10 an hour at the local Dollar General store,” she said.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">Also, she enjoys it. She has discussed science-fiction novels, mathematical paradoxes, children’s riddles, and TV shows. Sometimes the bot’s responses make her laugh; other times, she runs out of things to talk about. “Some days, my brain is just like, <em>I literally have no idea what on earth to ask it now,</em>” she said. “So I have a little notebook, and I’ve written about two pages of things — I just Google interesting topics — so I think I’ll be good for seven hours today, but that’s not always the case.”</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">Each time Anna prompts Sparrow, it delivers two responses and she picks the best one, thereby creating something called “human-feedback data.” When ChatGPT debuted late last year, its impressively natural-seeming conversational style was credited to its having been trained on troves of internet data. But the language that fuels ChatGPT and its competitors is filtered through several rounds of human annotation. One group of contractors writes examples of how the engineers want the bot to behave, creating questions followed by correct answers, descriptions of computer programs followed by functional code, and requests for tips on committing crimes followed by polite refusals. After the model is trained on these examples, yet more contractors are brought in to prompt it and rank its responses. This is what Anna is doing with Sparrow. Exactly which criteria the raters are told to use varies — honesty, or helpfulness, or just personal preference. The point is that they are creating data on human taste, and once there’s enough of it, engineers can train a second model to mimic their preferences at scale, automating the ranking process and training their AI to act in ways humans approve of. The result is a remarkably human-seeming bot that mostly declines harmful requests and explains its AI nature with seeming self-awareness.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">Put another way, ChatGPT seems so human because it was trained by an AI that was mimicking humans who were rating an AI that was mimicking humans who were pretending to be a better version of an AI that was trained on human writing.</p></div><div class=\"duet--article--article-body-component clear-both block w-full md:ml-[-100px] md:w-outdent\"><div class=\"my-9\"><div class=\"transition-all duration-300 ease-in-out\"><div class=\"fixed inset-0 h-[110vh] w-full bg-white transition-all duration-300 ease-in-out z-[-1] cursor-default opacity-0\"></div><div role=\"button\" aria-label=\"Zoom\" tabindex=\"0\" class=\"visible z-30 w-full origin-center transition-all duration-300 ease-in-out cursor-zoom-in\"><figure class=\"transition-all duration-300 ease-in-out lg:mx-0\"><div><div class=\"duet--media--content-warning relative\" style=\"padding-top:73.92578125%\"><span style=\"box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0\"><img alt=\"\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\"/><noscript><img alt=\"\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\" sizes=\"(max-width: 1023px) 100vw, 744px\" srcSet=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/376x278/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/384x284/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/415x307/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/480x355/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/540x399/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/640x473/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/750x554/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/828x612/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/1080x798/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/1200x887/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/1440x1065/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/1920x1419/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/2048x1514/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/2400x1774/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 2400w\" src=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/2400x1774/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg\"/></noscript></span></div></div></figure></div><div class=\"z-1 w-full hidden\"><figure class=\"transition-all duration-300 ease-in-out lg:mx-0\"><div><div class=\"duet--media--content-warning relative\" style=\"padding-top:73.92578125%\"><span style=\"box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0\"><img alt=\"\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\"/><noscript><img alt=\"\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\" sizes=\"(max-width: 1023px) 100vw, 744px\" srcSet=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/376x278/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/384x284/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/415x307/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/480x355/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/540x399/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/640x473/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/750x554/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/828x612/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/1080x798/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/1200x887/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/1440x1065/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/1920x1419/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/2048x1514/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/2400x1774/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 2400w\" src=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/2400x1774/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg\"/></noscript></span></div></div></figure></div></div></div></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">This circuitous technique is called “reinforcement learning from human feedback,” or RLHF, and it’s so effective that it’s worth pausing to fully register what it doesn’t do. When annotators teach a model to be accurate, for example, the model isn’t learning to check answers against logic or external sources or about what accuracy as a concept even is. The model is still a text-prediction machine mimicking patterns in human writing, but now its training corpus has been supplemented with bespoke examples, and the model has been weighted to favor them. Maybe this results in the model extracting patterns from the part of its linguistic map labeled as accurate and producing text that happens to align with the truth, but it can also result in it mimicking the confident style and expert jargon of the accurate text while writing things that are totally wrong. There is no guarantee that the text the labelers marked as accurate is in fact accurate, and when it is, there is no guarantee that the model learns the right patterns from it.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">This dynamic makes chatbot annotation a delicate process. It has to be rigorous and consistent because sloppy feedback, like marking material that merely sounds correct as accurate, risks training models to be even more convincing bullshitters. An early OpenAI and DeepMind joint project using RLHF, in this case to train a virtual robot hand to grab an item, resulted in also training the robot to position its hand between the object and its raters and wiggle around such that it only appeared to its human overseers to grab the item. Ranking a language model’s responses is always going to be somewhat subjective because it’s language. A text of any length will have multiple elements that could be right or wrong or, taken together, misleading. OpenAI researchers ran into this obstacle in another early RLHF paper. Trying to get their model to summarize text, the researchers found they agreed only 60 percent of the time that a summary was good. “Unlike many tasks in [machine learning] our queries do not have unambiguous ground truth,” they lamented.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">When Anna rates Sparrow’s responses, she’s supposed to be looking at their accuracy, helpfulness, and harmlessness while also checking that the model isn’t giving medical or financial advice or anthropomorphizing itself or running afoul of other criteria. To be useful training data, the model’s responses have to be quantifiably ranked against one another: Is a bot that helpfully tells you how to make a bomb “better” than a bot that’s so harmless it refuses to answer any questions? In one DeepMind paper, when Sparrow’s makers took a turn annotating, four researchers wound up debating whether their bot had assumed the gender of a user who asked it for relationship advice. According to Geoffrey Irving, one of DeepMind’s research scientists, the company’s researchers hold weekly annotation meetings in which they rerate data themselves and discuss ambiguous cases, consulting with ethical or subject-matter experts when a case is particularly tricky.</p></div><div class=\"duet--article--article-body-component clear-both block md:float-left md:mr-30 md:w-[320px] lg:-ml-100\"><div class=\"duet--article--article-pullquote mb-20\"><div class=\"mb-10 h-[22px] w-[65px] bg-franklin\"></div><p class=\"duet--article--dangerously-set-cms-markup relative bg-repeating-lines-dark bg-[length:1px_1.2em] pb-8 font-polysans text-28 font-medium leading-120 tracking-1 selection:bg-franklin-20  dark:bg-repeating-lines-light dark:text-white dark:selection:bg-blurple\">There are people classifying the emotional content of TikTok videos, new variants of email spam, and the precise sexual provocativeness of online ads.</p></div></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">Anna often finds herself having to choose between two bad options. “Even if they’re both absolutely, ridiculously wrong, you still have to figure out which one is better and then write words explaining why,” she said. Sometimes, when both responses are bad, she’s encouraged to write a better response herself, which she does about half the time.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">Because feedback data is difficult to collect, it fetches a higher price. Basic preferences of the sort Anna is producing sell for about $1 each, according to people with knowledge of the industry. But if you want to train a model to do legal research, you need someone with training in law, and this gets expensive. Everyone involved is reluctant to say how much they’re spending, but in general, specialized written examples can go for hundreds of dollars, while expert ratings can cost $50 or more. One engineer told me about buying examples of Socratic dialogues for up to $300 a pop. Another told me about paying $15 for a “darkly funny limerick about a goldfish.”</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">OpenAI, Microsoft, Meta, and Anthropic did not comment about how many people contribute annotations to their models, how much they are paid, or where in the world they are located. Irving of DeepMind, which is a subsidiary of Google, said the annotators working on Sparrow are paid “at least the hourly living wage” based on their location. Anna knows “absolutely nothing” about Remotasks, but Sparrow has been more open. She wasn’t the only annotator I spoke with who got more information from the AI they were training than from their employer; several others learned whom they were working for by asking their AI for its company’s terms of service. “I literally asked it, ‘What is your purpose, Sparrow?’” Anna said. It pulled up a link to DeepMind’s website and explained that it’s an AI assistant and that its creators trained it using RLHF to be helpful and safe.</p></div><div class=\"duet--article--article-body-component\"><hr class=\"duet--layout--standard-divider my-36 border-0 border-b border-gray-94\"/></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white min-h-[80px] first-letter:float-left first-letter:mr-18 first-letter:font-polysans-mono first-letter:text-100 first-letter:font-medium first-letter:leading-[.72]  first-letter:selection:bg-franklin-20 dark:first-letter:text-franklin\">Until recently, it was relatively easy to spot bad output from a language model. It looked like gibberish. But this gets harder as the models get better — a problem called “scalable oversight.” Google inadvertently demonstrated how hard it is to catch the errors of a modern-language model when one made it into the splashy debut of its AI assistant, Bard. (It stated confidently that the James Webb Space Telescope “took the very first pictures of a planet outside of our own solar system,” which is wrong.) This trajectory means annotation increasingly requires specific skills and expertise.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">Last year, someone I’ll call Lewis was working on Mechanical Turk when, after completing a task, he received a message inviting him to apply for a platform he hadn’t heard of. It was called Taskup.ai, and its website was remarkably basic: just a navy background with text reading GET PAID FOR TASKS ON DEMAND. He applied.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">The work paid far better than anything he had tried before, often around $30 an hour. It was more challenging, too: devising complex scenarios to trick chatbots into giving dangerous advice, testing a model’s ability to stay in character, and having detailed conversations about scientific topics so technical they required extensive research. He found the work “satisfying and stimulating.” While checking one model’s attempts to code in Python, Lewis was learning too. He couldn’t work for more than four hours at a stretch, lest he risk becoming mentally drained and making mistakes, and he wanted to keep the job.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">“If there was one thing I could change, I would just like to have more information about what happens on the other end,” he said. “We only know as much as we need to know to get work done, but if I could know more, then maybe I could get more established and perhaps pursue this as a career.”</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">I spoke with eight other workers, most based in the U.S., who had similar experiences of answering surveys or completing tasks on other platforms and finding themselves recruited for Taskup.ai or several similarly generic sites, such as DataAnnotation.tech or Gethybrid.io. Often their work involved training chatbots, though with higher-quality expectations and more specialized purposes than other sites they had worked for. One was demonstrating spreadsheet macros. Another was just supposed to have conversations and rate responses according to whatever criteria she wanted. She often asked the chatbot things that had come up in conversations with her 7-year-old daughter, like “What is the largest dinosaur?” and “Write a story about a tiger.” “I haven’t fully gotten my head around what they’re trying to do with it,” she told me.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">Taskup.ai, DataAnnotation.tech, and Gethybrid.io all appear to be owned by the same company: Surge AI. Its CEO, Edwin Chen, would neither confirm nor deny the connection, but he was willing to talk about his company and how he sees annotation evolving.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">“I’ve always felt the annotation landscape is overly simplistic,” Chen said over a video call from Surge’s office. He founded Surge in 2020 after working on AI at Google, Facebook, and Twitter convinced him that crowdsourced labeling was inadequate. “We want AI to tell jokes or write really good marketing copy or help me out when I need therapy or whatnot,” Chen said. “You can’t ask five people to independently come up with a joke and combine it into a majority answer. Not everybody can tell a joke or solve a Python program. The annotation landscape needs to shift from this low-quality, low-skill mind-set to something that’s much richer and captures the range of human skills and creativity and values that we want AI systems to possess.”</p></div><div class=\"duet--article--article-body-component clear-both block w-full md:ml-[-100px] md:w-outdent\"><div class=\"my-9\"><div class=\"transition-all duration-300 ease-in-out\"><div class=\"fixed inset-0 h-[110vh] w-full bg-white transition-all duration-300 ease-in-out z-[-1] cursor-default opacity-0\"></div><div role=\"button\" aria-label=\"Zoom\" tabindex=\"0\" class=\"visible z-30 w-full origin-center transition-all duration-300 ease-in-out cursor-zoom-in\"><figure class=\"transition-all duration-300 ease-in-out lg:mx-0\"><div><div class=\"duet--media--content-warning relative\" style=\"padding-top:76.7578125%\"><span style=\"box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0\"><img alt=\"\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\"/><noscript><img alt=\"\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\" sizes=\"(max-width: 1023px) 100vw, 744px\" srcSet=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/376x289/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/384x295/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/415x319/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/480x368/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/540x414/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/640x491/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/750x576/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/828x636/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/1080x829/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/1200x921/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/1440x1105/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/1920x1474/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/2048x1572/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/2400x1842/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 2400w\" src=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/2400x1842/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg\"/></noscript></span></div></div></figure></div><div class=\"z-1 w-full hidden\"><figure class=\"transition-all duration-300 ease-in-out lg:mx-0\"><div><div class=\"duet--media--content-warning relative\" style=\"padding-top:76.7578125%\"><span style=\"box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0\"><img alt=\"\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\"/><noscript><img alt=\"\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\" sizes=\"(max-width: 1023px) 100vw, 744px\" srcSet=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/376x289/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/384x295/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/415x319/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/480x368/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/540x414/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/640x491/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/750x576/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/828x636/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/1080x829/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/1200x921/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/1440x1105/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/1920x1474/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/2048x1572/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/2400x1842/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 2400w\" src=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/2400x1842/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg\"/></noscript></span></div></div></figure></div></div></div></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">Last year, Surge relabeled Google’s dataset classifying Reddit posts by emotion. Google had stripped each post of context and sent them to workers in India for labeling. Surge employees familiar with American internet culture found that 30 percent of the labels were wrong. Posts like “hell yeah my brother” had been classified as annoyance and “Yay, cold McDonald’s. My favorite” as love.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">Surge claims to vet its workers for qualifications — that people doing creative-writing tasks have experience with creative writing, for example — but exactly how Surge finds workers is “proprietary,” Chen said. As with Remotasks, workers often have to complete training courses, though unlike Remotasks, they are paid for it, according to the annotators I spoke with. Having fewer, better-trained workers producing higher-quality data allows Surge to compensate better than its peers, Chen said, though he declined to elaborate, saying only that people are paid “fair and ethical wages.” The workers I spoke with earned between $15 and $30 per hour, but they are a small sample of all the annotators, a group Chen said now consists of 100,000 people. The secrecy, he explained, stems from clients’ demands for confidentiality.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">Surge’s customers include OpenAI, Google, Microsoft, Meta, and Anthropic. Surge specializes in feedback and language annotation, and after ChatGPT launched, it got an influx of requests, Chen said: “I thought everybody knew the power of RLHF, but I guess people just didn’t viscerally understand.”</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">The new models are so impressive they’ve inspired another round of predictions that annotation is about to be automated. Given the costs involved, there is significant financial pressure to do so. Anthropic, Meta, and other companies have recently made strides in using AI to drastically reduce the amount of human annotation needed to guide models, and other developers have started using GPT-4 to generate training data. However, a recent paper found that GPT-4-trained models may be learning to mimic GPT’s authoritative style with even less accuracy, and so far, when improvements in AI have made one form of annotation obsolete, demand for other, more sophisticated types of labeling has gone up. This debate spilled into the open earlier this year, when Scale’s CEO, Wang, tweeted that he predicted AI labs will soon be spending as many billions of dollars on human data as they do on computing power; OpenAI’s CEO, Sam Altman, responded that data needs will decrease as AI improves.</p></div><div class=\"duet--article--article-body-component clear-both block md:float-left md:mr-30 md:w-[320px] lg:-ml-100\"><div class=\"duet--article--article-pullquote mb-20\"><div class=\"mb-10 h-[22px] w-[65px] bg-franklin\"></div><p class=\"duet--article--dangerously-set-cms-markup relative bg-repeating-lines-dark bg-[length:1px_1.2em] pb-8 font-polysans text-28 font-medium leading-120 tracking-1 selection:bg-franklin-20  dark:bg-repeating-lines-light dark:text-white dark:selection:bg-blurple\">“I mean, what it can do is amazing,” she said of the chatbot. “But it still does some really weird shit.”</p></div></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">Chen is skeptical AI will reach a point where human feedback is no longer needed, but he does see annotation becoming more difficult as models improve. Like many researchers, he believes the path forward will involve AI systems helping humans oversee other AI. Surge recently collaborated with Anthropic on a proof of concept, having human labelers answer questions about a lengthy text with the help of an unreliable AI assistant, on the theory that the humans would have to feel out the weaknesses of their AI assistant and collaborate to reason their way to the correct answer. Another possibility has two AIs debating each other and a human rendering the final verdict on which is correct. “We still have yet to see really good practical implementations of this stuff, but it’s starting to become necessary because it’s getting really hard for labelers to keep up with the models,” said OpenAI research scientist John Schulman in a recent talk at Berkeley.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">“I think you always need a human to monitor what AIs are doing just because they are this kind of alien entity,” Chen said. Machine-learning systems are just too strange ever to fully trust. The most impressive models today have what, to a human, seems like bizarre weaknesses, he added, pointing out that though GPT-4 can generate complex and convincing prose, it can’t pick out which words are adjectives: “Either that or models get so good that they’re better than humans at all things, in which case, you reach your utopia and who cares?”</p></div><div class=\"duet--article--article-body-component\"><hr class=\"duet--layout--standard-divider my-36 border-0 border-b border-gray-94\"/></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white min-h-[80px] first-letter:float-left first-letter:mr-18 first-letter:font-polysans-mono first-letter:text-100 first-letter:font-medium first-letter:leading-[.72]  first-letter:selection:bg-franklin-20 dark:first-letter:text-franklin\">As 2022 ended, Joe started hearing from his students that their task queues were often empty. Then he got an email informing him the boot camps in Kenya were closing. He continued training taskers online, but he began to worry about the future.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">“There were signs that it was not going to last long,” he said. Annotation was leaving Kenya. From colleagues he had met online, he heard tasks were going to Nepal, India, and the Philippines. “The companies shift from one region to another,” Joe said. “They don’t have infrastructure locally, so it makes them flexible to shift to regions that favor them in terms of operation cost.”</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">One way the AI industry differs from manufacturers of phones and cars is in its fluidity. The work is constantly changing, constantly getting automated away and replaced with new needs for new types of data. It’s an assembly line but one that can be endlessly and instantly reconfigured, moving to wherever there is the right combination of skills, bandwidth, and wages.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">Lately, the best-paying work is in the U.S. In May, Scale started listing annotation jobs on its own website, soliciting people with experience in practically every field AI is predicted to conquer. There were listings for AI trainers with expertise in health coaching, human resources, finance, economics, data science, programming, computer science, chemistry, biology, accounting, taxes, nutrition, physics, travel, K-12 education, sports journalism, and self-help. You can make $45 an hour teaching robots law or make $25 an hour teaching them poetry. There were also listings for people with security clearance, presumably to help train military AI. Scale recently launched a defense-oriented language model called Donovan, which Wang called “ammunition in the AI war,” and won a contract to work on the Army’s robotic-combat-vehicle program.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">Anna is still training chatbots in Texas. Colleagues have been turned into reviewers and Slack admins — she isn’t sure why, but it has given her hope that the gig could be a longer-term career. One thing she isn’t worried about is being automated out of a job. “I mean, what it can do is amazing,” she said of the chatbot. “But it still does some really weird shit.”</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">When Remotasks first arrived in Kenya, Joe thought annotation could be a good career. Even after the work moved elsewhere, he was determined to make it one. There were thousands of people in Nairobi who knew how to do the work, he reasoned — he had trained many of them, after all. Joe rented office space in the city and began sourcing contracts: a job annotating blueprints for a construction company, another labeling fruits despoiled by insects for some sort of agricultural project, plus the usual work of annotating for self-driving cars and e-commerce.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">But he has found his vision difficult to achieve. He has just one full-time employee, down from two. “We haven’t been having a consistent flow of work,” he said. There are weeks with nothing to do because customers are still collecting data, and when they’re done, he has to bring in short-term contractors to meet their deadlines: “Clients don’t care whether we have consistent work or not. So long as the datasets have been completed, then that’s the end of that.”</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">Rather than let their skills go to waste, other taskers decided to chase the work wherever it went. They rented proxy servers to disguise their locations and bought fake IDs to pass security checks so they could pretend to work from Singapore, the Netherlands, Mississippi, or wherever the tasks were flowing. It’s a risky business. Scale has become increasingly aggressive about suspending accounts caught disguising their location, according to multiple taskers. It was during one of these crackdowns that my account got banned, presumably because I had been using a VPN to see what workers in other countries were seeing, and all $1.50 or so of my earnings were seized.</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white\">“These days, we have become a bit cunning because we noticed that in other countries they are paying well,” said Victor, who was earning double the Kenyan rate by tasking in Malaysia. “You do it cautiously.”</p></div><div class=\"duet--article--article-body-component\"><p class=\"duet--article--dangerously-set-cms-markup duet--article--standard-paragraph mb-20 font-fkroman text-18 leading-160 -tracking-1 selection:bg-franklin-20 dark:text-white dark:selection:bg-blurple [&amp;_a:hover]:shadow-highlight-franklin dark:[&amp;_a:hover]:shadow-highlight-blurple [&amp;_a]:shadow-underline-black dark:[&amp;_a]:shadow-underline-white after:absolute after:ml-8 after:mt-2 after:content-[url(/icons/endmark.svg)]\">Another Kenyan annotator said that after his account got suspended for mysterious reasons, he decided to stop playing by the rules. Now, he runs multiple accounts in multiple countries, tasking wherever the pay is best. He works fast and gets high marks for quality, he said, thanks to ChatGPT. The bot is wonderful, he said, letting him speed through $10 tasks in a matter of minutes. When we spoke, he was having it rate another chatbot’s responses according to seven different criteria, one AI training the other.</p></div></div><div class=\"mb-40 mt-30\"><button class=\"duet--article--comments-button group inline-flex h-40 w-full items-center justify-center rounded-[2px] border-[1px] border-solid border-blurple font-polysans-mono text-11 font-light uppercase tracking-12 text-blurple hover:bg-blurple hover:text-white md:w-auto md:px-30\"><svg class=\"mr-10 inline pt-2\" width=\"12\" height=\"14\" fill=\"none\" viewBox=\"0 0 12 12\" stroke-width=\"1px\" xmlns=\"http://www.w3.org/2000/svg\"><title>Comments</title><path d=\"M2.4 9.1h-.207l-.147.146L.5 10.793V1.2c0-.384.316-.7.7-.7h9.6c.384 0 .7.316.7.7v7.2c0 .384-.316.7-.7.7H2.4Z\" stroke=\"currentColor\"></path></svg><span class=\"coral-count\" data-coral-id=\"e6a44b77-f363-473b-9651-3e323f6f4fd9\"></span></button></div></div><div class=\"duet--layout--rail max-h-[8000px] max-w-[300px] hidden z-0 text-white lg:flex lg:flex-1 lg:flex-col\"><div class=\"flex-auto\"><div style=\"min-height:250px;min-width:300px;position:sticky;top:90px;margin-bottom:40px\" class=\"mx-auto hidden lg:block\" data-concert=\"medium_rectangle_variable\"></div></div><div class=\"flex-auto\"><div class=\"duet--recirculation--list-breaker-standard sticky m-auto my-50 w-mobile-breaker rounded-[4px] p-20 lg:mb-40 lg:mt-0 bg-white top-90\"><div class=\"absolute right-[-25px] top-0 h-full rotate-180 whitespace-nowrap text-center font-manuka text-[172px] font-black leading-100 text-franklin\" style=\"writing-mode:vertical-rl;text-orientation:sideways\">Most Popular</div><ol class=\"styled-counter styled-counter-standard w-full\"><li class=\"leading-120 text-blurple\"><a class=\"text-black hover:text-blurple\" href=\"/2023/7/11/23779039/microsoft-activision-blizzard-ftc-trial-win\"><h2 class=\"mb-4 inline w-[181px] font-polysans text-16 font-bold tracking-1\">Microsoft wins FTC fight to buy Activision Blizzard</h2></a><hr class=\"-mx-28 my-20 w-[calc(50%+14px)] border text-black/0 border-b-blurple\"/></li><li class=\"leading-120 text-blurple\"><a class=\"text-black hover:text-blurple\" href=\"/2023/7/9/23788741/sarah-silverman-openai-meta-chatgpt-llama-copyright-infringement-chatbots-artificial-intelligence-ai\"><h2 class=\"mb-4 inline w-[181px] font-polysans text-16 font-bold tracking-1\">Sarah Silverman is suing OpenAI and Meta for copyright infringement</h2></a><hr class=\"-mx-28 my-20 w-[calc(50%+14px)] border text-black/0 border-b-blurple\"/></li><li class=\"leading-120 text-blurple\"><a class=\"text-black hover:text-blurple\" href=\"/2023/7/10/23789481/elon-musk-private-jet-tracker-threads-twitter-bot-elonjet\"><h2 class=\"mb-4 inline w-[181px] font-polysans text-16 font-bold tracking-1\">The Elon Musk private jet tracker resurfaces on Threads and immediately goads Mark Zuckerberg</h2></a><hr class=\"-mx-28 my-20 w-[calc(50%+14px)] border text-black/0 border-b-blurple\"/></li><li class=\"leading-120 text-blurple\"><a class=\"text-black hover:text-blurple\" href=\"/2023/7/10/23787453/meta-instagram-threads-100-million-users-milestone\"><h2 class=\"mb-4 inline w-[181px] font-polysans text-16 font-bold tracking-1\">Instagram’s Threads surpasses 100 million users</h2></a><hr class=\"-mx-28 my-20 w-[calc(50%+14px)] border text-black/0 border-b-blurple\"/></li><li class=\"leading-120 text-blurple\"><a class=\"text-black hover:text-blurple\" href=\"/2023/7/10/23790132/google-memo-moat-ai-leak-demis-hassabis\"><h2 class=\"mb-4 inline w-[181px] font-polysans text-16 font-bold tracking-1\">That Google memo about having ‘no moat’ in AI was real — and Google’s AI boss disagrees with it</h2></a><hr class=\"-mx-28 my-20 w-[calc(50%+14px)] border text-black/0 border-b-blurple\"/></li></ol></div> </div><div class=\"flex-auto\"><div class=\"sticky top-90\"><div style=\"min-height:250px;min-width:300px;margin-bottom:40px\" class=\"mx-auto hidden lg:block\" data-concert=\"medium_rectangle_gamestop\"></div><div style=\"min-height:100px;min-width:300px;padding-bottom:40px\" class=\"mx-auto hidden lg:block\" data-concert=\"connatix_right_rail\"></div></div></div><div class=\"flex-auto\"><aside class=\"sticky top-90 pb-40 duet--article--rail\"><div class=\"mb-8 hidden md:block\"><form action=\"#\"><div class=\"duet--cta--newsletter flex w-full flex-col border-t px-12 pt-16 font-polysans-mono text-14 font-light leading-130 -tracking-2 md:text-15 text-blurple border-blurple\"><div class=\"mb-10\"><h2 class=\"inline font-medium\">Verge Deals</h2><p class=\"inline\"> / <span class=\"duet--article--dangerously-set-cms-markup\">Sign up for Verge Deals to get deals on products we've tested sent to your inbox daily.</span></p></div><div><fieldset><div class=\"mb-4 flex\"><label class=\"sr-only\" for=\"email\">Email (required)</label><input name=\"email\" class=\"mr-8 rounded-sm border px-10 font-polysans text-15 font-light focus:outline-none w-full placeholder:text-blurple bg-white\" id=\"email\" type=\"email\" placeholder=\"Enter your email\" value=\"\"/><button type=\"submit\" class=\"whitespace-nowrap rounded-sm border px-18 py-12 text-12 font-medium uppercase tracking-12 no-underline border-blurple hover:bg-blurple hover:text-white\">Sign up</button></div></fieldset><div class=\"mt-2 font-polysans text-11 leading-110\">By submitting your email, you agree to our<!-- --> <a href=\"https://www.voxmedia.com/legal/terms-of-use\" class=\"underline\">Terms</a> and <a href=\"https://www.voxmedia.com/legal/privacy-notice\" class=\"underline\">Privacy Notice</a>. <!-- -->This site is protected by reCAPTCHA and the Google<!-- --> <a href=\"https://policies.google.com/privacy\" class=\"underline\">Privacy Policy</a> <!-- -->and<!-- --> <a href=\"https://policies.google.com/terms\" class=\"underline\">Terms of Service</a> <!-- -->apply.</div></div></div></form></div></aside></div><div class=\"duet--ad--native-ad-rail hidden flex-auto\" data-native-ad-id=\"container\"><div class=\"sticky top-90 mb-40\"><div class=\"hidden\"><div class=\"dynamic-native-ad-native_ad_latest\"></div></div><div class=\"flex items-center text-black\"><div class=\"w-[210px]\"><div class=\"mb-6\"><span class=\"border-b border-b-blurple pb-6 font-polysans text-10 font-medium uppercase leading-140 tracking-15 text-gray-5a\">From our sponsor</span></div><h3 class=\"font-polysans text-20 leading-110 tracking-1\"><a data-native-ad-id=\"title\" href=\"http://theverge.com\" class=\"hover:shadow-underline-black\"></a></h3><a href=\"http://theverge.com\"><div class=\"mb-4 flex items-center text-gray-31\"><span data-native-ad-id=\"preamble\" class=\"font-polysans text-10 font-medium uppercase leading-140 tracking-15\">Advertiser Content From</span><img data-native-ad-id=\"sponsored_logo\" class=\"max-h-[24px] max-w-[120px] pl-8\" alt=\"Sponsor logo\" src=\"/icons/native-ad-placeholder.png\"/></div></a></div><div><img data-native-ad-id=\"thumbnail\" class=\"max-w-[75px] pl-8\" alt=\"Sponsor thumbnail\" src=\"/icons/native-ad-placeholder.png\"/></div></div></div></div><div class=\"flex-auto\"><div style=\"min-height:250px;min-width:300px;position:sticky;top:90px;margin-bottom:40px\" class=\"mx-auto hidden lg:block\" data-concert=\"btf_medium_rectangle_variable_article\"></div></div></div><div style=\"position:absolute;top:8200px;right:10px;bottom:40px\" class=\"mx-auto hidden lg:block\" data-concert=\"btf_medium_rectangle_variable_feature_extended_sticky\"></div></div></article></main><div style=\"min-height:250px;min-width:300px;margin-bottom:40px\" class=\"mx-auto block lg:hidden\" data-concert=\"medium_rectangle_gamestop\"></div><section class=\"duet--article--more-stories bg-franklin px-20 pb-16 pt-30 lg:pb-36 lg:pt-50\"><div class=\"md:mx-auto md:max-w-container-md lg:max-w-container-lg\"><h2 class=\"mb-16 font-polysans-mono text-16 font-light leading-120 tracking-2 text-gray-13\">More from<!-- --> <a class=\"border-b font-medium hover:border-blurple hover:text-blurple\" href=\"/features\">Features</a></h2><ul class=\"divide-y\"><li class=\"flex items-start border-black/30 py-16 lg:items-center\"><div class=\"relative ml-10 mr-20 aspect-square h-[60px] w-[60px] [&amp;&gt;span]:rounded-[2px]\"><span style=\"box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0\"><img alt=\"\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\"/><noscript><img alt=\"\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\" sizes=\"100vw\" srcSet=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:1512x1510/376x376/filters:focal(756x755:757x756):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24747256/best_tech_books.png 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1512x1510/415x415/filters:focal(756x755:757x756):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24747256/best_tech_books.png 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1512x1510/480x480/filters:focal(756x755:757x756):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24747256/best_tech_books.png 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1512x1510/540x540/filters:focal(756x755:757x756):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24747256/best_tech_books.png 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1512x1510/640x640/filters:focal(756x755:757x756):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24747256/best_tech_books.png 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1512x1510/750x750/filters:focal(756x755:757x756):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24747256/best_tech_books.png 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1512x1510/828x828/filters:focal(756x755:757x756):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24747256/best_tech_books.png 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1512x1510/1080x1080/filters:focal(756x755:757x756):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24747256/best_tech_books.png 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1512x1510/1200x1200/filters:focal(756x755:757x756):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24747256/best_tech_books.png 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1512x1510/1440x1440/filters:focal(756x755:757x756):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24747256/best_tech_books.png 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1512x1510/1920x1920/filters:focal(756x755:757x756):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24747256/best_tech_books.png 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1512x1510/2048x2048/filters:focal(756x755:757x756):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24747256/best_tech_books.png 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:1512x1510/2400x2400/filters:focal(756x755:757x756):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24747256/best_tech_books.png 2400w\" src=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:1512x1510/2400x2400/filters:focal(756x755:757x756):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24747256/best_tech_books.png\"/></noscript></span></div><h3 class=\"font-polysans text-22 font-medium leading-100 -tracking-1 lg:text-34\"><a class=\"hover:shadow-underline-black\" href=\"/c/23771068/best-tech-books-nonfiction-recommendations\">The greatest tech books of all time</a></h3></li><li class=\"flex items-start border-black/30 py-16 lg:items-center\"><div class=\"relative ml-10 mr-20 aspect-square h-[60px] w-[60px] [&amp;&gt;span]:rounded-[2px]\"><span style=\"box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0\"><img alt=\"\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\"/><noscript><img alt=\"\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\" sizes=\"100vw\" srcSet=\"https://duet-cdn.vox-cdn.com/thumbor/72x50:1178x774/376x376/filters:focal(1143x749:1144x750):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24739587/01_1250x820.png 376w, https://duet-cdn.vox-cdn.com/thumbor/72x50:1178x774/415x415/filters:focal(1143x749:1144x750):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24739587/01_1250x820.png 415w, https://duet-cdn.vox-cdn.com/thumbor/72x50:1178x774/480x480/filters:focal(1143x749:1144x750):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24739587/01_1250x820.png 480w, https://duet-cdn.vox-cdn.com/thumbor/72x50:1178x774/540x540/filters:focal(1143x749:1144x750):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24739587/01_1250x820.png 540w, https://duet-cdn.vox-cdn.com/thumbor/72x50:1178x774/640x640/filters:focal(1143x749:1144x750):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24739587/01_1250x820.png 640w, https://duet-cdn.vox-cdn.com/thumbor/72x50:1178x774/750x750/filters:focal(1143x749:1144x750):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24739587/01_1250x820.png 750w, https://duet-cdn.vox-cdn.com/thumbor/72x50:1178x774/828x828/filters:focal(1143x749:1144x750):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24739587/01_1250x820.png 828w, https://duet-cdn.vox-cdn.com/thumbor/72x50:1178x774/1080x1080/filters:focal(1143x749:1144x750):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24739587/01_1250x820.png 1080w, https://duet-cdn.vox-cdn.com/thumbor/72x50:1178x774/1200x1200/filters:focal(1143x749:1144x750):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24739587/01_1250x820.png 1200w, https://duet-cdn.vox-cdn.com/thumbor/72x50:1178x774/1440x1440/filters:focal(1143x749:1144x750):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24739587/01_1250x820.png 1440w, https://duet-cdn.vox-cdn.com/thumbor/72x50:1178x774/1920x1920/filters:focal(1143x749:1144x750):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24739587/01_1250x820.png 1920w, https://duet-cdn.vox-cdn.com/thumbor/72x50:1178x774/2048x2048/filters:focal(1143x749:1144x750):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24739587/01_1250x820.png 2048w, https://duet-cdn.vox-cdn.com/thumbor/72x50:1178x774/2400x2400/filters:focal(1143x749:1144x750):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24739587/01_1250x820.png 2400w\" src=\"https://duet-cdn.vox-cdn.com/thumbor/72x50:1178x774/2400x2400/filters:focal(1143x749:1144x750):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24739587/01_1250x820.png\"/></noscript></span></div><h3 class=\"font-polysans text-22 font-medium leading-100 -tracking-1 lg:text-34\"><a class=\"hover:shadow-underline-black\" href=\"/c/23558791/goodnight-phone-comic-interactive-gina-wynbrandt\">Goodnight Phone</a></h3></li><li class=\"flex items-start border-black/30 py-16 lg:items-center\"><div class=\"relative ml-10 mr-20 aspect-square h-[60px] w-[60px] [&amp;&gt;span]:rounded-[2px]\"><span style=\"box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0\"><img alt=\"\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\"/><noscript><img alt=\"\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\" sizes=\"100vw\" srcSet=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/376x376/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24726611/236693_Small_Business_Google_SEO_HHerrera.jpeg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/415x415/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24726611/236693_Small_Business_Google_SEO_HHerrera.jpeg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/480x480/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24726611/236693_Small_Business_Google_SEO_HHerrera.jpeg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/540x540/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24726611/236693_Small_Business_Google_SEO_HHerrera.jpeg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/640x640/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24726611/236693_Small_Business_Google_SEO_HHerrera.jpeg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/750x750/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24726611/236693_Small_Business_Google_SEO_HHerrera.jpeg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/828x828/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24726611/236693_Small_Business_Google_SEO_HHerrera.jpeg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/1080x1080/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24726611/236693_Small_Business_Google_SEO_HHerrera.jpeg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/1200x1200/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24726611/236693_Small_Business_Google_SEO_HHerrera.jpeg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/1440x1440/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24726611/236693_Small_Business_Google_SEO_HHerrera.jpeg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/1920x1920/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24726611/236693_Small_Business_Google_SEO_HHerrera.jpeg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/2048x2048/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24726611/236693_Small_Business_Google_SEO_HHerrera.jpeg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/2400x2400/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24726611/236693_Small_Business_Google_SEO_HHerrera.jpeg 2400w\" src=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:3000x2000/2400x2400/filters:focal(1500x1000:1501x1001):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24726611/236693_Small_Business_Google_SEO_HHerrera.jpeg\"/></noscript></span></div><h3 class=\"font-polysans text-22 font-medium leading-100 -tracking-1 lg:text-34\"><a class=\"hover:shadow-underline-black\" href=\"/23753963/google-seo-shopify-small-business-ai\">The store is for people, but the storefront is for Google’s web crawlers</a></h3></li><li class=\"flex items-start border-black/30 py-16 lg:items-center\"><div class=\"relative ml-10 mr-20 aspect-square h-[60px] w-[60px] [&amp;&gt;span]:rounded-[2px]\"><span style=\"box-sizing:border-box;display:block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:absolute;top:0;left:0;bottom:0;right:0\"><img alt=\"A car tangled up in a charging cable.\" src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\"/><noscript><img alt=\"A car tangled up in a charging cable.\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" style=\"position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%;object-fit:cover\" sizes=\"100vw\" srcSet=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/376x376/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24223304/226423_Sean_Dong_Kia_Boys.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/415x415/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24223304/226423_Sean_Dong_Kia_Boys.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/480x480/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24223304/226423_Sean_Dong_Kia_Boys.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/540x540/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24223304/226423_Sean_Dong_Kia_Boys.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/640x640/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24223304/226423_Sean_Dong_Kia_Boys.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/750x750/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24223304/226423_Sean_Dong_Kia_Boys.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/828x828/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24223304/226423_Sean_Dong_Kia_Boys.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/1080x1080/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24223304/226423_Sean_Dong_Kia_Boys.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/1200x1200/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24223304/226423_Sean_Dong_Kia_Boys.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/1440x1440/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24223304/226423_Sean_Dong_Kia_Boys.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/1920x1920/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24223304/226423_Sean_Dong_Kia_Boys.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/2048x2048/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24223304/226423_Sean_Dong_Kia_Boys.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/2400x2400/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24223304/226423_Sean_Dong_Kia_Boys.jpg 2400w\" src=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2040x1360/2400x2400/filters:focal(1020x680:1021x681):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24223304/226423_Sean_Dong_Kia_Boys.jpg\"/></noscript></span></div><h3 class=\"font-polysans text-22 font-medium leading-100 -tracking-1 lg:text-34\"><a class=\"hover:shadow-underline-black\" href=\"/23742425/kia-boys-car-theft-steal-tiktok-hyundai-usb\">The Kia Boys will steal your car for clout</a></h3></li><li class=\"duet--ad--native-ad-linkset hidden py-16\" data-native-ad-id=\"container\"><div class=\"hidden\"><div class=\"dynamic-native-ad-native_ad_linkset_link\"></div></div><a href=\"http://theverge.com\"><div class=\"mb-4 flex items-center\"><span class=\"font-polysans text-11 uppercase leading-140 tracking-15\" data-native-ad-id=\"byline\">Advertiser Content From</span><img data-native-ad-id=\"logo\" class=\"max-h-[24px] max-w-[120px] pl-8\" alt=\"Sponsor logo\" src=\"/icons/native-ad-placeholder.png\"/></div></a><h3 class=\"font-polysans text-22 font-medium leading-100 -tracking-1 lg:text-34\"><a href=\"http://theverge.com\" class=\"hover:shadow-underline-black\" data-native-ad-id=\"title\"></a></h3></li></ul></div></section></div></div><footer class=\"duet--navigation--footer bg-gray-13 pb-70 pt-20 text-center font-polysans text-10 uppercase leading-[19px] tracking-[0.1em] text-white md:pt-40 lg:text-left lg:text-12 lg:leading-[21px]\"><div class=\"mx-auto max-w-container-lg\"><a href=\"/\" class=\"mx-auto mb-24 inline-block w-full overflow-hidden lg:mx-0\"><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 309 70\" role=\"img\" class=\"relative mx-auto w-[calc(100vw-40px)] fill-white md:static md:w-[204px] lg:ml-0 lg:w-[398px]\" width=\"100%\" height=\"100%\" fill=\"none\"><title>The Verge</title><desc>The Verge logo.</desc><path d=\"m231.196 17.897-.302 9.071c-10.592-.726-13.618 1.996-13.618 10.885V39h-9.078V18.441h9.078v5.866c2.724-4.777 6.416-6.954 13.92-6.41ZM15.131 54.786h9.078V19.71h-9.078v35.075Zm44.968-36.828c-6.355 0-10.228 2.842-12.286 5.986V4.593H0v8.466h39.34V39h8.654c0-7.438 4.298-12.697 9.563-12.697 4.54 0 6.597 2.237 6.597 10.28v18.203h9.078V33.318c0-10.28-5.265-15.36-13.133-15.36ZM95.807 47.83c-5.507 0-9.078-3.326-9.683-8.829H77.59c.847 9.676 7.202 16.51 18.157 16.51 8.473 0 13.254-3.81 15.736-9.555l-7.687-3.387c-1.15 3.447-3.268 5.261-7.989 5.261Zm-.363-29.692a19.226 19.226 0 0 0-9.32 2.177l4.357 6.168c1.634-.846 3.39-1.27 5.266-1.21 5.084 0 7.686 3.327 8.049 7.68H95.02v6.048h17.31c.121-.907.182-1.754.182-2.66.06-13.184-8.655-18.203-17.068-18.203ZM185.32 47.83c-5.507 0-9.078-3.326-9.683-8.829h-8.534c.847 9.676 7.202 16.51 18.157 16.51 8.473 0 13.254-3.81 15.736-9.555l-7.687-3.387c-1.21 3.447-3.328 5.261-7.989 5.261Zm-.302-29.692a19.226 19.226 0 0 0-9.321 2.177l4.358 6.168c1.634-.846 3.389-1.27 5.265-1.21 5.084 0 7.687 3.327 8.05 7.68h-8.776v6.048h17.31c.121-.907.181-1.754.181-2.66.061-13.184-8.655-18.203-17.067-18.203ZM291.416 47.83c-5.507 0-9.078-3.326-9.683-8.829h-8.534c.847 9.676 7.202 16.51 18.157 16.51 8.473 0 13.254-3.81 15.736-9.555l-7.687-3.387c-1.21 3.447-3.328 5.261-7.989 5.261Zm-.484-29.692a19.225 19.225 0 0 0-9.32 2.177l4.357 6.168c1.635-.846 3.39-1.27 5.266-1.21 5.084 0 7.686 3.327 8.049 7.68h-8.775v6.048h17.309c.121-.907.182-1.754.182-2.66.06-13.184-8.655-18.203-17.068-18.203ZM117.172.299 133.5 39h9.926L130.971 8.221h16.099V.36L117.172.3Zm48.418.06L146.888 47.71l-2.784 7.076h9.502L176.06.36h-10.47Zm83.461 53.58c3.873 0 7.081-1.089 9.32-2.963l-3.631-5.745c-1.15.484-2.421.665-3.692.665-4.963 0-7.808-2.963-8.776-6.894h-8.897c1.211 8.406 7.263 14.937 15.676 14.937Zm11.196-30.418c-2.057-3.265-6.234-5.624-12.044-5.624-5.689-.06-10.954 3.024-13.738 8.043l7.565 4.838c1.392-2.903 4.116-4.838 8.292-4.838 5.931 0 9.925 4.596 9.925 10.038 0 1.029-.121 2.057-.423 3.024h9.502v-20.5h-9.079v5.019Zm-8.775 38.642c-5.871 0-8.05-2.842-8.474-6.168h-8.654c.181 6.35 4.418 13.304 17.309 13.304 8.715 0 14.404-4.354 16.765-10.885l-8.171-2.842c-1.15 4.233-4.297 6.591-8.775 6.591Z\"></path></svg></a><div class=\"flex flex-col lg:flex-row\"><div class=\"mb-4 sm:mb-0 sm:basis-1/3 lg:basis-2/3\"><div class=\"flex flex-col\"><ul class=\"mb-16 flex list-inside flex-wrap justify-center pl-20 lg:justify-start\"><li class=\"mr-8 list-none before:mr-8 before:inline-block before:text-franklin before:hidden\"><a rel=\"nofollow\" class=\"hover:shadow-underline-inherit\" href=\"https://www.voxmedia.com/legal/terms-of-use\">Terms of Use</a></li><li class=\"mr-8 list-none before:mr-8 before:inline-block before:text-franklin before:content-[&#x27;/&#x27;]\"><a rel=\"nofollow\" class=\"hover:shadow-underline-inherit\" href=\"https://www.voxmedia.com/legal/privacy-notice\">Privacy Notice</a></li><li class=\"mr-8 list-none before:mr-8 before:inline-block before:text-franklin before:content-[&#x27;/&#x27;]\"><a rel=\"nofollow\" class=\"hover:shadow-underline-inherit\" href=\"https://www.voxmedia.com/legal/cookie-policy\">Cookie Policy</a></li><li class=\"mr-8 list-none before:mr-8 before:inline-block before:text-franklin before:content-[&#x27;/&#x27;]\"><a rel=\"nofollow\" class=\"hover:shadow-underline-inherit\" href=\"/contact\">Do Not Sell Or Share My Personal Info</a></li><li class=\"mr-8 list-none before:mr-8 before:inline-block before:text-franklin before:content-[&#x27;/&#x27;]\"><a rel=\"nofollow\" class=\"hover:shadow-underline-inherit\" href=\"https://www.voxmedia.com/pages/licensing\">Licensing FAQ</a></li><li class=\"mr-8 list-none before:mr-8 before:inline-block before:text-franklin before:content-[&#x27;/&#x27;]\"><a rel=\"nofollow\" class=\"hover:shadow-underline-inherit\" href=\"https://www.voxmedia.com/legal/accessibility\">Accessibility</a></li><li class=\"mr-8 list-none before:mr-8 before:inline-block before:text-franklin before:content-[&#x27;/&#x27;]\"><a rel=\"nofollow\" class=\"hover:shadow-underline-inherit\" href=\"https://status.voxmedia.com\">Platform Status</a></li><li class=\"mr-8 list-none before:mr-8 before:inline-block before:text-franklin before:content-[&#x27;/&#x27;]\"><a rel=\"nofollow\" class=\"hover:shadow-underline-inherit\" href=\"/pages/how-we-rate\">How We Rate and Review Products</a></li></ul><ul class=\"mb-16 flex list-inside flex-wrap justify-center pl-20 lg:justify-start\"><li class=\"mr-8 list-none before:mr-8 before:inline-block before:text-pernod before:hidden\"><a rel=\"nofollow\" class=\"hover:shadow-underline-inherit\" href=\"/contact-the-verge\">Contact</a></li><li class=\"mr-8 list-none before:mr-8 before:inline-block before:text-pernod before:content-[&#x27;/&#x27;]\"><a rel=\"nofollow\" class=\"hover:shadow-underline-inherit\" href=\"/a/tip-us-secure-contact-email\">Tip Us</a></li><li class=\"mr-8 list-none before:mr-8 before:inline-block before:text-pernod before:content-[&#x27;/&#x27;]\"><a rel=\"nofollow\" class=\"hover:shadow-underline-inherit\" href=\"/community-guidelines\">Community Guidelines</a></li><li class=\"mr-8 list-none before:mr-8 before:inline-block before:text-pernod before:content-[&#x27;/&#x27;]\"><a rel=\"nofollow\" class=\"hover:shadow-underline-inherit\" href=\"/about-the-verge\">About</a></li><li class=\"mr-8 list-none before:mr-8 before:inline-block before:text-pernod before:content-[&#x27;/&#x27;]\"><a rel=\"nofollow\" class=\"hover:shadow-underline-inherit\" href=\"/ethics-statement\">Ethics Statement</a></li></ul></div></div><div class=\"lg:basis-1/3\"><p class=\"mb-8 font-bold uppercase\">The Verge is a vox media network</p><ul class=\"mb-8 flex list-inside flex-wrap justify-center lg:justify-start\"><li class=\"mr-8 list-none leading-5 before:mr-8 before:inline-block before:text-hot-brick before:hidden\"><a rel=\"nofollow\" class=\"hover:shadow-underline-inherit\" href=\"https://www.voxmedia.com/vox-advertising\">Advertise with us</a></li><li class=\"mr-8 list-none leading-5 before:mr-8 before:inline-block before:text-hot-brick before:content-[&#x27;/&#x27;]\"><a rel=\"nofollow\" class=\"hover:shadow-underline-inherit\" href=\"https://jobs.voxmedia.com\">Jobs @ Vox Media</a></li></ul><p class=\"font-fkroman tracking-12 text-white\">© <!-- -->2023<!-- --> <a rel=\"nofollow\" href=\"https://www.voxmedia.com\">Vox Media</a>, LLC. All Rights Reserved</p></div></div></div></footer></div><script id=\"__NEXT_DATA__\" type=\"application/json\">{\"props\":{\"pageProps\":{\"hydration\":{\"responses\":[{\"operationName\":\"FeatureArticleLayoutQuery\",\"variables\":{\"uid\":\"Entry:e6a44b77-f363-473b-9651-3e323f6f4fd9\",\"communityId\":372},\"data\":{\"entryRevision\":{\"__typename\":\"Entry\",\"uid\":\"Entry:e6a44b77-f363-473b-9651-3e323f6f4fd9\",\"author\":{\"_id\":1966323,\"fullName\":\"Josh Dzieza\",\"authorProfile\":{\"url\":\"https://www.theverge.com/authors/josh-dzieza\",\"shortBio\":\"an investigations editor covering tech, business, and climate change. Since joining The Verge in 2014, he’s won a Loeb Award for feature writing, among others.\",\"uid\":\"AuthorProfile:23973\"}},\"uuid\":\"e6a44b77-f363-473b-9651-3e323f6f4fd9\",\"type\":\"STORY\",\"community\":{\"_id\":372,\"domain\":\"theverge.com\",\"network\":{\"domain\":\"theverge.com\"},\"placeholderImageUrl\":\"https://cdn.vox-cdn.com/uploads/network/placeholder_image/2/The_Verge.644.jpg\",\"slug\":\"verge\",\"name\":\"The Verge\",\"googleAmpLogo\":{\"url\":\"https://cdn.vox-cdn.com/uploads/chorus_asset/file/24015294/verge_duet_google_news.png\",\"width\":250,\"height\":50},\"communityID\":372},\"title\":\"AI Is a Lot of Work\",\"seoHeadline\":\"Inside the AI Factory: the humans that make tech seem human\",\"socialHeadline\":\"Inside the AI Factory\",\"promoHeadline\":\"Inside the AI Factory\",\"legacyId\":23528625,\"hasAffiliateLinks\":false,\"publishDate\":\"2023-06-20T12:05:00.000Z\",\"originalPublishDate\":\"2023-06-20T12:05:00.000Z\",\"wordCount\":7055,\"streams\":null,\"contributors\":[],\"primaryCampaignGroup\":null,\"campaignGroups\":[],\"communityGroups\":[{\"slug\":\"front-page\",\"isInternal\":false,\"hubPage\":{\"slug\":\"\",\"uid\":\"HubPage:270\"},\"isDisclaimer\":false,\"description\":null,\"uid\":\"EntryGroup:51\",\"name\":\"Front Page\",\"url\":\"https://www.theverge.com/\",\"isStarred\":false,\"recentEntries\":{\"results\":[{\"primaryCommunityGroup\":{\"name\":\"Front Page\",\"isInternal\":false},\"type\":\"STORY\",\"promoHeadline\":null,\"title\":\"Here are the best Kindle deals right now\",\"uid\":\"Entry:fcce30be-1c01-48e9-b609-41b168ee4013\",\"url\":\"https://www.theverge.com/21539047/best-amazon-kindle-deals\",\"author\":{\"fullName\":\"Sheena Vasani\"},\"leadImage\":{\"url\":\"https://cdn.vox-cdn.com/thumbor/Iw5yUKLaMarH6iZuGKdBWEgQaE0=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/22954895/cgartenberg_211020_4803_0006.jpg\",\"variantUrl\":\"https://cdn.vox-cdn.com/thumbor/oncZFD4igTrtqzA8ysUuMDEM8eM=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/22954895/cgartenberg_211020_4803_0006.jpg\",\"asset\":{\"title\":\"The Kindle Paperwhite against a backdrop of physical books.\"},\"caption\":{\"plaintext\":\"The latest Kindle Paperwhite is on sale as a part of a bundle.\"}},\"promoImage\":null,\"communityGroups\":[{\"name\":\"Deals\",\"slug\":\"good-deals\",\"hubPage\":{\"uid\":\"HubPage:17413\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"guidebook\",\"slug\":\"guidebook\",\"hubPage\":null,\"isInternal\":true,\"isStarred\":false},{\"name\":\"Tech\",\"slug\":\"tech\",\"hubPage\":{\"uid\":\"HubPage:8135\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Evergreen Deals\",\"slug\":\"evergreen-deals\",\"hubPage\":null,\"isInternal\":true,\"isStarred\":false},{\"name\":\"Amazon\",\"slug\":\"amazon\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false},{\"name\":\"Front Page\",\"slug\":\"front-page\",\"hubPage\":{\"uid\":\"HubPage:270\"},\"isInternal\":false,\"isStarred\":false}]},{\"primaryCommunityGroup\":{\"name\":\"Front Page\",\"isInternal\":false},\"type\":\"STORY\",\"promoHeadline\":null,\"title\":\"Nothing Phone 2 camera and display specs leak days ahead of launch\",\"uid\":\"Entry:a1e4584c-7c7c-4008-b799-0edc05e3a252\",\"url\":\"https://www.theverge.com/2023/7/6/23785836/nothing-phone-2-camera-display-specs-launch-leak\",\"author\":{\"fullName\":\"Emma Roth\"},\"leadImage\":{\"url\":\"https://cdn.vox-cdn.com/thumbor/ZIt54jMc61J7bAfe40ZaBAZnnzU=/0x0:4096x4096/4096x4096/filters:focal(2071x1695:2072x1696)/cdn.vox-cdn.com/uploads/chorus_asset/file/24773343/nothing_phone_2_tease.jpg\",\"variantUrl\":\"https://cdn.vox-cdn.com/thumbor/pTj6D_5p6t513RHueH6ZsQTC-J0=/0x0:4096x4096/100x100/filters:focal(2071x1695:2072x1696)/cdn.vox-cdn.com/uploads/chorus_asset/file/24773343/nothing_phone_2_tease.jpg\",\"asset\":{\"title\":\"An image showing the Nothing Phone 2\"},\"caption\":null},\"promoImage\":null,\"communityGroups\":[{\"name\":\"Front Page\",\"slug\":\"front-page\",\"hubPage\":{\"uid\":\"HubPage:270\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Mobile\",\"slug\":\"mobile\",\"hubPage\":{\"uid\":\"HubPage:282\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Tech\",\"slug\":\"tech\",\"hubPage\":{\"uid\":\"HubPage:8135\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"News\",\"slug\":\"news\",\"hubPage\":null,\"isInternal\":true,\"isStarred\":false}]},{\"primaryCommunityGroup\":{\"name\":\"Front Page\",\"isInternal\":false},\"type\":\"STREAM\",\"promoHeadline\":null,\"title\":\"Instagram’s Threads: all the updates on the new Twitter competitor\",\"uid\":\"Entry:29993508-0271-4f0f-9027-037244bc2394\",\"url\":\"https://www.theverge.com/2023/7/5/23784480/threads-instagram-meta-news-twitter-competitor\",\"author\":{\"fullName\":\"Emma Roth\"},\"leadImage\":{\"url\":\"https://cdn.vox-cdn.com/thumbor/9_PDucpVjbtBIugl1ryeeBQXays=/0x0:700x600/700x600/filters:focal(350x300:351x301)/cdn.vox-cdn.com/uploads/chorus_asset/file/24771846/threads_logo.jpg\",\"variantUrl\":\"https://cdn.vox-cdn.com/thumbor/7UsMPDBuJmQb7eLibiILhZGFtZc=/0x0:700x600/100x100/filters:focal(350x300:351x301)/cdn.vox-cdn.com/uploads/chorus_asset/file/24771846/threads_logo.jpg\",\"asset\":{\"title\":\"An image showing the Threads logo on a black background\"},\"caption\":null},\"promoImage\":null,\"communityGroups\":[{\"name\":\"Front Page\",\"slug\":\"front-page\",\"hubPage\":{\"uid\":\"HubPage:270\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Meta\",\"slug\":\"meta\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false},{\"name\":\"Tech\",\"slug\":\"tech\",\"hubPage\":{\"uid\":\"HubPage:8135\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"News\",\"slug\":\"news\",\"hubPage\":null,\"isInternal\":true,\"isStarred\":false},{\"name\":\"Instagram\",\"slug\":\"instagram\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false},{\"name\":\"Twitter\",\"slug\":\"twitter\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false},{\"name\":\"Apps\",\"slug\":\"apps\",\"hubPage\":{\"uid\":\"HubPage:277\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Creators\",\"slug\":\"creators\",\"hubPage\":{\"uid\":\"HubPage:18970\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Featured Stories\",\"slug\":\"featured-story\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false}]},{\"primaryCommunityGroup\":{\"name\":\"Front Page\",\"isInternal\":false},\"type\":\"STORY\",\"promoHeadline\":null,\"title\":\"Pokémon Sleep looks adorable and sounds kind of intrusive in new video\",\"uid\":\"Entry:db7fc52d-28a4-42cc-bfd0-e8254a0a585e\",\"url\":\"https://www.theverge.com/2023/7/6/23785767/pokemon-sleep-how-to-play-android-preregister\",\"author\":{\"fullName\":\"Charles Pulliam-Moore\"},\"leadImage\":null,\"promoImage\":{\"url\":\"https://cdn.vox-cdn.com/thumbor/EOZuefjKWnZVRxW9b4MZahdQ4kE=/0x0:2385x1235/2385x1235/filters:focal(1188x553:1189x554)/cdn.vox-cdn.com/uploads/chorus_asset/file/24773042/Screen_Shot_2023_07_06_at_10.54.16_AM.png\",\"variantUrl\":\"https://cdn.vox-cdn.com/thumbor/Lxk5KB0gTOIVQHP35QKZnNBA-90=/0x0:2385x1235/100x100/filters:focal(1188x553:1189x554)/cdn.vox-cdn.com/uploads/chorus_asset/file/24773042/Screen_Shot_2023_07_06_at_10.54.16_AM.png\",\"asset\":{\"title\":null},\"caption\":null},\"communityGroups\":[{\"name\":\"Front Page\",\"slug\":\"front-page\",\"hubPage\":{\"uid\":\"HubPage:270\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Pokemon\",\"slug\":\"pokemon\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false},{\"name\":\"Gaming\",\"slug\":\"games\",\"hubPage\":{\"uid\":\"HubPage:276\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Entertainment\",\"slug\":\"entertainment\",\"hubPage\":{\"uid\":\"HubPage:8141\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Nintendo\",\"slug\":\"nintendo\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false}]},{\"primaryCommunityGroup\":{\"name\":\"Front Page\",\"isInternal\":false},\"type\":\"STORY\",\"promoHeadline\":null,\"title\":\"The Super Mario Bros. Movie will start streaming on Peacock in August\",\"uid\":\"Entry:8456b308-a0ac-4844-bf16-f86cb7a1f218\",\"url\":\"https://www.theverge.com/23785874/super-mario-bros-movie-streaming-peacock-release-date\",\"author\":{\"fullName\":\"Jay Peters\"},\"leadImage\":{\"url\":\"https://cdn.vox-cdn.com/thumbor/WNo9YcHvd2BCv6jTN6UJ8kiuOSs=/0x0:3588x1500/3588x1500/filters:focal(1794x750:1795x751)/cdn.vox-cdn.com/uploads/chorus_asset/file/24706551/mario_bros_movie.jpg\",\"variantUrl\":\"https://cdn.vox-cdn.com/thumbor/HupHvV1rZGrUk38zeLKwp_YDJdM=/0x0:3588x1500/100x100/filters:focal(1794x750:1795x751)/cdn.vox-cdn.com/uploads/chorus_asset/file/24706551/mario_bros_movie.jpg\",\"asset\":{\"title\":\"An image showing Mario and Luigi in The Super Mario Bros. Movie\"},\"caption\":null},\"promoImage\":null,\"communityGroups\":[{\"name\":\"Front Page\",\"slug\":\"front-page\",\"hubPage\":{\"uid\":\"HubPage:270\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Gaming\",\"slug\":\"games\",\"hubPage\":{\"uid\":\"HubPage:276\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Entertainment\",\"slug\":\"entertainment\",\"hubPage\":{\"uid\":\"HubPage:8141\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Film\",\"slug\":\"film\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false},{\"name\":\"News\",\"slug\":\"news\",\"hubPage\":null,\"isInternal\":true,\"isStarred\":false},{\"name\":\"Tech\",\"slug\":\"tech\",\"hubPage\":{\"uid\":\"HubPage:8135\"},\"isInternal\":false,\"isStarred\":false}]}]},\"type\":\"SITE_GROUP\"},{\"slug\":\"features\",\"isInternal\":false,\"hubPage\":{\"slug\":\"features\",\"uid\":\"HubPage:19098\"},\"isDisclaimer\":false,\"description\":\"\\u003cem\\u003eThe Verge\\u003c/em\\u003e’s features pursue rigorous, forward-looking journalism. Here you’ll find our most ambitious, award-winning reporting, profiles, essays, and oral histories across all the intersecting areas we cover, from technology to TV/film, climate change to creators.\",\"uid\":\"EntryGroup:468\",\"name\":\"Features\",\"url\":\"https://www.theverge.com/features\",\"isStarred\":false,\"recentEntries\":{\"results\":[{\"primaryCommunityGroup\":{\"name\":\"Books\",\"isInternal\":false},\"type\":\"CUSTOM_STORY\",\"promoHeadline\":null,\"title\":\"The greatest tech books of all time\",\"uid\":\"Entry:94642a96-ab16-40bf-8dbc-77f0d201f0ce\",\"url\":\"https://www.theverge.com/c/23771068/best-tech-books-nonfiction-recommendations\",\"author\":{\"fullName\":\"Verge Staff\"},\"leadImage\":{\"url\":\"https://cdn.vox-cdn.com/thumbor/aApYdgjBJWy8UJGqHM6Aligqh24=/0x0:1512x1510/1512x1510/filters:focal(756x755:757x756)/cdn.vox-cdn.com/uploads/chorus_asset/file/24747256/best_tech_books.png\",\"variantUrl\":\"https://cdn.vox-cdn.com/thumbor/VhKq-gpD5icQR_uhBS-GZcNtjeA=/0x0:1512x1510/100x100/filters:focal(756x755:757x756)/cdn.vox-cdn.com/uploads/chorus_asset/file/24747256/best_tech_books.png\",\"asset\":{\"title\":null},\"caption\":null},\"promoImage\":null,\"communityGroups\":[{\"name\":\"Front Page\",\"slug\":\"front-page\",\"hubPage\":{\"uid\":\"HubPage:270\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Featured Stories\",\"slug\":\"featured-story\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false},{\"name\":\"Books\",\"slug\":\"books\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false},{\"name\":\"Entertainment\",\"slug\":\"entertainment\",\"hubPage\":{\"uid\":\"HubPage:8141\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Tech\",\"slug\":\"tech\",\"hubPage\":{\"uid\":\"HubPage:8135\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Features\",\"slug\":\"features\",\"hubPage\":{\"uid\":\"HubPage:19098\"},\"isInternal\":false,\"isStarred\":false}]},{\"primaryCommunityGroup\":{\"name\":\"Front Page\",\"isInternal\":false},\"type\":\"CUSTOM_STORY\",\"promoHeadline\":null,\"title\":\"Goodnight Phone\",\"uid\":\"Entry:aa9e2204-db43-4b5d-b9f8-05bf41856ff5\",\"url\":\"https://www.theverge.com/c/23558791/goodnight-phone-comic-interactive-gina-wynbrandt\",\"author\":{\"fullName\":\"Gina Wynbrandt\"},\"leadImage\":{\"url\":\"https://cdn.vox-cdn.com/thumbor/lapMOFlVh083VfdHWjlKNhNKAYI=/72x50:1178x774/1106x724/filters:focal(1143x749:1144x750)/cdn.vox-cdn.com/uploads/chorus_asset/file/24739587/01_1250x820.png\",\"variantUrl\":\"https://cdn.vox-cdn.com/thumbor/_9Tof7gHnmjF_MPHR6qICNWXqXc=/72x50:1178x774/100x100/filters:focal(1143x749:1144x750)/cdn.vox-cdn.com/uploads/chorus_asset/file/24739587/01_1250x820.png\",\"asset\":{\"title\":null},\"caption\":null},\"promoImage\":null,\"communityGroups\":[{\"name\":\"Front Page\",\"slug\":\"front-page\",\"hubPage\":{\"uid\":\"HubPage:270\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Features\",\"slug\":\"features\",\"hubPage\":{\"uid\":\"HubPage:19098\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Featured Stories\",\"slug\":\"featured-story\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false}]},{\"primaryCommunityGroup\":{\"name\":\"Features\",\"isInternal\":false},\"type\":\"STORY\",\"promoHeadline\":\"Inside the AI Factory\",\"title\":\"AI Is a Lot of Work\",\"uid\":\"Entry:e6a44b77-f363-473b-9651-3e323f6f4fd9\",\"url\":\"https://www.theverge.com/features/23764584/ai-artificial-intelligence-data-notation-labor-scale-surge-remotasks-openai-chatbots\",\"author\":{\"fullName\":\"Josh Dzieza\"},\"leadImage\":{\"url\":\"https://cdn.vox-cdn.com/thumbor/8c4Gg5x_MwNBMS1a0Lnev77RVZs=/0x0:2048x1365/2048x1365/filters:focal(1024x683:1025x684)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg\",\"variantUrl\":\"https://cdn.vox-cdn.com/thumbor/4lwAlsROJFf30gLwEURKbEblgWQ=/0x0:2048x1365/100x100/filters:focal(1024x683:1025x684)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg\",\"asset\":{\"title\":null},\"caption\":null},\"promoImage\":{\"url\":\"https://cdn.vox-cdn.com/thumbor/9Snl5IydxWJ9OX-SIaz3_qWwnJo=/0x0:2048x2048/2048x2048/filters:focal(1024x1024:1025x1025)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737792/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_Square.jpg\",\"variantUrl\":\"https://cdn.vox-cdn.com/thumbor/hNA22KupxK4fYGvhgkVx8TCHL40=/0x0:2048x2048/100x100/filters:focal(1024x1024:1025x1025)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737792/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_Square.jpg\",\"asset\":{\"title\":null},\"caption\":null},\"communityGroups\":[{\"name\":\"Front Page\",\"slug\":\"front-page\",\"hubPage\":{\"uid\":\"HubPage:270\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Features\",\"slug\":\"features\",\"hubPage\":{\"uid\":\"HubPage:19098\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Artificial Intelligence\",\"slug\":\"ai-artificial-intelligence\",\"hubPage\":{\"uid\":\"HubPage:17957\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Tech\",\"slug\":\"tech\",\"hubPage\":{\"uid\":\"HubPage:8135\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Featured Stories\",\"slug\":\"featured-story\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false}]},{\"primaryCommunityGroup\":{\"name\":\"Front Page\",\"isInternal\":false},\"type\":\"STORY\",\"promoHeadline\":\"The store is for people, but the storefront is for Google’s web crawlers\",\"title\":\"A storefront for robots\",\"uid\":\"Entry:129681d1-c69b-4c0b-adc1-a42e88951bff\",\"url\":\"https://www.theverge.com/23753963/google-seo-shopify-small-business-ai\",\"author\":{\"fullName\":\"Mia Sato\"},\"leadImage\":{\"url\":\"https://cdn.vox-cdn.com/thumbor/DX9uNiyMvy6GR_c8Pzr0J-226nQ=/0x0:3000x2000/3000x2000/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/24726611/236693_Small_Business_Google_SEO_HHerrera.jpeg\",\"variantUrl\":\"https://cdn.vox-cdn.com/thumbor/3f1LBq2OY96StUs-zBxmPyRLFPI=/0x0:3000x2000/100x100/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/24726611/236693_Small_Business_Google_SEO_HHerrera.jpeg\",\"asset\":{\"title\":null},\"caption\":null},\"promoImage\":null,\"communityGroups\":[{\"name\":\"Front Page\",\"slug\":\"front-page\",\"hubPage\":{\"uid\":\"HubPage:270\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Google\",\"slug\":\"google\",\"hubPage\":{\"uid\":\"HubPage:274\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Tech\",\"slug\":\"tech\",\"hubPage\":{\"uid\":\"HubPage:8135\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Artificial Intelligence\",\"slug\":\"ai-artificial-intelligence\",\"hubPage\":{\"uid\":\"HubPage:17957\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Features\",\"slug\":\"features\",\"hubPage\":{\"uid\":\"HubPage:19098\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Creators\",\"slug\":\"creators\",\"hubPage\":{\"uid\":\"HubPage:18970\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Featured Stories\",\"slug\":\"featured-story\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false}]},{\"primaryCommunityGroup\":{\"name\":\"Front Page\",\"isInternal\":false},\"type\":\"STORY\",\"promoHeadline\":null,\"title\":\"The Kia Boys will steal your car for clout\",\"uid\":\"Entry:042c4aa7-0f57-4102-9152-104c7c10e2f2\",\"url\":\"https://www.theverge.com/23742425/kia-boys-car-theft-steal-tiktok-hyundai-usb\",\"author\":{\"fullName\":\"Taylor Dorrell\"},\"leadImage\":{\"url\":\"https://cdn.vox-cdn.com/thumbor/XI2Fy5nU3qySSep5X_bXoSFeL3Y=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/24223304/226423_Sean_Dong_Kia_Boys.jpg\",\"variantUrl\":\"https://cdn.vox-cdn.com/thumbor/yQ3NMv7GofTbkEny269MUN63fKg=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/24223304/226423_Sean_Dong_Kia_Boys.jpg\",\"asset\":{\"title\":\"A car tangled up in a charging cable.\"},\"caption\":null},\"promoImage\":null,\"communityGroups\":[{\"name\":\"Front Page\",\"slug\":\"front-page\",\"hubPage\":{\"uid\":\"HubPage:270\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Features\",\"slug\":\"features\",\"hubPage\":{\"uid\":\"HubPage:19098\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Transpo\",\"slug\":\"transportation\",\"hubPage\":{\"uid\":\"HubPage:11464\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"TikTok\",\"slug\":\"tiktok\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false},{\"name\":\"Creators\",\"slug\":\"creators\",\"hubPage\":{\"uid\":\"HubPage:18970\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Tech\",\"slug\":\"tech\",\"hubPage\":{\"uid\":\"HubPage:8135\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Cars\",\"slug\":\"cars\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false},{\"name\":\"Featured Stories\",\"slug\":\"featured-story\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false}]}]},\"type\":\"SITE_GROUP\"},{\"slug\":\"ai-artificial-intelligence\",\"isInternal\":false,\"hubPage\":{\"slug\":\"ai-artificial-intelligence\",\"uid\":\"HubPage:17957\"},\"isDisclaimer\":false,\"description\":\"Machines with brains are the future, and \\u003cem\\u003eThe Verge\\u003c/em\\u003e is here to explain it all. From Google and Facebook’s use of machine learning to rule the web, to cutting-edge research and why Alexa still sucks at conversation. We want to dispel the hype of AI and distill what it is you need to know.\",\"uid\":\"EntryGroup:45647\",\"name\":\"Artificial Intelligence\",\"url\":\"https://www.theverge.com/ai-artificial-intelligence\",\"isStarred\":false,\"recentEntries\":{\"results\":[{\"primaryCommunityGroup\":{\"name\":\"Front Page\",\"isInternal\":false},\"type\":\"STORY\",\"promoHeadline\":null,\"title\":\"G/O Media’s AI ‘innovation’ is off to a rocky start\",\"uid\":\"Entry:bad75a99-66a3-4c42-90ab-79514875a136\",\"url\":\"https://www.theverge.com/2023/7/6/23785645/go-media-ai-generated-articles-gizmodo-av-club-artificial-intelligence-bots\",\"author\":{\"fullName\":\"Mia Sato\"},\"leadImage\":{\"url\":\"https://cdn.vox-cdn.com/thumbor/R8lqwdH7qtYVbldZ5nsQqtUkOOo=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/13292779/acastro_181017_1777_brain_ai_0002.jpg\",\"variantUrl\":\"https://cdn.vox-cdn.com/thumbor/w8RW8yJvudP7gBGAcu4vYpG_2NU=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/13292779/acastro_181017_1777_brain_ai_0002.jpg\",\"asset\":{\"title\":\"An illustration of a cartoon brain with a computer chip imposed on top.\"},\"caption\":null},\"promoImage\":null,\"communityGroups\":[{\"name\":\"Front Page\",\"slug\":\"front-page\",\"hubPage\":{\"uid\":\"HubPage:270\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Artificial Intelligence\",\"slug\":\"ai-artificial-intelligence\",\"hubPage\":{\"uid\":\"HubPage:17957\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Tech\",\"slug\":\"tech\",\"hubPage\":{\"uid\":\"HubPage:8135\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"News\",\"slug\":\"news\",\"hubPage\":null,\"isInternal\":true,\"isStarred\":false}]},{\"primaryCommunityGroup\":{\"name\":\"Front Page\",\"isInternal\":false},\"type\":\"STORY\",\"promoHeadline\":null,\"title\":\"Google confirms it’s training Bard on scraped web data, too\",\"uid\":\"Entry:572ee011-a80d-4b0e-b865-fd5b1a9c3e1c\",\"url\":\"https://www.theverge.com/2023/7/5/23784257/google-ai-bard-privacy-policy-train-web-scraping\",\"author\":{\"fullName\":\"Jess Weatherbed\"},\"leadImage\":{\"url\":\"https://cdn.vox-cdn.com/thumbor/ggJYscZZGN36r-HBSxSxVdb28SQ=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/24440561/AI_art_chat_H_Jeong_1.jpg\",\"variantUrl\":\"https://cdn.vox-cdn.com/thumbor/Xt7jJ2YYi9-rPqIpC-cZQIsadUs=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/24440561/AI_art_chat_H_Jeong_1.jpg\",\"asset\":{\"title\":\"A trippy graphic displaying a collection of items like paintbrushes, books, phone messages, and a notepad to represent generative AI. A large pair of eyes and hands can be seen at the center of the image.\"},\"caption\":{\"plaintext\":\"Whatever content is publically available on the web, Google has given itself permission to use it to train AI.\"}},\"promoImage\":null,\"communityGroups\":[{\"name\":\"Front Page\",\"slug\":\"front-page\",\"hubPage\":{\"uid\":\"HubPage:270\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Artificial Intelligence\",\"slug\":\"ai-artificial-intelligence\",\"hubPage\":{\"uid\":\"HubPage:17957\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Tech\",\"slug\":\"tech\",\"hubPage\":{\"uid\":\"HubPage:8135\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Google\",\"slug\":\"google\",\"hubPage\":{\"uid\":\"HubPage:274\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"News\",\"slug\":\"news\",\"hubPage\":null,\"isInternal\":true,\"isStarred\":false}]},{\"primaryCommunityGroup\":{\"name\":\"Front Page\",\"isInternal\":false},\"type\":\"STORY\",\"promoHeadline\":null,\"title\":\"Valve won’t approve Steam games that use copyright-infringing AI artwork\",\"uid\":\"Entry:2291bc74-7509-4b75-a55b-ba194909f2b5\",\"url\":\"https://www.theverge.com/2023/7/1/23781339/valve-steam-ai-artwork-rejecting-banning-pc-games\",\"author\":{\"fullName\":\"Wes Davis\"},\"leadImage\":{\"url\":\"https://cdn.vox-cdn.com/thumbor/jnEKQEz3bzQs0gz8VqjdDTD2UcQ=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/24062776/STK138_Stream_Kradtke_01.jpg\",\"variantUrl\":\"https://cdn.vox-cdn.com/thumbor/OIUUXUZas_FgT88fHsLGRD_YnwQ=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/24062776/STK138_Stream_Kradtke_01.jpg\",\"asset\":{\"title\":\"An illustration of the Steam logo.\"},\"caption\":null},\"promoImage\":null,\"communityGroups\":[{\"name\":\"Front Page\",\"slug\":\"front-page\",\"hubPage\":{\"uid\":\"HubPage:270\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Gaming\",\"slug\":\"games\",\"hubPage\":{\"uid\":\"HubPage:276\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Entertainment\",\"slug\":\"entertainment\",\"hubPage\":{\"uid\":\"HubPage:8141\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"PC Gaming\",\"slug\":\"pc-gaming\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false},{\"name\":\"Artificial Intelligence\",\"slug\":\"ai-artificial-intelligence\",\"hubPage\":{\"uid\":\"HubPage:17957\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Tech\",\"slug\":\"tech\",\"hubPage\":{\"uid\":\"HubPage:8135\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"News\",\"slug\":\"news\",\"hubPage\":null,\"isInternal\":true,\"isStarred\":false}]},{\"primaryCommunityGroup\":{\"name\":\"Front Page\",\"isInternal\":false},\"type\":\"STORY\",\"promoHeadline\":null,\"title\":\"Elon Musk blames data scraping by AI startups for his new paywalls on reading tweets\",\"uid\":\"Entry:c4101fcd-9d04-477e-869e-8fbe7d39c74f\",\"url\":\"https://www.theverge.com/2023/7/1/23781198/twitter-daily-reading-limit-elon-musk-verified-paywall\",\"author\":{\"fullName\":\"Wes Davis\"},\"leadImage\":{\"url\":\"https://cdn.vox-cdn.com/thumbor/NOZVZUEi_zauzyVqDDLQfPMHnIE=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/23382328/VRG_Illo_STK022_K_Radtke_Musk_Twitter_Shrug.jpg\",\"variantUrl\":\"https://cdn.vox-cdn.com/thumbor/y4qDeaHgM7nJ8_zleHIQLqeky8I=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/23382328/VRG_Illo_STK022_K_Radtke_Musk_Twitter_Shrug.jpg\",\"asset\":{\"title\":\"Elon Musk shrugging on a background with the Twitter logo\"},\"caption\":null},\"promoImage\":null,\"communityGroups\":[{\"name\":\"Front Page\",\"slug\":\"front-page\",\"hubPage\":{\"uid\":\"HubPage:270\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Twitter\",\"slug\":\"twitter\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false},{\"name\":\"Tech\",\"slug\":\"tech\",\"hubPage\":{\"uid\":\"HubPage:8135\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Elon Musk\",\"slug\":\"elon-musk\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false},{\"name\":\"News\",\"slug\":\"news\",\"hubPage\":null,\"isInternal\":true,\"isStarred\":false},{\"name\":\"Breaking\",\"slug\":\"breaking\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false},{\"name\":\"Business\",\"slug\":\"business\",\"hubPage\":{\"uid\":\"HubPage:8139\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Artificial Intelligence\",\"slug\":\"ai-artificial-intelligence\",\"hubPage\":{\"uid\":\"HubPage:17957\"},\"isInternal\":false,\"isStarred\":false}]},{\"primaryCommunityGroup\":{\"name\":\"Front Page\",\"isInternal\":false},\"type\":\"STORY\",\"promoHeadline\":null,\"title\":\"The FTC wants to put a ban on fake reviews\",\"uid\":\"Entry:6d7b7f14-9c0d-4546-8176-ca69c129316f\",\"url\":\"https://www.theverge.com/2023/6/30/23779880/ftc-fake-reviews-ban-ai\",\"author\":{\"fullName\":\"Emma Roth\"},\"leadImage\":{\"url\":\"https://cdn.vox-cdn.com/thumbor/0eLAv6PkzMcWZCJmDxevxmQ-kyI=/0x0:3000x2000/3000x2000/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/8839371/acastro_170711_1777_0001.jpg\",\"variantUrl\":\"https://cdn.vox-cdn.com/thumbor/IR-ek0DeejZ5IkMeR5TCFTOprr4=/0x0:3000x2000/100x100/filters:focal(1500x1000:1501x1001)/cdn.vox-cdn.com/uploads/chorus_asset/file/8839371/acastro_170711_1777_0001.jpg\",\"asset\":{\"title\":\"An image showing a silhouette of Capitol Hill\"},\"caption\":null},\"promoImage\":null,\"communityGroups\":[{\"name\":\"Front Page\",\"slug\":\"front-page\",\"hubPage\":{\"uid\":\"HubPage:270\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Policy\",\"slug\":\"policy\",\"hubPage\":{\"uid\":\"HubPage:278\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"News\",\"slug\":\"news\",\"hubPage\":null,\"isInternal\":true,\"isStarred\":false},{\"name\":\"Tech\",\"slug\":\"tech\",\"hubPage\":{\"uid\":\"HubPage:8135\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Artificial Intelligence\",\"slug\":\"ai-artificial-intelligence\",\"hubPage\":{\"uid\":\"HubPage:17957\"},\"isInternal\":false,\"isStarred\":false}]}]},\"type\":\"SITE_GROUP\"},{\"slug\":\"tech\",\"isInternal\":false,\"hubPage\":{\"slug\":\"tech\",\"uid\":\"HubPage:8135\"},\"isDisclaimer\":false,\"description\":\"The latest tech news about the world's best (and sometimes worst) hardware, apps, and much more. From top companies like Google and Apple to tiny startups vying for your attention, Verge Tech has the latest in what matters in technology daily.\",\"uid\":\"EntryGroup:21019\",\"name\":\"Tech\",\"url\":\"https://www.theverge.com/tech\",\"isStarred\":false,\"recentEntries\":{\"results\":[{\"primaryCommunityGroup\":{\"name\":\"Front Page\",\"isInternal\":false},\"type\":\"STORY\",\"promoHeadline\":null,\"title\":\"Here are the best Kindle deals right now\",\"uid\":\"Entry:fcce30be-1c01-48e9-b609-41b168ee4013\",\"url\":\"https://www.theverge.com/21539047/best-amazon-kindle-deals\",\"author\":{\"fullName\":\"Sheena Vasani\"},\"leadImage\":{\"url\":\"https://cdn.vox-cdn.com/thumbor/Iw5yUKLaMarH6iZuGKdBWEgQaE0=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/22954895/cgartenberg_211020_4803_0006.jpg\",\"variantUrl\":\"https://cdn.vox-cdn.com/thumbor/oncZFD4igTrtqzA8ysUuMDEM8eM=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/22954895/cgartenberg_211020_4803_0006.jpg\",\"asset\":{\"title\":\"The Kindle Paperwhite against a backdrop of physical books.\"},\"caption\":{\"plaintext\":\"The latest Kindle Paperwhite is on sale as a part of a bundle.\"}},\"promoImage\":null,\"communityGroups\":[{\"name\":\"Deals\",\"slug\":\"good-deals\",\"hubPage\":{\"uid\":\"HubPage:17413\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"guidebook\",\"slug\":\"guidebook\",\"hubPage\":null,\"isInternal\":true,\"isStarred\":false},{\"name\":\"Tech\",\"slug\":\"tech\",\"hubPage\":{\"uid\":\"HubPage:8135\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Evergreen Deals\",\"slug\":\"evergreen-deals\",\"hubPage\":null,\"isInternal\":true,\"isStarred\":false},{\"name\":\"Amazon\",\"slug\":\"amazon\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false},{\"name\":\"Front Page\",\"slug\":\"front-page\",\"hubPage\":{\"uid\":\"HubPage:270\"},\"isInternal\":false,\"isStarred\":false}]},{\"primaryCommunityGroup\":{\"name\":\"Front Page\",\"isInternal\":false},\"type\":\"STORY\",\"promoHeadline\":null,\"title\":\"Nothing Phone 2 camera and display specs leak days ahead of launch\",\"uid\":\"Entry:a1e4584c-7c7c-4008-b799-0edc05e3a252\",\"url\":\"https://www.theverge.com/2023/7/6/23785836/nothing-phone-2-camera-display-specs-launch-leak\",\"author\":{\"fullName\":\"Emma Roth\"},\"leadImage\":{\"url\":\"https://cdn.vox-cdn.com/thumbor/ZIt54jMc61J7bAfe40ZaBAZnnzU=/0x0:4096x4096/4096x4096/filters:focal(2071x1695:2072x1696)/cdn.vox-cdn.com/uploads/chorus_asset/file/24773343/nothing_phone_2_tease.jpg\",\"variantUrl\":\"https://cdn.vox-cdn.com/thumbor/pTj6D_5p6t513RHueH6ZsQTC-J0=/0x0:4096x4096/100x100/filters:focal(2071x1695:2072x1696)/cdn.vox-cdn.com/uploads/chorus_asset/file/24773343/nothing_phone_2_tease.jpg\",\"asset\":{\"title\":\"An image showing the Nothing Phone 2\"},\"caption\":null},\"promoImage\":null,\"communityGroups\":[{\"name\":\"Front Page\",\"slug\":\"front-page\",\"hubPage\":{\"uid\":\"HubPage:270\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Mobile\",\"slug\":\"mobile\",\"hubPage\":{\"uid\":\"HubPage:282\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Tech\",\"slug\":\"tech\",\"hubPage\":{\"uid\":\"HubPage:8135\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"News\",\"slug\":\"news\",\"hubPage\":null,\"isInternal\":true,\"isStarred\":false}]},{\"primaryCommunityGroup\":{\"name\":\"Front Page\",\"isInternal\":false},\"type\":\"STREAM\",\"promoHeadline\":null,\"title\":\"Instagram’s Threads: all the updates on the new Twitter competitor\",\"uid\":\"Entry:29993508-0271-4f0f-9027-037244bc2394\",\"url\":\"https://www.theverge.com/2023/7/5/23784480/threads-instagram-meta-news-twitter-competitor\",\"author\":{\"fullName\":\"Emma Roth\"},\"leadImage\":{\"url\":\"https://cdn.vox-cdn.com/thumbor/9_PDucpVjbtBIugl1ryeeBQXays=/0x0:700x600/700x600/filters:focal(350x300:351x301)/cdn.vox-cdn.com/uploads/chorus_asset/file/24771846/threads_logo.jpg\",\"variantUrl\":\"https://cdn.vox-cdn.com/thumbor/7UsMPDBuJmQb7eLibiILhZGFtZc=/0x0:700x600/100x100/filters:focal(350x300:351x301)/cdn.vox-cdn.com/uploads/chorus_asset/file/24771846/threads_logo.jpg\",\"asset\":{\"title\":\"An image showing the Threads logo on a black background\"},\"caption\":null},\"promoImage\":null,\"communityGroups\":[{\"name\":\"Front Page\",\"slug\":\"front-page\",\"hubPage\":{\"uid\":\"HubPage:270\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Meta\",\"slug\":\"meta\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false},{\"name\":\"Tech\",\"slug\":\"tech\",\"hubPage\":{\"uid\":\"HubPage:8135\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"News\",\"slug\":\"news\",\"hubPage\":null,\"isInternal\":true,\"isStarred\":false},{\"name\":\"Instagram\",\"slug\":\"instagram\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false},{\"name\":\"Twitter\",\"slug\":\"twitter\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false},{\"name\":\"Apps\",\"slug\":\"apps\",\"hubPage\":{\"uid\":\"HubPage:277\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Creators\",\"slug\":\"creators\",\"hubPage\":{\"uid\":\"HubPage:18970\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Featured Stories\",\"slug\":\"featured-story\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false}]},{\"primaryCommunityGroup\":{\"name\":\"Front Page\",\"isInternal\":false},\"type\":\"STORY\",\"promoHeadline\":null,\"title\":\"The Super Mario Bros. Movie will start streaming on Peacock in August\",\"uid\":\"Entry:8456b308-a0ac-4844-bf16-f86cb7a1f218\",\"url\":\"https://www.theverge.com/23785874/super-mario-bros-movie-streaming-peacock-release-date\",\"author\":{\"fullName\":\"Jay Peters\"},\"leadImage\":{\"url\":\"https://cdn.vox-cdn.com/thumbor/WNo9YcHvd2BCv6jTN6UJ8kiuOSs=/0x0:3588x1500/3588x1500/filters:focal(1794x750:1795x751)/cdn.vox-cdn.com/uploads/chorus_asset/file/24706551/mario_bros_movie.jpg\",\"variantUrl\":\"https://cdn.vox-cdn.com/thumbor/HupHvV1rZGrUk38zeLKwp_YDJdM=/0x0:3588x1500/100x100/filters:focal(1794x750:1795x751)/cdn.vox-cdn.com/uploads/chorus_asset/file/24706551/mario_bros_movie.jpg\",\"asset\":{\"title\":\"An image showing Mario and Luigi in The Super Mario Bros. Movie\"},\"caption\":null},\"promoImage\":null,\"communityGroups\":[{\"name\":\"Front Page\",\"slug\":\"front-page\",\"hubPage\":{\"uid\":\"HubPage:270\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Gaming\",\"slug\":\"games\",\"hubPage\":{\"uid\":\"HubPage:276\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Entertainment\",\"slug\":\"entertainment\",\"hubPage\":{\"uid\":\"HubPage:8141\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Film\",\"slug\":\"film\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false},{\"name\":\"News\",\"slug\":\"news\",\"hubPage\":null,\"isInternal\":true,\"isStarred\":false},{\"name\":\"Tech\",\"slug\":\"tech\",\"hubPage\":{\"uid\":\"HubPage:8135\"},\"isInternal\":false,\"isStarred\":false}]},{\"primaryCommunityGroup\":{\"name\":\"Front Page\",\"isInternal\":false},\"type\":\"STORY\",\"promoHeadline\":null,\"title\":\"Honor 90 comes to Europe with a 200-megapixel camera and midrange price\",\"uid\":\"Entry:67359d6e-fbc8-491f-b586-1861ccee7876\",\"url\":\"https://www.theverge.com/2023/7/6/23785751/honor-90-global-launch-price-release-date-specs-features\",\"author\":{\"fullName\":\"Jon Porter\"},\"leadImage\":{\"url\":\"https://cdn.vox-cdn.com/thumbor/87putMn1ZyX8WJ3XhJ6ta-rLABg=/0x0:1620x1080/1620x1080/filters:focal(810x540:811x541)/cdn.vox-cdn.com/uploads/chorus_asset/file/24773043/H90_lifestyle_16x9__23_.jpg\",\"variantUrl\":\"https://cdn.vox-cdn.com/thumbor/6E_1Am9axLadKECiQV21NIHm950=/0x0:1620x1080/100x100/filters:focal(810x540:811x541)/cdn.vox-cdn.com/uploads/chorus_asset/file/24773043/H90_lifestyle_16x9__23_.jpg\",\"asset\":{\"title\":\"Models holding the Honor 90.\"},\"caption\":null},\"promoImage\":null,\"communityGroups\":[{\"name\":\"Front Page\",\"slug\":\"front-page\",\"hubPage\":{\"uid\":\"HubPage:270\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Gadgets\",\"slug\":\"gadgets\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false},{\"name\":\"Tech\",\"slug\":\"tech\",\"hubPage\":{\"uid\":\"HubPage:8135\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Huawei\",\"slug\":\"huawei\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false},{\"name\":\"News\",\"slug\":\"news\",\"hubPage\":null,\"isInternal\":true,\"isStarred\":false},{\"name\":\"Mobile\",\"slug\":\"mobile\",\"hubPage\":{\"uid\":\"HubPage:282\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Android\",\"slug\":\"android\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false},{\"name\":\"Google\",\"slug\":\"google\",\"hubPage\":{\"uid\":\"HubPage:274\"},\"isInternal\":false,\"isStarred\":false}]}]},\"type\":\"SITE_GROUP\"},{\"slug\":\"featured-story\",\"isInternal\":false,\"hubPage\":null,\"isDisclaimer\":false,\"description\":\"\",\"uid\":\"EntryGroup:63067\",\"name\":\"Featured Stories\",\"url\":\"https://www.theverge.com/featured-story\",\"isStarred\":false,\"recentEntries\":{\"results\":[{\"primaryCommunityGroup\":{\"name\":\"Front Page\",\"isInternal\":false},\"type\":\"STREAM\",\"promoHeadline\":null,\"title\":\"Instagram’s Threads: all the updates on the new Twitter competitor\",\"uid\":\"Entry:29993508-0271-4f0f-9027-037244bc2394\",\"url\":\"https://www.theverge.com/2023/7/5/23784480/threads-instagram-meta-news-twitter-competitor\",\"author\":{\"fullName\":\"Emma Roth\"},\"leadImage\":{\"url\":\"https://cdn.vox-cdn.com/thumbor/9_PDucpVjbtBIugl1ryeeBQXays=/0x0:700x600/700x600/filters:focal(350x300:351x301)/cdn.vox-cdn.com/uploads/chorus_asset/file/24771846/threads_logo.jpg\",\"variantUrl\":\"https://cdn.vox-cdn.com/thumbor/7UsMPDBuJmQb7eLibiILhZGFtZc=/0x0:700x600/100x100/filters:focal(350x300:351x301)/cdn.vox-cdn.com/uploads/chorus_asset/file/24771846/threads_logo.jpg\",\"asset\":{\"title\":\"An image showing the Threads logo on a black background\"},\"caption\":null},\"promoImage\":null,\"communityGroups\":[{\"name\":\"Front Page\",\"slug\":\"front-page\",\"hubPage\":{\"uid\":\"HubPage:270\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Meta\",\"slug\":\"meta\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false},{\"name\":\"Tech\",\"slug\":\"tech\",\"hubPage\":{\"uid\":\"HubPage:8135\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"News\",\"slug\":\"news\",\"hubPage\":null,\"isInternal\":true,\"isStarred\":false},{\"name\":\"Instagram\",\"slug\":\"instagram\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false},{\"name\":\"Twitter\",\"slug\":\"twitter\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false},{\"name\":\"Apps\",\"slug\":\"apps\",\"hubPage\":{\"uid\":\"HubPage:277\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Creators\",\"slug\":\"creators\",\"hubPage\":{\"uid\":\"HubPage:18970\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Featured Stories\",\"slug\":\"featured-story\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false}]},{\"primaryCommunityGroup\":{\"name\":\"Front Page\",\"isInternal\":false},\"type\":\"STORY\",\"promoHeadline\":null,\"title\":\"Why Instagram is taking on Twitter with Threads\",\"uid\":\"Entry:6f0bd737-de8e-47b6-8aa6-f22574c3e71d\",\"url\":\"https://www.theverge.com/2023/7/5/23784870/instagram-threads-adam-mosseri-interview-twitter-competitor\",\"author\":{\"fullName\":\"Alex Heath\"},\"leadImage\":{\"url\":\"https://cdn.vox-cdn.com/thumbor/QAb4WnQRXQi3xGe2E666HW3xNEU=/0x0:6000x3375/6000x3375/filters:focal(3000x1688:3001x1689)/cdn.vox-cdn.com/uploads/chorus_asset/file/24771646/Threads_screenshots.png\",\"variantUrl\":\"https://cdn.vox-cdn.com/thumbor/bEootwPnZoTPzvMHqzKDO8GK7cM=/0x0:6000x3375/100x100/filters:focal(3000x1688:3001x1689)/cdn.vox-cdn.com/uploads/chorus_asset/file/24771646/Threads_screenshots.png\",\"asset\":{\"title\":\"Screenshots of Meta’s Threads app.\"},\"caption\":null},\"promoImage\":null,\"communityGroups\":[{\"name\":\"Front Page\",\"slug\":\"front-page\",\"hubPage\":{\"uid\":\"HubPage:270\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Instagram\",\"slug\":\"instagram\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false},{\"name\":\"Meta\",\"slug\":\"meta\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false},{\"name\":\"Tech\",\"slug\":\"tech\",\"hubPage\":{\"uid\":\"HubPage:8135\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"News\",\"slug\":\"news\",\"hubPage\":null,\"isInternal\":true,\"isStarred\":false},{\"name\":\"Featured Stories\",\"slug\":\"featured-story\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false},{\"name\":\"Interview\",\"slug\":\"interview\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false},{\"name\":\"Twitter\",\"slug\":\"twitter\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false}]},{\"primaryCommunityGroup\":{\"name\":\"Front Page\",\"isInternal\":false},\"type\":\"STORY\",\"promoHeadline\":null,\"title\":\"The best fitness trackers to buy right now\",\"uid\":\"Entry:e10686a6-8083-47e5-a414-6929431f7219\",\"url\":\"https://www.theverge.com/22985108/best-fitness-tracker\",\"author\":{\"fullName\":\"Victoria Song\"},\"leadImage\":{\"url\":\"https://cdn.vox-cdn.com/thumbor/0u4uxAfNSkLRw34nNWlJatj1bI8=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/23336503/acastro_220321_5092_0001.jpg\",\"variantUrl\":\"https://cdn.vox-cdn.com/thumbor/MVqp_uzwj_nULic52mYdt34NH9s=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/23336503/acastro_220321_5092_0001.jpg\",\"asset\":{\"title\":null},\"caption\":null},\"promoImage\":null,\"communityGroups\":[{\"name\":\"Front Page\",\"slug\":\"front-page\",\"hubPage\":{\"uid\":\"HubPage:270\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Tech\",\"slug\":\"tech\",\"hubPage\":{\"uid\":\"HubPage:8135\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Wearable\",\"slug\":\"wearables\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false},{\"name\":\"Fitness\",\"slug\":\"fitness-trackers\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false},{\"name\":\"guidebook\",\"slug\":\"guidebook\",\"hubPage\":null,\"isInternal\":true,\"isStarred\":false},{\"name\":\"Fitness Tracker Reviews\",\"slug\":\"fitness-tracker-review\",\"hubPage\":{\"uid\":\"HubPage:15835\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Buying Guide\",\"slug\":\"this-is-my-next\",\"hubPage\":{\"uid\":\"HubPage:11570\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Featured Stories\",\"slug\":\"featured-story\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false}]},{\"primaryCommunityGroup\":{\"name\":\"Front Page\",\"isInternal\":false},\"type\":\"STORY\",\"promoHeadline\":null,\"title\":\"So where are we all supposed to go now?\",\"uid\":\"Entry:98a033e2-ba40-4f68-bc04-817d82e2e2b1\",\"url\":\"https://www.theverge.com/2023/7/3/23782607/social-web-public-apps-end-reddit-twitter-mastodon\",\"author\":{\"fullName\":\"David Pierce\"},\"leadImage\":{\"url\":\"https://cdn.vox-cdn.com/thumbor/IPe1BYkJmrelCmbhTnGkEQq_LPE=/0x0:4288x2848/4288x2848/filters:focal(2144x1424:2145x1425)/cdn.vox-cdn.com/uploads/chorus_asset/file/24767998/868706204.jpg\",\"variantUrl\":\"https://cdn.vox-cdn.com/thumbor/fiWi9uw4-T164JO4e_FjbhFmsbI=/0x0:4288x2848/100x100/filters:focal(2144x1424:2145x1425)/cdn.vox-cdn.com/uploads/chorus_asset/file/24767998/868706204.jpg\",\"asset\":{\"title\":\"A picture of a neon Like button on Facebook\"},\"caption\":null},\"promoImage\":null,\"communityGroups\":[{\"name\":\"Front Page\",\"slug\":\"front-page\",\"hubPage\":{\"uid\":\"HubPage:270\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Web\",\"slug\":\"web\",\"hubPage\":{\"uid\":\"HubPage:275\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Tech\",\"slug\":\"tech\",\"hubPage\":{\"uid\":\"HubPage:8135\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Twitter\",\"slug\":\"twitter\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false},{\"name\":\"Reddit\",\"slug\":\"reddit\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false},{\"name\":\"Snapchat\",\"slug\":\"snapchat\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false},{\"name\":\"Meta\",\"slug\":\"meta\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false},{\"name\":\"Featured Stories\",\"slug\":\"featured-story\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false}]},{\"primaryCommunityGroup\":{\"name\":\"Front Page\",\"isInternal\":false},\"type\":\"STORY\",\"promoHeadline\":null,\"title\":\"The best robot vacuum you can buy right now\",\"uid\":\"Entry:2c3eb6c5-d451-40a0-9ca9-0a11a2e934dd\",\"url\":\"https://www.theverge.com/22997597/best-robot-vacuum-cleaner\",\"author\":{\"fullName\":\"Jennifer Pattison Tuohy\"},\"leadImage\":{\"url\":\"https://cdn.vox-cdn.com/thumbor/eoyPd5OJ2gJ6S5uwqvCcgIEfD08=/0x0:2040x1360/2040x1360/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/24545661/Buying_Guide_Robot_vacuums_Roomba_H_Herrera_236591.jpg\",\"variantUrl\":\"https://cdn.vox-cdn.com/thumbor/Tb3Y9GxstMOrOyWDA81IJmpNA5A=/0x0:2040x1360/100x100/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/24545661/Buying_Guide_Robot_vacuums_Roomba_H_Herrera_236591.jpg\",\"asset\":{\"title\":null},\"caption\":null},\"promoImage\":null,\"communityGroups\":[{\"name\":\"Front Page\",\"slug\":\"front-page\",\"hubPage\":{\"uid\":\"HubPage:270\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Tech\",\"slug\":\"tech\",\"hubPage\":{\"uid\":\"HubPage:8135\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"guidebook\",\"slug\":\"guidebook\",\"hubPage\":null,\"isInternal\":true,\"isStarred\":false},{\"name\":\"Buying Guide\",\"slug\":\"this-is-my-next\",\"hubPage\":{\"uid\":\"HubPage:11570\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Smart Home\",\"slug\":\"smart-home\",\"hubPage\":{\"uid\":\"HubPage:279\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Smart Home Reviews\",\"slug\":\"smart-home-review\",\"hubPage\":{\"uid\":\"HubPage:15843\"},\"isInternal\":false,\"isStarred\":false},{\"name\":\"Featured Stories\",\"slug\":\"featured-story\",\"hubPage\":null,\"isInternal\":false,\"isStarred\":false}]}]},\"type\":\"SITE_GROUP\"}],\"primaryCommunityGroup\":{\"name\":\"Features\",\"slug\":\"features\",\"parentEntryGroup\":null,\"isInternal\":false},\"primaryPackageGroup\":null,\"liveCoverageStart\":null,\"__isEntryRevision\":\"Entry\",\"slug\":\"features/23764584/ai-artificial-intelligence-data-notation-labor-scale-surge-remotasks-openai-chatbots\",\"layoutTemplate\":\"HEADLINE_ABOVE__2\",\"styles\":\"\\nmain .md\\\\:hidden figure {\\n\\tbackground-image: url('https://cdn.vox-cdn.com/uploads/chorus_asset/file/24738362/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_Square_min.jpeg');\\n  background-position: center center;\\n  background-size: cover;\\n}\\n\\nmain .md\\\\:hidden figure img {\\n\\topacity: 0;\\n}\",\"seoSchema\":[{\"@context\":\"http://schema.org/\",\"@type\":\"NewsArticle\",\"headline\":\"Inside the AI Factory: the humans that make tech seem human\",\"description\":\"How many humans does it take to make tech seem human? Millions to support OpenAI, Google, Meta, and every other major tech company. As AI becomes ubiquitous, a vast tasker underclass is emerging — and not going anywhere.\",\"datePublished\":\"2023-06-20T12:05:00.000Z\",\"dateModified\":\"2023-06-20T12:05:00.000Z\",\"thumbnailUrl\":\"https://cdn.vox-cdn.com/thumbor/MFiURNjiF1enowJ5t0oyd0gkPlU=/0x0:2048x1365/1400x788/filters:focal(1024x683:1025x684)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg\",\"author\":[{\"@type\":\"Person\",\"name\":\"Josh Dzieza\",\"url\":\"https://www.theverge.com/authors/josh-dzieza\"}],\"publisher\":{\"@type\":\"Organization\",\"name\":\"The Verge\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https://cdn.vox-cdn.com/uploads/chorus_asset/file/24015294/verge_duet_google_news.png\",\"width\":250,\"height\":50}},\"image\":[{\"@type\":\"ImageObject\",\"url\":\"https://cdn.vox-cdn.com/thumbor/MFiURNjiF1enowJ5t0oyd0gkPlU=/0x0:2048x1365/1400x788/filters:focal(1024x683:1025x684)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg\",\"width\":1400,\"height\":788},{\"@type\":\"ImageObject\",\"url\":\"https://cdn.vox-cdn.com/thumbor/aD8beUZUaAWE-Xp9Nxghr39hEc8=/0x0:2048x1365/1400x1050/filters:focal(1024x683:1025x684)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg\",\"width\":1400,\"height\":1050},{\"@type\":\"ImageObject\",\"url\":\"https://cdn.vox-cdn.com/thumbor/3DumuHSwStBgrpK3v23C-ipMVRE=/0x0:2048x1365/1400x1400/filters:focal(1024x683:1025x684)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg\",\"width\":1400,\"height\":1400}],\"url\":\"https://www.theverge.com/features/23764584/ai-artificial-intelligence-data-notation-labor-scale-surge-remotasks-openai-chatbots\",\"articleBody\":\"This article is a collaboration between New York Magazine and The Verge.\\n\\n---\\n\\nA few months after graduating from college in Nairobi, a 30-year-old I’ll call Joe got a job as an annotator — the tedious work of processing the raw information used to train artificial intelligence. AI learns by finding patterns in enormous quantities of data, but first that data has to be sorted and tagged by people, a vast workforce mostly hidden behind the machines. In Joe’s case, he was labeling footage for self-driving cars — identifying every vehicle, pedestrian, cyclist, anything a driver needs to be aware of — frame by frame and from every possible camera angle. It’s difficult and repetitive work. A several-second blip of footage took eight hours to annotate, for which Joe was paid about $10.\\n\\nThen, in 2019, an opportunity arose: Joe could make four times as much running an annotation boot camp for a new company that was hungry for labelers. Every two weeks, 50 new recruits would file into an office building in Nairobi to begin their apprenticeships. There seemed to be limitless demand for the work. They would be asked to categorize clothing seen in mirror selfies, look through the eyes of robot vacuum cleaners to determine which rooms they were in, and draw squares around lidar scans of motorcycles. Over half of Joe’s students usually dropped out before the boot camp was finished. “Some people don’t know how to stay in one place for long,” he explained with gracious understatement. Also, he acknowledged, “it is very boring.”\\n\\n---\\n[Image: https://cdn.vox-cdn.com/thumbor/bqRhb5A3myLSYGiXMDOshxcrXCE=/0x0:2400x3000/2400x3000/filters:focal(1200x1500:1201x1501)/cdn.vox-cdn.com/uploads/chorus_asset/file/24734352/1323Cov4x5_AI_Factory.jpg]\\n\\nThis article is a collaboration between New York Magazine and The Verge.\\n---\\n\\nBut it was a job in a place where jobs were scarce, and Joe turned out hundreds of graduates. After boot camp, they went home to work alone in their bedrooms and kitchens, forbidden from telling anyone what they were working on, which wasn’t really a problem because they rarely knew themselves. Labeling objects for self-driving cars was obvious, but what about categorizing whether snippets of distorted dialogue were spoken by a robot or a human? Uploading photos of yourself staring into a webcam with a blank expression, then with a grin, then wearing a motorcycle helmet? Each project was such a small component of some larger process that it was difficult to say what they were actually training AI to do. Nor did the names of the projects offer any clues: Crab Generation, Whale Segment, Woodland Gyro, and Pillbox Bratwurst. They were non sequitur code names for non sequitur work.\\n\\nAs for the company employing them, most knew it only as Remotasks, a website offering work to anyone fluent in English. Like most of the annotators I spoke with, Joe was unaware until I told him that Remotasks is the worker-facing subsidiary of a company called Scale AI, a multibillion-dollar Silicon Valley data vendor that counts OpenAI and the U.S. military among its customers. Neither Remotasks’ or Scale’s website mentions the other.\\n\\nMuch of the public response to language models like OpenAI’s ChatGPT has focused on all the jobs they appear poised to automate. But behind even the most impressive AI system are people — huge numbers of people labeling data to train it and clarifying data when it gets confused. Only the companies that can afford to buy this data can compete, and those that get it are highly motivated to keep it secret. The result is that, with few exceptions, little is known about the information shaping these systems’ behavior, and even less is known about the people doing the shaping.\\n\\nFor Joe’s students, it was work stripped of all its normal trappings: a schedule, colleagues, knowledge of what they were working on or whom they were working for. In fact, they rarely called it work at all — just “tasking.” They were taskers.\\n\\nThe anthropologist David Graeber defines “bullshit jobs” as employment without meaning or purpose, work that should be automated but for reasons of bureaucracy or status or inertia is not. These AI jobs are their bizarro twin: work that people want to automate, and often think is already automated, yet still requires a human stand-in. The jobs have a purpose; it’s just that workers often have no idea what it is.\\n\\n---\\n\\nThe current AI boom — the convincingly human-sounding chatbots, the artwork that can be generated from simple prompts, and the multibillion-dollar valuations of the companies behind these technologies — began with an unprecedented feat of tedious and repetitive labor.\\n\\nIn 2007, the AI researcher Fei-Fei Li, then a professor at Princeton, suspected the key to improving image-recognition neural networks, a method of machine learning that had been languishing for years, was training on more data — millions of labeled images rather than tens of thousands. The problem was that it would take decades and millions of dollars for her team of undergrads to label that many photos.\\n\\nLi found thousands of workers on Mechanical Turk, Amazon’s crowdsourcing platform where people around the world complete small tasks for cheap. The resulting annotated dataset, called ImageNet, enabled breakthroughs in machine learning that revitalized the field and ushered in a decade of progress.\\n\\nAnnotation remains a foundational part of making AI, but there is often a sense among engineers that it’s a passing, inconvenient prerequisite to the more glamorous work of building models. You collect as much labeled data as you can get as cheaply as possible to train your model, and if it works, at least in theory, you no longer need the annotators. But annotation is never really finished. Machine-learning systems are what researchers call “brittle,” prone to fail when encountering something that isn’t well represented in their training data. These failures, called “edge cases,” can have serious consequences. In 2018, an Uber self-driving test car killed a woman because, though it was programmed to avoid cyclists and pedestrians, it didn’t know what to make of someone walking a bike across the street. The more AI systems are put out into the world to dispense legal advice and medical help, the more edge cases they will encounter and the more humans will be needed to sort them. Already, this has given rise to a global industry staffed by people like Joe who use their uniquely human faculties to help the machines.\\n\\n\\\"Is that a red shirt with white stripes or a white shirt with red stripes? Is a wicker bowl a “decorative bowl” if it’s full of apples? What color is leopard print?\\\"\\n\\nOver the past six months, I spoke with more than two dozen annotators from around the world, and while many of them were training cutting-edge chatbots, just as many were doing the mundane manual labor required to keep AI running. There are people classifying the emotional content of TikTok videos, new variants of email spam, and the precise sexual provocativeness of online ads. Others are looking at credit-card transactions and figuring out what sort of purchase they relate to or checking e-commerce recommendations and deciding whether that shirt is really something you might like after buying that other shirt. Humans are correcting customer-service chatbots, listening to Alexa requests, and categorizing the emotions of people on video calls. They are labeling food so that smart refrigerators don’t get confused by new packaging, checking automated security cameras before sounding alarms, and identifying corn for baffled autonomous tractors.\\n\\n“There’s an entire supply chain,” said Sonam Jindal, the program and research lead of the nonprofit Partnership on AI. “The general perception in the industry is that this work isn’t a critical part of development and isn’t going to be needed for long. All the excitement is around building artificial intelligence, and once we build that, it won’t be needed anymore, so why think about it? But it’s infrastructure for AI. Human intelligence is the basis of artificial intelligence, and we need to be valuing these as real jobs in the AI economy that are going to be here for a while.”\\n\\nThe data vendors behind familiar names like OpenAI, Google, and Microsoft come in different forms. There are private outsourcing companies with call-center-like offices, such as the Kenya- and Nepal-based CloudFactory, where Joe annotated for $1.20 an hour before switching to Remotasks. There are also “crowdworking” sites like Mechanical Turk and Clickworker where anyone can sign up to perform tasks. In the middle are services like Scale AI. Anyone can sign up, but everyone has to pass qualification exams and training courses and undergo performance monitoring. Annotation is big business. Scale, founded in 2016 by then-19-year-old Alexandr Wang, was valued in 2021 at $7.3 billion, making him what Forbes called “the youngest self-made billionaire,” though the magazine noted in a recent profile that his stake has fallen on secondary markets since then.\\n\\n[Image: https://cdn.vox-cdn.com/thumbor/tzXNAIWOaBlv7KbHabZQPNgOKvU=/0x0:2048x1500/2048x1500/filters:focal(1024x750:1025x751)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg]\\n\\nThis tangled supply chain is deliberately hard to map. According to people in the industry, the companies buying the data demand strict confidentiality. (This is the reason Scale cited to explain why Remotasks has a different name.) Annotation reveals too much about the systems being developed, and the huge number of workers required makes leaks difficult to prevent. Annotators are warned repeatedly not to tell anyone about their jobs, not even their friends and co-workers, but corporate aliases, project code names, and, crucially, the extreme division of labor ensure they don’t have enough information about them to talk even if they wanted to. (Most workers requested pseudonyms for fear of being booted from the platforms.) Consequently, there are no granular estimates of the number of people who work in annotation, but it is a lot, and it is growing. A recent Google Research paper gave an order-of-magnitude figure of “millions” with the potential to become “billions.”\\n\\nAutomation often unfolds in unexpected ways. Erik Duhaime, CEO of medical-data-annotation company Centaur Labs, recalled how, several years ago, prominent machine-learning engineers were predicting AI would make the job of radiologist obsolete. When that didn’t happen, conventional wisdom shifted to radiologists using AI as a tool. Neither of those is quite what he sees occurring. AI is very good at specific tasks, Duhaime said, and that leads work to be broken up and distributed across a system of specialized algorithms and to equally specialized humans. An AI system might be capable of spotting cancer, he said, giving a hypothetical example, but only in a certain type of imagery from a certain type of machine; so now, you need a human to check that the AI is being fed the right type of data and maybe another human who checks its work before passing it to another AI that writes a report, which goes to another human, and so on. “AI doesn’t replace work,” he said. “But it does change how work is organized.”\\n\\nYou might miss this if you believe AI is a brilliant, thinking machine. But if you pull back the curtain even a little, it looks more familiar, the latest iteration of a particularly Silicon Valley division of labor, in which the futuristic gleam of new technologies hides a sprawling manufacturing apparatus and the people who make it run. Duhaime reached back farther for a comparison, a digital version of the transition from craftsmen to industrial manufacturing: coherent processes broken into tasks and arrayed along assembly lines with some steps done by machines and some by humans but none resembling what came before.\\n\\nWorries about AI-driven disruption are often countered with the argument that AI automates tasks, not jobs, and that these tasks will be the dull ones, leaving people to pursue more fulfilling and human work. But just as likely, the rise of AI will look like past labor-saving technologies, maybe like the telephone or typewriter, which vanquished the drudgery of message delivering and handwriting but generated so much new correspondence, commerce, and paperwork that new offices staffed by new types of workers — clerks, accountants, typists — were required to manage it. When AI comes for your job, you may not lose it, but it might become more alien, more isolating, more tedious.\\n\\n---\\n\\nEarlier this year, I signed up for Scale AI’s Remotasks. The process was straightforward. After entering my computer specs, internet speed, and some basic contact information, I found myself in the “training center.” To access a paying task, I first had to complete an associated (unpaid) intro course.\\n\\nThe training center displayed a range of courses with inscrutable names like Glue Swimsuit and Poster Macadamia. I clicked on something called GFD Chunking, which revealed itself to be labeling clothing in social-media photos.\\n\\nThe instructions, however, were odd. For one, they basically consisted of the same direction reiterated in the idiosyncratically colored and capitalized typography of a collaged bomb threat.\\n\\n“DO LABEL items that are real and can be worn by humans or are intended to be worn by real people,” it read.\\n\\n“All items below SHOULD be labeled because they are real and can be worn by real-life humans,” it reiterated above photos of an Air Jordans ad, someone in a Kylo Ren helmet, and mannequins in dresses, over which was a lime-green box explaining, once again, “DO Label real items that can be worn by real people.”\\n\\n[Image: Remotasks instructions for labeling clothing. https://cdn.vox-cdn.com/thumbor/MHHrTeYM1ECpMGl9kVhgPdVy6QM=/0x0:2083x2083/2083x2083/filters:focal(1042x1042:1043x1043)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg]\\n\\nI skimmed to the bottom of the manual, where the instructor had written in the large bright-red font equivalent of grabbing someone by the shoulders and shaking them, “THE FOLLOWING ITEMS SHOULD NOT BE LABELED because a human could not actually put wear any of these items!” above a photo of C-3PO, Princess Jasmine from Aladdin, and a cartoon shoe with eyeballs.\\n\\nFeeling confident in my ability to distinguish between real clothes that can be worn by real people and not-real clothes that cannot, I proceeded to the test. Right away, it threw an ontological curveball: a picture of a magazine depicting photos of women in dresses. Is a photograph of clothing real clothing? No, I thought, because a human cannot wear a photograph of clothing. Wrong! As far as AI is concerned, photos of real clothes are real clothes. Next came a photo of a woman in a dimly lit bedroom taking a selfie before a full-length mirror. The blouse and shorts she’s wearing are real. What about their reflection? Also real! Reflections of real clothes are also real clothes.\\n\\nAfter an embarrassing amount of trial and error, I made it to the actual work, only to make the horrifying discovery that the instructions I’d been struggling to follow had been updated and clarified so many times that they were now a full 43 printed pages of directives: Do NOT label open suitcases full of clothes; DO label shoes but do NOT label flippers; DO label leggings but do NOT label tights; do NOT label towels even if someone is wearing it; label costumes but do NOT label armor. And so on.\\n\\nThere has been general instruction disarray across the industry, according to Milagros Miceli, a researcher at the Weizenbaum Institute in Germany who studies data work. It is in part a product of the way machine-learning systems learn. Where a human would get the concept of “shirt” with a few examples, machine-learning programs need thousands, and they need to be categorized with perfect consistency yet varied enough (polo shirts, shirts being worn outdoors, shirts hanging on a rack) that the very literal system can handle the diversity of the real world. “Imagine simplifying complex realities into something that is readable for a machine that is totally dumb,” she said.\\n\\n\\\"Once, Victor stayed up 36 hours straight labeling elbows and knees and heads in photographs of crowds — he has no idea why.\\\"\\n\\nThe act of simplifying reality for a machine results in a great deal of complexity for the human. Instruction writers must come up with rules that will get humans to categorize the world with perfect consistency. To do so, they often create categories no human would use. A human asked to tag all the shirts in a photo probably wouldn’t tag the reflection of a shirt in a mirror because they would know it is a reflection and not real. But to the AI, which has no understanding of the world, it’s all just pixels and the two are perfectly identical. Fed a dataset with some shirts labeled and other (reflected) shirts unlabeled, the model won’t work. So the engineer goes back to the vendor with an update: DO label reflections of shirts. Soon, you have a 43-page guide descending into red all-caps.\\n\\n“When you start off, the rules are relatively simple,” said a former Scale employee who requested anonymity because of an NDA. “Then they get back a thousand images and then they’re like, Wait a second, and then you have multiple engineers and they start to argue with each other. It’s very much a human thing.”\\n\\nThe job of the annotator often involves putting human understanding aside and following instructions very, very literally — to think, as one annotator said, like a robot. It’s a strange mental space to inhabit, doing your best to follow nonsensical but rigorous rules, like taking a standardized test while on hallucinogens. Annotators invariably end up confronted with confounding questions like, Is that a red shirt with white stripes or a white shirt with red stripes? Is a wicker bowl a “decorative bowl” if it’s full of apples? What color is leopard print? When instructors said to label traffic-control directors, did they also mean to label traffic-control directors eating lunch on the sidewalk? Every question must be answered, and a wrong guess could get you banned and booted to a new, totally different task with its own baffling rules.\\n\\n[Image: https://cdn.vox-cdn.com/thumbor/kQBljfwrhkJGYtW8XWVY30BSM1k=/0x0:2048x1737/2048x1737/filters:focal(1024x869:1025x870)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg]\\n\\nMost of the work on Remotasks is paid at a piece rate with a single task earning anywhere from a few cents to several dollars. Because tasks can take seconds or hours, wages are hard to predict. When Remotasks first arrived in Kenya, annotators said it paid relatively well — averaging about $5 to $10 per hour depending on the task — but the amount fell as time went on.\\n\\nScale AI spokesperson Anna Franko said that the company’s economists analyze the specifics of a project, the skills required, the regional cost of living, and other factors “to ensure fair and competitive compensation.” Former Scale employees also said pay is determined through a surge-pricing-like mechanism that adjusts for how many annotators are available and how quickly the data is needed.\\n\\nAccording to workers I spoke with and job listings, U.S.-based Remotasks annotators generally earn between $10 and $25 per hour, though some subject-matter experts can make more. By the beginning of this year, pay for the Kenyan annotators I spoke with had dropped to between $1 and $3 per hour.\\n\\nThat is, when they were making any money at all. The most common complaint about Remotasks work is its variability; it’s steady enough to be a full-time job for long stretches but too unpredictable to rely on. Annotators spend hours reading instructions and completing unpaid trainings only to do a dozen tasks and then have the project end. There might be nothing new for days, then, without warning, a totally different task appears and could last anywhere from a few hours to weeks. Any task could be their last, and they never know when the next one will come.\\n\\nThis boom-and-bust cycle results from the cadence of AI development, according to engineers and data vendors. Training a large model requires an enormous amount of annotation followed by more iterative updates, and engineers want it all as fast as possible so they can hit their target launch date. There may be monthslong demand for thousands of annotators, then for only a few hundred, then for a dozen specialists of a certain type, and then thousands again. “The question is, Who bears the cost for these fluctuations?” said Jindal of Partnership on AI. “Because right now, it’s the workers.”\\n\\n\\\"“I really am wasting my life here if I made somebody a billionaire and I’m earning a couple of bucks a week.”\\\"\\n\\nTo succeed, annotators work together. When I told Victor, who started working for Remotasks while at university in Nairobi, about my struggles with the traffic-control-directors task, he told me everyone knew to stay away from that one: too tricky, bad pay, not worth it. Like a lot of annotators, Victor uses unofficial WhatsApp groups to spread the word when a good task drops. When he figures out a new one, he starts impromptu Google Meets to show others how it’s done. Anyone can join and work together for a time, sharing tips. “It’s a culture we have developed of helping each other because we know when on your own, you can’t know all the tricks,” he said.\\n\\nBecause work appears and vanishes without warning, taskers always need to be on alert. Victor has found that projects pop up very late at night, so he is in the habit of waking every three hours or so to check his queue. When a task is there, he’ll stay awake as long as he can to work. Once, he stayed up 36 hours straight labeling elbows and knees and heads in photographs of crowds — he has no idea why. Another time, he stayed up so long his mother asked him what was wrong with his eyes. He looked in the mirror to discover they were swollen.\\n\\nAnnotators generally know only that they are training AI for companies located vaguely elsewhere, but sometimes the veil of anonymity drops — instructions mentioning a brand or a chatbot say too much. “I read and I Googled and found I am working for a 25-year-old billionaire,” said one worker, who, when we spoke, was labeling the emotions of people calling to order Domino’s pizza. “I really am wasting my life here if I made somebody a billionaire and I’m earning a couple of bucks a week.”\\n\\nVictor is a self-proclaimed “fanatic” about AI and started annotating because he wants to help bring about a fully automated post-work future. But earlier this year, someone dropped a Time story into one of his WhatsApp groups about workers training ChatGPT to recognize toxic content who were getting paid less than $2 an hour by the vendor Sama AI. “People were angry that these companies are so profitable but paying so poorly,” Victor said. He was unaware until I told him about Remotasks’ connection to Scale. Instructions for one of the tasks he worked on were nearly identical to those used by OpenAI, which meant he had likely been training ChatGPT as well, for approximately $3 per hour.\\n\\n“I remember that someone posted that we will be remembered in the future,” he said. “And somebody else replied, ‘We are being treated worse than foot soldiers. We will be remembered nowhere in the future.’ I remember that very well. Nobody will recognize the work we did or the effort we put in.”\\n\\n---\\n\\nIdentifying clothing and labeling customer-service conversations are just some of the annotation gigs available. Lately, the hottest on the market has been chatbot trainer. Because it demands specific areas of expertise or language fluency and wages are often adjusted regionally, this job tends to pay better. Certain types of specialist annotation can go for $50 or more per hour.\\n\\nA woman I’ll call Anna was searching for a job in Texas when she stumbled across a generic listing for online work and applied. It was Remotasks, and after passing an introductory exam, she was brought into a Slack room of 1,500 people who were training a project code-named Dolphin, which she later discovered to be Google DeepMind’s chatbot, Sparrow, one of the many bots competing with ChatGPT. Her job is to talk with it all day. At about $14 an hour, plus bonuses for high productivity, “it definitely beats getting paid $10 an hour at the local Dollar General store,” she said.\\n\\nAlso, she enjoys it. She has discussed science-fiction novels, mathematical paradoxes, children’s riddles, and TV shows. Sometimes the bot’s responses make her laugh; other times, she runs out of things to talk about. “Some days, my brain is just like, I literally have no idea what on earth to ask it now,” she said. “So I have a little notebook, and I’ve written about two pages of things — I just Google interesting topics — so I think I’ll be good for seven hours today, but that’s not always the case.”\\n\\nEach time Anna prompts Sparrow, it delivers two responses and she picks the best one, thereby creating something called “human-feedback data.” When ChatGPT debuted late last year, its impressively natural-seeming conversational style was credited to its having been trained on troves of internet data. But the language that fuels ChatGPT and its competitors is filtered through several rounds of human annotation. One group of contractors writes examples of how the engineers want the bot to behave, creating questions followed by correct answers, descriptions of computer programs followed by functional code, and requests for tips on committing crimes followed by polite refusals. After the model is trained on these examples, yet more contractors are brought in to prompt it and rank its responses. This is what Anna is doing with Sparrow. Exactly which criteria the raters are told to use varies — honesty, or helpfulness, or just personal preference. The point is that they are creating data on human taste, and once there’s enough of it, engineers can train a second model to mimic their preferences at scale, automating the ranking process and training their AI to act in ways humans approve of. The result is a remarkably human-seeming bot that mostly declines harmful requests and explains its AI nature with seeming self-awareness.\\n\\nPut another way, ChatGPT seems so human because it was trained by an AI that was mimicking humans who were rating an AI that was mimicking humans who were pretending to be a better version of an AI that was trained on human writing.\\n\\n[Image: https://cdn.vox-cdn.com/thumbor/BJ1voW9GJtnRC0ZSvYAl9KHBH-c=/0x0:2048x1514/2048x1514/filters:focal(1024x757:1025x758)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg]\\n\\nThis circuitous technique is called “reinforcement learning from human feedback,” or RLHF, and it’s so effective that it’s worth pausing to fully register what it doesn’t do. When annotators teach a model to be accurate, for example, the model isn’t learning to check answers against logic or external sources or about what accuracy as a concept even is. The model is still a text-prediction machine mimicking patterns in human writing, but now its training corpus has been supplemented with bespoke examples, and the model has been weighted to favor them. Maybe this results in the model extracting patterns from the part of its linguistic map labeled as accurate and producing text that happens to align with the truth, but it can also result in it mimicking the confident style and expert jargon of the accurate text while writing things that are totally wrong. There is no guarantee that the text the labelers marked as accurate is in fact accurate, and when it is, there is no guarantee that the model learns the right patterns from it.\\n\\nThis dynamic makes chatbot annotation a delicate process. It has to be rigorous and consistent because sloppy feedback, like marking material that merely sounds correct as accurate, risks training models to be even more convincing bullshitters. An early OpenAI and DeepMind joint project using RLHF, in this case to train a virtual robot hand to grab an item, resulted in also training the robot to position its hand between the object and its raters and wiggle around such that it only appeared to its human overseers to grab the item. Ranking a language model’s responses is always going to be somewhat subjective because it’s language. A text of any length will have multiple elements that could be right or wrong or, taken together, misleading. OpenAI researchers ran into this obstacle in another early RLHF paper. Trying to get their model to summarize text, the researchers found they agreed only 60 percent of the time that a summary was good. “Unlike many tasks in [machine learning] our queries do not have unambiguous ground truth,” they lamented.\\n\\nWhen Anna rates Sparrow’s responses, she’s supposed to be looking at their accuracy, helpfulness, and harmlessness while also checking that the model isn’t giving medical or financial advice or anthropomorphizing itself or running afoul of other criteria. To be useful training data, the model’s responses have to be quantifiably ranked against one another: Is a bot that helpfully tells you how to make a bomb “better” than a bot that’s so harmless it refuses to answer any questions? In one DeepMind paper, when Sparrow’s makers took a turn annotating, four researchers wound up debating whether their bot had assumed the gender of a user who asked it for relationship advice. According to Geoffrey Irving, one of DeepMind’s research scientists, the company’s researchers hold weekly annotation meetings in which they rerate data themselves and discuss ambiguous cases, consulting with ethical or subject-matter experts when a case is particularly tricky.\\n\\n\\\"There are people classifying the emotional content of TikTok videos, new variants of email spam, and the precise sexual provocativeness of online ads.\\\"\\n\\nAnna often finds herself having to choose between two bad options. “Even if they’re both absolutely, ridiculously wrong, you still have to figure out which one is better and then write words explaining why,” she said. Sometimes, when both responses are bad, she’s encouraged to write a better response herself, which she does about half the time.\\n\\nBecause feedback data is difficult to collect, it fetches a higher price. Basic preferences of the sort Anna is producing sell for about $1 each, according to people with knowledge of the industry. But if you want to train a model to do legal research, you need someone with training in law, and this gets expensive. Everyone involved is reluctant to say how much they’re spending, but in general, specialized written examples can go for hundreds of dollars, while expert ratings can cost $50 or more. One engineer told me about buying examples of Socratic dialogues for up to $300 a pop. Another told me about paying $15 for a “darkly funny limerick about a goldfish.”\\n\\nOpenAI, Microsoft, Meta, and Anthropic did not comment about how many people contribute annotations to their models, how much they are paid, or where in the world they are located. Irving of DeepMind, which is a subsidiary of Google, said the annotators working on Sparrow are paid “at least the hourly living wage” based on their location. Anna knows “absolutely nothing” about Remotasks, but Sparrow has been more open. She wasn’t the only annotator I spoke with who got more information from the AI they were training than from their employer; several others learned whom they were working for by asking their AI for its company’s terms of service. “I literally asked it, ‘What is your purpose, Sparrow?’” Anna said. It pulled up a link to DeepMind’s website and explained that it’s an AI assistant and that its creators trained it using RLHF to be helpful and safe.\\n\\n---\\n\\nUntil recently, it was relatively easy to spot bad output from a language model. It looked like gibberish. But this gets harder as the models get better — a problem called “scalable oversight.” Google inadvertently demonstrated how hard it is to catch the errors of a modern-language model when one made it into the splashy debut of its AI assistant, Bard. (It stated confidently that the James Webb Space Telescope “took the very first pictures of a planet outside of our own solar system,” which is wrong.) This trajectory means annotation increasingly requires specific skills and expertise.\\n\\nLast year, someone I’ll call Lewis was working on Mechanical Turk when, after completing a task, he received a message inviting him to apply for a platform he hadn’t heard of. It was called Taskup.ai, and its website was remarkably basic: just a navy background with text reading GET PAID FOR TASKS ON DEMAND. He applied.\\n\\nThe work paid far better than anything he had tried before, often around $30 an hour. It was more challenging, too: devising complex scenarios to trick chatbots into giving dangerous advice, testing a model’s ability to stay in character, and having detailed conversations about scientific topics so technical they required extensive research. He found the work “satisfying and stimulating.” While checking one model’s attempts to code in Python, Lewis was learning too. He couldn’t work for more than four hours at a stretch, lest he risk becoming mentally drained and making mistakes, and he wanted to keep the job.\\n\\n“If there was one thing I could change, I would just like to have more information about what happens on the other end,” he said. “We only know as much as we need to know to get work done, but if I could know more, then maybe I could get more established and perhaps pursue this as a career.”\\n\\nI spoke with eight other workers, most based in the U.S., who had similar experiences of answering surveys or completing tasks on other platforms and finding themselves recruited for Taskup.ai or several similarly generic sites, such as DataAnnotation.tech or Gethybrid.io. Often their work involved training chatbots, though with higher-quality expectations and more specialized purposes than other sites they had worked for. One was demonstrating spreadsheet macros. Another was just supposed to have conversations and rate responses according to whatever criteria she wanted. She often asked the chatbot things that had come up in conversations with her 7-year-old daughter, like “What is the largest dinosaur?” and “Write a story about a tiger.” “I haven’t fully gotten my head around what they’re trying to do with it,” she told me.\\n\\nTaskup.ai, DataAnnotation.tech, and Gethybrid.io all appear to be owned by the same company: Surge AI. Its CEO, Edwin Chen, would neither confirm nor deny the connection, but he was willing to talk about his company and how he sees annotation evolving.\\n\\n“I’ve always felt the annotation landscape is overly simplistic,” Chen said over a video call from Surge’s office. He founded Surge in 2020 after working on AI at Google, Facebook, and Twitter convinced him that crowdsourced labeling was inadequate. “We want AI to tell jokes or write really good marketing copy or help me out when I need therapy or whatnot,” Chen said. “You can’t ask five people to independently come up with a joke and combine it into a majority answer. Not everybody can tell a joke or solve a Python program. The annotation landscape needs to shift from this low-quality, low-skill mind-set to something that’s much richer and captures the range of human skills and creativity and values that we want AI systems to possess.”\\n\\n[Image: https://cdn.vox-cdn.com/thumbor/Qe4htQ4VivRXnS0BWZowjTY8hE8=/0x0:2048x1572/2048x1572/filters:focal(1024x786:1025x787)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg]\\n\\nLast year, Surge relabeled Google’s dataset classifying Reddit posts by emotion. Google had stripped each post of context and sent them to workers in India for labeling. Surge employees familiar with American internet culture found that 30 percent of the labels were wrong. Posts like “hell yeah my brother” had been classified as annoyance and “Yay, cold McDonald’s. My favorite” as love.\\n\\nSurge claims to vet its workers for qualifications — that people doing creative-writing tasks have experience with creative writing, for example — but exactly how Surge finds workers is “proprietary,” Chen said. As with Remotasks, workers often have to complete training courses, though unlike Remotasks, they are paid for it, according to the annotators I spoke with. Having fewer, better-trained workers producing higher-quality data allows Surge to compensate better than its peers, Chen said, though he declined to elaborate, saying only that people are paid “fair and ethical wages.” The workers I spoke with earned between $15 and $30 per hour, but they are a small sample of all the annotators, a group Chen said now consists of 100,000 people. The secrecy, he explained, stems from clients’ demands for confidentiality.\\n\\nSurge’s customers include OpenAI, Google, Microsoft, Meta, and Anthropic. Surge specializes in feedback and language annotation, and after ChatGPT launched, it got an influx of requests, Chen said: “I thought everybody knew the power of RLHF, but I guess people just didn’t viscerally understand.”\\n\\nThe new models are so impressive they’ve inspired another round of predictions that annotation is about to be automated. Given the costs involved, there is significant financial pressure to do so. Anthropic, Meta, and other companies have recently made strides in using AI to drastically reduce the amount of human annotation needed to guide models, and other developers have started using GPT-4 to generate training data. However, a recent paper found that GPT-4-trained models may be learning to mimic GPT’s authoritative style with even less accuracy, and so far, when improvements in AI have made one form of annotation obsolete, demand for other, more sophisticated types of labeling has gone up. This debate spilled into the open earlier this year, when Scale’s CEO, Wang, tweeted that he predicted AI labs will soon be spending as many billions of dollars on human data as they do on computing power; OpenAI’s CEO, Sam Altman, responded that data needs will decrease as AI improves.\\n\\n\\\"“I mean, what it can do is amazing,” she said of the chatbot. “But it still does some really weird shit.”\\\"\\n\\nChen is skeptical AI will reach a point where human feedback is no longer needed, but he does see annotation becoming more difficult as models improve. Like many researchers, he believes the path forward will involve AI systems helping humans oversee other AI. Surge recently collaborated with Anthropic on a proof of concept, having human labelers answer questions about a lengthy text with the help of an unreliable AI assistant, on the theory that the humans would have to feel out the weaknesses of their AI assistant and collaborate to reason their way to the correct answer. Another possibility has two AIs debating each other and a human rendering the final verdict on which is correct. “We still have yet to see really good practical implementations of this stuff, but it’s starting to become necessary because it’s getting really hard for labelers to keep up with the models,” said OpenAI research scientist John Schulman in a recent talk at Berkeley.\\n\\n“I think you always need a human to monitor what AIs are doing just because they are this kind of alien entity,” Chen said. Machine-learning systems are just too strange ever to fully trust. The most impressive models today have what, to a human, seems like bizarre weaknesses, he added, pointing out that though GPT-4 can generate complex and convincing prose, it can’t pick out which words are adjectives: “Either that or models get so good that they’re better than humans at all things, in which case, you reach your utopia and who cares?”\\n\\n---\\n\\nAs 2022 ended, Joe started hearing from his students that their task queues were often empty. Then he got an email informing him the boot camps in Kenya were closing. He continued training taskers online, but he began to worry about the future.\\n\\n“There were signs that it was not going to last long,” he said. Annotation was leaving Kenya. From colleagues he had met online, he heard tasks were going to Nepal, India, and the Philippines. “The companies shift from one region to another,” Joe said. “They don’t have infrastructure locally, so it makes them flexible to shift to regions that favor them in terms of operation cost.”\\n\\nOne way the AI industry differs from manufacturers of phones and cars is in its fluidity. The work is constantly changing, constantly getting automated away and replaced with new needs for new types of data. It’s an assembly line but one that can be endlessly and instantly reconfigured, moving to wherever there is the right combination of skills, bandwidth, and wages.\\n\\nLately, the best-paying work is in the U.S. In May, Scale started listing annotation jobs on its own website, soliciting people with experience in practically every field AI is predicted to conquer. There were listings for AI trainers with expertise in health coaching, human resources, finance, economics, data science, programming, computer science, chemistry, biology, accounting, taxes, nutrition, physics, travel, K-12 education, sports journalism, and self-help. You can make $45 an hour teaching robots law or make $25 an hour teaching them poetry. There were also listings for people with security clearance, presumably to help train military AI. Scale recently launched a defense-oriented language model called Donovan, which Wang called “ammunition in the AI war,” and won a contract to work on the Army’s robotic-combat-vehicle program.\\n\\nAnna is still training chatbots in Texas. Colleagues have been turned into reviewers and Slack admins — she isn’t sure why, but it has given her hope that the gig could be a longer-term career. One thing she isn’t worried about is being automated out of a job. “I mean, what it can do is amazing,” she said of the chatbot. “But it still does some really weird shit.”\\n\\nWhen Remotasks first arrived in Kenya, Joe thought annotation could be a good career. Even after the work moved elsewhere, he was determined to make it one. There were thousands of people in Nairobi who knew how to do the work, he reasoned — he had trained many of them, after all. Joe rented office space in the city and began sourcing contracts: a job annotating blueprints for a construction company, another labeling fruits despoiled by insects for some sort of agricultural project, plus the usual work of annotating for self-driving cars and e-commerce.\\n\\nBut he has found his vision difficult to achieve. He has just one full-time employee, down from two. “We haven’t been having a consistent flow of work,” he said. There are weeks with nothing to do because customers are still collecting data, and when they’re done, he has to bring in short-term contractors to meet their deadlines: “Clients don’t care whether we have consistent work or not. So long as the datasets have been completed, then that’s the end of that.”\\n\\nRather than let their skills go to waste, other taskers decided to chase the work wherever it went. They rented proxy servers to disguise their locations and bought fake IDs to pass security checks so they could pretend to work from Singapore, the Netherlands, Mississippi, or wherever the tasks were flowing. It’s a risky business. Scale has become increasingly aggressive about suspending accounts caught disguising their location, according to multiple taskers. It was during one of these crackdowns that my account got banned, presumably because I had been using a VPN to see what workers in other countries were seeing, and all $1.50 or so of my earnings were seized.\\n\\n“These days, we have become a bit cunning because we noticed that in other countries they are paying well,” said Victor, who was earning double the Kenyan rate by tasking in Malaysia. “You do it cautiously.”\\n\\nAnother Kenyan annotator said that after his account got suspended for mysterious reasons, he decided to stop playing by the rules. Now, he runs multiple accounts in multiple countries, tasking wherever the pay is best. He works fast and gets high marks for quality, he said, thanks to ChatGPT. The bot is wonderful, he said, letting him speed through $10 tasks in a matter of minutes. When we spoke, he was having it rate another chatbot’s responses according to seven different criteria, one AI training the other.\\n\"}],\"leadComponent\":{\"__typename\":\"EntryLeadImage\",\"standard\":{\"hideCredit\":true,\"asset\":{\"title\":null},\"caption\":null,\"credit\":{\"html\":\"Illustration by Richard Parry for The Verge\"},\"variantUrl\":\"https://cdn.vox-cdn.com/thumbor/REc1pI-ZrFoiN3zTjwMYryssndo=/0x0:2048x1365/2000x1333/filters:focal(1024x683:1025x684)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg\"},\"square\":{\"hideCredit\":true,\"asset\":{\"title\":null},\"caption\":null,\"credit\":{\"html\":\"Illustration by Richard Parry for The Verge\"},\"variantUrl\":\"https://cdn.vox-cdn.com/thumbor/lrxf8x5NH8TXj35jUviyBm5xFic=/0x0:2048x1365/1000x1000/filters:focal(1024x683:1025x684)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg\"},\"standardBg\":{\"hideCredit\":true,\"asset\":{\"title\":null},\"caption\":null,\"credit\":{\"html\":\"Illustration by Richard Parry for The Verge\"},\"variantUrl\":\"https://cdn.vox-cdn.com/thumbor/EfzwZ-oj_FNz0PHVog2_JcLL3sc=/0x0:2048x1365/2400x1356/filters:focal(1024x683:1025x684)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg\"},\"portraitBg\":{\"hideCredit\":true,\"asset\":{\"title\":null},\"caption\":null,\"credit\":{\"html\":\"Illustration by Richard Parry for The Verge\"},\"variantUrl\":\"https://cdn.vox-cdn.com/thumbor/Qe5ZsJ1rFFIWM20TpetW-aoMZz4=/0x0:2048x1365/1000x1429/filters:focal(1024x683:1025x684)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg\"}},\"package\":null,\"body\":{\"components\":[{\"placement\":{\"id\":\"DiSAFH\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"\\u003csmall\\u003e\\u003cem\\u003eThis article is a collaboration between \\u003c/em\\u003e\\u003c/small\\u003e\\u003ca href=\\\"https://nymag.com/intelligencer/article/ai-artificial-intelligence-humans-technology-business-factory.html\\\"\\u003e\\u003csmall\\u003eNew York Magazine\\u003c/small\\u003e\\u003c/a\\u003e\\u003csmall\\u003e\\u003cem\\u003e and The Verge.\\u003c/em\\u003e\\u003c/small\\u003e\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"WTaIZX\",\"alignment\":null},\"__typename\":\"EntryBodyHorizontalRule\",\"__isEntryBodyComponent\":\"EntryBodyHorizontalRule\"},{\"placement\":{\"id\":\"rkCosQ\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"\\u003cstrong\\u003eA few months\\u003c/strong\\u003e after graduating from college in Nairobi, a 30-year-old I’ll call Joe got a job as an annotator — the tedious work of processing the raw information used to train artificial intelligence. AI learns by finding patterns in enormous quantities of data, but first that data has to be sorted and tagged by people, a vast workforce mostly hidden behind the machines. In Joe’s case, he was labeling footage for self-driving cars — identifying every vehicle, pedestrian, cyclist, anything a driver needs to be aware of — frame by frame and from every possible camera angle. It’s difficult and repetitive work. A several-second blip of footage took eight hours to annotate, for which Joe was paid about $10.\"},\"dropcap\":true,\"endmark\":false,\"lead\":true},{\"placement\":{\"id\":\"aOJBqQ\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"Then, in 2019, an opportunity arose: Joe could make four times as much running an annotation boot camp for a new company that was hungry for labelers. Every two weeks, 50 new recruits would file into an office building in Nairobi to begin their apprenticeships. There seemed to be limitless demand for the work. They would be asked to categorize clothing seen in mirror selfies, look through the eyes of robot vacuum cleaners to determine which rooms they were in, and draw squares around lidar scans of motorcycles. Over half of Joe’s students usually dropped out before the boot camp was finished. “Some people don’t know how to stay in one place for long,” he explained with gracious understatement. Also, he acknowledged, “it is very boring.”\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"ZGHHp9\",\"alignment\":\"HANG_LEFT\"},\"__typename\":\"EntryBodySidebar\",\"__isEntryBodyComponent\":\"EntryBodySidebar\",\"sidebar\":{\"body\":[{\"__typename\":\"EntryBodyImage\",\"contentWarning\":\"\",\"image\":{\"url\":\"https://cdn.vox-cdn.com/thumbor/bqRhb5A3myLSYGiXMDOshxcrXCE=/0x0:2400x3000/2400x3000/filters:focal(1200x1500:1201x1501)/cdn.vox-cdn.com/uploads/chorus_asset/file/24734352/1323Cov4x5_AI_Factory.jpg\",\"height\":3000,\"width\":2400,\"hideCredit\":false,\"caption\":null,\"credit\":null,\"asset\":{\"title\":\"“Inside the AI Factory” on the cover of New York Magazine\"}},\"placement\":{\"alignment\":null}},{\"__typename\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"\\u003csmall\\u003e\\u003cem\\u003eThis article is a collaboration between \\u003c/em\\u003e\\u003c/small\\u003e\\u003ca href=\\\"https://nymag.com/intelligencer/article/ai-artificial-intelligence-humans-technology-business-factory.html\\\"\\u003e\\u003csmall\\u003eNew York Magazine\\u003c/small\\u003e\\u003c/a\\u003e\\u003csmall\\u003e\\u003cem\\u003e and The Verge.\\u003c/em\\u003e\\u003c/small\\u003e\"},\"dropcap\":false,\"endmark\":false,\"lead\":false}]}},{\"placement\":{\"id\":\"hBH2jc\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"But it was a job in a place where jobs were scarce, and Joe turned out hundreds of graduates. After boot camp, they went home to work alone in their bedrooms and kitchens, forbidden from telling anyone what they were working on, which wasn’t really a problem because they rarely knew themselves. Labeling objects for self-driving cars was obvious, but what about categorizing whether snippets of distorted dialogue were spoken by a robot or a human? Uploading photos of yourself staring into a webcam with a blank expression, then with a grin, then wearing a motorcycle helmet? Each project was such a small component of some larger process that it was difficult to say what they were actually training AI to do. Nor did the names of the projects offer any clues: Crab Generation, Whale Segment, Woodland Gyro, and Pillbox Bratwurst. They were non sequitur code names for non sequitur work.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"zTXAC4\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"As for the company employing them, most knew it only as Remotasks, a website offering work to anyone fluent in English. Like most of the annotators I spoke with, Joe was unaware until I told him that Remotasks is the worker-facing subsidiary of a company called Scale AI, a multibillion-dollar Silicon Valley data vendor that counts OpenAI and the U.S. military among its customers. Neither Remotasks’ or Scale’s website mentions the other.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"WzbcFZ\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"Much of the public response to language models like OpenAI’s ChatGPT has focused on all the jobs they appear poised to automate. But behind even the most impressive AI system are people — huge numbers of people labeling data to train it and clarifying data when it gets confused. Only the companies that can afford to buy this data can compete, and those that get it are highly motivated to keep it secret. The result is that, with few exceptions, little is known about the information shaping these systems’ behavior, and even less is known about the people doing the shaping.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"cPnMjB\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"For Joe’s students, it was work stripped of all its normal trappings: a schedule, colleagues, knowledge of what they were working on or whom they were working for. In fact, they rarely called it work at all — just “tasking.” They were taskers.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"SCKhgq\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"The anthropologist David Graeber defines “bullshit jobs” as employment without meaning or purpose, work that should be automated but for reasons of bureaucracy or status or inertia is not. These AI jobs are their bizarro twin: work that people want to automate, and often think is already automated, yet still requires a human stand-in. The jobs have a purpose; it’s just that workers often have no idea what it is.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"XmIITv\",\"alignment\":null},\"__typename\":\"EntryBodyHorizontalRule\",\"__isEntryBodyComponent\":\"EntryBodyHorizontalRule\"},{\"placement\":{\"id\":\"LmwoCI\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"The current AI boom — the convincingly human-sounding chatbots, the artwork that can be generated from simple prompts, and the multibillion-dollar valuations of the companies behind these technologies — began with an unprecedented feat of tedious and repetitive labor.\"},\"dropcap\":true,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"GMJ6gt\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"In 2007, the AI researcher Fei-Fei Li, then a professor at Princeton, suspected the key to improving image-recognition neural networks, a method of machine learning that had been languishing for years, was training on more data — millions of labeled images rather than tens of thousands. The problem was that it would take decades and millions of dollars for her team of undergrads to label that many photos.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"k9s7rF\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"Li found thousands of workers on Mechanical Turk, Amazon’s crowdsourcing platform where people around the world complete small tasks for cheap. The resulting annotated dataset, called ImageNet, enabled breakthroughs in machine learning that revitalized the field and ushered in a decade of progress.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"yrZYQ2\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"Annotation remains a foundational part of making AI, but there is often a sense among engineers that it’s a passing, inconvenient prerequisite to the more glamorous work of building models. You collect as much labeled data as you can get as cheaply as possible to train your model, and if it works, at least in theory, you no longer need the annotators. But annotation is never really finished. Machine-learning systems are what researchers call “brittle,” prone to fail when encountering something that isn’t well represented in their training data. These failures, called “edge cases,” can have serious consequences. In 2018, an Uber self-driving test car killed a woman because, though it was programmed to avoid cyclists and pedestrians, it didn’t know what to make of someone walking a bike across the street. The more AI systems are put out into the world to dispense legal advice and medical help, the more edge cases they will encounter and the more humans will be needed to sort them. Already, this has given rise to a global industry staffed by people like Joe who use their uniquely human faculties to help the machines.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"18xa4t\",\"alignment\":\"HANG_LEFT\"},\"__typename\":\"EntryBodyPullquote\",\"__isEntryBodyComponent\":\"EntryBodyPullquote\",\"quote\":{\"html\":\"Is that a red shirt with white stripes or a white shirt with red stripes? Is a wicker bowl a “decorative bowl” if it’s full of apples? What color is leopard print?\"}},{\"placement\":{\"id\":\"fFYjFC\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"Over the past six months, I spoke with more than two dozen annotators from around the world, and while many of them were training cutting-edge chatbots, just as many were doing the mundane manual labor required to keep AI running. There are people classifying the emotional content of TikTok videos, new variants of email spam, and the precise sexual provocativeness of online ads. Others are looking at credit-card transactions and figuring out what sort of purchase they relate to or checking e-commerce recommendations and deciding whether that shirt is really something you might like after buying that other shirt. Humans are correcting customer-service chatbots, listening to Alexa requests, and categorizing the emotions of people on video calls. They are labeling food so that smart refrigerators don’t get confused by new packaging, checking automated security cameras before sounding alarms, and identifying corn for baffled autonomous tractors.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"JvOT3i\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"“There’s an entire supply chain,” said Sonam Jindal, the program and research lead of the nonprofit Partnership on AI. “The general perception in the industry is that this work isn’t a critical part of development and isn’t going to be needed for long. All the excitement is around building artificial intelligence, and once we build that, it won’t be needed anymore, so why think about it? But it’s infrastructure for AI. Human intelligence is the basis of artificial intelligence, and we need to be valuing these as real jobs in the AI economy that are going to be here for a while.”\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"ICKN1N\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"The data vendors behind familiar names like OpenAI, Google, and Microsoft come in different forms. There are private outsourcing companies with call-center-like offices, such as the Kenya- and Nepal-based CloudFactory, where Joe annotated for $1.20 an hour before switching to Remotasks. There are also “crowdworking” sites like Mechanical Turk and Clickworker where anyone can sign up to perform tasks. In the middle are services like Scale AI. Anyone can sign up, but everyone has to pass qualification exams and training courses and undergo performance monitoring. Annotation is big business. Scale, founded in 2016 by then-19-year-old Alexandr Wang, was valued in 2021 at $7.3 billion, making him what \\u003cem\\u003eForbes\\u003c/em\\u003e called “the youngest self-made billionaire,” though the magazine noted in a recent profile that his stake has fallen on secondary markets since then.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"vlRWUq\",\"alignment\":\"WIDE_BLOCK\"},\"__typename\":\"EntryBodyImage\",\"__isEntryBodyComponent\":\"EntryBodyImage\",\"contentWarning\":\"\",\"image\":{\"url\":\"https://cdn.vox-cdn.com/thumbor/tzXNAIWOaBlv7KbHabZQPNgOKvU=/0x0:2048x1500/2048x1500/filters:focal(1024x750:1025x751)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg\",\"height\":1500,\"width\":2048,\"hideCredit\":true,\"caption\":null,\"credit\":{\"html\":\"Illustration by Richard Parry for The Verge\"},\"asset\":{\"title\":null}}},{\"placement\":{\"id\":\"0Rz1g6\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"This tangled supply chain is deliberately hard to map. According to people in the industry, the companies buying the data demand strict confidentiality. (This is the reason Scale cited to explain why Remotasks has a different name.) Annotation reveals too much about the systems being developed, and the huge number of workers required makes leaks difficult to prevent. Annotators are warned repeatedly not to tell anyone about their jobs, not even their friends and co-workers, but corporate aliases, project code names, and, crucially, the extreme division of labor ensure they don’t have enough information about them to talk even if they wanted to. (Most workers requested pseudonyms for fear of being booted from the platforms.) Consequently, there are no granular estimates of the number of people who work in annotation, but it is a lot, and it is growing. A recent Google Research paper gave an order-of-magnitude figure of “millions” with the potential to become “billions.”\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"HGxQ5G\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"Automation often unfolds in unexpected ways. Erik Duhaime, CEO of medical-data-annotation company Centaur Labs, recalled how, several years ago, prominent machine-learning engineers were predicting AI would make the job of radiologist obsolete. When that didn’t happen, conventional wisdom shifted to radiologists using AI as a tool. Neither of those is quite what he sees occurring. AI is very good at specific tasks, Duhaime said, and that leads work to be broken up and distributed across a system of specialized algorithms and to equally specialized humans. An AI system might be capable of spotting cancer, he said, giving a hypothetical example, but only in a certain type of imagery from a certain type of machine; so now, you need a human to check that the AI is being fed the right type of data and maybe another human who checks its work before passing it to another AI that writes a report, which goes to another human, and so on. “AI doesn’t replace work,” he said. “But it does change how work is organized.”\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"Owh2zA\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"You might miss this if you believe AI is a brilliant, thinking machine. But if you pull back the curtain even a little, it looks more familiar, the latest iteration of a particularly Silicon Valley division of labor, in which the futuristic gleam of new technologies hides a sprawling manufacturing apparatus and the people who make it run. Duhaime reached back farther for a comparison, a digital version of the transition from craftsmen to industrial manufacturing: coherent processes broken into tasks and arrayed along assembly lines with some steps done by machines and some by humans but none resembling what came before.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"rzMXtI\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"Worries about AI-driven disruption are often countered with the argument that AI automates tasks, not jobs, and that these tasks will be the dull ones, leaving people to pursue more fulfilling and human work. But just as likely, the rise of AI will look like past labor-saving technologies, maybe like the telephone or typewriter, which vanquished the drudgery of message delivering and handwriting but generated so much new correspondence, commerce, and paperwork that new offices staffed by new types of workers — clerks, accountants, typists — were required to manage it. When AI comes for your job, you may not lose it, but it might become more alien, more isolating, more tedious.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"H98j2F\",\"alignment\":null},\"__typename\":\"EntryBodyHorizontalRule\",\"__isEntryBodyComponent\":\"EntryBodyHorizontalRule\"},{\"placement\":{\"id\":\"XCpv42\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"Earlier this year, I signed up for Scale AI’s Remotasks. The process was straightforward. After entering my computer specs, internet speed, and some basic contact information, I found myself in the “training center.” To access a paying task, I first had to complete an associated (unpaid) intro course.\"},\"dropcap\":true,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"44Q0uj\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"The training center displayed a range of courses with inscrutable names like Glue Swimsuit and Poster Macadamia. I clicked on something called GFD Chunking, which revealed itself to be labeling clothing in social-media photos.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"LboieZ\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"The instructions, however, were odd. For one, they basically consisted of the same direction reiterated in the idiosyncratically colored and capitalized typography of a collaged bomb threat.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"tJIaxS\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"“DO LABEL items that are real and can be worn by humans or are intended to be worn by real people,” it read.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"U0QHaR\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"“All items below SHOULD be labeled because they are real and can be worn by real-life humans,” it reiterated above photos of an Air Jordans ad, someone in a Kylo Ren helmet, and mannequins in dresses, over which was a lime-green box explaining, once again, “DO Label real items that can be worn by real people.”\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"xogSY2\",\"alignment\":null},\"__typename\":\"EntryBodyImage\",\"__isEntryBodyComponent\":\"EntryBodyImage\",\"contentWarning\":\"\",\"image\":{\"url\":\"https://cdn.vox-cdn.com/thumbor/MHHrTeYM1ECpMGl9kVhgPdVy6QM=/0x0:2083x2083/2083x2083/filters:focal(1042x1042:1043x1043)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg\",\"height\":2083,\"width\":2083,\"hideCredit\":false,\"caption\":{\"html\":\"Remotasks instructions for labeling clothing.\",\"plaintext\":\"Remotasks instructions for labeling clothing.\"},\"credit\":null,\"asset\":{\"title\":\"Remotasks instructions for labeling clothing.\\u0026nbsp;\"}}},{\"placement\":{\"id\":\"iPycIF\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"I skimmed to the bottom of the manual, where the instructor had written in the large bright-red font equivalent of grabbing someone by the shoulders and shaking them, “THE FOLLOWING ITEMS SHOULD NOT BE LABELED because a human could not actually put wear any of these items!” above a photo of C-3PO, Princess Jasmine from \\u003cem\\u003eAladdin, \\u003c/em\\u003eand a cartoon shoe with eyeballs.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"ykk1Ar\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"Feeling confident in my ability to distinguish between real clothes that can be worn by real people and not-real clothes that cannot, I proceeded to the test. Right away, it threw an ontological curveball: a picture of a magazine depicting photos of women in dresses. Is a photograph of clothing real clothing? \\u003cem\\u003eNo,\\u003c/em\\u003e I thought, \\u003cem\\u003ebecause a human cannot wear a photograph of clothing.\\u003c/em\\u003e Wrong! As far as AI is concerned, photos of real clothes are real clothes. Next came a photo of a woman in a dimly lit bedroom taking a selfie before a full-length mirror. The blouse and shorts she’s wearing are real. What about their reflection? Also real! Reflections of real clothes are also real clothes.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"1UYZTc\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"After an embarrassing amount of trial and error, I made it to the actual work, only to make the horrifying discovery that the instructions I’d been struggling to follow had been updated and clarified so many times that they were now a full 43 printed pages of directives: Do NOT label open suitcases full of clothes; DO label shoes but do NOT label flippers; DO label leggings but do NOT label tights; do NOT label towels even if someone is wearing it; label costumes but do NOT label armor. And so on.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"wv1cyl\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"There has been general instruction disarray across the industry, according to Milagros Miceli, a researcher at the Weizenbaum Institute in Germany who studies data work. It is in part a product of the way machine-learning systems learn. Where a human would get the concept of “shirt” with a few examples, machine-learning programs need thousands, and they need to be categorized with perfect consistency yet varied enough (polo shirts, shirts being worn outdoors, shirts hanging on a rack) that the very literal system can handle the diversity of the real world. “Imagine simplifying complex realities into something that is readable for a machine that is totally dumb,” she said.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"WvFXuD\",\"alignment\":\"HANG_LEFT\"},\"__typename\":\"EntryBodyPullquote\",\"__isEntryBodyComponent\":\"EntryBodyPullquote\",\"quote\":{\"html\":\"Once, Victor stayed up 36 hours straight labeling elbows and knees and heads in photographs of crowds — he has no idea why.\"}},{\"placement\":{\"id\":\"mjnNc5\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"The act of simplifying reality for a machine results in a great deal of complexity for the human. Instruction writers must come up with rules that will get humans to categorize the world with perfect consistency. To do so, they often create categories no human would use. A human asked to tag all the shirts in a photo probably wouldn’t tag the reflection of a shirt in a mirror because they would know it is a reflection and not real. But to the AI, which has no understanding of the world, it’s all just pixels and the two are perfectly identical. Fed a dataset with some shirts labeled and other (reflected) shirts unlabeled, the model won’t work. So the engineer goes back to the vendor with an update: DO label reflections of shirts. Soon, you have a 43-page guide descending into red all-caps.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"P38dZl\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"“When you start off, the rules are relatively simple,” said a former Scale employee who requested anonymity because of an NDA. “Then they get back a thousand images and then they’re like, \\u003cem\\u003eWait a second, \\u003c/em\\u003eand then you have multiple engineers and they start to argue with each other. It’s very much a human thing.”\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"UpCtdV\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"The job of the annotator often involves putting human understanding aside and following instructions very, \\u003cem\\u003every\\u003c/em\\u003e literally — to think, as one annotator said, like a robot. It’s a strange mental space to inhabit, doing your best to follow nonsensical but rigorous rules, like taking a standardized test while on hallucinogens. Annotators invariably end up confronted with confounding questions like, Is that a red shirt with white stripes or a white shirt with red stripes? Is a wicker bowl a “decorative bowl” if it’s full of apples? What color is leopard print? When instructors said to label traffic-control directors, did they also mean to label traffic-control directors eating lunch on the sidewalk? Every question must be answered, and a wrong guess could get you banned and booted to a new, totally different task with its own baffling rules.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"7FMmHE\",\"alignment\":\"WIDE_BLOCK\"},\"__typename\":\"EntryBodyImage\",\"__isEntryBodyComponent\":\"EntryBodyImage\",\"contentWarning\":\"\",\"image\":{\"url\":\"https://cdn.vox-cdn.com/thumbor/kQBljfwrhkJGYtW8XWVY30BSM1k=/0x0:2048x1737/2048x1737/filters:focal(1024x869:1025x870)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg\",\"height\":1737,\"width\":2048,\"hideCredit\":true,\"caption\":null,\"credit\":{\"html\":\"Illustration by Richard Parry for The Verge\"},\"asset\":{\"title\":null}}},{\"placement\":{\"id\":\"cph023\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"Most of the work on Remotasks is paid at a piece rate with a single task earning anywhere from a few cents to several dollars. Because tasks can take seconds or hours, wages are hard to predict. When Remotasks first arrived in Kenya, annotators said it paid relatively well — averaging about $5 to $10 per hour depending on the task — but the amount fell as time went on.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"O4b1rx\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"Scale AI spokesperson Anna Franko said that the company’s economists analyze the specifics of a project, the skills required, the regional cost of living, and other factors “to ensure fair and competitive compensation.” Former Scale employees also said pay is determined through a surge-pricing-like mechanism that adjusts for how many annotators are available and how quickly the data is needed.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"vje7vJ\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"According to workers I spoke with and job listings, U.S.-based Remotasks annotators generally earn between $10 and $25 per hour, though some subject-matter experts can make more. By the beginning of this year, pay for the Kenyan annotators I spoke with had dropped to between $1 and $3 per hour.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"SrNbYr\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"That is, when they were making any money at all. The most common complaint about Remotasks work is its variability; it’s steady enough to be a full-time job for long stretches but too unpredictable to rely on. Annotators spend hours reading instructions and completing unpaid trainings only to do a dozen tasks and then have the project end. There might be nothing new for days, then, without warning, a totally different task appears and could last anywhere from a few hours to weeks. Any task could be their last, and they never know when the next one will come.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"OZYqyL\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"This boom-and-bust cycle results from the cadence of AI development, according to engineers and data vendors. Training a large model requires an enormous amount of annotation followed by more iterative updates, and engineers want it all as fast as possible so they can hit their target launch date. There may be monthslong demand for thousands of annotators, then for only a few hundred, then for a dozen specialists of a certain type, and then thousands again. “The question is, Who bears the cost for these fluctuations?” said Jindal of Partnership on AI. “Because right now, it’s the workers.”\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"lWLYTF\",\"alignment\":\"HANG_LEFT\"},\"__typename\":\"EntryBodyPullquote\",\"__isEntryBodyComponent\":\"EntryBodyPullquote\",\"quote\":{\"html\":\"“I really am wasting my life here if I made somebody a billionaire and I’m earning a couple of bucks a week.”\"}},{\"placement\":{\"id\":\"okEUz7\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"To succeed, annotators work together. When I told Victor, who started working for Remotasks while at university in Nairobi, about my struggles with the traffic-control-directors task, he told me everyone knew to stay away from that one: too tricky, bad pay, not worth it. Like a lot of annotators, Victor uses unofficial WhatsApp groups to spread the word when a good task drops. When he figures out a new one, he starts impromptu Google Meets to show others how it’s done. Anyone can join and work together for a time, sharing tips. “It’s a culture we have developed of helping each other because we know when on your own, you can’t know all the tricks,” he said.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"HFIvUC\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"Because work appears and vanishes without warning, taskers always need to be on alert. Victor has found that projects pop up very late at night, so he is in the habit of waking every three hours or so to check his queue. When a task is there, he’ll stay awake as long as he can to work. Once, he stayed up 36 hours straight labeling elbows and knees and heads in photographs of crowds — he has no idea why. Another time, he stayed up so long his mother asked him what was wrong with his eyes. He looked in the mirror to discover they were swollen.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"PVJ0ce\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"Annotators generally know only that they are training AI for companies located vaguely elsewhere, but sometimes the veil of anonymity drops — instructions mentioning a brand or a chatbot say too much. “I read and I Googled and found I am working for a 25-year-old billionaire,” said one worker, who, when we spoke, was labeling the emotions of people calling to order Domino’s pizza. “I really am wasting my life here if I made somebody a billionaire and I’m earning a couple of bucks a week.”\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"F196H8\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"Victor is a self-proclaimed “fanatic” about AI and started annotating because he wants to help bring about a fully automated post-work future. But earlier this year, someone dropped a \\u003cem\\u003eTime\\u003c/em\\u003e story into one of his WhatsApp groups about workers training ChatGPT to recognize toxic content who were getting paid less than $2 an hour by the vendor Sama AI. “People were angry that these companies are so profitable but paying so poorly,” Victor said. He was unaware until I told him about Remotasks’ connection to Scale. Instructions for one of the tasks he worked on were nearly identical to those used by OpenAI, which meant he had likely been training ChatGPT as well, for approximately $3 per hour.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"NJ9yJN\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"“I remember that someone posted that we will be remembered in the future,” he said. “And somebody else replied, ‘We are being treated worse than foot soldiers. We will be remembered nowhere in the future.’ I remember that very well. Nobody will recognize the work we did or the effort we put in.”\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"J7WkzP\",\"alignment\":null},\"__typename\":\"EntryBodyHorizontalRule\",\"__isEntryBodyComponent\":\"EntryBodyHorizontalRule\"},{\"placement\":{\"id\":\"J9nAyh\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"Identifying clothing and labeling customer-service conversations are just some of the annotation gigs available. Lately, the hottest on the market has been chatbot trainer. Because it demands specific areas of expertise or language fluency and wages are often adjusted regionally, this job tends to pay better. Certain types of specialist annotation can go for $50 or more per hour.\"},\"dropcap\":true,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"sCdGdf\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"A woman I’ll call Anna was searching for a job in Texas when she stumbled across a generic listing for online work and applied. It was Remotasks, and after passing an introductory exam, she was brought into a Slack room of 1,500 people who were training a project code-named Dolphin, which she later discovered to be Google DeepMind’s chatbot, Sparrow, one of the many bots competing with ChatGPT. Her job is to talk with it all day. At about $14 an hour, plus bonuses for high productivity, “it definitely beats getting paid $10 an hour at the local Dollar General store,” she said.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"VeFmgC\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"Also, she enjoys it. She has discussed science-fiction novels, mathematical paradoxes, children’s riddles, and TV shows. Sometimes the bot’s responses make her laugh; other times, she runs out of things to talk about. “Some days, my brain is just like, \\u003cem\\u003eI literally have no idea what on earth to ask it now,\\u003c/em\\u003e” she said. “So I have a little notebook, and I’ve written about two pages of things — I just Google interesting topics — so I think I’ll be good for seven hours today, but that’s not always the case.”\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"TNEkFu\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"Each time Anna prompts Sparrow, it delivers two responses and she picks the best one, thereby creating something called “human-feedback data.” When ChatGPT debuted late last year, its impressively natural-seeming conversational style was credited to its having been trained on troves of internet data. But the language that fuels ChatGPT and its competitors is filtered through several rounds of human annotation. One group of contractors writes examples of how the engineers want the bot to behave, creating questions followed by correct answers, descriptions of computer programs followed by functional code, and requests for tips on committing crimes followed by polite refusals. After the model is trained on these examples, yet more contractors are brought in to prompt it and rank its responses. This is what Anna is doing with Sparrow. Exactly which criteria the raters are told to use varies — honesty, or helpfulness, or just personal preference. The point is that they are creating data on human taste, and once there’s enough of it, engineers can train a second model to mimic their preferences at scale, automating the ranking process and training their AI to act in ways humans approve of. The result is a remarkably human-seeming bot that mostly declines harmful requests and explains its AI nature with seeming self-awareness.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"e1Mnpu\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"Put another way, ChatGPT seems so human because it was trained by an AI that was mimicking humans who were rating an AI that was mimicking humans who were pretending to be a better version of an AI that was trained on human writing.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"JwnoTx\",\"alignment\":\"WIDE_BLOCK\"},\"__typename\":\"EntryBodyImage\",\"__isEntryBodyComponent\":\"EntryBodyImage\",\"contentWarning\":\"\",\"image\":{\"url\":\"https://cdn.vox-cdn.com/thumbor/BJ1voW9GJtnRC0ZSvYAl9KHBH-c=/0x0:2048x1514/2048x1514/filters:focal(1024x757:1025x758)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg\",\"height\":1514,\"width\":2048,\"hideCredit\":true,\"caption\":null,\"credit\":{\"html\":\"Illustration by Richard Parry for The Verge\"},\"asset\":{\"title\":null}}},{\"placement\":{\"id\":\"38f34o\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"This circuitous technique is called “reinforcement learning from human feedback,” or RLHF, and it’s so effective that it’s worth pausing to fully register what it doesn’t do. When annotators teach a model to be accurate, for example, the model isn’t learning to check answers against logic or external sources or about what accuracy as a concept even is. The model is still a text-prediction machine mimicking patterns in human writing, but now its training corpus has been supplemented with bespoke examples, and the model has been weighted to favor them. Maybe this results in the model extracting patterns from the part of its linguistic map labeled as accurate and producing text that happens to align with the truth, but it can also result in it mimicking the confident style and expert jargon of the accurate text while writing things that are totally wrong. There is no guarantee that the text the labelers marked as accurate is in fact accurate, and when it is, there is no guarantee that the model learns the right patterns from it.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"LPyiWh\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"This dynamic makes chatbot annotation a delicate process. It has to be rigorous and consistent because sloppy feedback, like marking material that merely sounds correct as accurate, risks training models to be even more convincing bullshitters. An early OpenAI and DeepMind joint project using RLHF, in this case to train a virtual robot hand to grab an item, resulted in also training the robot to position its hand between the object and its raters and wiggle around such that it only appeared to its human overseers to grab the item. Ranking a language model’s responses is always going to be somewhat subjective because it’s language. A text of any length will have multiple elements that could be right or wrong or, taken together, misleading. OpenAI researchers ran into this obstacle in another early RLHF paper. Trying to get their model to summarize text, the researchers found they agreed only 60 percent of the time that a summary was good. “Unlike many tasks in [machine learning] our queries do not have unambiguous ground truth,” they lamented.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"CIIKop\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"When Anna rates Sparrow’s responses, she’s supposed to be looking at their accuracy, helpfulness, and harmlessness while also checking that the model isn’t giving medical or financial advice or anthropomorphizing itself or running afoul of other criteria. To be useful training data, the model’s responses have to be quantifiably ranked against one another: Is a bot that helpfully tells you how to make a bomb “better” than a bot that’s so harmless it refuses to answer any questions? In one DeepMind paper, when Sparrow’s makers took a turn annotating, four researchers wound up debating whether their bot had assumed the gender of a user who asked it for relationship advice. According to Geoffrey Irving, one of DeepMind’s research scientists, the company’s researchers hold weekly annotation meetings in which they rerate data themselves and discuss ambiguous cases, consulting with ethical or subject-matter experts when a case is particularly tricky.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"WEcLbZ\",\"alignment\":\"HANG_LEFT\"},\"__typename\":\"EntryBodyPullquote\",\"__isEntryBodyComponent\":\"EntryBodyPullquote\",\"quote\":{\"html\":\"There are people classifying the emotional content of TikTok videos, new variants of email spam, and the precise sexual provocativeness of online ads.\"}},{\"placement\":{\"id\":\"GBki6f\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"Anna often finds herself having to choose between two bad options. “Even if they’re both absolutely, ridiculously wrong, you still have to figure out which one is better and then write words explaining why,” she said. Sometimes, when both responses are bad, she’s encouraged to write a better response herself, which she does about half the time.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"qc1nH9\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"Because feedback data is difficult to collect, it fetches a higher price. Basic preferences of the sort Anna is producing sell for about $1 each, according to people with knowledge of the industry. But if you want to train a model to do legal research, you need someone with training in law, and this gets expensive. Everyone involved is reluctant to say how much they’re spending, but in general, specialized written examples can go for hundreds of dollars, while expert ratings can cost $50 or more. One engineer told me about buying examples of Socratic dialogues for up to $300 a pop. Another told me about paying $15 for a “darkly funny limerick about a goldfish.”\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"RKNAc2\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"OpenAI, Microsoft, Meta, and Anthropic did not comment about how many people contribute annotations to their models, how much they are paid, or where in the world they are located. Irving of DeepMind, which is a subsidiary of Google, said the annotators working on Sparrow are paid “at least the hourly living wage” based on their location. Anna knows “absolutely nothing” about Remotasks, but Sparrow has been more open. She wasn’t the only annotator I spoke with who got more information from the AI they were training than from their employer; several others learned whom they were working for by asking their AI for its company’s terms of service. “I literally asked it, ‘What is your purpose, Sparrow?’” Anna said. It pulled up a link to DeepMind’s website and explained that it’s an AI assistant and that its creators trained it using RLHF to be helpful and safe.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"U51AbE\",\"alignment\":null},\"__typename\":\"EntryBodyHorizontalRule\",\"__isEntryBodyComponent\":\"EntryBodyHorizontalRule\"},{\"placement\":{\"id\":\"fw2lFQ\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"Until recently, it was relatively easy to spot bad output from a language model. It looked like gibberish. But this gets harder as the models get better — a problem called “scalable oversight.” Google inadvertently demonstrated how hard it is to catch the errors of a modern-language model when one made it into the splashy debut of its AI assistant, Bard. (It stated confidently that the James Webb Space Telescope “took the very first pictures of a planet outside of our own solar system,” which is wrong.) This trajectory means annotation increasingly requires specific skills and expertise.\"},\"dropcap\":true,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"6pLQuK\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"Last year, someone I’ll call Lewis was working on Mechanical Turk when, after completing a task, he received a message inviting him to apply for a platform he hadn’t heard of. It was called Taskup.ai, and its website was remarkably basic: just a navy background with text reading GET PAID FOR TASKS ON DEMAND. He applied.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"hQzXZN\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"The work paid far better than anything he had tried before, often around $30 an hour. It was more challenging, too: devising complex scenarios to trick chatbots into giving dangerous advice, testing a model’s ability to stay in character, and having detailed conversations about scientific topics so technical they required extensive research. He found the work “satisfying and stimulating.” While checking one model’s attempts to code in Python, Lewis was learning too. He couldn’t work for more than four hours at a stretch, lest he risk becoming mentally drained and making mistakes, and he wanted to keep the job.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"XPpoce\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"“If there was one thing I could change, I would just like to have more information about what happens on the other end,” he said. “We only know as much as we need to know to get work done, but if I could know more, then maybe I could get more established and perhaps pursue this as a career.”\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"premKi\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"I spoke with eight other workers, most based in the U.S., who had similar experiences of answering surveys or completing tasks on other platforms and finding themselves recruited for Taskup.ai or several similarly generic sites, such as DataAnnotation.tech or Gethybrid.io. Often their work involved training chatbots, though with higher-quality expectations and more specialized purposes than other sites they had worked for. One was demonstrating spreadsheet macros. Another was just supposed to have conversations and rate responses according to whatever criteria she wanted. She often asked the chatbot things that had come up in conversations with her 7-year-old daughter, like “What is the largest dinosaur?” and “Write a story about a tiger.” “I haven’t fully gotten my head around what they’re trying to do with it,” she told me.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"5sJ3K8\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"Taskup.ai, DataAnnotation.tech, and Gethybrid.io all appear to be owned by the same company: Surge AI. Its CEO, Edwin Chen, would neither confirm nor deny the connection, but he was willing to talk about his company and how he sees annotation evolving.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"vRrYxI\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"“I’ve always felt the annotation landscape is overly simplistic,” Chen said over a video call from Surge’s office. He founded Surge in 2020 after working on AI at Google, Facebook, and Twitter convinced him that crowdsourced labeling was inadequate. “We want AI to tell jokes or write really good marketing copy or help me out when I need therapy or whatnot,” Chen said. “You can’t ask five people to independently come up with a joke and combine it into a majority answer. Not everybody can tell a joke or solve a Python program. The annotation landscape needs to shift from this low-quality, low-skill mind-set to something that’s much richer and captures the range of human skills and creativity and values that we want AI systems to possess.”\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"BbEw88\",\"alignment\":\"WIDE_BLOCK\"},\"__typename\":\"EntryBodyImage\",\"__isEntryBodyComponent\":\"EntryBodyImage\",\"contentWarning\":\"\",\"image\":{\"url\":\"https://cdn.vox-cdn.com/thumbor/Qe4htQ4VivRXnS0BWZowjTY8hE8=/0x0:2048x1572/2048x1572/filters:focal(1024x786:1025x787)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg\",\"height\":1572,\"width\":2048,\"hideCredit\":true,\"caption\":null,\"credit\":{\"html\":\"Illustration by Richard Parry for The Verge\"},\"asset\":{\"title\":null}}},{\"placement\":{\"id\":\"hZTTwN\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"Last year, Surge relabeled Google’s dataset classifying Reddit posts by emotion. Google had stripped each post of context and sent them to workers in India for labeling. Surge employees familiar with American internet culture found that 30 percent of the labels were wrong. Posts like “hell yeah my brother” had been classified as annoyance and “Yay, cold McDonald’s. My favorite” as love.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"A7z003\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"Surge claims to vet its workers for qualifications — that people doing creative-writing tasks have experience with creative writing, for example — but exactly how Surge finds workers is “proprietary,” Chen said. As with Remotasks, workers often have to complete training courses, though unlike Remotasks, they are paid for it, according to the annotators I spoke with. Having fewer, better-trained workers producing higher-quality data allows Surge to compensate better than its peers, Chen said, though he declined to elaborate, saying only that people are paid “fair and ethical wages.” The workers I spoke with earned between $15 and $30 per hour, but they are a small sample of all the annotators, a group Chen said now consists of 100,000 people. The secrecy, he explained, stems from clients’ demands for confidentiality.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"qQPegh\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"Surge’s customers include OpenAI, Google, Microsoft, Meta, and Anthropic. Surge specializes in feedback and language annotation, and after ChatGPT launched, it got an influx of requests, Chen said: “I thought everybody knew the power of RLHF, but I guess people just didn’t viscerally understand.”\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"eJOOVh\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"The new models are so impressive they’ve inspired another round of predictions that annotation is about to be automated. Given the costs involved, there is significant financial pressure to do so. Anthropic, Meta, and other companies have recently made strides in using AI to drastically reduce the amount of human annotation needed to guide models, and other developers have started using GPT-4 to generate training data. However, a recent paper found that GPT-4-trained models may be learning to mimic GPT’s authoritative style with even less accuracy, and so far, when improvements in AI have made one form of annotation obsolete, demand for other, more sophisticated types of labeling has gone up. This debate spilled into the open earlier this year, when Scale’s CEO, Wang, tweeted that he predicted AI labs will soon be spending as many billions of dollars on human data as they do on computing power; OpenAI’s CEO, Sam Altman, responded that data needs will decrease as AI improves.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"RSTLp7\",\"alignment\":\"HANG_LEFT\"},\"__typename\":\"EntryBodyPullquote\",\"__isEntryBodyComponent\":\"EntryBodyPullquote\",\"quote\":{\"html\":\"“I mean, what it can do is amazing,” she said of the chatbot. “But it still does some really weird shit.”\"}},{\"placement\":{\"id\":\"ikjy1Y\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"Chen is skeptical AI will reach a point where human feedback is no longer needed, but he does see annotation becoming more difficult as models improve. Like many researchers, he believes the path forward will involve AI systems helping humans oversee other AI. Surge recently collaborated with Anthropic on a proof of concept, having human labelers answer questions about a lengthy text with the help of an unreliable AI assistant, on the theory that the humans would have to feel out the weaknesses of their AI assistant and collaborate to reason their way to the correct answer. Another possibility has two AIs debating each other and a human rendering the final verdict on which is correct. “We still have yet to see really good practical implementations of this stuff, but it’s starting to become necessary because it’s getting really hard for labelers to keep up with the models,” said OpenAI research scientist John Schulman in a recent talk at Berkeley.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"uCUg8A\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"“I think you always need a human to monitor what AIs are doing just because they are this kind of alien entity,” Chen said. Machine-learning systems are just too strange ever to fully trust. The most impressive models today have what, to a human, seems like bizarre weaknesses, he added, pointing out that though GPT-4 can generate complex and convincing prose, it can’t pick out which words are adjectives: “Either that or models get so good that they’re better than humans at all things, in which case, you reach your utopia and who cares?”\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"zQbpof\",\"alignment\":null},\"__typename\":\"EntryBodyHorizontalRule\",\"__isEntryBodyComponent\":\"EntryBodyHorizontalRule\"},{\"placement\":{\"id\":\"urEAUB\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"As 2022 ended, Joe started hearing from his students that their task queues were often empty. Then he got an email informing him the boot camps in Kenya were closing. He continued training taskers online, but he began to worry about the future.\"},\"dropcap\":true,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"L19qy8\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"“There were signs that it was not going to last long,” he said. Annotation was leaving Kenya. From colleagues he had met online, he heard tasks were going to Nepal, India, and the Philippines. “The companies shift from one region to another,” Joe said. “They don’t have infrastructure locally, so it makes them flexible to shift to regions that favor them in terms of operation cost.”\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"RsLx3E\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"One way the AI industry differs from manufacturers of phones and cars is in its fluidity. The work is constantly changing, constantly getting automated away and replaced with new needs for new types of data. It’s an assembly line but one that can be endlessly and instantly reconfigured, moving to wherever there is the right combination of skills, bandwidth, and wages.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"Jvjzpr\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"Lately, the best-paying work is in the U.S. In May, Scale started listing annotation jobs on its own website, soliciting people with experience in practically every field AI is predicted to conquer. There were listings for AI trainers with expertise in health coaching, human resources, finance, economics, data science, programming, computer science, chemistry, biology, accounting, taxes, nutrition, physics, travel, K-12 education, sports journalism, and self-help. You can make $45 an hour teaching robots law or make $25 an hour teaching them poetry. There were also listings for people with security clearance, presumably to help train military AI. Scale recently launched a defense-oriented language model called Donovan, which Wang called “ammunition in the AI war,” and won a contract to work on the Army’s robotic-combat-vehicle program.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"iJM8zU\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"Anna is still training chatbots in Texas. Colleagues have been turned into reviewers and Slack admins — she isn’t sure why, but it has given her hope that the gig could be a longer-term career. One thing she isn’t worried about is being automated out of a job. “I mean, what it can do is amazing,” she said of the chatbot. “But it still does some really weird shit.”\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"s2KUvX\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"When Remotasks first arrived in Kenya, Joe thought annotation could be a good career. Even after the work moved elsewhere, he was determined to make it one. There were thousands of people in Nairobi who knew how to do the work, he reasoned — he had trained many of them, after all. Joe rented office space in the city and began sourcing contracts: a job annotating blueprints for a construction company, another labeling fruits despoiled by insects for some sort of agricultural project, plus the usual work of annotating for self-driving cars and e-commerce.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"JmKtcc\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"But he has found his vision difficult to achieve. He has just one full-time employee, down from two. “We haven’t been having a consistent flow of work,” he said. There are weeks with nothing to do because customers are still collecting data, and when they’re done, he has to bring in short-term contractors to meet their deadlines: “Clients don’t care whether we have consistent work or not. So long as the datasets have been completed, then that’s the end of that.”\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"bDfi2q\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"Rather than let their skills go to waste, other taskers decided to chase the work wherever it went. They rented proxy servers to disguise their locations and bought fake IDs to pass security checks so they could pretend to work from Singapore, the Netherlands, Mississippi, or wherever the tasks were flowing. It’s a risky business. Scale has become increasingly aggressive about suspending accounts caught disguising their location, according to multiple taskers. It was during one of these crackdowns that my account got banned, presumably because I had been using a VPN to see what workers in other countries were seeing, and all $1.50 or so of my earnings were seized.\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"PMHvWD\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"“These days, we have become a bit cunning because we noticed that in other countries they are paying well,” said Victor, who was earning double the Kenyan rate by tasking in Malaysia. “You do it cautiously.”\"},\"dropcap\":false,\"endmark\":false,\"lead\":false},{\"placement\":{\"id\":\"Z0J5Uq\",\"alignment\":null},\"__typename\":\"EntryBodyParagraph\",\"__isEntryBodyComponent\":\"EntryBodyParagraph\",\"contents\":{\"html\":\"Another Kenyan annotator said that after his account got suspended for mysterious reasons, he decided to stop playing by the rules. Now, he runs multiple accounts in multiple countries, tasking wherever the pay is best. He works fast and gets high marks for quality, he said, thanks to ChatGPT. The bot is wonderful, he said, letting him speed through $10 tasks in a matter of minutes. When we spoke, he was having it rate another chatbot’s responses according to seven different criteria, one AI training the other.\"},\"dropcap\":false,\"endmark\":true,\"lead\":false}]},\"url\":\"https://www.theverge.com/features/23764584/ai-artificial-intelligence-data-notation-labor-scale-surge-remotasks-openai-chatbots\",\"railComponents\":[{\"__typename\":\"EntryRailNewsletter\",\"entryRailNewsletter\":{\"name\":\"Verge Deals\",\"slug\":\"deals\"}}],\"dek\":{\"plaintext\":\"As the technology becomes ubiquitous, a vast tasker underclass is emerging — and not going anywhere.\",\"html\":\"As the technology becomes ubiquitous, a vast tasker underclass is emerging — and not going anywhere.\"},\"leadImage\":{\"defaultImageUrl\":\"https://cdn.vox-cdn.com/thumbor/v9wxGGbTW0yvHsZtt1mg8laUnOA=/0x0:2048x1365/1200x628/filters:focal(1024x683:1025x684)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg\",\"asset\":{\"title\":null,\"contentType\":\"image/jpeg\"}},\"seoDescription\":{\"plaintext\":\"How many humans does it take to make tech seem human? Millions to support OpenAI, Google, Meta, and every other major tech company. As AI becomes ubiquitous, a vast tasker underclass is emerging — and not going anywhere.\"},\"socialDescription\":{\"plaintext\":\"How many humans does it take to make tech seem human? Millions.\"},\"socialImage\":null,\"shouldUseHTMLNoindex\":false,\"shouldUseHTMLNofollow\":false,\"password\":null,\"additionalContributors\":{\"html\":\"Illustrations by Richard Parry for The Verge\"},\"_id\":23528625,\"liveCoverageEnd\":null,\"seoArticleBody\":\"This article is a collaboration between New York Magazine and The Verge.\\n\\n---\\n\\nA few months after graduating from college in Nairobi, a 30-year-old I’ll call Joe got a job as an annotator — the tedious work of processing the raw information used to train artificial intelligence. AI learns by finding patterns in enormous quantities of data, but first that data has to be sorted and tagged by people, a vast workforce mostly hidden behind the machines. In Joe’s case, he was labeling footage for self-driving cars — identifying every vehicle, pedestrian, cyclist, anything a driver needs to be aware of — frame by frame and from every possible camera angle. It’s difficult and repetitive work. A several-second blip of footage took eight hours to annotate, for which Joe was paid about $10.\\n\\nThen, in 2019, an opportunity arose: Joe could make four times as much running an annotation boot camp for a new company that was hungry for labelers. Every two weeks, 50 new recruits would file into an office building in Nairobi to begin their apprenticeships. There seemed to be limitless demand for the work. They would be asked to categorize clothing seen in mirror selfies, look through the eyes of robot vacuum cleaners to determine which rooms they were in, and draw squares around lidar scans of motorcycles. Over half of Joe’s students usually dropped out before the boot camp was finished. “Some people don’t know how to stay in one place for long,” he explained with gracious understatement. Also, he acknowledged, “it is very boring.”\\n\\n---\\n[Image: https://cdn.vox-cdn.com/thumbor/bqRhb5A3myLSYGiXMDOshxcrXCE=/0x0:2400x3000/2400x3000/filters:focal(1200x1500:1201x1501)/cdn.vox-cdn.com/uploads/chorus_asset/file/24734352/1323Cov4x5_AI_Factory.jpg]\\n\\nThis article is a collaboration between New York Magazine and The Verge.\\n---\\n\\nBut it was a job in a place where jobs were scarce, and Joe turned out hundreds of graduates. After boot camp, they went home to work alone in their bedrooms and kitchens, forbidden from telling anyone what they were working on, which wasn’t really a problem because they rarely knew themselves. Labeling objects for self-driving cars was obvious, but what about categorizing whether snippets of distorted dialogue were spoken by a robot or a human? Uploading photos of yourself staring into a webcam with a blank expression, then with a grin, then wearing a motorcycle helmet? Each project was such a small component of some larger process that it was difficult to say what they were actually training AI to do. Nor did the names of the projects offer any clues: Crab Generation, Whale Segment, Woodland Gyro, and Pillbox Bratwurst. They were non sequitur code names for non sequitur work.\\n\\nAs for the company employing them, most knew it only as Remotasks, a website offering work to anyone fluent in English. Like most of the annotators I spoke with, Joe was unaware until I told him that Remotasks is the worker-facing subsidiary of a company called Scale AI, a multibillion-dollar Silicon Valley data vendor that counts OpenAI and the U.S. military among its customers. Neither Remotasks’ or Scale’s website mentions the other.\\n\\nMuch of the public response to language models like OpenAI’s ChatGPT has focused on all the jobs they appear poised to automate. But behind even the most impressive AI system are people — huge numbers of people labeling data to train it and clarifying data when it gets confused. Only the companies that can afford to buy this data can compete, and those that get it are highly motivated to keep it secret. The result is that, with few exceptions, little is known about the information shaping these systems’ behavior, and even less is known about the people doing the shaping.\\n\\nFor Joe’s students, it was work stripped of all its normal trappings: a schedule, colleagues, knowledge of what they were working on or whom they were working for. In fact, they rarely called it work at all — just “tasking.” They were taskers.\\n\\nThe anthropologist David Graeber defines “bullshit jobs” as employment without meaning or purpose, work that should be automated but for reasons of bureaucracy or status or inertia is not. These AI jobs are their bizarro twin: work that people want to automate, and often think is already automated, yet still requires a human stand-in. The jobs have a purpose; it’s just that workers often have no idea what it is.\\n\\n---\\n\\nThe current AI boom — the convincingly human-sounding chatbots, the artwork that can be generated from simple prompts, and the multibillion-dollar valuations of the companies behind these technologies — began with an unprecedented feat of tedious and repetitive labor.\\n\\nIn 2007, the AI researcher Fei-Fei Li, then a professor at Princeton, suspected the key to improving image-recognition neural networks, a method of machine learning that had been languishing for years, was training on more data — millions of labeled images rather than tens of thousands. The problem was that it would take decades and millions of dollars for her team of undergrads to label that many photos.\\n\\nLi found thousands of workers on Mechanical Turk, Amazon’s crowdsourcing platform where people around the world complete small tasks for cheap. The resulting annotated dataset, called ImageNet, enabled breakthroughs in machine learning that revitalized the field and ushered in a decade of progress.\\n\\nAnnotation remains a foundational part of making AI, but there is often a sense among engineers that it’s a passing, inconvenient prerequisite to the more glamorous work of building models. You collect as much labeled data as you can get as cheaply as possible to train your model, and if it works, at least in theory, you no longer need the annotators. But annotation is never really finished. Machine-learning systems are what researchers call “brittle,” prone to fail when encountering something that isn’t well represented in their training data. These failures, called “edge cases,” can have serious consequences. In 2018, an Uber self-driving test car killed a woman because, though it was programmed to avoid cyclists and pedestrians, it didn’t know what to make of someone walking a bike across the street. The more AI systems are put out into the world to dispense legal advice and medical help, the more edge cases they will encounter and the more humans will be needed to sort them. Already, this has given rise to a global industry staffed by people like Joe who use their uniquely human faculties to help the machines.\\n\\n\\\"Is that a red shirt with white stripes or a white shirt with red stripes? Is a wicker bowl a “decorative bowl” if it’s full of apples? What color is leopard print?\\\"\\n\\nOver the past six months, I spoke with more than two dozen annotators from around the world, and while many of them were training cutting-edge chatbots, just as many were doing the mundane manual labor required to keep AI running. There are people classifying the emotional content of TikTok videos, new variants of email spam, and the precise sexual provocativeness of online ads. Others are looking at credit-card transactions and figuring out what sort of purchase they relate to or checking e-commerce recommendations and deciding whether that shirt is really something you might like after buying that other shirt. Humans are correcting customer-service chatbots, listening to Alexa requests, and categorizing the emotions of people on video calls. They are labeling food so that smart refrigerators don’t get confused by new packaging, checking automated security cameras before sounding alarms, and identifying corn for baffled autonomous tractors.\\n\\n“There’s an entire supply chain,” said Sonam Jindal, the program and research lead of the nonprofit Partnership on AI. “The general perception in the industry is that this work isn’t a critical part of development and isn’t going to be needed for long. All the excitement is around building artificial intelligence, and once we build that, it won’t be needed anymore, so why think about it? But it’s infrastructure for AI. Human intelligence is the basis of artificial intelligence, and we need to be valuing these as real jobs in the AI economy that are going to be here for a while.”\\n\\nThe data vendors behind familiar names like OpenAI, Google, and Microsoft come in different forms. There are private outsourcing companies with call-center-like offices, such as the Kenya- and Nepal-based CloudFactory, where Joe annotated for $1.20 an hour before switching to Remotasks. There are also “crowdworking” sites like Mechanical Turk and Clickworker where anyone can sign up to perform tasks. In the middle are services like Scale AI. Anyone can sign up, but everyone has to pass qualification exams and training courses and undergo performance monitoring. Annotation is big business. Scale, founded in 2016 by then-19-year-old Alexandr Wang, was valued in 2021 at $7.3 billion, making him what Forbes called “the youngest self-made billionaire,” though the magazine noted in a recent profile that his stake has fallen on secondary markets since then.\\n\\n[Image: https://cdn.vox-cdn.com/thumbor/tzXNAIWOaBlv7KbHabZQPNgOKvU=/0x0:2048x1500/2048x1500/filters:focal(1024x750:1025x751)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg]\\n\\nThis tangled supply chain is deliberately hard to map. According to people in the industry, the companies buying the data demand strict confidentiality. (This is the reason Scale cited to explain why Remotasks has a different name.) Annotation reveals too much about the systems being developed, and the huge number of workers required makes leaks difficult to prevent. Annotators are warned repeatedly not to tell anyone about their jobs, not even their friends and co-workers, but corporate aliases, project code names, and, crucially, the extreme division of labor ensure they don’t have enough information about them to talk even if they wanted to. (Most workers requested pseudonyms for fear of being booted from the platforms.) Consequently, there are no granular estimates of the number of people who work in annotation, but it is a lot, and it is growing. A recent Google Research paper gave an order-of-magnitude figure of “millions” with the potential to become “billions.”\\n\\nAutomation often unfolds in unexpected ways. Erik Duhaime, CEO of medical-data-annotation company Centaur Labs, recalled how, several years ago, prominent machine-learning engineers were predicting AI would make the job of radiologist obsolete. When that didn’t happen, conventional wisdom shifted to radiologists using AI as a tool. Neither of those is quite what he sees occurring. AI is very good at specific tasks, Duhaime said, and that leads work to be broken up and distributed across a system of specialized algorithms and to equally specialized humans. An AI system might be capable of spotting cancer, he said, giving a hypothetical example, but only in a certain type of imagery from a certain type of machine; so now, you need a human to check that the AI is being fed the right type of data and maybe another human who checks its work before passing it to another AI that writes a report, which goes to another human, and so on. “AI doesn’t replace work,” he said. “But it does change how work is organized.”\\n\\nYou might miss this if you believe AI is a brilliant, thinking machine. But if you pull back the curtain even a little, it looks more familiar, the latest iteration of a particularly Silicon Valley division of labor, in which the futuristic gleam of new technologies hides a sprawling manufacturing apparatus and the people who make it run. Duhaime reached back farther for a comparison, a digital version of the transition from craftsmen to industrial manufacturing: coherent processes broken into tasks and arrayed along assembly lines with some steps done by machines and some by humans but none resembling what came before.\\n\\nWorries about AI-driven disruption are often countered with the argument that AI automates tasks, not jobs, and that these tasks will be the dull ones, leaving people to pursue more fulfilling and human work. But just as likely, the rise of AI will look like past labor-saving technologies, maybe like the telephone or typewriter, which vanquished the drudgery of message delivering and handwriting but generated so much new correspondence, commerce, and paperwork that new offices staffed by new types of workers — clerks, accountants, typists — were required to manage it. When AI comes for your job, you may not lose it, but it might become more alien, more isolating, more tedious.\\n\\n---\\n\\nEarlier this year, I signed up for Scale AI’s Remotasks. The process was straightforward. After entering my computer specs, internet speed, and some basic contact information, I found myself in the “training center.” To access a paying task, I first had to complete an associated (unpaid) intro course.\\n\\nThe training center displayed a range of courses with inscrutable names like Glue Swimsuit and Poster Macadamia. I clicked on something called GFD Chunking, which revealed itself to be labeling clothing in social-media photos.\\n\\nThe instructions, however, were odd. For one, they basically consisted of the same direction reiterated in the idiosyncratically colored and capitalized typography of a collaged bomb threat.\\n\\n“DO LABEL items that are real and can be worn by humans or are intended to be worn by real people,” it read.\\n\\n“All items below SHOULD be labeled because they are real and can be worn by real-life humans,” it reiterated above photos of an Air Jordans ad, someone in a Kylo Ren helmet, and mannequins in dresses, over which was a lime-green box explaining, once again, “DO Label real items that can be worn by real people.”\\n\\n[Image: Remotasks instructions for labeling clothing. https://cdn.vox-cdn.com/thumbor/MHHrTeYM1ECpMGl9kVhgPdVy6QM=/0x0:2083x2083/2083x2083/filters:focal(1042x1042:1043x1043)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg]\\n\\nI skimmed to the bottom of the manual, where the instructor had written in the large bright-red font equivalent of grabbing someone by the shoulders and shaking them, “THE FOLLOWING ITEMS SHOULD NOT BE LABELED because a human could not actually put wear any of these items!” above a photo of C-3PO, Princess Jasmine from Aladdin, and a cartoon shoe with eyeballs.\\n\\nFeeling confident in my ability to distinguish between real clothes that can be worn by real people and not-real clothes that cannot, I proceeded to the test. Right away, it threw an ontological curveball: a picture of a magazine depicting photos of women in dresses. Is a photograph of clothing real clothing? No, I thought, because a human cannot wear a photograph of clothing. Wrong! As far as AI is concerned, photos of real clothes are real clothes. Next came a photo of a woman in a dimly lit bedroom taking a selfie before a full-length mirror. The blouse and shorts she’s wearing are real. What about their reflection? Also real! Reflections of real clothes are also real clothes.\\n\\nAfter an embarrassing amount of trial and error, I made it to the actual work, only to make the horrifying discovery that the instructions I’d been struggling to follow had been updated and clarified so many times that they were now a full 43 printed pages of directives: Do NOT label open suitcases full of clothes; DO label shoes but do NOT label flippers; DO label leggings but do NOT label tights; do NOT label towels even if someone is wearing it; label costumes but do NOT label armor. And so on.\\n\\nThere has been general instruction disarray across the industry, according to Milagros Miceli, a researcher at the Weizenbaum Institute in Germany who studies data work. It is in part a product of the way machine-learning systems learn. Where a human would get the concept of “shirt” with a few examples, machine-learning programs need thousands, and they need to be categorized with perfect consistency yet varied enough (polo shirts, shirts being worn outdoors, shirts hanging on a rack) that the very literal system can handle the diversity of the real world. “Imagine simplifying complex realities into something that is readable for a machine that is totally dumb,” she said.\\n\\n\\\"Once, Victor stayed up 36 hours straight labeling elbows and knees and heads in photographs of crowds — he has no idea why.\\\"\\n\\nThe act of simplifying reality for a machine results in a great deal of complexity for the human. Instruction writers must come up with rules that will get humans to categorize the world with perfect consistency. To do so, they often create categories no human would use. A human asked to tag all the shirts in a photo probably wouldn’t tag the reflection of a shirt in a mirror because they would know it is a reflection and not real. But to the AI, which has no understanding of the world, it’s all just pixels and the two are perfectly identical. Fed a dataset with some shirts labeled and other (reflected) shirts unlabeled, the model won’t work. So the engineer goes back to the vendor with an update: DO label reflections of shirts. Soon, you have a 43-page guide descending into red all-caps.\\n\\n“When you start off, the rules are relatively simple,” said a former Scale employee who requested anonymity because of an NDA. “Then they get back a thousand images and then they’re like, Wait a second, and then you have multiple engineers and they start to argue with each other. It’s very much a human thing.”\\n\\nThe job of the annotator often involves putting human understanding aside and following instructions very, very literally — to think, as one annotator said, like a robot. It’s a strange mental space to inhabit, doing your best to follow nonsensical but rigorous rules, like taking a standardized test while on hallucinogens. Annotators invariably end up confronted with confounding questions like, Is that a red shirt with white stripes or a white shirt with red stripes? Is a wicker bowl a “decorative bowl” if it’s full of apples? What color is leopard print? When instructors said to label traffic-control directors, did they also mean to label traffic-control directors eating lunch on the sidewalk? Every question must be answered, and a wrong guess could get you banned and booted to a new, totally different task with its own baffling rules.\\n\\n[Image: https://cdn.vox-cdn.com/thumbor/kQBljfwrhkJGYtW8XWVY30BSM1k=/0x0:2048x1737/2048x1737/filters:focal(1024x869:1025x870)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg]\\n\\nMost of the work on Remotasks is paid at a piece rate with a single task earning anywhere from a few cents to several dollars. Because tasks can take seconds or hours, wages are hard to predict. When Remotasks first arrived in Kenya, annotators said it paid relatively well — averaging about $5 to $10 per hour depending on the task — but the amount fell as time went on.\\n\\nScale AI spokesperson Anna Franko said that the company’s economists analyze the specifics of a project, the skills required, the regional cost of living, and other factors “to ensure fair and competitive compensation.” Former Scale employees also said pay is determined through a surge-pricing-like mechanism that adjusts for how many annotators are available and how quickly the data is needed.\\n\\nAccording to workers I spoke with and job listings, U.S.-based Remotasks annotators generally earn between $10 and $25 per hour, though some subject-matter experts can make more. By the beginning of this year, pay for the Kenyan annotators I spoke with had dropped to between $1 and $3 per hour.\\n\\nThat is, when they were making any money at all. The most common complaint about Remotasks work is its variability; it’s steady enough to be a full-time job for long stretches but too unpredictable to rely on. Annotators spend hours reading instructions and completing unpaid trainings only to do a dozen tasks and then have the project end. There might be nothing new for days, then, without warning, a totally different task appears and could last anywhere from a few hours to weeks. Any task could be their last, and they never know when the next one will come.\\n\\nThis boom-and-bust cycle results from the cadence of AI development, according to engineers and data vendors. Training a large model requires an enormous amount of annotation followed by more iterative updates, and engineers want it all as fast as possible so they can hit their target launch date. There may be monthslong demand for thousands of annotators, then for only a few hundred, then for a dozen specialists of a certain type, and then thousands again. “The question is, Who bears the cost for these fluctuations?” said Jindal of Partnership on AI. “Because right now, it’s the workers.”\\n\\n\\\"“I really am wasting my life here if I made somebody a billionaire and I’m earning a couple of bucks a week.”\\\"\\n\\nTo succeed, annotators work together. When I told Victor, who started working for Remotasks while at university in Nairobi, about my struggles with the traffic-control-directors task, he told me everyone knew to stay away from that one: too tricky, bad pay, not worth it. Like a lot of annotators, Victor uses unofficial WhatsApp groups to spread the word when a good task drops. When he figures out a new one, he starts impromptu Google Meets to show others how it’s done. Anyone can join and work together for a time, sharing tips. “It’s a culture we have developed of helping each other because we know when on your own, you can’t know all the tricks,” he said.\\n\\nBecause work appears and vanishes without warning, taskers always need to be on alert. Victor has found that projects pop up very late at night, so he is in the habit of waking every three hours or so to check his queue. When a task is there, he’ll stay awake as long as he can to work. Once, he stayed up 36 hours straight labeling elbows and knees and heads in photographs of crowds — he has no idea why. Another time, he stayed up so long his mother asked him what was wrong with his eyes. He looked in the mirror to discover they were swollen.\\n\\nAnnotators generally know only that they are training AI for companies located vaguely elsewhere, but sometimes the veil of anonymity drops — instructions mentioning a brand or a chatbot say too much. “I read and I Googled and found I am working for a 25-year-old billionaire,” said one worker, who, when we spoke, was labeling the emotions of people calling to order Domino’s pizza. “I really am wasting my life here if I made somebody a billionaire and I’m earning a couple of bucks a week.”\\n\\nVictor is a self-proclaimed “fanatic” about AI and started annotating because he wants to help bring about a fully automated post-work future. But earlier this year, someone dropped a Time story into one of his WhatsApp groups about workers training ChatGPT to recognize toxic content who were getting paid less than $2 an hour by the vendor Sama AI. “People were angry that these companies are so profitable but paying so poorly,” Victor said. He was unaware until I told him about Remotasks’ connection to Scale. Instructions for one of the tasks he worked on were nearly identical to those used by OpenAI, which meant he had likely been training ChatGPT as well, for approximately $3 per hour.\\n\\n“I remember that someone posted that we will be remembered in the future,” he said. “And somebody else replied, ‘We are being treated worse than foot soldiers. We will be remembered nowhere in the future.’ I remember that very well. Nobody will recognize the work we did or the effort we put in.”\\n\\n---\\n\\nIdentifying clothing and labeling customer-service conversations are just some of the annotation gigs available. Lately, the hottest on the market has been chatbot trainer. Because it demands specific areas of expertise or language fluency and wages are often adjusted regionally, this job tends to pay better. Certain types of specialist annotation can go for $50 or more per hour.\\n\\nA woman I’ll call Anna was searching for a job in Texas when she stumbled across a generic listing for online work and applied. It was Remotasks, and after passing an introductory exam, she was brought into a Slack room of 1,500 people who were training a project code-named Dolphin, which she later discovered to be Google DeepMind’s chatbot, Sparrow, one of the many bots competing with ChatGPT. Her job is to talk with it all day. At about $14 an hour, plus bonuses for high productivity, “it definitely beats getting paid $10 an hour at the local Dollar General store,” she said.\\n\\nAlso, she enjoys it. She has discussed science-fiction novels, mathematical paradoxes, children’s riddles, and TV shows. Sometimes the bot’s responses make her laugh; other times, she runs out of things to talk about. “Some days, my brain is just like, I literally have no idea what on earth to ask it now,” she said. “So I have a little notebook, and I’ve written about two pages of things — I just Google interesting topics — so I think I’ll be good for seven hours today, but that’s not always the case.”\\n\\nEach time Anna prompts Sparrow, it delivers two responses and she picks the best one, thereby creating something called “human-feedback data.” When ChatGPT debuted late last year, its impressively natural-seeming conversational style was credited to its having been trained on troves of internet data. But the language that fuels ChatGPT and its competitors is filtered through several rounds of human annotation. One group of contractors writes examples of how the engineers want the bot to behave, creating questions followed by correct answers, descriptions of computer programs followed by functional code, and requests for tips on committing crimes followed by polite refusals. After the model is trained on these examples, yet more contractors are brought in to prompt it and rank its responses. This is what Anna is doing with Sparrow. Exactly which criteria the raters are told to use varies — honesty, or helpfulness, or just personal preference. The point is that they are creating data on human taste, and once there’s enough of it, engineers can train a second model to mimic their preferences at scale, automating the ranking process and training their AI to act in ways humans approve of. The result is a remarkably human-seeming bot that mostly declines harmful requests and explains its AI nature with seeming self-awareness.\\n\\nPut another way, ChatGPT seems so human because it was trained by an AI that was mimicking humans who were rating an AI that was mimicking humans who were pretending to be a better version of an AI that was trained on human writing.\\n\\n[Image: https://cdn.vox-cdn.com/thumbor/BJ1voW9GJtnRC0ZSvYAl9KHBH-c=/0x0:2048x1514/2048x1514/filters:focal(1024x757:1025x758)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg]\\n\\nThis circuitous technique is called “reinforcement learning from human feedback,” or RLHF, and it’s so effective that it’s worth pausing to fully register what it doesn’t do. When annotators teach a model to be accurate, for example, the model isn’t learning to check answers against logic or external sources or about what accuracy as a concept even is. The model is still a text-prediction machine mimicking patterns in human writing, but now its training corpus has been supplemented with bespoke examples, and the model has been weighted to favor them. Maybe this results in the model extracting patterns from the part of its linguistic map labeled as accurate and producing text that happens to align with the truth, but it can also result in it mimicking the confident style and expert jargon of the accurate text while writing things that are totally wrong. There is no guarantee that the text the labelers marked as accurate is in fact accurate, and when it is, there is no guarantee that the model learns the right patterns from it.\\n\\nThis dynamic makes chatbot annotation a delicate process. It has to be rigorous and consistent because sloppy feedback, like marking material that merely sounds correct as accurate, risks training models to be even more convincing bullshitters. An early OpenAI and DeepMind joint project using RLHF, in this case to train a virtual robot hand to grab an item, resulted in also training the robot to position its hand between the object and its raters and wiggle around such that it only appeared to its human overseers to grab the item. Ranking a language model’s responses is always going to be somewhat subjective because it’s language. A text of any length will have multiple elements that could be right or wrong or, taken together, misleading. OpenAI researchers ran into this obstacle in another early RLHF paper. Trying to get their model to summarize text, the researchers found they agreed only 60 percent of the time that a summary was good. “Unlike many tasks in [machine learning] our queries do not have unambiguous ground truth,” they lamented.\\n\\nWhen Anna rates Sparrow’s responses, she’s supposed to be looking at their accuracy, helpfulness, and harmlessness while also checking that the model isn’t giving medical or financial advice or anthropomorphizing itself or running afoul of other criteria. To be useful training data, the model’s responses have to be quantifiably ranked against one another: Is a bot that helpfully tells you how to make a bomb “better” than a bot that’s so harmless it refuses to answer any questions? In one DeepMind paper, when Sparrow’s makers took a turn annotating, four researchers wound up debating whether their bot had assumed the gender of a user who asked it for relationship advice. According to Geoffrey Irving, one of DeepMind’s research scientists, the company’s researchers hold weekly annotation meetings in which they rerate data themselves and discuss ambiguous cases, consulting with ethical or subject-matter experts when a case is particularly tricky.\\n\\n\\\"There are people classifying the emotional content of TikTok videos, new variants of email spam, and the precise sexual provocativeness of online ads.\\\"\\n\\nAnna often finds herself having to choose between two bad options. “Even if they’re both absolutely, ridiculously wrong, you still have to figure out which one is better and then write words explaining why,” she said. Sometimes, when both responses are bad, she’s encouraged to write a better response herself, which she does about half the time.\\n\\nBecause feedback data is difficult to collect, it fetches a higher price. Basic preferences of the sort Anna is producing sell for about $1 each, according to people with knowledge of the industry. But if you want to train a model to do legal research, you need someone with training in law, and this gets expensive. Everyone involved is reluctant to say how much they’re spending, but in general, specialized written examples can go for hundreds of dollars, while expert ratings can cost $50 or more. One engineer told me about buying examples of Socratic dialogues for up to $300 a pop. Another told me about paying $15 for a “darkly funny limerick about a goldfish.”\\n\\nOpenAI, Microsoft, Meta, and Anthropic did not comment about how many people contribute annotations to their models, how much they are paid, or where in the world they are located. Irving of DeepMind, which is a subsidiary of Google, said the annotators working on Sparrow are paid “at least the hourly living wage” based on their location. Anna knows “absolutely nothing” about Remotasks, but Sparrow has been more open. She wasn’t the only annotator I spoke with who got more information from the AI they were training than from their employer; several others learned whom they were working for by asking their AI for its company’s terms of service. “I literally asked it, ‘What is your purpose, Sparrow?’” Anna said. It pulled up a link to DeepMind’s website and explained that it’s an AI assistant and that its creators trained it using RLHF to be helpful and safe.\\n\\n---\\n\\nUntil recently, it was relatively easy to spot bad output from a language model. It looked like gibberish. But this gets harder as the models get better — a problem called “scalable oversight.” Google inadvertently demonstrated how hard it is to catch the errors of a modern-language model when one made it into the splashy debut of its AI assistant, Bard. (It stated confidently that the James Webb Space Telescope “took the very first pictures of a planet outside of our own solar system,” which is wrong.) This trajectory means annotation increasingly requires specific skills and expertise.\\n\\nLast year, someone I’ll call Lewis was working on Mechanical Turk when, after completing a task, he received a message inviting him to apply for a platform he hadn’t heard of. It was called Taskup.ai, and its website was remarkably basic: just a navy background with text reading GET PAID FOR TASKS ON DEMAND. He applied.\\n\\nThe work paid far better than anything he had tried before, often around $30 an hour. It was more challenging, too: devising complex scenarios to trick chatbots into giving dangerous advice, testing a model’s ability to stay in character, and having detailed conversations about scientific topics so technical they required extensive research. He found the work “satisfying and stimulating.” While checking one model’s attempts to code in Python, Lewis was learning too. He couldn’t work for more than four hours at a stretch, lest he risk becoming mentally drained and making mistakes, and he wanted to keep the job.\\n\\n“If there was one thing I could change, I would just like to have more information about what happens on the other end,” he said. “We only know as much as we need to know to get work done, but if I could know more, then maybe I could get more established and perhaps pursue this as a career.”\\n\\nI spoke with eight other workers, most based in the U.S., who had similar experiences of answering surveys or completing tasks on other platforms and finding themselves recruited for Taskup.ai or several similarly generic sites, such as DataAnnotation.tech or Gethybrid.io. Often their work involved training chatbots, though with higher-quality expectations and more specialized purposes than other sites they had worked for. One was demonstrating spreadsheet macros. Another was just supposed to have conversations and rate responses according to whatever criteria she wanted. She often asked the chatbot things that had come up in conversations with her 7-year-old daughter, like “What is the largest dinosaur?” and “Write a story about a tiger.” “I haven’t fully gotten my head around what they’re trying to do with it,” she told me.\\n\\nTaskup.ai, DataAnnotation.tech, and Gethybrid.io all appear to be owned by the same company: Surge AI. Its CEO, Edwin Chen, would neither confirm nor deny the connection, but he was willing to talk about his company and how he sees annotation evolving.\\n\\n“I’ve always felt the annotation landscape is overly simplistic,” Chen said over a video call from Surge’s office. He founded Surge in 2020 after working on AI at Google, Facebook, and Twitter convinced him that crowdsourced labeling was inadequate. “We want AI to tell jokes or write really good marketing copy or help me out when I need therapy or whatnot,” Chen said. “You can’t ask five people to independently come up with a joke and combine it into a majority answer. Not everybody can tell a joke or solve a Python program. The annotation landscape needs to shift from this low-quality, low-skill mind-set to something that’s much richer and captures the range of human skills and creativity and values that we want AI systems to possess.”\\n\\n[Image: https://cdn.vox-cdn.com/thumbor/Qe4htQ4VivRXnS0BWZowjTY8hE8=/0x0:2048x1572/2048x1572/filters:focal(1024x786:1025x787)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg]\\n\\nLast year, Surge relabeled Google’s dataset classifying Reddit posts by emotion. Google had stripped each post of context and sent them to workers in India for labeling. Surge employees familiar with American internet culture found that 30 percent of the labels were wrong. Posts like “hell yeah my brother” had been classified as annoyance and “Yay, cold McDonald’s. My favorite” as love.\\n\\nSurge claims to vet its workers for qualifications — that people doing creative-writing tasks have experience with creative writing, for example — but exactly how Surge finds workers is “proprietary,” Chen said. As with Remotasks, workers often have to complete training courses, though unlike Remotasks, they are paid for it, according to the annotators I spoke with. Having fewer, better-trained workers producing higher-quality data allows Surge to compensate better than its peers, Chen said, though he declined to elaborate, saying only that people are paid “fair and ethical wages.” The workers I spoke with earned between $15 and $30 per hour, but they are a small sample of all the annotators, a group Chen said now consists of 100,000 people. The secrecy, he explained, stems from clients’ demands for confidentiality.\\n\\nSurge’s customers include OpenAI, Google, Microsoft, Meta, and Anthropic. Surge specializes in feedback and language annotation, and after ChatGPT launched, it got an influx of requests, Chen said: “I thought everybody knew the power of RLHF, but I guess people just didn’t viscerally understand.”\\n\\nThe new models are so impressive they’ve inspired another round of predictions that annotation is about to be automated. Given the costs involved, there is significant financial pressure to do so. Anthropic, Meta, and other companies have recently made strides in using AI to drastically reduce the amount of human annotation needed to guide models, and other developers have started using GPT-4 to generate training data. However, a recent paper found that GPT-4-trained models may be learning to mimic GPT’s authoritative style with even less accuracy, and so far, when improvements in AI have made one form of annotation obsolete, demand for other, more sophisticated types of labeling has gone up. This debate spilled into the open earlier this year, when Scale’s CEO, Wang, tweeted that he predicted AI labs will soon be spending as many billions of dollars on human data as they do on computing power; OpenAI’s CEO, Sam Altman, responded that data needs will decrease as AI improves.\\n\\n\\\"“I mean, what it can do is amazing,” she said of the chatbot. “But it still does some really weird shit.”\\\"\\n\\nChen is skeptical AI will reach a point where human feedback is no longer needed, but he does see annotation becoming more difficult as models improve. Like many researchers, he believes the path forward will involve AI systems helping humans oversee other AI. Surge recently collaborated with Anthropic on a proof of concept, having human labelers answer questions about a lengthy text with the help of an unreliable AI assistant, on the theory that the humans would have to feel out the weaknesses of their AI assistant and collaborate to reason their way to the correct answer. Another possibility has two AIs debating each other and a human rendering the final verdict on which is correct. “We still have yet to see really good practical implementations of this stuff, but it’s starting to become necessary because it’s getting really hard for labelers to keep up with the models,” said OpenAI research scientist John Schulman in a recent talk at Berkeley.\\n\\n“I think you always need a human to monitor what AIs are doing just because they are this kind of alien entity,” Chen said. Machine-learning systems are just too strange ever to fully trust. The most impressive models today have what, to a human, seems like bizarre weaknesses, he added, pointing out that though GPT-4 can generate complex and convincing prose, it can’t pick out which words are adjectives: “Either that or models get so good that they’re better than humans at all things, in which case, you reach your utopia and who cares?”\\n\\n---\\n\\nAs 2022 ended, Joe started hearing from his students that their task queues were often empty. Then he got an email informing him the boot camps in Kenya were closing. He continued training taskers online, but he began to worry about the future.\\n\\n“There were signs that it was not going to last long,” he said. Annotation was leaving Kenya. From colleagues he had met online, he heard tasks were going to Nepal, India, and the Philippines. “The companies shift from one region to another,” Joe said. “They don’t have infrastructure locally, so it makes them flexible to shift to regions that favor them in terms of operation cost.”\\n\\nOne way the AI industry differs from manufacturers of phones and cars is in its fluidity. The work is constantly changing, constantly getting automated away and replaced with new needs for new types of data. It’s an assembly line but one that can be endlessly and instantly reconfigured, moving to wherever there is the right combination of skills, bandwidth, and wages.\\n\\nLately, the best-paying work is in the U.S. In May, Scale started listing annotation jobs on its own website, soliciting people with experience in practically every field AI is predicted to conquer. There were listings for AI trainers with expertise in health coaching, human resources, finance, economics, data science, programming, computer science, chemistry, biology, accounting, taxes, nutrition, physics, travel, K-12 education, sports journalism, and self-help. You can make $45 an hour teaching robots law or make $25 an hour teaching them poetry. There were also listings for people with security clearance, presumably to help train military AI. Scale recently launched a defense-oriented language model called Donovan, which Wang called “ammunition in the AI war,” and won a contract to work on the Army’s robotic-combat-vehicle program.\\n\\nAnna is still training chatbots in Texas. Colleagues have been turned into reviewers and Slack admins — she isn’t sure why, but it has given her hope that the gig could be a longer-term career. One thing she isn’t worried about is being automated out of a job. “I mean, what it can do is amazing,” she said of the chatbot. “But it still does some really weird shit.”\\n\\nWhen Remotasks first arrived in Kenya, Joe thought annotation could be a good career. Even after the work moved elsewhere, he was determined to make it one. There were thousands of people in Nairobi who knew how to do the work, he reasoned — he had trained many of them, after all. Joe rented office space in the city and began sourcing contracts: a job annotating blueprints for a construction company, another labeling fruits despoiled by insects for some sort of agricultural project, plus the usual work of annotating for self-driving cars and e-commerce.\\n\\nBut he has found his vision difficult to achieve. He has just one full-time employee, down from two. “We haven’t been having a consistent flow of work,” he said. There are weeks with nothing to do because customers are still collecting data, and when they’re done, he has to bring in short-term contractors to meet their deadlines: “Clients don’t care whether we have consistent work or not. So long as the datasets have been completed, then that’s the end of that.”\\n\\nRather than let their skills go to waste, other taskers decided to chase the work wherever it went. They rented proxy servers to disguise their locations and bought fake IDs to pass security checks so they could pretend to work from Singapore, the Netherlands, Mississippi, or wherever the tasks were flowing. It’s a risky business. Scale has become increasingly aggressive about suspending accounts caught disguising their location, according to multiple taskers. It was during one of these crackdowns that my account got banned, presumably because I had been using a VPN to see what workers in other countries were seeing, and all $1.50 or so of my earnings were seized.\\n\\n“These days, we have become a bit cunning because we noticed that in other countries they are paying well,” said Victor, who was earning double the Kenyan rate by tasking in Malaysia. “You do it cautiously.”\\n\\nAnother Kenyan annotator said that after his account got suspended for mysterious reasons, he decided to stop playing by the rules. Now, he runs multiple accounts in multiple countries, tasking wherever the pay is best. He works fast and gets high marks for quality, he said, thanks to ChatGPT. The bot is wonderful, he said, letting him speed through $10 tasks in a matter of minutes. When we spoke, he was having it rate another chatbot’s responses according to seven different criteria, one AI training the other.\\n\",\"stream\":null,\"visibleNetworkIds\":[],\"scheduledForExpirationAt\":null}}}]},\"uid\":\"Entry:e6a44b77-f363-473b-9651-3e323f6f4fd9\",\"mostPopular\":[{\"author\":{\"fullName\":\"Tom Warren\"},\"publishDate\":\"2023-07-11T15:06:24\",\"title\":\"Microsoft wins FTC fight to buy Activision Blizzard\",\"url\":\"https://www.theverge.com/2023/7/11/23779039/microsoft-activision-blizzard-ftc-trial-win\",\"uid\":\"0\"},{\"author\":{\"fullName\":\"Wes Davis\"},\"publishDate\":\"2023-07-09T18:14:30\",\"title\":\"Sarah Silverman is suing OpenAI and Meta for copyright infringement\",\"url\":\"https://www.theverge.com/2023/7/9/23788741/sarah-silverman-openai-meta-chatgpt-llama-copyright-infringement-chatbots-artificial-intelligence-ai\",\"uid\":\"1\"},{\"author\":{\"fullName\":\"Jess Weatherbed\"},\"publishDate\":\"2023-07-10T12:26:08\",\"title\":\"The Elon Musk private jet tracker resurfaces on Threads and immediately goads Mark Zuckerberg\",\"url\":\"https://www.theverge.com/2023/7/10/23789481/elon-musk-private-jet-tracker-threads-twitter-bot-elonjet\",\"uid\":\"2\"},{\"author\":{\"fullName\":\"Jay Peters\"},\"publishDate\":\"2023-07-10T07:20:00\",\"title\":\"Instagram’s Threads surpasses 100 million users\",\"url\":\"https://www.theverge.com/2023/7/10/23787453/meta-instagram-threads-100-million-users-milestone\",\"uid\":\"3\"},{\"author\":{\"fullName\":\"Emma Roth\"},\"publishDate\":\"2023-07-10T20:09:13\",\"title\":\"That Google memo about having ‘no moat’ in AI was real — and Google’s AI boss disagrees with it\",\"url\":\"https://www.theverge.com/2023/7/10/23790132/google-memo-moat-ai-leak-demis-hassabis\",\"uid\":\"4\"}],\"navProps\":{\"navContainerClassName\":\"\",\"campaignGroup\":null,\"stickyNav\":true,\"logoColor\":\"blurpleBlack\",\"lightText\":true},\"_sentryTraceData\":\"52a1dbc498364fc9b75cc89c9a635310-a707108e57115b06-0\",\"_sentryBaggage\":\"sentry-environment=production,sentry-release=wU_WuKX-JRgzsS4AEFUjj,sentry-transaction=%2Fentry%2Ffeature%2F%5Buid%5D,sentry-public_key=6547365f9d98454ba8daa58e42013d33,sentry-trace_id=52a1dbc498364fc9b75cc89c9a635310,sentry-sample_rate=0\"},\"__N_SSP\":true},\"page\":\"/entry/feature/[uid]\",\"query\":{\"uid\":\"Entry:e6a44b77-f363-473b-9651-3e323f6f4fd9\"},\"buildId\":\"wU_WuKX-JRgzsS4AEFUjj\",\"isFallback\":false,\"gssp\":true,\"scriptLoader\":[{\"src\":\"https://theverge.coral.coralproject.net/assets/js/count.js?v=0\",\"strategy\":\"lazyOnload\",\"className\":\"coral-script\",\"defer\":true}]}</script></body></html>","oembed":false,"readabilityObject":{"title":"Inside the AI Factory","content":"<div id=\"readability-page-1\" class=\"page\"><div id=\"content\"><p><small><em>This article is a collaboration between </em></small><a href=\"https://nymag.com/intelligencer/article/ai-artificial-intelligence-humans-technology-business-factory.html\"><small>New York Magazine</small></a><small><em> and The Verge.</em></small></p><p><strong>A few months</strong> after graduating from college in Nairobi, a 30-year-old I’ll call Joe got a job as an annotator — the tedious work of processing the raw information used to train artificial intelligence. AI learns by finding patterns in enormous quantities of data, but first that data has to be sorted and tagged by people, a vast workforce mostly hidden behind the machines. In Joe’s case, he was labeling footage for self-driving cars — identifying every vehicle, pedestrian, cyclist, anything a driver needs to be aware of — frame by frame and from every possible camera angle. It’s difficult and repetitive work. A several-second blip of footage took eight hours to annotate, for which Joe was paid about $10.</p><p>Then, in 2019, an opportunity arose: Joe could make four times as much running an annotation boot camp for a new company that was hungry for labelers. Every two weeks, 50 new recruits would file into an office building in Nairobi to begin their apprenticeships. There seemed to be limitless demand for the work. They would be asked to categorize clothing seen in mirror selfies, look through the eyes of robot vacuum cleaners to determine which rooms they were in, and draw squares around lidar scans of motorcycles. Over half of Joe’s students usually dropped out before the boot camp was finished. “Some people don’t know how to stay in one place for long,” he explained with gracious understatement. Also, he acknowledged, “it is very boring.”</p><p>But it was a job in a place where jobs were scarce, and Joe turned out hundreds of graduates. After boot camp, they went home to work alone in their bedrooms and kitchens, forbidden from telling anyone what they were working on, which wasn’t really a problem because they rarely knew themselves. Labeling objects for self-driving cars was obvious, but what about categorizing whether snippets of distorted dialogue were spoken by a robot or a human? Uploading photos of yourself staring into a webcam with a blank expression, then with a grin, then wearing a motorcycle helmet? Each project was such a small component of some larger process that it was difficult to say what they were actually training AI to do. Nor did the names of the projects offer any clues: Crab Generation, Whale Segment, Woodland Gyro, and Pillbox Bratwurst. They were non sequitur code names for non sequitur work.</p><p>As for the company employing them, most knew it only as Remotasks, a website offering work to anyone fluent in English. Like most of the annotators I spoke with, Joe was unaware until I told him that Remotasks is the worker-facing subsidiary of a company called Scale AI, a multibillion-dollar Silicon Valley data vendor that counts OpenAI and the U.S. military among its customers. Neither Remotasks’ or Scale’s website mentions the other.</p><p>Much of the public response to language models like OpenAI’s ChatGPT has focused on all the jobs they appear poised to automate. But behind even the most impressive AI system are people — huge numbers of people labeling data to train it and clarifying data when it gets confused. Only the companies that can afford to buy this data can compete, and those that get it are highly motivated to keep it secret. The result is that, with few exceptions, little is known about the information shaping these systems’ behavior, and even less is known about the people doing the shaping.</p><p>For Joe’s students, it was work stripped of all its normal trappings: a schedule, colleagues, knowledge of what they were working on or whom they were working for. In fact, they rarely called it work at all — just “tasking.” They were taskers.</p><p>The anthropologist David Graeber defines “bullshit jobs” as employment without meaning or purpose, work that should be automated but for reasons of bureaucracy or status or inertia is not. These AI jobs are their bizarro twin: work that people want to automate, and often think is already automated, yet still requires a human stand-in. The jobs have a purpose; it’s just that workers often have no idea what it is.</p><p>The current AI boom — the convincingly human-sounding chatbots, the artwork that can be generated from simple prompts, and the multibillion-dollar valuations of the companies behind these technologies — began with an unprecedented feat of tedious and repetitive labor.</p><p>In 2007, the AI researcher Fei-Fei Li, then a professor at Princeton, suspected the key to improving image-recognition neural networks, a method of machine learning that had been languishing for years, was training on more data — millions of labeled images rather than tens of thousands. The problem was that it would take decades and millions of dollars for her team of undergrads to label that many photos.</p><p>Li found thousands of workers on Mechanical Turk, Amazon’s crowdsourcing platform where people around the world complete small tasks for cheap. The resulting annotated dataset, called ImageNet, enabled breakthroughs in machine learning that revitalized the field and ushered in a decade of progress.</p><p>Annotation remains a foundational part of making AI, but there is often a sense among engineers that it’s a passing, inconvenient prerequisite to the more glamorous work of building models. You collect as much labeled data as you can get as cheaply as possible to train your model, and if it works, at least in theory, you no longer need the annotators. But annotation is never really finished. Machine-learning systems are what researchers call “brittle,” prone to fail when encountering something that isn’t well represented in their training data. These failures, called “edge cases,” can have serious consequences. In 2018, an Uber self-driving test car killed a woman because, though it was programmed to avoid cyclists and pedestrians, it didn’t know what to make of someone walking a bike across the street. The more AI systems are put out into the world to dispense legal advice and medical help, the more edge cases they will encounter and the more humans will be needed to sort them. Already, this has given rise to a global industry staffed by people like Joe who use their uniquely human faculties to help the machines.</p><div><p>Is that a red shirt with white stripes or a white shirt with red stripes? Is a wicker bowl a “decorative bowl” if it’s full of apples? What color is leopard print?</p></div><p>Over the past six months, I spoke with more than two dozen annotators from around the world, and while many of them were training cutting-edge chatbots, just as many were doing the mundane manual labor required to keep AI running. There are people classifying the emotional content of TikTok videos, new variants of email spam, and the precise sexual provocativeness of online ads. Others are looking at credit-card transactions and figuring out what sort of purchase they relate to or checking e-commerce recommendations and deciding whether that shirt is really something you might like after buying that other shirt. Humans are correcting customer-service chatbots, listening to Alexa requests, and categorizing the emotions of people on video calls. They are labeling food so that smart refrigerators don’t get confused by new packaging, checking automated security cameras before sounding alarms, and identifying corn for baffled autonomous tractors.</p><p>“There’s an entire supply chain,” said Sonam Jindal, the program and research lead of the nonprofit Partnership on AI. “The general perception in the industry is that this work isn’t a critical part of development and isn’t going to be needed for long. All the excitement is around building artificial intelligence, and once we build that, it won’t be needed anymore, so why think about it? But it’s infrastructure for AI. Human intelligence is the basis of artificial intelligence, and we need to be valuing these as real jobs in the AI economy that are going to be here for a while.”</p><p>The data vendors behind familiar names like OpenAI, Google, and Microsoft come in different forms. There are private outsourcing companies with call-center-like offices, such as the Kenya- and Nepal-based CloudFactory, where Joe annotated for $1.20 an hour before switching to Remotasks. There are also “crowdworking” sites like Mechanical Turk and Clickworker where anyone can sign up to perform tasks. In the middle are services like Scale AI. Anyone can sign up, but everyone has to pass qualification exams and training courses and undergo performance monitoring. Annotation is big business. Scale, founded in 2016 by then-19-year-old Alexandr Wang, was valued in 2021 at $7.3 billion, making him what <em>Forbes</em> called “the youngest self-made billionaire,” though the magazine noted in a recent profile that his stake has fallen on secondary markets since then.</p><div role=\"button\" aria-label=\"Zoom\" tabindex=\"0\"><figure><div><p><span><img alt=\"\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" sizes=\"(max-width: 1023px) 100vw, 744px\" srcset=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/376x275/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/384x281/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/415x304/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/480x352/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/540x396/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/640x469/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/750x549/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/828x606/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/1080x791/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/1200x879/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/1440x1055/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/1920x1406/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/2048x1500/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/2400x1758/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg 2400w\" src=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1500/2400x1758/filters:focal(1024x750:1025x751):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg\" data-old-src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\"></span></p></div></figure></div><p>This tangled supply chain is deliberately hard to map. According to people in the industry, the companies buying the data demand strict confidentiality. (This is the reason Scale cited to explain why Remotasks has a different name.) Annotation reveals too much about the systems being developed, and the huge number of workers required makes leaks difficult to prevent. Annotators are warned repeatedly not to tell anyone about their jobs, not even their friends and co-workers, but corporate aliases, project code names, and, crucially, the extreme division of labor ensure they don’t have enough information about them to talk even if they wanted to. (Most workers requested pseudonyms for fear of being booted from the platforms.) Consequently, there are no granular estimates of the number of people who work in annotation, but it is a lot, and it is growing. A recent Google Research paper gave an order-of-magnitude figure of “millions” with the potential to become “billions.”</p><p>Automation often unfolds in unexpected ways. Erik Duhaime, CEO of medical-data-annotation company Centaur Labs, recalled how, several years ago, prominent machine-learning engineers were predicting AI would make the job of radiologist obsolete. When that didn’t happen, conventional wisdom shifted to radiologists using AI as a tool. Neither of those is quite what he sees occurring. AI is very good at specific tasks, Duhaime said, and that leads work to be broken up and distributed across a system of specialized algorithms and to equally specialized humans. An AI system might be capable of spotting cancer, he said, giving a hypothetical example, but only in a certain type of imagery from a certain type of machine; so now, you need a human to check that the AI is being fed the right type of data and maybe another human who checks its work before passing it to another AI that writes a report, which goes to another human, and so on. “AI doesn’t replace work,” he said. “But it does change how work is organized.”</p><p>You might miss this if you believe AI is a brilliant, thinking machine. But if you pull back the curtain even a little, it looks more familiar, the latest iteration of a particularly Silicon Valley division of labor, in which the futuristic gleam of new technologies hides a sprawling manufacturing apparatus and the people who make it run. Duhaime reached back farther for a comparison, a digital version of the transition from craftsmen to industrial manufacturing: coherent processes broken into tasks and arrayed along assembly lines with some steps done by machines and some by humans but none resembling what came before.</p><p>Worries about AI-driven disruption are often countered with the argument that AI automates tasks, not jobs, and that these tasks will be the dull ones, leaving people to pursue more fulfilling and human work. But just as likely, the rise of AI will look like past labor-saving technologies, maybe like the telephone or typewriter, which vanquished the drudgery of message delivering and handwriting but generated so much new correspondence, commerce, and paperwork that new offices staffed by new types of workers — clerks, accountants, typists — were required to manage it. When AI comes for your job, you may not lose it, but it might become more alien, more isolating, more tedious.</p><p>Earlier this year, I signed up for Scale AI’s Remotasks. The process was straightforward. After entering my computer specs, internet speed, and some basic contact information, I found myself in the “training center.” To access a paying task, I first had to complete an associated (unpaid) intro course.</p><p>The training center displayed a range of courses with inscrutable names like Glue Swimsuit and Poster Macadamia. I clicked on something called GFD Chunking, which revealed itself to be labeling clothing in social-media photos.</p><p>The instructions, however, were odd. For one, they basically consisted of the same direction reiterated in the idiosyncratically colored and capitalized typography of a collaged bomb threat.</p><p>“DO LABEL items that are real and can be worn by humans or are intended to be worn by real people,” it read.</p><p>“All items below SHOULD be labeled because they are real and can be worn by real-life humans,” it reiterated above photos of an Air Jordans ad, someone in a Kylo Ren helmet, and mannequins in dresses, over which was a lime-green box explaining, once again, “DO Label real items that can be worn by real people.”</p><div><div role=\"button\" aria-label=\"Zoom\" tabindex=\"0\"><figure><div><p><span><img alt=\"Remotasks instructions for labeling clothing.&amp;nbsp;\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" sizes=\"(max-width: 1023px) 100vw, 744px\" srcset=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/376x376/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/384x384/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/415x415/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/480x480/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/540x540/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/640x640/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/750x750/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/828x828/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/1080x1080/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/1200x1200/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/1440x1440/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/1920x1920/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/2048x2048/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/2400x2400/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg 2400w\" src=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2083x2083/2400x2400/filters:focal(1042x1042:1043x1043):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg\" data-old-src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\"></span></p></div></figure></div><p><figcaption>Remotasks instructions for labeling clothing.</figcaption></p></div><p>I skimmed to the bottom of the manual, where the instructor had written in the large bright-red font equivalent of grabbing someone by the shoulders and shaking them, “THE FOLLOWING ITEMS SHOULD NOT BE LABELED because a human could not actually put wear any of these items!” above a photo of C-3PO, Princess Jasmine from <em>Aladdin, </em>and a cartoon shoe with eyeballs.</p><p>Feeling confident in my ability to distinguish between real clothes that can be worn by real people and not-real clothes that cannot, I proceeded to the test. Right away, it threw an ontological curveball: a picture of a magazine depicting photos of women in dresses. Is a photograph of clothing real clothing? <em>No,</em> I thought, <em>because a human cannot wear a photograph of clothing.</em> Wrong! As far as AI is concerned, photos of real clothes are real clothes. Next came a photo of a woman in a dimly lit bedroom taking a selfie before a full-length mirror. The blouse and shorts she’s wearing are real. What about their reflection? Also real! Reflections of real clothes are also real clothes.</p><p>After an embarrassing amount of trial and error, I made it to the actual work, only to make the horrifying discovery that the instructions I’d been struggling to follow had been updated and clarified so many times that they were now a full 43 printed pages of directives: Do NOT label open suitcases full of clothes; DO label shoes but do NOT label flippers; DO label leggings but do NOT label tights; do NOT label towels even if someone is wearing it; label costumes but do NOT label armor. And so on.</p><p>There has been general instruction disarray across the industry, according to Milagros Miceli, a researcher at the Weizenbaum Institute in Germany who studies data work. It is in part a product of the way machine-learning systems learn. Where a human would get the concept of “shirt” with a few examples, machine-learning programs need thousands, and they need to be categorized with perfect consistency yet varied enough (polo shirts, shirts being worn outdoors, shirts hanging on a rack) that the very literal system can handle the diversity of the real world. “Imagine simplifying complex realities into something that is readable for a machine that is totally dumb,” she said.</p><div><p>Once, Victor stayed up 36 hours straight labeling elbows and knees and heads in photographs of crowds — he has no idea why.</p></div><p>The act of simplifying reality for a machine results in a great deal of complexity for the human. Instruction writers must come up with rules that will get humans to categorize the world with perfect consistency. To do so, they often create categories no human would use. A human asked to tag all the shirts in a photo probably wouldn’t tag the reflection of a shirt in a mirror because they would know it is a reflection and not real. But to the AI, which has no understanding of the world, it’s all just pixels and the two are perfectly identical. Fed a dataset with some shirts labeled and other (reflected) shirts unlabeled, the model won’t work. So the engineer goes back to the vendor with an update: DO label reflections of shirts. Soon, you have a 43-page guide descending into red all-caps.</p><p>“When you start off, the rules are relatively simple,” said a former Scale employee who requested anonymity because of an NDA. “Then they get back a thousand images and then they’re like, <em>Wait a second, </em>and then you have multiple engineers and they start to argue with each other. It’s very much a human thing.”</p><p>The job of the annotator often involves putting human understanding aside and following instructions very, <em>very</em> literally — to think, as one annotator said, like a robot. It’s a strange mental space to inhabit, doing your best to follow nonsensical but rigorous rules, like taking a standardized test while on hallucinogens. Annotators invariably end up confronted with confounding questions like, Is that a red shirt with white stripes or a white shirt with red stripes? Is a wicker bowl a “decorative bowl” if it’s full of apples? What color is leopard print? When instructors said to label traffic-control directors, did they also mean to label traffic-control directors eating lunch on the sidewalk? Every question must be answered, and a wrong guess could get you banned and booted to a new, totally different task with its own baffling rules.</p><div role=\"button\" aria-label=\"Zoom\" tabindex=\"0\"><figure><div><p><span><img alt=\"\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" sizes=\"(max-width: 1023px) 100vw, 744px\" srcset=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/376x319/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/384x326/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/415x352/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/480x407/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/540x458/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/640x543/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/750x636/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/828x702/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/1080x916/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/1200x1018/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/1440x1221/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/1920x1628/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/2048x1737/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/2400x2036/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg 2400w\" src=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1737/2400x2036/filters:focal(1024x869:1025x870):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg\" data-old-src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\"></span></p></div></figure></div><p>Most of the work on Remotasks is paid at a piece rate with a single task earning anywhere from a few cents to several dollars. Because tasks can take seconds or hours, wages are hard to predict. When Remotasks first arrived in Kenya, annotators said it paid relatively well — averaging about $5 to $10 per hour depending on the task — but the amount fell as time went on.</p><p>Scale AI spokesperson Anna Franko said that the company’s economists analyze the specifics of a project, the skills required, the regional cost of living, and other factors “to ensure fair and competitive compensation.” Former Scale employees also said pay is determined through a surge-pricing-like mechanism that adjusts for how many annotators are available and how quickly the data is needed.</p><p>According to workers I spoke with and job listings, U.S.-based Remotasks annotators generally earn between $10 and $25 per hour, though some subject-matter experts can make more. By the beginning of this year, pay for the Kenyan annotators I spoke with had dropped to between $1 and $3 per hour.</p><p>That is, when they were making any money at all. The most common complaint about Remotasks work is its variability; it’s steady enough to be a full-time job for long stretches but too unpredictable to rely on. Annotators spend hours reading instructions and completing unpaid trainings only to do a dozen tasks and then have the project end. There might be nothing new for days, then, without warning, a totally different task appears and could last anywhere from a few hours to weeks. Any task could be their last, and they never know when the next one will come.</p><p>This boom-and-bust cycle results from the cadence of AI development, according to engineers and data vendors. Training a large model requires an enormous amount of annotation followed by more iterative updates, and engineers want it all as fast as possible so they can hit their target launch date. There may be monthslong demand for thousands of annotators, then for only a few hundred, then for a dozen specialists of a certain type, and then thousands again. “The question is, Who bears the cost for these fluctuations?” said Jindal of Partnership on AI. “Because right now, it’s the workers.”</p><div><p>“I really am wasting my life here if I made somebody a billionaire and I’m earning a couple of bucks a week.”</p></div><p>To succeed, annotators work together. When I told Victor, who started working for Remotasks while at university in Nairobi, about my struggles with the traffic-control-directors task, he told me everyone knew to stay away from that one: too tricky, bad pay, not worth it. Like a lot of annotators, Victor uses unofficial WhatsApp groups to spread the word when a good task drops. When he figures out a new one, he starts impromptu Google Meets to show others how it’s done. Anyone can join and work together for a time, sharing tips. “It’s a culture we have developed of helping each other because we know when on your own, you can’t know all the tricks,” he said.</p><p>Because work appears and vanishes without warning, taskers always need to be on alert. Victor has found that projects pop up very late at night, so he is in the habit of waking every three hours or so to check his queue. When a task is there, he’ll stay awake as long as he can to work. Once, he stayed up 36 hours straight labeling elbows and knees and heads in photographs of crowds — he has no idea why. Another time, he stayed up so long his mother asked him what was wrong with his eyes. He looked in the mirror to discover they were swollen.</p><p>Annotators generally know only that they are training AI for companies located vaguely elsewhere, but sometimes the veil of anonymity drops — instructions mentioning a brand or a chatbot say too much. “I read and I Googled and found I am working for a 25-year-old billionaire,” said one worker, who, when we spoke, was labeling the emotions of people calling to order Domino’s pizza. “I really am wasting my life here if I made somebody a billionaire and I’m earning a couple of bucks a week.”</p><p>Victor is a self-proclaimed “fanatic” about AI and started annotating because he wants to help bring about a fully automated post-work future. But earlier this year, someone dropped a <em>Time</em> story into one of his WhatsApp groups about workers training ChatGPT to recognize toxic content who were getting paid less than $2 an hour by the vendor Sama AI. “People were angry that these companies are so profitable but paying so poorly,” Victor said. He was unaware until I told him about Remotasks’ connection to Scale. Instructions for one of the tasks he worked on were nearly identical to those used by OpenAI, which meant he had likely been training ChatGPT as well, for approximately $3 per hour.</p><p>“I remember that someone posted that we will be remembered in the future,” he said. “And somebody else replied, ‘We are being treated worse than foot soldiers. We will be remembered nowhere in the future.’ I remember that very well. Nobody will recognize the work we did or the effort we put in.”</p><p>Identifying clothing and labeling customer-service conversations are just some of the annotation gigs available. Lately, the hottest on the market has been chatbot trainer. Because it demands specific areas of expertise or language fluency and wages are often adjusted regionally, this job tends to pay better. Certain types of specialist annotation can go for $50 or more per hour.</p><p>A woman I’ll call Anna was searching for a job in Texas when she stumbled across a generic listing for online work and applied. It was Remotasks, and after passing an introductory exam, she was brought into a Slack room of 1,500 people who were training a project code-named Dolphin, which she later discovered to be Google DeepMind’s chatbot, Sparrow, one of the many bots competing with ChatGPT. Her job is to talk with it all day. At about $14 an hour, plus bonuses for high productivity, “it definitely beats getting paid $10 an hour at the local Dollar General store,” she said.</p><p>Also, she enjoys it. She has discussed science-fiction novels, mathematical paradoxes, children’s riddles, and TV shows. Sometimes the bot’s responses make her laugh; other times, she runs out of things to talk about. “Some days, my brain is just like, <em>I literally have no idea what on earth to ask it now,</em>” she said. “So I have a little notebook, and I’ve written about two pages of things — I just Google interesting topics — so I think I’ll be good for seven hours today, but that’s not always the case.”</p><p>Each time Anna prompts Sparrow, it delivers two responses and she picks the best one, thereby creating something called “human-feedback data.” When ChatGPT debuted late last year, its impressively natural-seeming conversational style was credited to its having been trained on troves of internet data. But the language that fuels ChatGPT and its competitors is filtered through several rounds of human annotation. One group of contractors writes examples of how the engineers want the bot to behave, creating questions followed by correct answers, descriptions of computer programs followed by functional code, and requests for tips on committing crimes followed by polite refusals. After the model is trained on these examples, yet more contractors are brought in to prompt it and rank its responses. This is what Anna is doing with Sparrow. Exactly which criteria the raters are told to use varies — honesty, or helpfulness, or just personal preference. The point is that they are creating data on human taste, and once there’s enough of it, engineers can train a second model to mimic their preferences at scale, automating the ranking process and training their AI to act in ways humans approve of. The result is a remarkably human-seeming bot that mostly declines harmful requests and explains its AI nature with seeming self-awareness.</p><p>Put another way, ChatGPT seems so human because it was trained by an AI that was mimicking humans who were rating an AI that was mimicking humans who were pretending to be a better version of an AI that was trained on human writing.</p><div role=\"button\" aria-label=\"Zoom\" tabindex=\"0\"><figure><div><p><span><img alt=\"\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" sizes=\"(max-width: 1023px) 100vw, 744px\" srcset=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/376x278/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/384x284/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/415x307/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/480x355/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/540x399/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/640x473/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/750x554/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/828x612/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/1080x798/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/1200x887/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/1440x1065/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/1920x1419/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/2048x1514/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/2400x1774/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg 2400w\" src=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1514/2400x1774/filters:focal(1024x757:1025x758):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg\" data-old-src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\"></span></p></div></figure></div><p>This circuitous technique is called “reinforcement learning from human feedback,” or RLHF, and it’s so effective that it’s worth pausing to fully register what it doesn’t do. When annotators teach a model to be accurate, for example, the model isn’t learning to check answers against logic or external sources or about what accuracy as a concept even is. The model is still a text-prediction machine mimicking patterns in human writing, but now its training corpus has been supplemented with bespoke examples, and the model has been weighted to favor them. Maybe this results in the model extracting patterns from the part of its linguistic map labeled as accurate and producing text that happens to align with the truth, but it can also result in it mimicking the confident style and expert jargon of the accurate text while writing things that are totally wrong. There is no guarantee that the text the labelers marked as accurate is in fact accurate, and when it is, there is no guarantee that the model learns the right patterns from it.</p><p>This dynamic makes chatbot annotation a delicate process. It has to be rigorous and consistent because sloppy feedback, like marking material that merely sounds correct as accurate, risks training models to be even more convincing bullshitters. An early OpenAI and DeepMind joint project using RLHF, in this case to train a virtual robot hand to grab an item, resulted in also training the robot to position its hand between the object and its raters and wiggle around such that it only appeared to its human overseers to grab the item. Ranking a language model’s responses is always going to be somewhat subjective because it’s language. A text of any length will have multiple elements that could be right or wrong or, taken together, misleading. OpenAI researchers ran into this obstacle in another early RLHF paper. Trying to get their model to summarize text, the researchers found they agreed only 60 percent of the time that a summary was good. “Unlike many tasks in [machine learning] our queries do not have unambiguous ground truth,” they lamented.</p><p>When Anna rates Sparrow’s responses, she’s supposed to be looking at their accuracy, helpfulness, and harmlessness while also checking that the model isn’t giving medical or financial advice or anthropomorphizing itself or running afoul of other criteria. To be useful training data, the model’s responses have to be quantifiably ranked against one another: Is a bot that helpfully tells you how to make a bomb “better” than a bot that’s so harmless it refuses to answer any questions? In one DeepMind paper, when Sparrow’s makers took a turn annotating, four researchers wound up debating whether their bot had assumed the gender of a user who asked it for relationship advice. According to Geoffrey Irving, one of DeepMind’s research scientists, the company’s researchers hold weekly annotation meetings in which they rerate data themselves and discuss ambiguous cases, consulting with ethical or subject-matter experts when a case is particularly tricky.</p><div><p>There are people classifying the emotional content of TikTok videos, new variants of email spam, and the precise sexual provocativeness of online ads.</p></div><p>Anna often finds herself having to choose between two bad options. “Even if they’re both absolutely, ridiculously wrong, you still have to figure out which one is better and then write words explaining why,” she said. Sometimes, when both responses are bad, she’s encouraged to write a better response herself, which she does about half the time.</p><p>Because feedback data is difficult to collect, it fetches a higher price. Basic preferences of the sort Anna is producing sell for about $1 each, according to people with knowledge of the industry. But if you want to train a model to do legal research, you need someone with training in law, and this gets expensive. Everyone involved is reluctant to say how much they’re spending, but in general, specialized written examples can go for hundreds of dollars, while expert ratings can cost $50 or more. One engineer told me about buying examples of Socratic dialogues for up to $300 a pop. Another told me about paying $15 for a “darkly funny limerick about a goldfish.”</p><p>OpenAI, Microsoft, Meta, and Anthropic did not comment about how many people contribute annotations to their models, how much they are paid, or where in the world they are located. Irving of DeepMind, which is a subsidiary of Google, said the annotators working on Sparrow are paid “at least the hourly living wage” based on their location. Anna knows “absolutely nothing” about Remotasks, but Sparrow has been more open. She wasn’t the only annotator I spoke with who got more information from the AI they were training than from their employer; several others learned whom they were working for by asking their AI for its company’s terms of service. “I literally asked it, ‘What is your purpose, Sparrow?’” Anna said. It pulled up a link to DeepMind’s website and explained that it’s an AI assistant and that its creators trained it using RLHF to be helpful and safe.</p><p>Until recently, it was relatively easy to spot bad output from a language model. It looked like gibberish. But this gets harder as the models get better — a problem called “scalable oversight.” Google inadvertently demonstrated how hard it is to catch the errors of a modern-language model when one made it into the splashy debut of its AI assistant, Bard. (It stated confidently that the James Webb Space Telescope “took the very first pictures of a planet outside of our own solar system,” which is wrong.) This trajectory means annotation increasingly requires specific skills and expertise.</p><p>Last year, someone I’ll call Lewis was working on Mechanical Turk when, after completing a task, he received a message inviting him to apply for a platform he hadn’t heard of. It was called Taskup.ai, and its website was remarkably basic: just a navy background with text reading GET PAID FOR TASKS ON DEMAND. He applied.</p><p>The work paid far better than anything he had tried before, often around $30 an hour. It was more challenging, too: devising complex scenarios to trick chatbots into giving dangerous advice, testing a model’s ability to stay in character, and having detailed conversations about scientific topics so technical they required extensive research. He found the work “satisfying and stimulating.” While checking one model’s attempts to code in Python, Lewis was learning too. He couldn’t work for more than four hours at a stretch, lest he risk becoming mentally drained and making mistakes, and he wanted to keep the job.</p><p>“If there was one thing I could change, I would just like to have more information about what happens on the other end,” he said. “We only know as much as we need to know to get work done, but if I could know more, then maybe I could get more established and perhaps pursue this as a career.”</p><p>I spoke with eight other workers, most based in the U.S., who had similar experiences of answering surveys or completing tasks on other platforms and finding themselves recruited for Taskup.ai or several similarly generic sites, such as DataAnnotation.tech or Gethybrid.io. Often their work involved training chatbots, though with higher-quality expectations and more specialized purposes than other sites they had worked for. One was demonstrating spreadsheet macros. Another was just supposed to have conversations and rate responses according to whatever criteria she wanted. She often asked the chatbot things that had come up in conversations with her 7-year-old daughter, like “What is the largest dinosaur?” and “Write a story about a tiger.” “I haven’t fully gotten my head around what they’re trying to do with it,” she told me.</p><p>Taskup.ai, DataAnnotation.tech, and Gethybrid.io all appear to be owned by the same company: Surge AI. Its CEO, Edwin Chen, would neither confirm nor deny the connection, but he was willing to talk about his company and how he sees annotation evolving.</p><p>“I’ve always felt the annotation landscape is overly simplistic,” Chen said over a video call from Surge’s office. He founded Surge in 2020 after working on AI at Google, Facebook, and Twitter convinced him that crowdsourced labeling was inadequate. “We want AI to tell jokes or write really good marketing copy or help me out when I need therapy or whatnot,” Chen said. “You can’t ask five people to independently come up with a joke and combine it into a majority answer. Not everybody can tell a joke or solve a Python program. The annotation landscape needs to shift from this low-quality, low-skill mind-set to something that’s much richer and captures the range of human skills and creativity and values that we want AI systems to possess.”</p><div role=\"button\" aria-label=\"Zoom\" tabindex=\"0\"><figure><div><p><span><img alt=\"\" loading=\"lazy\" decoding=\"async\" data-nimg=\"fill\" sizes=\"(max-width: 1023px) 100vw, 744px\" srcset=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/376x289/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 376w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/384x295/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 384w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/415x319/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 415w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/480x368/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 480w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/540x414/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 540w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/640x491/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 640w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/750x576/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 750w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/828x636/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 828w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/1080x829/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 1080w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/1200x921/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 1200w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/1440x1105/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 1440w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/1920x1474/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 1920w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/2048x1572/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 2048w, https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/2400x1842/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg 2400w\" src=\"https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1572/2400x1842/filters:focal(1024x786:1025x787):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg\" data-old-src=\"data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7\"></span></p></div></figure></div><p>Last year, Surge relabeled Google’s dataset classifying Reddit posts by emotion. Google had stripped each post of context and sent them to workers in India for labeling. Surge employees familiar with American internet culture found that 30 percent of the labels were wrong. Posts like “hell yeah my brother” had been classified as annoyance and “Yay, cold McDonald’s. My favorite” as love.</p><p>Surge claims to vet its workers for qualifications — that people doing creative-writing tasks have experience with creative writing, for example — but exactly how Surge finds workers is “proprietary,” Chen said. As with Remotasks, workers often have to complete training courses, though unlike Remotasks, they are paid for it, according to the annotators I spoke with. Having fewer, better-trained workers producing higher-quality data allows Surge to compensate better than its peers, Chen said, though he declined to elaborate, saying only that people are paid “fair and ethical wages.” The workers I spoke with earned between $15 and $30 per hour, but they are a small sample of all the annotators, a group Chen said now consists of 100,000 people. The secrecy, he explained, stems from clients’ demands for confidentiality.</p><p>Surge’s customers include OpenAI, Google, Microsoft, Meta, and Anthropic. Surge specializes in feedback and language annotation, and after ChatGPT launched, it got an influx of requests, Chen said: “I thought everybody knew the power of RLHF, but I guess people just didn’t viscerally understand.”</p><p>The new models are so impressive they’ve inspired another round of predictions that annotation is about to be automated. Given the costs involved, there is significant financial pressure to do so. Anthropic, Meta, and other companies have recently made strides in using AI to drastically reduce the amount of human annotation needed to guide models, and other developers have started using GPT-4 to generate training data. However, a recent paper found that GPT-4-trained models may be learning to mimic GPT’s authoritative style with even less accuracy, and so far, when improvements in AI have made one form of annotation obsolete, demand for other, more sophisticated types of labeling has gone up. This debate spilled into the open earlier this year, when Scale’s CEO, Wang, tweeted that he predicted AI labs will soon be spending as many billions of dollars on human data as they do on computing power; OpenAI’s CEO, Sam Altman, responded that data needs will decrease as AI improves.</p><div><p>“I mean, what it can do is amazing,” she said of the chatbot. “But it still does some really weird shit.”</p></div><p>Chen is skeptical AI will reach a point where human feedback is no longer needed, but he does see annotation becoming more difficult as models improve. Like many researchers, he believes the path forward will involve AI systems helping humans oversee other AI. Surge recently collaborated with Anthropic on a proof of concept, having human labelers answer questions about a lengthy text with the help of an unreliable AI assistant, on the theory that the humans would have to feel out the weaknesses of their AI assistant and collaborate to reason their way to the correct answer. Another possibility has two AIs debating each other and a human rendering the final verdict on which is correct. “We still have yet to see really good practical implementations of this stuff, but it’s starting to become necessary because it’s getting really hard for labelers to keep up with the models,” said OpenAI research scientist John Schulman in a recent talk at Berkeley.</p><p>“I think you always need a human to monitor what AIs are doing just because they are this kind of alien entity,” Chen said. Machine-learning systems are just too strange ever to fully trust. The most impressive models today have what, to a human, seems like bizarre weaknesses, he added, pointing out that though GPT-4 can generate complex and convincing prose, it can’t pick out which words are adjectives: “Either that or models get so good that they’re better than humans at all things, in which case, you reach your utopia and who cares?”</p><p>As 2022 ended, Joe started hearing from his students that their task queues were often empty. Then he got an email informing him the boot camps in Kenya were closing. He continued training taskers online, but he began to worry about the future.</p><p>“There were signs that it was not going to last long,” he said. Annotation was leaving Kenya. From colleagues he had met online, he heard tasks were going to Nepal, India, and the Philippines. “The companies shift from one region to another,” Joe said. “They don’t have infrastructure locally, so it makes them flexible to shift to regions that favor them in terms of operation cost.”</p><p>One way the AI industry differs from manufacturers of phones and cars is in its fluidity. The work is constantly changing, constantly getting automated away and replaced with new needs for new types of data. It’s an assembly line but one that can be endlessly and instantly reconfigured, moving to wherever there is the right combination of skills, bandwidth, and wages.</p><p>Lately, the best-paying work is in the U.S. In May, Scale started listing annotation jobs on its own website, soliciting people with experience in practically every field AI is predicted to conquer. There were listings for AI trainers with expertise in health coaching, human resources, finance, economics, data science, programming, computer science, chemistry, biology, accounting, taxes, nutrition, physics, travel, K-12 education, sports journalism, and self-help. You can make $45 an hour teaching robots law or make $25 an hour teaching them poetry. There were also listings for people with security clearance, presumably to help train military AI. Scale recently launched a defense-oriented language model called Donovan, which Wang called “ammunition in the AI war,” and won a contract to work on the Army’s robotic-combat-vehicle program.</p><p>Anna is still training chatbots in Texas. Colleagues have been turned into reviewers and Slack admins — she isn’t sure why, but it has given her hope that the gig could be a longer-term career. One thing she isn’t worried about is being automated out of a job. “I mean, what it can do is amazing,” she said of the chatbot. “But it still does some really weird shit.”</p><p>When Remotasks first arrived in Kenya, Joe thought annotation could be a good career. Even after the work moved elsewhere, he was determined to make it one. There were thousands of people in Nairobi who knew how to do the work, he reasoned — he had trained many of them, after all. Joe rented office space in the city and began sourcing contracts: a job annotating blueprints for a construction company, another labeling fruits despoiled by insects for some sort of agricultural project, plus the usual work of annotating for self-driving cars and e-commerce.</p><p>But he has found his vision difficult to achieve. He has just one full-time employee, down from two. “We haven’t been having a consistent flow of work,” he said. There are weeks with nothing to do because customers are still collecting data, and when they’re done, he has to bring in short-term contractors to meet their deadlines: “Clients don’t care whether we have consistent work or not. So long as the datasets have been completed, then that’s the end of that.”</p><p>Rather than let their skills go to waste, other taskers decided to chase the work wherever it went. They rented proxy servers to disguise their locations and bought fake IDs to pass security checks so they could pretend to work from Singapore, the Netherlands, Mississippi, or wherever the tasks were flowing. It’s a risky business. Scale has become increasingly aggressive about suspending accounts caught disguising their location, according to multiple taskers. It was during one of these crackdowns that my account got banned, presumably because I had been using a VPN to see what workers in other countries were seeing, and all $1.50 or so of my earnings were seized.</p><p>“These days, we have become a bit cunning because we noticed that in other countries they are paying well,” said Victor, who was earning double the Kenyan rate by tasking in Malaysia. “You do it cautiously.”</p><p>Another Kenyan annotator said that after his account got suspended for mysterious reasons, he decided to stop playing by the rules. Now, he runs multiple accounts in multiple countries, tasking wherever the pay is best. He works fast and gets high marks for quality, he said, thanks to ChatGPT. The bot is wonderful, he said, letting him speed through $10 tasks in a matter of minutes. When we spoke, he was having it rate another chatbot’s responses according to seven different criteria, one AI training the other.</p></div></div>","textContent":"This article is a collaboration between New York Magazine and The Verge.A few months after graduating from college in Nairobi, a 30-year-old I’ll call Joe got a job as an annotator — the tedious work of processing the raw information used to train artificial intelligence. AI learns by finding patterns in enormous quantities of data, but first that data has to be sorted and tagged by people, a vast workforce mostly hidden behind the machines. In Joe’s case, he was labeling footage for self-driving cars — identifying every vehicle, pedestrian, cyclist, anything a driver needs to be aware of — frame by frame and from every possible camera angle. It’s difficult and repetitive work. A several-second blip of footage took eight hours to annotate, for which Joe was paid about $10.Then, in 2019, an opportunity arose: Joe could make four times as much running an annotation boot camp for a new company that was hungry for labelers. Every two weeks, 50 new recruits would file into an office building in Nairobi to begin their apprenticeships. There seemed to be limitless demand for the work. They would be asked to categorize clothing seen in mirror selfies, look through the eyes of robot vacuum cleaners to determine which rooms they were in, and draw squares around lidar scans of motorcycles. Over half of Joe’s students usually dropped out before the boot camp was finished. “Some people don’t know how to stay in one place for long,” he explained with gracious understatement. Also, he acknowledged, “it is very boring.”But it was a job in a place where jobs were scarce, and Joe turned out hundreds of graduates. After boot camp, they went home to work alone in their bedrooms and kitchens, forbidden from telling anyone what they were working on, which wasn’t really a problem because they rarely knew themselves. Labeling objects for self-driving cars was obvious, but what about categorizing whether snippets of distorted dialogue were spoken by a robot or a human? Uploading photos of yourself staring into a webcam with a blank expression, then with a grin, then wearing a motorcycle helmet? Each project was such a small component of some larger process that it was difficult to say what they were actually training AI to do. Nor did the names of the projects offer any clues: Crab Generation, Whale Segment, Woodland Gyro, and Pillbox Bratwurst. They were non sequitur code names for non sequitur work.As for the company employing them, most knew it only as Remotasks, a website offering work to anyone fluent in English. Like most of the annotators I spoke with, Joe was unaware until I told him that Remotasks is the worker-facing subsidiary of a company called Scale AI, a multibillion-dollar Silicon Valley data vendor that counts OpenAI and the U.S. military among its customers. Neither Remotasks’ or Scale’s website mentions the other.Much of the public response to language models like OpenAI’s ChatGPT has focused on all the jobs they appear poised to automate. But behind even the most impressive AI system are people — huge numbers of people labeling data to train it and clarifying data when it gets confused. Only the companies that can afford to buy this data can compete, and those that get it are highly motivated to keep it secret. The result is that, with few exceptions, little is known about the information shaping these systems’ behavior, and even less is known about the people doing the shaping.For Joe’s students, it was work stripped of all its normal trappings: a schedule, colleagues, knowledge of what they were working on or whom they were working for. In fact, they rarely called it work at all — just “tasking.” They were taskers.The anthropologist David Graeber defines “bullshit jobs” as employment without meaning or purpose, work that should be automated but for reasons of bureaucracy or status or inertia is not. These AI jobs are their bizarro twin: work that people want to automate, and often think is already automated, yet still requires a human stand-in. The jobs have a purpose; it’s just that workers often have no idea what it is.The current AI boom — the convincingly human-sounding chatbots, the artwork that can be generated from simple prompts, and the multibillion-dollar valuations of the companies behind these technologies — began with an unprecedented feat of tedious and repetitive labor.In 2007, the AI researcher Fei-Fei Li, then a professor at Princeton, suspected the key to improving image-recognition neural networks, a method of machine learning that had been languishing for years, was training on more data — millions of labeled images rather than tens of thousands. The problem was that it would take decades and millions of dollars for her team of undergrads to label that many photos.Li found thousands of workers on Mechanical Turk, Amazon’s crowdsourcing platform where people around the world complete small tasks for cheap. The resulting annotated dataset, called ImageNet, enabled breakthroughs in machine learning that revitalized the field and ushered in a decade of progress.Annotation remains a foundational part of making AI, but there is often a sense among engineers that it’s a passing, inconvenient prerequisite to the more glamorous work of building models. You collect as much labeled data as you can get as cheaply as possible to train your model, and if it works, at least in theory, you no longer need the annotators. But annotation is never really finished. Machine-learning systems are what researchers call “brittle,” prone to fail when encountering something that isn’t well represented in their training data. These failures, called “edge cases,” can have serious consequences. In 2018, an Uber self-driving test car killed a woman because, though it was programmed to avoid cyclists and pedestrians, it didn’t know what to make of someone walking a bike across the street. The more AI systems are put out into the world to dispense legal advice and medical help, the more edge cases they will encounter and the more humans will be needed to sort them. Already, this has given rise to a global industry staffed by people like Joe who use their uniquely human faculties to help the machines.Is that a red shirt with white stripes or a white shirt with red stripes? Is a wicker bowl a “decorative bowl” if it’s full of apples? What color is leopard print?Over the past six months, I spoke with more than two dozen annotators from around the world, and while many of them were training cutting-edge chatbots, just as many were doing the mundane manual labor required to keep AI running. There are people classifying the emotional content of TikTok videos, new variants of email spam, and the precise sexual provocativeness of online ads. Others are looking at credit-card transactions and figuring out what sort of purchase they relate to or checking e-commerce recommendations and deciding whether that shirt is really something you might like after buying that other shirt. Humans are correcting customer-service chatbots, listening to Alexa requests, and categorizing the emotions of people on video calls. They are labeling food so that smart refrigerators don’t get confused by new packaging, checking automated security cameras before sounding alarms, and identifying corn for baffled autonomous tractors.“There’s an entire supply chain,” said Sonam Jindal, the program and research lead of the nonprofit Partnership on AI. “The general perception in the industry is that this work isn’t a critical part of development and isn’t going to be needed for long. All the excitement is around building artificial intelligence, and once we build that, it won’t be needed anymore, so why think about it? But it’s infrastructure for AI. Human intelligence is the basis of artificial intelligence, and we need to be valuing these as real jobs in the AI economy that are going to be here for a while.”The data vendors behind familiar names like OpenAI, Google, and Microsoft come in different forms. There are private outsourcing companies with call-center-like offices, such as the Kenya- and Nepal-based CloudFactory, where Joe annotated for $1.20 an hour before switching to Remotasks. There are also “crowdworking” sites like Mechanical Turk and Clickworker where anyone can sign up to perform tasks. In the middle are services like Scale AI. Anyone can sign up, but everyone has to pass qualification exams and training courses and undergo performance monitoring. Annotation is big business. Scale, founded in 2016 by then-19-year-old Alexandr Wang, was valued in 2021 at $7.3 billion, making him what Forbes called “the youngest self-made billionaire,” though the magazine noted in a recent profile that his stake has fallen on secondary markets since then.This tangled supply chain is deliberately hard to map. According to people in the industry, the companies buying the data demand strict confidentiality. (This is the reason Scale cited to explain why Remotasks has a different name.) Annotation reveals too much about the systems being developed, and the huge number of workers required makes leaks difficult to prevent. Annotators are warned repeatedly not to tell anyone about their jobs, not even their friends and co-workers, but corporate aliases, project code names, and, crucially, the extreme division of labor ensure they don’t have enough information about them to talk even if they wanted to. (Most workers requested pseudonyms for fear of being booted from the platforms.) Consequently, there are no granular estimates of the number of people who work in annotation, but it is a lot, and it is growing. A recent Google Research paper gave an order-of-magnitude figure of “millions” with the potential to become “billions.”Automation often unfolds in unexpected ways. Erik Duhaime, CEO of medical-data-annotation company Centaur Labs, recalled how, several years ago, prominent machine-learning engineers were predicting AI would make the job of radiologist obsolete. When that didn’t happen, conventional wisdom shifted to radiologists using AI as a tool. Neither of those is quite what he sees occurring. AI is very good at specific tasks, Duhaime said, and that leads work to be broken up and distributed across a system of specialized algorithms and to equally specialized humans. An AI system might be capable of spotting cancer, he said, giving a hypothetical example, but only in a certain type of imagery from a certain type of machine; so now, you need a human to check that the AI is being fed the right type of data and maybe another human who checks its work before passing it to another AI that writes a report, which goes to another human, and so on. “AI doesn’t replace work,” he said. “But it does change how work is organized.”You might miss this if you believe AI is a brilliant, thinking machine. But if you pull back the curtain even a little, it looks more familiar, the latest iteration of a particularly Silicon Valley division of labor, in which the futuristic gleam of new technologies hides a sprawling manufacturing apparatus and the people who make it run. Duhaime reached back farther for a comparison, a digital version of the transition from craftsmen to industrial manufacturing: coherent processes broken into tasks and arrayed along assembly lines with some steps done by machines and some by humans but none resembling what came before.Worries about AI-driven disruption are often countered with the argument that AI automates tasks, not jobs, and that these tasks will be the dull ones, leaving people to pursue more fulfilling and human work. But just as likely, the rise of AI will look like past labor-saving technologies, maybe like the telephone or typewriter, which vanquished the drudgery of message delivering and handwriting but generated so much new correspondence, commerce, and paperwork that new offices staffed by new types of workers — clerks, accountants, typists — were required to manage it. When AI comes for your job, you may not lose it, but it might become more alien, more isolating, more tedious.Earlier this year, I signed up for Scale AI’s Remotasks. The process was straightforward. After entering my computer specs, internet speed, and some basic contact information, I found myself in the “training center.” To access a paying task, I first had to complete an associated (unpaid) intro course.The training center displayed a range of courses with inscrutable names like Glue Swimsuit and Poster Macadamia. I clicked on something called GFD Chunking, which revealed itself to be labeling clothing in social-media photos.The instructions, however, were odd. For one, they basically consisted of the same direction reiterated in the idiosyncratically colored and capitalized typography of a collaged bomb threat.“DO LABEL items that are real and can be worn by humans or are intended to be worn by real people,” it read.“All items below SHOULD be labeled because they are real and can be worn by real-life humans,” it reiterated above photos of an Air Jordans ad, someone in a Kylo Ren helmet, and mannequins in dresses, over which was a lime-green box explaining, once again, “DO Label real items that can be worn by real people.”Remotasks instructions for labeling clothing.I skimmed to the bottom of the manual, where the instructor had written in the large bright-red font equivalent of grabbing someone by the shoulders and shaking them, “THE FOLLOWING ITEMS SHOULD NOT BE LABELED because a human could not actually put wear any of these items!” above a photo of C-3PO, Princess Jasmine from Aladdin, and a cartoon shoe with eyeballs.Feeling confident in my ability to distinguish between real clothes that can be worn by real people and not-real clothes that cannot, I proceeded to the test. Right away, it threw an ontological curveball: a picture of a magazine depicting photos of women in dresses. Is a photograph of clothing real clothing? No, I thought, because a human cannot wear a photograph of clothing. Wrong! As far as AI is concerned, photos of real clothes are real clothes. Next came a photo of a woman in a dimly lit bedroom taking a selfie before a full-length mirror. The blouse and shorts she’s wearing are real. What about their reflection? Also real! Reflections of real clothes are also real clothes.After an embarrassing amount of trial and error, I made it to the actual work, only to make the horrifying discovery that the instructions I’d been struggling to follow had been updated and clarified so many times that they were now a full 43 printed pages of directives: Do NOT label open suitcases full of clothes; DO label shoes but do NOT label flippers; DO label leggings but do NOT label tights; do NOT label towels even if someone is wearing it; label costumes but do NOT label armor. And so on.There has been general instruction disarray across the industry, according to Milagros Miceli, a researcher at the Weizenbaum Institute in Germany who studies data work. It is in part a product of the way machine-learning systems learn. Where a human would get the concept of “shirt” with a few examples, machine-learning programs need thousands, and they need to be categorized with perfect consistency yet varied enough (polo shirts, shirts being worn outdoors, shirts hanging on a rack) that the very literal system can handle the diversity of the real world. “Imagine simplifying complex realities into something that is readable for a machine that is totally dumb,” she said.Once, Victor stayed up 36 hours straight labeling elbows and knees and heads in photographs of crowds — he has no idea why.The act of simplifying reality for a machine results in a great deal of complexity for the human. Instruction writers must come up with rules that will get humans to categorize the world with perfect consistency. To do so, they often create categories no human would use. A human asked to tag all the shirts in a photo probably wouldn’t tag the reflection of a shirt in a mirror because they would know it is a reflection and not real. But to the AI, which has no understanding of the world, it’s all just pixels and the two are perfectly identical. Fed a dataset with some shirts labeled and other (reflected) shirts unlabeled, the model won’t work. So the engineer goes back to the vendor with an update: DO label reflections of shirts. Soon, you have a 43-page guide descending into red all-caps.“When you start off, the rules are relatively simple,” said a former Scale employee who requested anonymity because of an NDA. “Then they get back a thousand images and then they’re like, Wait a second, and then you have multiple engineers and they start to argue with each other. It’s very much a human thing.”The job of the annotator often involves putting human understanding aside and following instructions very, very literally — to think, as one annotator said, like a robot. It’s a strange mental space to inhabit, doing your best to follow nonsensical but rigorous rules, like taking a standardized test while on hallucinogens. Annotators invariably end up confronted with confounding questions like, Is that a red shirt with white stripes or a white shirt with red stripes? Is a wicker bowl a “decorative bowl” if it’s full of apples? What color is leopard print? When instructors said to label traffic-control directors, did they also mean to label traffic-control directors eating lunch on the sidewalk? Every question must be answered, and a wrong guess could get you banned and booted to a new, totally different task with its own baffling rules.Most of the work on Remotasks is paid at a piece rate with a single task earning anywhere from a few cents to several dollars. Because tasks can take seconds or hours, wages are hard to predict. When Remotasks first arrived in Kenya, annotators said it paid relatively well — averaging about $5 to $10 per hour depending on the task — but the amount fell as time went on.Scale AI spokesperson Anna Franko said that the company’s economists analyze the specifics of a project, the skills required, the regional cost of living, and other factors “to ensure fair and competitive compensation.” Former Scale employees also said pay is determined through a surge-pricing-like mechanism that adjusts for how many annotators are available and how quickly the data is needed.According to workers I spoke with and job listings, U.S.-based Remotasks annotators generally earn between $10 and $25 per hour, though some subject-matter experts can make more. By the beginning of this year, pay for the Kenyan annotators I spoke with had dropped to between $1 and $3 per hour.That is, when they were making any money at all. The most common complaint about Remotasks work is its variability; it’s steady enough to be a full-time job for long stretches but too unpredictable to rely on. Annotators spend hours reading instructions and completing unpaid trainings only to do a dozen tasks and then have the project end. There might be nothing new for days, then, without warning, a totally different task appears and could last anywhere from a few hours to weeks. Any task could be their last, and they never know when the next one will come.This boom-and-bust cycle results from the cadence of AI development, according to engineers and data vendors. Training a large model requires an enormous amount of annotation followed by more iterative updates, and engineers want it all as fast as possible so they can hit their target launch date. There may be monthslong demand for thousands of annotators, then for only a few hundred, then for a dozen specialists of a certain type, and then thousands again. “The question is, Who bears the cost for these fluctuations?” said Jindal of Partnership on AI. “Because right now, it’s the workers.”“I really am wasting my life here if I made somebody a billionaire and I’m earning a couple of bucks a week.”To succeed, annotators work together. When I told Victor, who started working for Remotasks while at university in Nairobi, about my struggles with the traffic-control-directors task, he told me everyone knew to stay away from that one: too tricky, bad pay, not worth it. Like a lot of annotators, Victor uses unofficial WhatsApp groups to spread the word when a good task drops. When he figures out a new one, he starts impromptu Google Meets to show others how it’s done. Anyone can join and work together for a time, sharing tips. “It’s a culture we have developed of helping each other because we know when on your own, you can’t know all the tricks,” he said.Because work appears and vanishes without warning, taskers always need to be on alert. Victor has found that projects pop up very late at night, so he is in the habit of waking every three hours or so to check his queue. When a task is there, he’ll stay awake as long as he can to work. Once, he stayed up 36 hours straight labeling elbows and knees and heads in photographs of crowds — he has no idea why. Another time, he stayed up so long his mother asked him what was wrong with his eyes. He looked in the mirror to discover they were swollen.Annotators generally know only that they are training AI for companies located vaguely elsewhere, but sometimes the veil of anonymity drops — instructions mentioning a brand or a chatbot say too much. “I read and I Googled and found I am working for a 25-year-old billionaire,” said one worker, who, when we spoke, was labeling the emotions of people calling to order Domino’s pizza. “I really am wasting my life here if I made somebody a billionaire and I’m earning a couple of bucks a week.”Victor is a self-proclaimed “fanatic” about AI and started annotating because he wants to help bring about a fully automated post-work future. But earlier this year, someone dropped a Time story into one of his WhatsApp groups about workers training ChatGPT to recognize toxic content who were getting paid less than $2 an hour by the vendor Sama AI. “People were angry that these companies are so profitable but paying so poorly,” Victor said. He was unaware until I told him about Remotasks’ connection to Scale. Instructions for one of the tasks he worked on were nearly identical to those used by OpenAI, which meant he had likely been training ChatGPT as well, for approximately $3 per hour.“I remember that someone posted that we will be remembered in the future,” he said. “And somebody else replied, ‘We are being treated worse than foot soldiers. We will be remembered nowhere in the future.’ I remember that very well. Nobody will recognize the work we did or the effort we put in.”Identifying clothing and labeling customer-service conversations are just some of the annotation gigs available. Lately, the hottest on the market has been chatbot trainer. Because it demands specific areas of expertise or language fluency and wages are often adjusted regionally, this job tends to pay better. Certain types of specialist annotation can go for $50 or more per hour.A woman I’ll call Anna was searching for a job in Texas when she stumbled across a generic listing for online work and applied. It was Remotasks, and after passing an introductory exam, she was brought into a Slack room of 1,500 people who were training a project code-named Dolphin, which she later discovered to be Google DeepMind’s chatbot, Sparrow, one of the many bots competing with ChatGPT. Her job is to talk with it all day. At about $14 an hour, plus bonuses for high productivity, “it definitely beats getting paid $10 an hour at the local Dollar General store,” she said.Also, she enjoys it. She has discussed science-fiction novels, mathematical paradoxes, children’s riddles, and TV shows. Sometimes the bot’s responses make her laugh; other times, she runs out of things to talk about. “Some days, my brain is just like, I literally have no idea what on earth to ask it now,” she said. “So I have a little notebook, and I’ve written about two pages of things — I just Google interesting topics — so I think I’ll be good for seven hours today, but that’s not always the case.”Each time Anna prompts Sparrow, it delivers two responses and she picks the best one, thereby creating something called “human-feedback data.” When ChatGPT debuted late last year, its impressively natural-seeming conversational style was credited to its having been trained on troves of internet data. But the language that fuels ChatGPT and its competitors is filtered through several rounds of human annotation. One group of contractors writes examples of how the engineers want the bot to behave, creating questions followed by correct answers, descriptions of computer programs followed by functional code, and requests for tips on committing crimes followed by polite refusals. After the model is trained on these examples, yet more contractors are brought in to prompt it and rank its responses. This is what Anna is doing with Sparrow. Exactly which criteria the raters are told to use varies — honesty, or helpfulness, or just personal preference. The point is that they are creating data on human taste, and once there’s enough of it, engineers can train a second model to mimic their preferences at scale, automating the ranking process and training their AI to act in ways humans approve of. The result is a remarkably human-seeming bot that mostly declines harmful requests and explains its AI nature with seeming self-awareness.Put another way, ChatGPT seems so human because it was trained by an AI that was mimicking humans who were rating an AI that was mimicking humans who were pretending to be a better version of an AI that was trained on human writing.This circuitous technique is called “reinforcement learning from human feedback,” or RLHF, and it’s so effective that it’s worth pausing to fully register what it doesn’t do. When annotators teach a model to be accurate, for example, the model isn’t learning to check answers against logic or external sources or about what accuracy as a concept even is. The model is still a text-prediction machine mimicking patterns in human writing, but now its training corpus has been supplemented with bespoke examples, and the model has been weighted to favor them. Maybe this results in the model extracting patterns from the part of its linguistic map labeled as accurate and producing text that happens to align with the truth, but it can also result in it mimicking the confident style and expert jargon of the accurate text while writing things that are totally wrong. There is no guarantee that the text the labelers marked as accurate is in fact accurate, and when it is, there is no guarantee that the model learns the right patterns from it.This dynamic makes chatbot annotation a delicate process. It has to be rigorous and consistent because sloppy feedback, like marking material that merely sounds correct as accurate, risks training models to be even more convincing bullshitters. An early OpenAI and DeepMind joint project using RLHF, in this case to train a virtual robot hand to grab an item, resulted in also training the robot to position its hand between the object and its raters and wiggle around such that it only appeared to its human overseers to grab the item. Ranking a language model’s responses is always going to be somewhat subjective because it’s language. A text of any length will have multiple elements that could be right or wrong or, taken together, misleading. OpenAI researchers ran into this obstacle in another early RLHF paper. Trying to get their model to summarize text, the researchers found they agreed only 60 percent of the time that a summary was good. “Unlike many tasks in [machine learning] our queries do not have unambiguous ground truth,” they lamented.When Anna rates Sparrow’s responses, she’s supposed to be looking at their accuracy, helpfulness, and harmlessness while also checking that the model isn’t giving medical or financial advice or anthropomorphizing itself or running afoul of other criteria. To be useful training data, the model’s responses have to be quantifiably ranked against one another: Is a bot that helpfully tells you how to make a bomb “better” than a bot that’s so harmless it refuses to answer any questions? In one DeepMind paper, when Sparrow’s makers took a turn annotating, four researchers wound up debating whether their bot had assumed the gender of a user who asked it for relationship advice. According to Geoffrey Irving, one of DeepMind’s research scientists, the company’s researchers hold weekly annotation meetings in which they rerate data themselves and discuss ambiguous cases, consulting with ethical or subject-matter experts when a case is particularly tricky.There are people classifying the emotional content of TikTok videos, new variants of email spam, and the precise sexual provocativeness of online ads.Anna often finds herself having to choose between two bad options. “Even if they’re both absolutely, ridiculously wrong, you still have to figure out which one is better and then write words explaining why,” she said. Sometimes, when both responses are bad, she’s encouraged to write a better response herself, which she does about half the time.Because feedback data is difficult to collect, it fetches a higher price. Basic preferences of the sort Anna is producing sell for about $1 each, according to people with knowledge of the industry. But if you want to train a model to do legal research, you need someone with training in law, and this gets expensive. Everyone involved is reluctant to say how much they’re spending, but in general, specialized written examples can go for hundreds of dollars, while expert ratings can cost $50 or more. One engineer told me about buying examples of Socratic dialogues for up to $300 a pop. Another told me about paying $15 for a “darkly funny limerick about a goldfish.”OpenAI, Microsoft, Meta, and Anthropic did not comment about how many people contribute annotations to their models, how much they are paid, or where in the world they are located. Irving of DeepMind, which is a subsidiary of Google, said the annotators working on Sparrow are paid “at least the hourly living wage” based on their location. Anna knows “absolutely nothing” about Remotasks, but Sparrow has been more open. She wasn’t the only annotator I spoke with who got more information from the AI they were training than from their employer; several others learned whom they were working for by asking their AI for its company’s terms of service. “I literally asked it, ‘What is your purpose, Sparrow?’” Anna said. It pulled up a link to DeepMind’s website and explained that it’s an AI assistant and that its creators trained it using RLHF to be helpful and safe.Until recently, it was relatively easy to spot bad output from a language model. It looked like gibberish. But this gets harder as the models get better — a problem called “scalable oversight.” Google inadvertently demonstrated how hard it is to catch the errors of a modern-language model when one made it into the splashy debut of its AI assistant, Bard. (It stated confidently that the James Webb Space Telescope “took the very first pictures of a planet outside of our own solar system,” which is wrong.) This trajectory means annotation increasingly requires specific skills and expertise.Last year, someone I’ll call Lewis was working on Mechanical Turk when, after completing a task, he received a message inviting him to apply for a platform he hadn’t heard of. It was called Taskup.ai, and its website was remarkably basic: just a navy background with text reading GET PAID FOR TASKS ON DEMAND. He applied.The work paid far better than anything he had tried before, often around $30 an hour. It was more challenging, too: devising complex scenarios to trick chatbots into giving dangerous advice, testing a model’s ability to stay in character, and having detailed conversations about scientific topics so technical they required extensive research. He found the work “satisfying and stimulating.” While checking one model’s attempts to code in Python, Lewis was learning too. He couldn’t work for more than four hours at a stretch, lest he risk becoming mentally drained and making mistakes, and he wanted to keep the job.“If there was one thing I could change, I would just like to have more information about what happens on the other end,” he said. “We only know as much as we need to know to get work done, but if I could know more, then maybe I could get more established and perhaps pursue this as a career.”I spoke with eight other workers, most based in the U.S., who had similar experiences of answering surveys or completing tasks on other platforms and finding themselves recruited for Taskup.ai or several similarly generic sites, such as DataAnnotation.tech or Gethybrid.io. Often their work involved training chatbots, though with higher-quality expectations and more specialized purposes than other sites they had worked for. One was demonstrating spreadsheet macros. Another was just supposed to have conversations and rate responses according to whatever criteria she wanted. She often asked the chatbot things that had come up in conversations with her 7-year-old daughter, like “What is the largest dinosaur?” and “Write a story about a tiger.” “I haven’t fully gotten my head around what they’re trying to do with it,” she told me.Taskup.ai, DataAnnotation.tech, and Gethybrid.io all appear to be owned by the same company: Surge AI. Its CEO, Edwin Chen, would neither confirm nor deny the connection, but he was willing to talk about his company and how he sees annotation evolving.“I’ve always felt the annotation landscape is overly simplistic,” Chen said over a video call from Surge’s office. He founded Surge in 2020 after working on AI at Google, Facebook, and Twitter convinced him that crowdsourced labeling was inadequate. “We want AI to tell jokes or write really good marketing copy or help me out when I need therapy or whatnot,” Chen said. “You can’t ask five people to independently come up with a joke and combine it into a majority answer. Not everybody can tell a joke or solve a Python program. The annotation landscape needs to shift from this low-quality, low-skill mind-set to something that’s much richer and captures the range of human skills and creativity and values that we want AI systems to possess.”Last year, Surge relabeled Google’s dataset classifying Reddit posts by emotion. Google had stripped each post of context and sent them to workers in India for labeling. Surge employees familiar with American internet culture found that 30 percent of the labels were wrong. Posts like “hell yeah my brother” had been classified as annoyance and “Yay, cold McDonald’s. My favorite” as love.Surge claims to vet its workers for qualifications — that people doing creative-writing tasks have experience with creative writing, for example — but exactly how Surge finds workers is “proprietary,” Chen said. As with Remotasks, workers often have to complete training courses, though unlike Remotasks, they are paid for it, according to the annotators I spoke with. Having fewer, better-trained workers producing higher-quality data allows Surge to compensate better than its peers, Chen said, though he declined to elaborate, saying only that people are paid “fair and ethical wages.” The workers I spoke with earned between $15 and $30 per hour, but they are a small sample of all the annotators, a group Chen said now consists of 100,000 people. The secrecy, he explained, stems from clients’ demands for confidentiality.Surge’s customers include OpenAI, Google, Microsoft, Meta, and Anthropic. Surge specializes in feedback and language annotation, and after ChatGPT launched, it got an influx of requests, Chen said: “I thought everybody knew the power of RLHF, but I guess people just didn’t viscerally understand.”The new models are so impressive they’ve inspired another round of predictions that annotation is about to be automated. Given the costs involved, there is significant financial pressure to do so. Anthropic, Meta, and other companies have recently made strides in using AI to drastically reduce the amount of human annotation needed to guide models, and other developers have started using GPT-4 to generate training data. However, a recent paper found that GPT-4-trained models may be learning to mimic GPT’s authoritative style with even less accuracy, and so far, when improvements in AI have made one form of annotation obsolete, demand for other, more sophisticated types of labeling has gone up. This debate spilled into the open earlier this year, when Scale’s CEO, Wang, tweeted that he predicted AI labs will soon be spending as many billions of dollars on human data as they do on computing power; OpenAI’s CEO, Sam Altman, responded that data needs will decrease as AI improves.“I mean, what it can do is amazing,” she said of the chatbot. “But it still does some really weird shit.”Chen is skeptical AI will reach a point where human feedback is no longer needed, but he does see annotation becoming more difficult as models improve. Like many researchers, he believes the path forward will involve AI systems helping humans oversee other AI. Surge recently collaborated with Anthropic on a proof of concept, having human labelers answer questions about a lengthy text with the help of an unreliable AI assistant, on the theory that the humans would have to feel out the weaknesses of their AI assistant and collaborate to reason their way to the correct answer. Another possibility has two AIs debating each other and a human rendering the final verdict on which is correct. “We still have yet to see really good practical implementations of this stuff, but it’s starting to become necessary because it’s getting really hard for labelers to keep up with the models,” said OpenAI research scientist John Schulman in a recent talk at Berkeley.“I think you always need a human to monitor what AIs are doing just because they are this kind of alien entity,” Chen said. Machine-learning systems are just too strange ever to fully trust. The most impressive models today have what, to a human, seems like bizarre weaknesses, he added, pointing out that though GPT-4 can generate complex and convincing prose, it can’t pick out which words are adjectives: “Either that or models get so good that they’re better than humans at all things, in which case, you reach your utopia and who cares?”As 2022 ended, Joe started hearing from his students that their task queues were often empty. Then he got an email informing him the boot camps in Kenya were closing. He continued training taskers online, but he began to worry about the future.“There were signs that it was not going to last long,” he said. Annotation was leaving Kenya. From colleagues he had met online, he heard tasks were going to Nepal, India, and the Philippines. “The companies shift from one region to another,” Joe said. “They don’t have infrastructure locally, so it makes them flexible to shift to regions that favor them in terms of operation cost.”One way the AI industry differs from manufacturers of phones and cars is in its fluidity. The work is constantly changing, constantly getting automated away and replaced with new needs for new types of data. It’s an assembly line but one that can be endlessly and instantly reconfigured, moving to wherever there is the right combination of skills, bandwidth, and wages.Lately, the best-paying work is in the U.S. In May, Scale started listing annotation jobs on its own website, soliciting people with experience in practically every field AI is predicted to conquer. There were listings for AI trainers with expertise in health coaching, human resources, finance, economics, data science, programming, computer science, chemistry, biology, accounting, taxes, nutrition, physics, travel, K-12 education, sports journalism, and self-help. You can make $45 an hour teaching robots law or make $25 an hour teaching them poetry. There were also listings for people with security clearance, presumably to help train military AI. Scale recently launched a defense-oriented language model called Donovan, which Wang called “ammunition in the AI war,” and won a contract to work on the Army’s robotic-combat-vehicle program.Anna is still training chatbots in Texas. Colleagues have been turned into reviewers and Slack admins — she isn’t sure why, but it has given her hope that the gig could be a longer-term career. One thing she isn’t worried about is being automated out of a job. “I mean, what it can do is amazing,” she said of the chatbot. “But it still does some really weird shit.”When Remotasks first arrived in Kenya, Joe thought annotation could be a good career. Even after the work moved elsewhere, he was determined to make it one. There were thousands of people in Nairobi who knew how to do the work, he reasoned — he had trained many of them, after all. Joe rented office space in the city and began sourcing contracts: a job annotating blueprints for a construction company, another labeling fruits despoiled by insects for some sort of agricultural project, plus the usual work of annotating for self-driving cars and e-commerce.But he has found his vision difficult to achieve. He has just one full-time employee, down from two. “We haven’t been having a consistent flow of work,” he said. There are weeks with nothing to do because customers are still collecting data, and when they’re done, he has to bring in short-term contractors to meet their deadlines: “Clients don’t care whether we have consistent work or not. So long as the datasets have been completed, then that’s the end of that.”Rather than let their skills go to waste, other taskers decided to chase the work wherever it went. They rented proxy servers to disguise their locations and bought fake IDs to pass security checks so they could pretend to work from Singapore, the Netherlands, Mississippi, or wherever the tasks were flowing. It’s a risky business. Scale has become increasingly aggressive about suspending accounts caught disguising their location, according to multiple taskers. It was during one of these crackdowns that my account got banned, presumably because I had been using a VPN to see what workers in other countries were seeing, and all $1.50 or so of my earnings were seized.“These days, we have become a bit cunning because we noticed that in other countries they are paying well,” said Victor, who was earning double the Kenyan rate by tasking in Malaysia. “You do it cautiously.”Another Kenyan annotator said that after his account got suspended for mysterious reasons, he decided to stop playing by the rules. Now, he runs multiple accounts in multiple countries, tasking wherever the pay is best. He works fast and gets high marks for quality, he said, thanks to ChatGPT. The bot is wonderful, he said, letting him speed through $10 tasks in a matter of minutes. When we spoke, he was having it rate another chatbot’s responses according to seven different criteria, one AI training the other.","length":43138,"excerpt":"How many humans does it take to make tech seem human? Millions.","byline":null,"dir":null,"siteName":"The Verge","lang":"en-US"},"finalizedMeta":{"title":"Inside the AI Factory: the humans that make tech seem human","description":"How many humans does it take to make tech seem human? Millions to support OpenAI, Google, Meta, and every other major tech company. As AI becomes ubiquitous, a vast tasker underclass is emerging — and not going anywhere.","author":"","creator":"","publisher":"The Verge","date":"2023-06-20T12:05:00.000Z","image":{"@type":"ImageObject","url":"https://cdn.vox-cdn.com/thumbor/MFiURNjiF1enowJ5t0oyd0gkPlU=/0x0:2048x1365/1400x788/filters:focal(1024x683:1025x684)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg","width":1400,"height":788},"topics":[]},"jsonLd":{"@type":"NewsArticle","headline":"Inside the AI Factory: the humans that make tech seem human","description":"How many humans does it take to make tech seem human? Millions to support OpenAI, Google, Meta, and every other major tech company. As AI becomes ubiquitous, a vast tasker underclass is emerging — and not going anywhere.","image":[{"@type":"ImageObject","url":"https://cdn.vox-cdn.com/thumbor/MFiURNjiF1enowJ5t0oyd0gkPlU=/0x0:2048x1365/1400x788/filters:focal(1024x683:1025x684)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg","width":1400,"height":788},{"@type":"ImageObject","url":"https://cdn.vox-cdn.com/thumbor/aD8beUZUaAWE-Xp9Nxghr39hEc8=/0x0:2048x1365/1400x1050/filters:focal(1024x683:1025x684)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg","width":1400,"height":1050},{"@type":"ImageObject","url":"https://cdn.vox-cdn.com/thumbor/3DumuHSwStBgrpK3v23C-ipMVRE=/0x0:2048x1365/1400x1400/filters:focal(1024x683:1025x684)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg","width":1400,"height":1400}],"mainEntityOfPage":{"@type":false,"@id":false},"datePublished":"2023-06-20T12:05:00.000Z","dateModified":"2023-06-20T12:05:00.000Z","isAccessibleForFree":false,"isPartOf":{"@type":[],"name":false,"productID":false},"discussionUrl":false,"license":false,"author":[{"@type":"Person","name":"Josh Dzieza","url":"https://www.theverge.com/authors/josh-dzieza"}],"publisher":{"@type":"Organization","name":"The Verge","logo":{"@type":"ImageObject","url":"https://cdn.vox-cdn.com/uploads/chorus_asset/file/24015294/verge_duet_google_news.png","width":250,"height":50}},"editor":{"@type":false,"name":false,"description":false,"sameAs":false,"image":{"@type":false,"url":false},"givenName":false,"familyName":false,"alternateName":false,"publishingPrinciples":false},"@context":"http://schema.org/","thumbnailUrl":"https://cdn.vox-cdn.com/thumbor/MFiURNjiF1enowJ5t0oyd0gkPlU=/0x0:2048x1365/1400x788/filters:focal(1024x683:1025x684)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg","url":"https://www.theverge.com/features/23764584/ai-artificial-intelligence-data-notation-labor-scale-surge-remotasks-openai-chatbots","articleBody":"This article is a collaboration between New York Magazine and The Verge.\n\n---\n\nA few months after graduating from college in Nairobi, a 30-year-old I’ll call Joe got a job as an annotator — the tedious work of processing the raw information used to train artificial intelligence. AI learns by finding patterns in enormous quantities of data, but first that data has to be sorted and tagged by people, a vast workforce mostly hidden behind the machines. In Joe’s case, he was labeling footage for self-driving cars — identifying every vehicle, pedestrian, cyclist, anything a driver needs to be aware of — frame by frame and from every possible camera angle. It’s difficult and repetitive work. A several-second blip of footage took eight hours to annotate, for which Joe was paid about $10.\n\nThen, in 2019, an opportunity arose: Joe could make four times as much running an annotation boot camp for a new company that was hungry for labelers. Every two weeks, 50 new recruits would file into an office building in Nairobi to begin their apprenticeships. There seemed to be limitless demand for the work. They would be asked to categorize clothing seen in mirror selfies, look through the eyes of robot vacuum cleaners to determine which rooms they were in, and draw squares around lidar scans of motorcycles. Over half of Joe’s students usually dropped out before the boot camp was finished. “Some people don’t know how to stay in one place for long,” he explained with gracious understatement. Also, he acknowledged, “it is very boring.”\n\n---\n[Image: https://cdn.vox-cdn.com/thumbor/bqRhb5A3myLSYGiXMDOshxcrXCE=/0x0:2400x3000/2400x3000/filters:focal(1200x1500:1201x1501)/cdn.vox-cdn.com/uploads/chorus_asset/file/24734352/1323Cov4x5_AI_Factory.jpg]\n\nThis article is a collaboration between New York Magazine and The Verge.\n---\n\nBut it was a job in a place where jobs were scarce, and Joe turned out hundreds of graduates. After boot camp, they went home to work alone in their bedrooms and kitchens, forbidden from telling anyone what they were working on, which wasn’t really a problem because they rarely knew themselves. Labeling objects for self-driving cars was obvious, but what about categorizing whether snippets of distorted dialogue were spoken by a robot or a human? Uploading photos of yourself staring into a webcam with a blank expression, then with a grin, then wearing a motorcycle helmet? Each project was such a small component of some larger process that it was difficult to say what they were actually training AI to do. Nor did the names of the projects offer any clues: Crab Generation, Whale Segment, Woodland Gyro, and Pillbox Bratwurst. They were non sequitur code names for non sequitur work.\n\nAs for the company employing them, most knew it only as Remotasks, a website offering work to anyone fluent in English. Like most of the annotators I spoke with, Joe was unaware until I told him that Remotasks is the worker-facing subsidiary of a company called Scale AI, a multibillion-dollar Silicon Valley data vendor that counts OpenAI and the U.S. military among its customers. Neither Remotasks’ or Scale’s website mentions the other.\n\nMuch of the public response to language models like OpenAI’s ChatGPT has focused on all the jobs they appear poised to automate. But behind even the most impressive AI system are people — huge numbers of people labeling data to train it and clarifying data when it gets confused. Only the companies that can afford to buy this data can compete, and those that get it are highly motivated to keep it secret. The result is that, with few exceptions, little is known about the information shaping these systems’ behavior, and even less is known about the people doing the shaping.\n\nFor Joe’s students, it was work stripped of all its normal trappings: a schedule, colleagues, knowledge of what they were working on or whom they were working for. In fact, they rarely called it work at all — just “tasking.” They were taskers.\n\nThe anthropologist David Graeber defines “bullshit jobs” as employment without meaning or purpose, work that should be automated but for reasons of bureaucracy or status or inertia is not. These AI jobs are their bizarro twin: work that people want to automate, and often think is already automated, yet still requires a human stand-in. The jobs have a purpose; it’s just that workers often have no idea what it is.\n\n---\n\nThe current AI boom — the convincingly human-sounding chatbots, the artwork that can be generated from simple prompts, and the multibillion-dollar valuations of the companies behind these technologies — began with an unprecedented feat of tedious and repetitive labor.\n\nIn 2007, the AI researcher Fei-Fei Li, then a professor at Princeton, suspected the key to improving image-recognition neural networks, a method of machine learning that had been languishing for years, was training on more data — millions of labeled images rather than tens of thousands. The problem was that it would take decades and millions of dollars for her team of undergrads to label that many photos.\n\nLi found thousands of workers on Mechanical Turk, Amazon’s crowdsourcing platform where people around the world complete small tasks for cheap. The resulting annotated dataset, called ImageNet, enabled breakthroughs in machine learning that revitalized the field and ushered in a decade of progress.\n\nAnnotation remains a foundational part of making AI, but there is often a sense among engineers that it’s a passing, inconvenient prerequisite to the more glamorous work of building models. You collect as much labeled data as you can get as cheaply as possible to train your model, and if it works, at least in theory, you no longer need the annotators. But annotation is never really finished. Machine-learning systems are what researchers call “brittle,” prone to fail when encountering something that isn’t well represented in their training data. These failures, called “edge cases,” can have serious consequences. In 2018, an Uber self-driving test car killed a woman because, though it was programmed to avoid cyclists and pedestrians, it didn’t know what to make of someone walking a bike across the street. The more AI systems are put out into the world to dispense legal advice and medical help, the more edge cases they will encounter and the more humans will be needed to sort them. Already, this has given rise to a global industry staffed by people like Joe who use their uniquely human faculties to help the machines.\n\n\"Is that a red shirt with white stripes or a white shirt with red stripes? Is a wicker bowl a “decorative bowl” if it’s full of apples? What color is leopard print?\"\n\nOver the past six months, I spoke with more than two dozen annotators from around the world, and while many of them were training cutting-edge chatbots, just as many were doing the mundane manual labor required to keep AI running. There are people classifying the emotional content of TikTok videos, new variants of email spam, and the precise sexual provocativeness of online ads. Others are looking at credit-card transactions and figuring out what sort of purchase they relate to or checking e-commerce recommendations and deciding whether that shirt is really something you might like after buying that other shirt. Humans are correcting customer-service chatbots, listening to Alexa requests, and categorizing the emotions of people on video calls. They are labeling food so that smart refrigerators don’t get confused by new packaging, checking automated security cameras before sounding alarms, and identifying corn for baffled autonomous tractors.\n\n“There’s an entire supply chain,” said Sonam Jindal, the program and research lead of the nonprofit Partnership on AI. “The general perception in the industry is that this work isn’t a critical part of development and isn’t going to be needed for long. All the excitement is around building artificial intelligence, and once we build that, it won’t be needed anymore, so why think about it? But it’s infrastructure for AI. Human intelligence is the basis of artificial intelligence, and we need to be valuing these as real jobs in the AI economy that are going to be here for a while.”\n\nThe data vendors behind familiar names like OpenAI, Google, and Microsoft come in different forms. There are private outsourcing companies with call-center-like offices, such as the Kenya- and Nepal-based CloudFactory, where Joe annotated for $1.20 an hour before switching to Remotasks. There are also “crowdworking” sites like Mechanical Turk and Clickworker where anyone can sign up to perform tasks. In the middle are services like Scale AI. Anyone can sign up, but everyone has to pass qualification exams and training courses and undergo performance monitoring. Annotation is big business. Scale, founded in 2016 by then-19-year-old Alexandr Wang, was valued in 2021 at $7.3 billion, making him what Forbes called “the youngest self-made billionaire,” though the magazine noted in a recent profile that his stake has fallen on secondary markets since then.\n\n[Image: https://cdn.vox-cdn.com/thumbor/tzXNAIWOaBlv7KbHabZQPNgOKvU=/0x0:2048x1500/2048x1500/filters:focal(1024x750:1025x751)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738135/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_003_2.jpg]\n\nThis tangled supply chain is deliberately hard to map. According to people in the industry, the companies buying the data demand strict confidentiality. (This is the reason Scale cited to explain why Remotasks has a different name.) Annotation reveals too much about the systems being developed, and the huge number of workers required makes leaks difficult to prevent. Annotators are warned repeatedly not to tell anyone about their jobs, not even their friends and co-workers, but corporate aliases, project code names, and, crucially, the extreme division of labor ensure they don’t have enough information about them to talk even if they wanted to. (Most workers requested pseudonyms for fear of being booted from the platforms.) Consequently, there are no granular estimates of the number of people who work in annotation, but it is a lot, and it is growing. A recent Google Research paper gave an order-of-magnitude figure of “millions” with the potential to become “billions.”\n\nAutomation often unfolds in unexpected ways. Erik Duhaime, CEO of medical-data-annotation company Centaur Labs, recalled how, several years ago, prominent machine-learning engineers were predicting AI would make the job of radiologist obsolete. When that didn’t happen, conventional wisdom shifted to radiologists using AI as a tool. Neither of those is quite what he sees occurring. AI is very good at specific tasks, Duhaime said, and that leads work to be broken up and distributed across a system of specialized algorithms and to equally specialized humans. An AI system might be capable of spotting cancer, he said, giving a hypothetical example, but only in a certain type of imagery from a certain type of machine; so now, you need a human to check that the AI is being fed the right type of data and maybe another human who checks its work before passing it to another AI that writes a report, which goes to another human, and so on. “AI doesn’t replace work,” he said. “But it does change how work is organized.”\n\nYou might miss this if you believe AI is a brilliant, thinking machine. But if you pull back the curtain even a little, it looks more familiar, the latest iteration of a particularly Silicon Valley division of labor, in which the futuristic gleam of new technologies hides a sprawling manufacturing apparatus and the people who make it run. Duhaime reached back farther for a comparison, a digital version of the transition from craftsmen to industrial manufacturing: coherent processes broken into tasks and arrayed along assembly lines with some steps done by machines and some by humans but none resembling what came before.\n\nWorries about AI-driven disruption are often countered with the argument that AI automates tasks, not jobs, and that these tasks will be the dull ones, leaving people to pursue more fulfilling and human work. But just as likely, the rise of AI will look like past labor-saving technologies, maybe like the telephone or typewriter, which vanquished the drudgery of message delivering and handwriting but generated so much new correspondence, commerce, and paperwork that new offices staffed by new types of workers — clerks, accountants, typists — were required to manage it. When AI comes for your job, you may not lose it, but it might become more alien, more isolating, more tedious.\n\n---\n\nEarlier this year, I signed up for Scale AI’s Remotasks. The process was straightforward. After entering my computer specs, internet speed, and some basic contact information, I found myself in the “training center.” To access a paying task, I first had to complete an associated (unpaid) intro course.\n\nThe training center displayed a range of courses with inscrutable names like Glue Swimsuit and Poster Macadamia. I clicked on something called GFD Chunking, which revealed itself to be labeling clothing in social-media photos.\n\nThe instructions, however, were odd. For one, they basically consisted of the same direction reiterated in the idiosyncratically colored and capitalized typography of a collaged bomb threat.\n\n“DO LABEL items that are real and can be worn by humans or are intended to be worn by real people,” it read.\n\n“All items below SHOULD be labeled because they are real and can be worn by real-life humans,” it reiterated above photos of an Air Jordans ad, someone in a Kylo Ren helmet, and mannequins in dresses, over which was a lime-green box explaining, once again, “DO Label real items that can be worn by real people.”\n\n[Image: Remotasks instructions for labeling clothing. https://cdn.vox-cdn.com/thumbor/MHHrTeYM1ECpMGl9kVhgPdVy6QM=/0x0:2083x2083/2083x2083/filters:focal(1042x1042:1043x1043)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737331/AI_Secondary.jpeg]\n\nI skimmed to the bottom of the manual, where the instructor had written in the large bright-red font equivalent of grabbing someone by the shoulders and shaking them, “THE FOLLOWING ITEMS SHOULD NOT BE LABELED because a human could not actually put wear any of these items!” above a photo of C-3PO, Princess Jasmine from Aladdin, and a cartoon shoe with eyeballs.\n\nFeeling confident in my ability to distinguish between real clothes that can be worn by real people and not-real clothes that cannot, I proceeded to the test. Right away, it threw an ontological curveball: a picture of a magazine depicting photos of women in dresses. Is a photograph of clothing real clothing? No, I thought, because a human cannot wear a photograph of clothing. Wrong! As far as AI is concerned, photos of real clothes are real clothes. Next came a photo of a woman in a dimly lit bedroom taking a selfie before a full-length mirror. The blouse and shorts she’s wearing are real. What about their reflection? Also real! Reflections of real clothes are also real clothes.\n\nAfter an embarrassing amount of trial and error, I made it to the actual work, only to make the horrifying discovery that the instructions I’d been struggling to follow had been updated and clarified so many times that they were now a full 43 printed pages of directives: Do NOT label open suitcases full of clothes; DO label shoes but do NOT label flippers; DO label leggings but do NOT label tights; do NOT label towels even if someone is wearing it; label costumes but do NOT label armor. And so on.\n\nThere has been general instruction disarray across the industry, according to Milagros Miceli, a researcher at the Weizenbaum Institute in Germany who studies data work. It is in part a product of the way machine-learning systems learn. Where a human would get the concept of “shirt” with a few examples, machine-learning programs need thousands, and they need to be categorized with perfect consistency yet varied enough (polo shirts, shirts being worn outdoors, shirts hanging on a rack) that the very literal system can handle the diversity of the real world. “Imagine simplifying complex realities into something that is readable for a machine that is totally dumb,” she said.\n\n\"Once, Victor stayed up 36 hours straight labeling elbows and knees and heads in photographs of crowds — he has no idea why.\"\n\nThe act of simplifying reality for a machine results in a great deal of complexity for the human. Instruction writers must come up with rules that will get humans to categorize the world with perfect consistency. To do so, they often create categories no human would use. A human asked to tag all the shirts in a photo probably wouldn’t tag the reflection of a shirt in a mirror because they would know it is a reflection and not real. But to the AI, which has no understanding of the world, it’s all just pixels and the two are perfectly identical. Fed a dataset with some shirts labeled and other (reflected) shirts unlabeled, the model won’t work. So the engineer goes back to the vendor with an update: DO label reflections of shirts. Soon, you have a 43-page guide descending into red all-caps.\n\n“When you start off, the rules are relatively simple,” said a former Scale employee who requested anonymity because of an NDA. “Then they get back a thousand images and then they’re like, Wait a second, and then you have multiple engineers and they start to argue with each other. It’s very much a human thing.”\n\nThe job of the annotator often involves putting human understanding aside and following instructions very, very literally — to think, as one annotator said, like a robot. It’s a strange mental space to inhabit, doing your best to follow nonsensical but rigorous rules, like taking a standardized test while on hallucinogens. Annotators invariably end up confronted with confounding questions like, Is that a red shirt with white stripes or a white shirt with red stripes? Is a wicker bowl a “decorative bowl” if it’s full of apples? What color is leopard print? When instructors said to label traffic-control directors, did they also mean to label traffic-control directors eating lunch on the sidewalk? Every question must be answered, and a wrong guess could get you banned and booted to a new, totally different task with its own baffling rules.\n\n[Image: https://cdn.vox-cdn.com/thumbor/kQBljfwrhkJGYtW8XWVY30BSM1k=/0x0:2048x1737/2048x1737/filters:focal(1024x869:1025x870)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738137/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_005_2.jpg]\n\nMost of the work on Remotasks is paid at a piece rate with a single task earning anywhere from a few cents to several dollars. Because tasks can take seconds or hours, wages are hard to predict. When Remotasks first arrived in Kenya, annotators said it paid relatively well — averaging about $5 to $10 per hour depending on the task — but the amount fell as time went on.\n\nScale AI spokesperson Anna Franko said that the company’s economists analyze the specifics of a project, the skills required, the regional cost of living, and other factors “to ensure fair and competitive compensation.” Former Scale employees also said pay is determined through a surge-pricing-like mechanism that adjusts for how many annotators are available and how quickly the data is needed.\n\nAccording to workers I spoke with and job listings, U.S.-based Remotasks annotators generally earn between $10 and $25 per hour, though some subject-matter experts can make more. By the beginning of this year, pay for the Kenyan annotators I spoke with had dropped to between $1 and $3 per hour.\n\nThat is, when they were making any money at all. The most common complaint about Remotasks work is its variability; it’s steady enough to be a full-time job for long stretches but too unpredictable to rely on. Annotators spend hours reading instructions and completing unpaid trainings only to do a dozen tasks and then have the project end. There might be nothing new for days, then, without warning, a totally different task appears and could last anywhere from a few hours to weeks. Any task could be their last, and they never know when the next one will come.\n\nThis boom-and-bust cycle results from the cadence of AI development, according to engineers and data vendors. Training a large model requires an enormous amount of annotation followed by more iterative updates, and engineers want it all as fast as possible so they can hit their target launch date. There may be monthslong demand for thousands of annotators, then for only a few hundred, then for a dozen specialists of a certain type, and then thousands again. “The question is, Who bears the cost for these fluctuations?” said Jindal of Partnership on AI. “Because right now, it’s the workers.”\n\n\"“I really am wasting my life here if I made somebody a billionaire and I’m earning a couple of bucks a week.”\"\n\nTo succeed, annotators work together. When I told Victor, who started working for Remotasks while at university in Nairobi, about my struggles with the traffic-control-directors task, he told me everyone knew to stay away from that one: too tricky, bad pay, not worth it. Like a lot of annotators, Victor uses unofficial WhatsApp groups to spread the word when a good task drops. When he figures out a new one, he starts impromptu Google Meets to show others how it’s done. Anyone can join and work together for a time, sharing tips. “It’s a culture we have developed of helping each other because we know when on your own, you can’t know all the tricks,” he said.\n\nBecause work appears and vanishes without warning, taskers always need to be on alert. Victor has found that projects pop up very late at night, so he is in the habit of waking every three hours or so to check his queue. When a task is there, he’ll stay awake as long as he can to work. Once, he stayed up 36 hours straight labeling elbows and knees and heads in photographs of crowds — he has no idea why. Another time, he stayed up so long his mother asked him what was wrong with his eyes. He looked in the mirror to discover they were swollen.\n\nAnnotators generally know only that they are training AI for companies located vaguely elsewhere, but sometimes the veil of anonymity drops — instructions mentioning a brand or a chatbot say too much. “I read and I Googled and found I am working for a 25-year-old billionaire,” said one worker, who, when we spoke, was labeling the emotions of people calling to order Domino’s pizza. “I really am wasting my life here if I made somebody a billionaire and I’m earning a couple of bucks a week.”\n\nVictor is a self-proclaimed “fanatic” about AI and started annotating because he wants to help bring about a fully automated post-work future. But earlier this year, someone dropped a Time story into one of his WhatsApp groups about workers training ChatGPT to recognize toxic content who were getting paid less than $2 an hour by the vendor Sama AI. “People were angry that these companies are so profitable but paying so poorly,” Victor said. He was unaware until I told him about Remotasks’ connection to Scale. Instructions for one of the tasks he worked on were nearly identical to those used by OpenAI, which meant he had likely been training ChatGPT as well, for approximately $3 per hour.\n\n“I remember that someone posted that we will be remembered in the future,” he said. “And somebody else replied, ‘We are being treated worse than foot soldiers. We will be remembered nowhere in the future.’ I remember that very well. Nobody will recognize the work we did or the effort we put in.”\n\n---\n\nIdentifying clothing and labeling customer-service conversations are just some of the annotation gigs available. Lately, the hottest on the market has been chatbot trainer. Because it demands specific areas of expertise or language fluency and wages are often adjusted regionally, this job tends to pay better. Certain types of specialist annotation can go for $50 or more per hour.\n\nA woman I’ll call Anna was searching for a job in Texas when she stumbled across a generic listing for online work and applied. It was Remotasks, and after passing an introductory exam, she was brought into a Slack room of 1,500 people who were training a project code-named Dolphin, which she later discovered to be Google DeepMind’s chatbot, Sparrow, one of the many bots competing with ChatGPT. Her job is to talk with it all day. At about $14 an hour, plus bonuses for high productivity, “it definitely beats getting paid $10 an hour at the local Dollar General store,” she said.\n\nAlso, she enjoys it. She has discussed science-fiction novels, mathematical paradoxes, children’s riddles, and TV shows. Sometimes the bot’s responses make her laugh; other times, she runs out of things to talk about. “Some days, my brain is just like, I literally have no idea what on earth to ask it now,” she said. “So I have a little notebook, and I’ve written about two pages of things — I just Google interesting topics — so I think I’ll be good for seven hours today, but that’s not always the case.”\n\nEach time Anna prompts Sparrow, it delivers two responses and she picks the best one, thereby creating something called “human-feedback data.” When ChatGPT debuted late last year, its impressively natural-seeming conversational style was credited to its having been trained on troves of internet data. But the language that fuels ChatGPT and its competitors is filtered through several rounds of human annotation. One group of contractors writes examples of how the engineers want the bot to behave, creating questions followed by correct answers, descriptions of computer programs followed by functional code, and requests for tips on committing crimes followed by polite refusals. After the model is trained on these examples, yet more contractors are brought in to prompt it and rank its responses. This is what Anna is doing with Sparrow. Exactly which criteria the raters are told to use varies — honesty, or helpfulness, or just personal preference. The point is that they are creating data on human taste, and once there’s enough of it, engineers can train a second model to mimic their preferences at scale, automating the ranking process and training their AI to act in ways humans approve of. The result is a remarkably human-seeming bot that mostly declines harmful requests and explains its AI nature with seeming self-awareness.\n\nPut another way, ChatGPT seems so human because it was trained by an AI that was mimicking humans who were rating an AI that was mimicking humans who were pretending to be a better version of an AI that was trained on human writing.\n\n[Image: https://cdn.vox-cdn.com/thumbor/BJ1voW9GJtnRC0ZSvYAl9KHBH-c=/0x0:2048x1514/2048x1514/filters:focal(1024x757:1025x758)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738136/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_004_2.jpg]\n\nThis circuitous technique is called “reinforcement learning from human feedback,” or RLHF, and it’s so effective that it’s worth pausing to fully register what it doesn’t do. When annotators teach a model to be accurate, for example, the model isn’t learning to check answers against logic or external sources or about what accuracy as a concept even is. The model is still a text-prediction machine mimicking patterns in human writing, but now its training corpus has been supplemented with bespoke examples, and the model has been weighted to favor them. Maybe this results in the model extracting patterns from the part of its linguistic map labeled as accurate and producing text that happens to align with the truth, but it can also result in it mimicking the confident style and expert jargon of the accurate text while writing things that are totally wrong. There is no guarantee that the text the labelers marked as accurate is in fact accurate, and when it is, there is no guarantee that the model learns the right patterns from it.\n\nThis dynamic makes chatbot annotation a delicate process. It has to be rigorous and consistent because sloppy feedback, like marking material that merely sounds correct as accurate, risks training models to be even more convincing bullshitters. An early OpenAI and DeepMind joint project using RLHF, in this case to train a virtual robot hand to grab an item, resulted in also training the robot to position its hand between the object and its raters and wiggle around such that it only appeared to its human overseers to grab the item. Ranking a language model’s responses is always going to be somewhat subjective because it’s language. A text of any length will have multiple elements that could be right or wrong or, taken together, misleading. OpenAI researchers ran into this obstacle in another early RLHF paper. Trying to get their model to summarize text, the researchers found they agreed only 60 percent of the time that a summary was good. “Unlike many tasks in [machine learning] our queries do not have unambiguous ground truth,” they lamented.\n\nWhen Anna rates Sparrow’s responses, she’s supposed to be looking at their accuracy, helpfulness, and harmlessness while also checking that the model isn’t giving medical or financial advice or anthropomorphizing itself or running afoul of other criteria. To be useful training data, the model’s responses have to be quantifiably ranked against one another: Is a bot that helpfully tells you how to make a bomb “better” than a bot that’s so harmless it refuses to answer any questions? In one DeepMind paper, when Sparrow’s makers took a turn annotating, four researchers wound up debating whether their bot had assumed the gender of a user who asked it for relationship advice. According to Geoffrey Irving, one of DeepMind’s research scientists, the company’s researchers hold weekly annotation meetings in which they rerate data themselves and discuss ambiguous cases, consulting with ethical or subject-matter experts when a case is particularly tricky.\n\n\"There are people classifying the emotional content of TikTok videos, new variants of email spam, and the precise sexual provocativeness of online ads.\"\n\nAnna often finds herself having to choose between two bad options. “Even if they’re both absolutely, ridiculously wrong, you still have to figure out which one is better and then write words explaining why,” she said. Sometimes, when both responses are bad, she’s encouraged to write a better response herself, which she does about half the time.\n\nBecause feedback data is difficult to collect, it fetches a higher price. Basic preferences of the sort Anna is producing sell for about $1 each, according to people with knowledge of the industry. But if you want to train a model to do legal research, you need someone with training in law, and this gets expensive. Everyone involved is reluctant to say how much they’re spending, but in general, specialized written examples can go for hundreds of dollars, while expert ratings can cost $50 or more. One engineer told me about buying examples of Socratic dialogues for up to $300 a pop. Another told me about paying $15 for a “darkly funny limerick about a goldfish.”\n\nOpenAI, Microsoft, Meta, and Anthropic did not comment about how many people contribute annotations to their models, how much they are paid, or where in the world they are located. Irving of DeepMind, which is a subsidiary of Google, said the annotators working on Sparrow are paid “at least the hourly living wage” based on their location. Anna knows “absolutely nothing” about Remotasks, but Sparrow has been more open. She wasn’t the only annotator I spoke with who got more information from the AI they were training than from their employer; several others learned whom they were working for by asking their AI for its company’s terms of service. “I literally asked it, ‘What is your purpose, Sparrow?’” Anna said. It pulled up a link to DeepMind’s website and explained that it’s an AI assistant and that its creators trained it using RLHF to be helpful and safe.\n\n---\n\nUntil recently, it was relatively easy to spot bad output from a language model. It looked like gibberish. But this gets harder as the models get better — a problem called “scalable oversight.” Google inadvertently demonstrated how hard it is to catch the errors of a modern-language model when one made it into the splashy debut of its AI assistant, Bard. (It stated confidently that the James Webb Space Telescope “took the very first pictures of a planet outside of our own solar system,” which is wrong.) This trajectory means annotation increasingly requires specific skills and expertise.\n\nLast year, someone I’ll call Lewis was working on Mechanical Turk when, after completing a task, he received a message inviting him to apply for a platform he hadn’t heard of. It was called Taskup.ai, and its website was remarkably basic: just a navy background with text reading GET PAID FOR TASKS ON DEMAND. He applied.\n\nThe work paid far better than anything he had tried before, often around $30 an hour. It was more challenging, too: devising complex scenarios to trick chatbots into giving dangerous advice, testing a model’s ability to stay in character, and having detailed conversations about scientific topics so technical they required extensive research. He found the work “satisfying and stimulating.” While checking one model’s attempts to code in Python, Lewis was learning too. He couldn’t work for more than four hours at a stretch, lest he risk becoming mentally drained and making mistakes, and he wanted to keep the job.\n\n“If there was one thing I could change, I would just like to have more information about what happens on the other end,” he said. “We only know as much as we need to know to get work done, but if I could know more, then maybe I could get more established and perhaps pursue this as a career.”\n\nI spoke with eight other workers, most based in the U.S., who had similar experiences of answering surveys or completing tasks on other platforms and finding themselves recruited for Taskup.ai or several similarly generic sites, such as DataAnnotation.tech or Gethybrid.io. Often their work involved training chatbots, though with higher-quality expectations and more specialized purposes than other sites they had worked for. One was demonstrating spreadsheet macros. Another was just supposed to have conversations and rate responses according to whatever criteria she wanted. She often asked the chatbot things that had come up in conversations with her 7-year-old daughter, like “What is the largest dinosaur?” and “Write a story about a tiger.” “I haven’t fully gotten my head around what they’re trying to do with it,” she told me.\n\nTaskup.ai, DataAnnotation.tech, and Gethybrid.io all appear to be owned by the same company: Surge AI. Its CEO, Edwin Chen, would neither confirm nor deny the connection, but he was willing to talk about his company and how he sees annotation evolving.\n\n“I’ve always felt the annotation landscape is overly simplistic,” Chen said over a video call from Surge’s office. He founded Surge in 2020 after working on AI at Google, Facebook, and Twitter convinced him that crowdsourced labeling was inadequate. “We want AI to tell jokes or write really good marketing copy or help me out when I need therapy or whatnot,” Chen said. “You can’t ask five people to independently come up with a joke and combine it into a majority answer. Not everybody can tell a joke or solve a Python program. The annotation landscape needs to shift from this low-quality, low-skill mind-set to something that’s much richer and captures the range of human skills and creativity and values that we want AI systems to possess.”\n\n[Image: https://cdn.vox-cdn.com/thumbor/Qe4htQ4VivRXnS0BWZowjTY8hE8=/0x0:2048x1572/2048x1572/filters:focal(1024x786:1025x787)/cdn.vox-cdn.com/uploads/chorus_asset/file/24738134/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_002_2.jpg]\n\nLast year, Surge relabeled Google’s dataset classifying Reddit posts by emotion. Google had stripped each post of context and sent them to workers in India for labeling. Surge employees familiar with American internet culture found that 30 percent of the labels were wrong. Posts like “hell yeah my brother” had been classified as annoyance and “Yay, cold McDonald’s. My favorite” as love.\n\nSurge claims to vet its workers for qualifications — that people doing creative-writing tasks have experience with creative writing, for example — but exactly how Surge finds workers is “proprietary,” Chen said. As with Remotasks, workers often have to complete training courses, though unlike Remotasks, they are paid for it, according to the annotators I spoke with. Having fewer, better-trained workers producing higher-quality data allows Surge to compensate better than its peers, Chen said, though he declined to elaborate, saying only that people are paid “fair and ethical wages.” The workers I spoke with earned between $15 and $30 per hour, but they are a small sample of all the annotators, a group Chen said now consists of 100,000 people. The secrecy, he explained, stems from clients’ demands for confidentiality.\n\nSurge’s customers include OpenAI, Google, Microsoft, Meta, and Anthropic. Surge specializes in feedback and language annotation, and after ChatGPT launched, it got an influx of requests, Chen said: “I thought everybody knew the power of RLHF, but I guess people just didn’t viscerally understand.”\n\nThe new models are so impressive they’ve inspired another round of predictions that annotation is about to be automated. Given the costs involved, there is significant financial pressure to do so. Anthropic, Meta, and other companies have recently made strides in using AI to drastically reduce the amount of human annotation needed to guide models, and other developers have started using GPT-4 to generate training data. However, a recent paper found that GPT-4-trained models may be learning to mimic GPT’s authoritative style with even less accuracy, and so far, when improvements in AI have made one form of annotation obsolete, demand for other, more sophisticated types of labeling has gone up. This debate spilled into the open earlier this year, when Scale’s CEO, Wang, tweeted that he predicted AI labs will soon be spending as many billions of dollars on human data as they do on computing power; OpenAI’s CEO, Sam Altman, responded that data needs will decrease as AI improves.\n\n\"“I mean, what it can do is amazing,” she said of the chatbot. “But it still does some really weird shit.”\"\n\nChen is skeptical AI will reach a point where human feedback is no longer needed, but he does see annotation becoming more difficult as models improve. Like many researchers, he believes the path forward will involve AI systems helping humans oversee other AI. Surge recently collaborated with Anthropic on a proof of concept, having human labelers answer questions about a lengthy text with the help of an unreliable AI assistant, on the theory that the humans would have to feel out the weaknesses of their AI assistant and collaborate to reason their way to the correct answer. Another possibility has two AIs debating each other and a human rendering the final verdict on which is correct. “We still have yet to see really good practical implementations of this stuff, but it’s starting to become necessary because it’s getting really hard for labelers to keep up with the models,” said OpenAI research scientist John Schulman in a recent talk at Berkeley.\n\n“I think you always need a human to monitor what AIs are doing just because they are this kind of alien entity,” Chen said. Machine-learning systems are just too strange ever to fully trust. The most impressive models today have what, to a human, seems like bizarre weaknesses, he added, pointing out that though GPT-4 can generate complex and convincing prose, it can’t pick out which words are adjectives: “Either that or models get so good that they’re better than humans at all things, in which case, you reach your utopia and who cares?”\n\n---\n\nAs 2022 ended, Joe started hearing from his students that their task queues were often empty. Then he got an email informing him the boot camps in Kenya were closing. He continued training taskers online, but he began to worry about the future.\n\n“There were signs that it was not going to last long,” he said. Annotation was leaving Kenya. From colleagues he had met online, he heard tasks were going to Nepal, India, and the Philippines. “The companies shift from one region to another,” Joe said. “They don’t have infrastructure locally, so it makes them flexible to shift to regions that favor them in terms of operation cost.”\n\nOne way the AI industry differs from manufacturers of phones and cars is in its fluidity. The work is constantly changing, constantly getting automated away and replaced with new needs for new types of data. It’s an assembly line but one that can be endlessly and instantly reconfigured, moving to wherever there is the right combination of skills, bandwidth, and wages.\n\nLately, the best-paying work is in the U.S. In May, Scale started listing annotation jobs on its own website, soliciting people with experience in practically every field AI is predicted to conquer. There were listings for AI trainers with expertise in health coaching, human resources, finance, economics, data science, programming, computer science, chemistry, biology, accounting, taxes, nutrition, physics, travel, K-12 education, sports journalism, and self-help. You can make $45 an hour teaching robots law or make $25 an hour teaching them poetry. There were also listings for people with security clearance, presumably to help train military AI. Scale recently launched a defense-oriented language model called Donovan, which Wang called “ammunition in the AI war,” and won a contract to work on the Army’s robotic-combat-vehicle program.\n\nAnna is still training chatbots in Texas. Colleagues have been turned into reviewers and Slack admins — she isn’t sure why, but it has given her hope that the gig could be a longer-term career. One thing she isn’t worried about is being automated out of a job. “I mean, what it can do is amazing,” she said of the chatbot. “But it still does some really weird shit.”\n\nWhen Remotasks first arrived in Kenya, Joe thought annotation could be a good career. Even after the work moved elsewhere, he was determined to make it one. There were thousands of people in Nairobi who knew how to do the work, he reasoned — he had trained many of them, after all. Joe rented office space in the city and began sourcing contracts: a job annotating blueprints for a construction company, another labeling fruits despoiled by insects for some sort of agricultural project, plus the usual work of annotating for self-driving cars and e-commerce.\n\nBut he has found his vision difficult to achieve. He has just one full-time employee, down from two. “We haven’t been having a consistent flow of work,” he said. There are weeks with nothing to do because customers are still collecting data, and when they’re done, he has to bring in short-term contractors to meet their deadlines: “Clients don’t care whether we have consistent work or not. So long as the datasets have been completed, then that’s the end of that.”\n\nRather than let their skills go to waste, other taskers decided to chase the work wherever it went. They rented proxy servers to disguise their locations and bought fake IDs to pass security checks so they could pretend to work from Singapore, the Netherlands, Mississippi, or wherever the tasks were flowing. It’s a risky business. Scale has become increasingly aggressive about suspending accounts caught disguising their location, according to multiple taskers. It was during one of these crackdowns that my account got banned, presumably because I had been using a VPN to see what workers in other countries were seeing, and all $1.50 or so of my earnings were seized.\n\n“These days, we have become a bit cunning because we noticed that in other countries they are paying well,” said Victor, who was earning double the Kenyan rate by tasking in Malaysia. “You do it cautiously.”\n\nAnother Kenyan annotator said that after his account got suspended for mysterious reasons, he decided to stop playing by the rules. Now, he runs multiple accounts in multiple countries, tasking wherever the pay is best. He works fast and gets high marks for quality, he said, thanks to ChatGPT. The bot is wonderful, he said, letting him speed through $10 tasks in a matter of minutes. When we spoke, he was having it rate another chatbot’s responses according to seven different criteria, one AI training the other.\n"},"twitterObj":false,"status":200,"metadata":{"author":false,"title":"Inside the AI Factory: the humans that make tech seem human - The Verge","description":"How many humans does it take to make tech seem human? Millions to support OpenAI, Google, Meta, and every other major tech company. As AI becomes ubiquitous, a vast tasker underclass is emerging — and not going anywhere.","canonical":"https://www.theverge.com/features/23764584/ai-artificial-intelligence-data-notation-labor-scale-surge-remotasks-openai-chatbots","keywords":[],"image":"https://duet-cdn.vox-cdn.com/thumbor/0x0:2048x1365/2400x2400/filters:focal(1024x683:1025x684):format(webp)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg","firstParagraph":"By  Josh Dzieza, an investigations editor covering tech, business, and climate change. Since joining The Verge in 2014, he’s won a Loeb Award for feature writing, among others."},"dublinCore":{},"opengraph":{"title":"Inside the AI Factory","description":"How many humans does it take to make tech seem human? Millions.","url":"https://www.theverge.com/features/23764584/ai-artificial-intelligence-data-notation-labor-scale-surge-remotasks-openai-chatbots","site_name":"The Verge","locale":false,"type":"article","typeObject":{"published_time":"2023-06-20T12:05:00.000Z","modified_time":"2023-06-20T12:05:00.000Z","author":false,"publisher":false,"section":false,"tag":[]},"image":"https://cdn.vox-cdn.com/thumbor/v9wxGGbTW0yvHsZtt1mg8laUnOA=/0x0:2048x1365/1200x628/filters:focal(1024x683:1025x684)/cdn.vox-cdn.com/uploads/chorus_asset/file/24737787/236709_ai_data_notation_labor_scale_surge_remotasks_openai_chatbots_RParry_001.jpg","image:type":"image/jpeg","image:width":"1200","image:height":"628"},"twitter":{"site":"@verge","description":false,"card":"summary_large_image","creator":false,"title":false,"image":false},"archivedData":{"link":false,"wayback":false}}}