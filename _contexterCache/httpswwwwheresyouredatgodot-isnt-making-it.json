{"initialLink":"https://www.wheresyoured.at/godot-isnt-making-it/","sanitizedLink":"https://www.wheresyoured.at/godot-isnt-making-it/","finalLink":"https://www.wheresyoured.at/godot-isnt-making-it/","htmlEmbed":"<script>window.contexterSetup=window.contexterSetup||function(){window.contexterSetupComplete=!0;class ContexterLink extends HTMLAnchorElement{constructor(){super()}connectedCallback(){this.setAttribute(\"target\",\"_blank\")}}customElements.define(\"contexter-link\",ContexterLink,{extends:\"a\"}),customElements.define(\"contexter-inner\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__inner\"}}),customElements.define(\"contexter-thumbnail\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__thumbnail\"}}),customElements.define(\"contexter-byline\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__byline\"}}),customElements.define(\"contexter-keywordset\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__keywordset\"}}),customElements.define(\"contexter-linkset\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__linkset\"}}),customElements.define(\"contexter-meta\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__meta\"}}),customElements.define(\"contexter-summary\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"p-summary entry-summary\"}}),customElements.define(\"contexter-box-head\",class extends HTMLElement{constructor(){super()}connectedCallback(){this.className=\"contexter-box__head\"}}),customElements.define(\"contexter-box-inner\",class extends HTMLElement{constructor(){super()}connectedCallback(){}});class ContexterBox extends HTMLElement{constructor(){super(),this.first=!0,this.shadow=this.attachShadow({mode:\"open\"})}connectedCallback(){if(this.first){this.first=!1;var style=document.createElement(\"style\"),lightDomStyle=(style.innerHTML=`:host {--background: #f5f6f7;--border: darkblue;--blue: #0000ee;--font-color: black;--inner-border: black;font-family: Franklin,Arial,Helvetica,sans-serif;font-size: 14px;background: var(--background);width: 600px;color: var(--font-color);min-height: 90px;display: block;padding: 8px;border: 1px solid var(--border);cursor: pointer;box-sizing: border-box;margin: 6px;contain: content;margin: 6px auto;}// can only select top-level nodes with slotted::slotted(*) {max-width: 100%;display:block;}::slotted([slot=thumbnail]) {max-width: 100%;display:block;}::slotted([slot=header]) {width: 100%;font-size: 1.25rem;font-weight: bold;display:block;margin-bottom: 6px;}::slotted([slot=author]) {max-width: 50%;font-size: 12px;display:inline-block;float: left;}::slotted([slot=time]) {max-width: 50%;font-size: 12px;display:inline-block;float: right;}::slotted([slot=summary]) {width: 100%;margin-top: 6px;padding: 10px 2px;border-top: 1px solid var(--inner-border);font-size: 15px;display:inline-block;margin-bottom: 6px;}contexter-meta {height: auto;margin-bottom: 4px;width: 100%;display: grid;position: relative;min-height: 16px;grid-template-columns: repeat(2, 1fr);}::slotted([slot=keywords]) {width: 80%;padding: 2px 4px;border-top: 1px solid var(--inner-border);font-size: 11px;display: block;float: right;font-style: italic;text-align: right;grid-column: 2/2;grid-row: 1;align-self: end;justify-self: end;}::slotted([slot=keywords]):empty {border-top: 0px solid var(--inner-border);}::slotted([slot=archive-link]) {font-size: 1em;display: inline;}::slotted([slot=archive-link])::after {content: \"|\";display: inline;color: var(--font-color);text-decoration: none;margin: 0 .5em;}::slotted([slot=read-link]) {font-size: 1em;display: inline;}contexter-linkset {width: 80%;padding: 2px 4px;font-size: 13px;float: left;font-weight: bold;grid-row: 1;grid-column: 1/2;align-self: end;justify-self: start;}/* Extra small devices (phones, 600px and down) */@media only screen and (max-width: 600px) {:host {width: 310px;}}/* Small devices (portrait tablets and large phones, 600px and up) */@media only screen and (min-width: 600px) {...}/* Medium devices (landscape tablets, 768px and up) */@media only screen and (min-width: 768px) {...}/* Large devices (laptops/desktops, 992px and up) */@media only screen and (min-width: 992px) {...}/* Extra large devices (large laptops and desktops, 1200px and up) */@media only screen and (min-width: 1200px) {...}@media (prefers-color-scheme: dark){:host {--background: #354150;--border: #1f2b37;--blue: #55b0ff;--font-color: #ffffff;--inner-border: #787a7c;background: var(--background);border: 1px solid var(--border)}}`,document.createElement(\"style\"));lightDomStyle.innerHTML=`contexter-box {contain: content;}contexter-box .read-link {font-weight: bold;}contexter-box a {color: #0000ee;}contexter-box img {width: 100%;border: 0;padding: 0;margin: 0;}/* Extra small devices (phones, 600px and down) */@media only screen and (max-width: 600px) {...}/* Small devices (portrait tablets and large phones, 600px and up) */@media only screen and (min-width: 600px) {...}/* Medium devices (landscape tablets, 768px and up) */@media only screen and (min-width: 768px) {...}/* Large devices (laptops/desktops, 992px and up) */@media only screen and (min-width: 992px) {...}/* Extra large devices (large laptops and desktops, 1200px and up) */@media only screen and (min-width: 1200px) {...}@media (prefers-color-scheme: dark){contexter-box a {color: #55b0ff;}}`,this.appendChild(lightDomStyle),this.shadow.appendChild(style);const innerContainer=document.createElement(\"contexter-box-inner\"),innerSlotThumbnail=(this.shadow.appendChild(innerContainer),document.createElement(\"slot\")),innerSlotHeader=(innerSlotThumbnail.name=\"thumbnail\",innerContainer.appendChild(innerSlotThumbnail),document.createElement(\"slot\")),innerSlotAuthor=(innerSlotHeader.name=\"header\",innerContainer.appendChild(innerSlotHeader),document.createElement(\"slot\")),innerSlotTime=(innerSlotAuthor.name=\"author\",innerContainer.appendChild(innerSlotAuthor),document.createElement(\"slot\")),innerSlotSummary=(innerSlotTime.name=\"time\",innerContainer.appendChild(innerSlotTime),document.createElement(\"slot\")),metaContainer=(innerSlotSummary.name=\"summary\",innerContainer.appendChild(innerSlotSummary),document.createElement(\"contexter-meta\")),innerSlotInfo=(innerContainer.appendChild(metaContainer),document.createElement(\"slot\")),linkContainer=(innerSlotInfo.name=\"keywords\",metaContainer.appendChild(innerSlotInfo),document.createElement(\"contexter-linkset\")),innerSlotArchiveLink=(metaContainer.appendChild(linkContainer),document.createElement(\"slot\")),innerSlotReadLink=(innerSlotArchiveLink.name=\"archive-link\",linkContainer.appendChild(innerSlotArchiveLink),document.createElement(\"slot\"));innerSlotReadLink.name=\"read-link\",linkContainer.appendChild(innerSlotReadLink),this.className=\"contexter-box\",this.onclick=e=>{if(!e.target.className.includes(\"read-link\")&&!e.target.className.includes(\"title-link\")){const mainLinks=this.querySelectorAll(\"a.main-link\");mainLinks[0].click()}}}}}customElements.define(\"contexter-box\",ContexterBox)},window.contexterSetupComplete||window.contexterSetup();</script><contexter-box class=\"link-card h-entry hentry\" itemscope=\"\" itemtype=\"https://schema.org/CreativeWork\"><contexter-thumbnail class=\"thumbnail\" slot=\"thumbnail\"></contexter-thumbnail><contexter-box-head slot=\"header\" class=\"p-name entry-title\" itemprop=\"headline\"><contexter-box-head slot=\"header\" class=\"p-name entry-title\" itemprop=\"headline\"><a is=\"contexter-link\" href=\"https://www.wheresyoured.at/godot-isnt-making-it/\" itemprop=\"url\">Godot Isn&#x27;t Making it</a></contexter-box-head></contexter-box-head><contexter-byline class=\"p-author author\" slot=\"author\"><span class=\"p-name byline\" rel=\"author\" itemprop=\"author\">Edward Zitron</span></contexter-byline><time class=\"dt-published published\" slot=\"time\" itemprop=\"datePublished\" datetime=\"2024-12-03T20:55:22.000Z\">12/3/2024</time><contexter-summary class=\"p-summary entry-summary\" itemprop=\"abstract\" slot=\"summary\"><p>Before we get going — please enjoy my speech from Web Summit, Why Are All Tech Products Now Shit? I didn’t write the title.What if what we&#x27;re seeing today isn&#x27;t a glimpse of the future, but the new terms of the present? What if artificial intelligence isn&#x27;t actually capable of doing much more than what we&#x27;re seeing today, and what if there&#x27;s no clear timeline when it&#x27;ll be able to do more? What if this entire hype cycle has been built, goosed by a compliant media ready and willing to take care</p></contexter-summary><contexter-keywordset itemprop=\"keywords\" slot=\"keywords\"></contexter-keywordset><a href=\"https://web.archive.org/web/20241204200151/https://www.wheresyoured.at/godot-isnt-making-it/\" is=\"contexter-link\" target=\"_blank\" rel=\"timemap\" class=\"read-link archive-link\" itemprop=\"archivedAt\" slot=\"archive-link\">Archived</a><a is=\"contexter-link\" href=\"https://www.wheresyoured.at/godot-isnt-making-it/\" class=\"read-link main-link\" itemprop=\"sameAs\" slot=\"read-link\">Read</a></contexter-box>","linkId":"f770017fe566a713973c0f87791ec11059c7d160","data":{"originalLink":"https://www.wheresyoured.at/godot-isnt-making-it/","sanitizedLink":"https://www.wheresyoured.at/godot-isnt-making-it/","canonical":"https://www.wheresyoured.at/godot-isnt-making-it/","htmlText":"<!DOCTYPE html>\n<html lang=\"en\" data-color-scheme=\"ivory\">\n  <head>\n    <meta charset=\"utf-8\">\n    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=edge\">\n\n    <title>Godot Isn&#x27;t Making it</title>\n\n    <meta name=\"HandheldFriendly\" content=\"True\" />\n    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n    \n    <meta name=\"theme-color\" content=\"#dd0000\">\n\n\n    <link rel=\"preload\" href=\"https://www.wheresyoured.at/assets/dist/app.min.js?v=1562b67321\" as=\"script\">\n    <link rel=\"preload\" href=\"https://www.wheresyoured.at/assets/dist/app.min.css?v=1562b67321\" as=\"style\">\n\n        <link rel=\"preconnect\" href=\"https://fonts.googleapis.com\">\n    <link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin>\n\n\n\n    <link rel=\"preload stylesheet\" href=\"https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&display=swap\" \n          as=\"style\" onload=\"this.onload=null;this.rel='stylesheet'\" crossorigin>    \n    <style>body { --font-body: 'Inter', sans-serif; --font-headings: 'Inter', sans-serif;}</style>\n\n\n\n\n\n    <script async defer src=\"https://www.wheresyoured.at/assets/dist/app.min.js?v=1562b67321\"></script>\n\n    <link rel=\"stylesheet\" type=\"text/css\" href=\"https://www.wheresyoured.at/assets/dist/app.min.css?v=1562b67321\" />\n\n    <style>\n  :root {\n    --global-max-width: 1280px; /* site max width */\n    --global-content-width: 680px; /* post-content-width */\n    --global-wide-width: 960px; /* site max width */\n    --global-radius: 10px; /* default radius */\n    --global-gallery-gap: 1em; /* Image gallery distance between images */\n    --global-hyphens: none; /* none/auto */\n    --global-header-height: 80px;\n    --global-theme-notifications: visible; /* visible/hidden */\n    --global-progress-bar: visible; /* visible/hidden */\n    --global-content-preview-fading: 0%; /* 50%-100% for fading effect */\n  }\n</style>\n\n<script>\n  let preferredTheme = localStorage.getItem('PREFERRED_COLOR_SCHEME') || `ivory`;\n  document.documentElement.setAttribute('data-color-scheme', preferredTheme);\n  \n  // Global values needed\n  const themeGlobal = {\n    currentPage: parseInt(''),\n    nextPage: parseInt(''),\n    nextPageLink: '',\n    maxPages: parseInt(''), \n    lastPage: `` === `` ? true : false,\n    postsPerPage: parseInt('12'),\n    scrollPos: 0\n  }\n\n  // Calculate contrast & HSL value;\n  function getBrandColorInfo(hexcolor) {\n    // get contrast\n    if (hexcolor.slice(0, 1) === '#') { hexcolor = hexcolor.slice(1); }\n    if (hexcolor.length === 3) { hexcolor = hexcolor.split('').map(function (hex) { return hex + hex;}).join(''); }\n    let r = parseInt(hexcolor.substr(0,2),16), g = parseInt(hexcolor.substr(2,2),16), b = parseInt(hexcolor.substr(4,2),16);\n    let yiq = ((r * 299) + (g * 587) + (b * 114)) / 1000;\n    const colorContrast = (yiq >= 128) ? '#000' : '#fff';\n\n    //get HSL\n    r /= 255, g /= 255, b /= 255;\n    const max = Math.max(r, g, b), min = Math.min(r, g, b);\n    let h, s, l = (max + min)  /  2;  \n    if ( max == min ) { h = s = 0; } else {\n      let d = max - min;\n      s = l > 0.5 ? d / (2 - max - min) : d / (max + min);\n      switch(max){\n        case r: h = (g - b) / d + (g < b ? 6 : 0); break;\n        case g: h = (b - r) / d + 2; break;\n        case b: h = (r - g) / d + 4; break;\n      }\n      h /= 6;\n    }\n    const colorHSL = [Math.round(h * 360), Math.round(s * 100), Math.round(l * 100)];\n\n    // return\n    return { colorContrast, colorHSL }\n  };\n\n  const brandColor = getBrandColorInfo(\"#dd0000\");\n  let style = document.createElement('style');\n  style.innerHTML = `:root { \n    --color-brand-contrast: ${brandColor.colorContrast}; \n    --color-brand-hsl: ${brandColor.colorHSL[0]} ${brandColor.colorHSL[1]}% ${brandColor.colorHSL[2]}%;\n  }`\n  document.getElementsByTagName('head')[0].appendChild(style);\n</script>\n\n    \n    \n     \n\n    <link rel=\"icon\" href=\"https://www.wheresyoured.at/content/images/size/w256h256/2024/01/wyea-.jpeg\" type=\"image/jpeg\">\n    <link rel=\"canonical\" href=\"https://www.wheresyoured.at/godot-isnt-making-it/\">\n    <meta name=\"referrer\" content=\"no-referrer-when-downgrade\">\n    \n    <meta property=\"og:site_name\" content=\"Ed Zitron&#x27;s Where&#x27;s Your Ed At\">\n    <meta property=\"og:type\" content=\"article\">\n    <meta property=\"og:title\" content=\"Godot Isn&#x27;t Making it\">\n    <meta property=\"og:description\" content=\"Before we get going — please enjoy my speech from Web Summit, Why Are All Tech Products Now Shit? I didn’t write the title.\n\nWhat if what we&#x27;re seeing today isn&#x27;t a glimpse of the future, but the new terms of the present? What if artificial intelligence isn&#x27;t actually capable\">\n    <meta property=\"og:url\" content=\"https://www.wheresyoured.at/godot-isnt-making-it/\">\n    <meta property=\"og:image\" content=\"https://www.wheresyoured.at/content/images/2024/01/wyea--1.jpeg\">\n    <meta property=\"article:published_time\" content=\"2024-12-03T20:55:22.000Z\">\n    <meta property=\"article:modified_time\" content=\"2024-12-03T20:55:22.000Z\">\n    <meta name=\"twitter:card\" content=\"summary_large_image\">\n    <meta name=\"twitter:title\" content=\"Godot Isn&#x27;t Making it\">\n    <meta name=\"twitter:description\" content=\"Before we get going — please enjoy my speech from Web Summit, Why Are All Tech Products Now Shit? I didn’t write the title.\n\nWhat if what we&#x27;re seeing today isn&#x27;t a glimpse of the future, but the new terms of the present? What if artificial intelligence isn&#x27;t actually capable\">\n    <meta name=\"twitter:url\" content=\"https://www.wheresyoured.at/godot-isnt-making-it/\">\n    <meta name=\"twitter:image\" content=\"https://www.wheresyoured.at/content/images/2024/01/wyea--1.jpeg\">\n    <meta name=\"twitter:label1\" content=\"Written by\">\n    <meta name=\"twitter:data1\" content=\"Edward Zitron\">\n    <meta name=\"twitter:site\" content=\"@edzitron\">\n    <meta property=\"og:image:width\" content=\"1200\">\n    <meta property=\"og:image:height\" content=\"1200\">\n    \n    <script type=\"application/ld+json\">\n{\n    \"@context\": \"https://schema.org\",\n    \"@type\": \"Article\",\n    \"publisher\": {\n        \"@type\": \"Organization\",\n        \"name\": \"Ed Zitron&#x27;s Where&#x27;s Your Ed At\",\n        \"url\": \"https://www.wheresyoured.at/\",\n        \"logo\": {\n            \"@type\": \"ImageObject\",\n            \"url\": \"https://www.wheresyoured.at/content/images/2024/01/wide-with-letters-1.jpeg\"\n        }\n    },\n    \"author\": {\n        \"@type\": \"Person\",\n        \"name\": \"Edward Zitron\",\n        \"image\": {\n            \"@type\": \"ImageObject\",\n            \"url\": \"https://www.gravatar.com/avatar/257728ef58ec6562631bc7ebf24dd007?s=250&r=x&d=mp\",\n            \"width\": 250,\n            \"height\": 250\n        },\n        \"url\": \"https://www.wheresyoured.at/author/edward/\",\n        \"sameAs\": []\n    },\n    \"headline\": \"Godot Isn&#x27;t Making it\",\n    \"url\": \"https://www.wheresyoured.at/godot-isnt-making-it/\",\n    \"datePublished\": \"2024-12-03T20:55:22.000Z\",\n    \"dateModified\": \"2024-12-03T20:55:22.000Z\",\n    \"description\": \"Before we get going — please enjoy my speech from Web Summit, Why Are All Tech Products Now Shit? I didn’t write the title.\\n\\nWhat if what we&#x27;re seeing today isn&#x27;t a glimpse of the future, but the new terms of the present? What if artificial intelligence isn&#x27;t actually capable of doing much more than what we&#x27;re seeing today, and what if there&#x27;s no clear timeline when it&#x27;ll be able to do more? What if this entire hype cycle has been built, goosed by a compliant media ready and willing to take care\",\n    \"mainEntityOfPage\": \"https://www.wheresyoured.at/godot-isnt-making-it/\"\n}\n    </script>\n\n    <meta name=\"generator\" content=\"Ghost 5.101\">\n    <link rel=\"alternate\" type=\"application/rss+xml\" title=\"Ed Zitron&#x27;s Where&#x27;s Your Ed At\" href=\"https://www.wheresyoured.at/rss/\">\n    <script defer src=\"https://cdn.jsdelivr.net/ghost/portal@~2.46/umd/portal.min.js\" data-i18n=\"true\" data-ghost=\"https://www.wheresyoured.at/\" data-key=\"e36e7d7220258a9362c249dff6\" data-api=\"https://ed-zitrons-wheres-your-ed-at.ghost.io/ghost/api/content/\" data-locale=\"en\" crossorigin=\"anonymous\"></script><style id=\"gh-members-styles\">.gh-post-upgrade-cta-content,\n.gh-post-upgrade-cta {\n    display: flex;\n    flex-direction: column;\n    align-items: center;\n    font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Open Sans', 'Helvetica Neue', sans-serif;\n    text-align: center;\n    width: 100%;\n    color: #ffffff;\n    font-size: 16px;\n}\n\n.gh-post-upgrade-cta-content {\n    border-radius: 8px;\n    padding: 40px 4vw;\n}\n\n.gh-post-upgrade-cta h2 {\n    color: #ffffff;\n    font-size: 28px;\n    letter-spacing: -0.2px;\n    margin: 0;\n    padding: 0;\n}\n\n.gh-post-upgrade-cta p {\n    margin: 20px 0 0;\n    padding: 0;\n}\n\n.gh-post-upgrade-cta small {\n    font-size: 16px;\n    letter-spacing: -0.2px;\n}\n\n.gh-post-upgrade-cta a {\n    color: #ffffff;\n    cursor: pointer;\n    font-weight: 500;\n    box-shadow: none;\n    text-decoration: underline;\n}\n\n.gh-post-upgrade-cta a:hover {\n    color: #ffffff;\n    opacity: 0.8;\n    box-shadow: none;\n    text-decoration: underline;\n}\n\n.gh-post-upgrade-cta a.gh-btn {\n    display: block;\n    background: #ffffff;\n    text-decoration: none;\n    margin: 28px 0 0;\n    padding: 8px 18px;\n    border-radius: 4px;\n    font-size: 16px;\n    font-weight: 600;\n}\n\n.gh-post-upgrade-cta a.gh-btn:hover {\n    opacity: 0.92;\n}</style><script async src=\"https://js.stripe.com/v3/\"></script>\n    <script defer src=\"https://cdn.jsdelivr.net/ghost/sodo-search@~1.5/umd/sodo-search.min.js\" data-key=\"e36e7d7220258a9362c249dff6\" data-styles=\"https://cdn.jsdelivr.net/ghost/sodo-search@~1.5/umd/main.css\" data-sodo-search=\"https://ed-zitrons-wheres-your-ed-at.ghost.io/\" data-locale=\"en\" crossorigin=\"anonymous\"></script>\n    \n    <link href=\"https://www.wheresyoured.at/webmentions/receive/\" rel=\"webmention\">\n    <script defer src=\"/public/cards.min.js?v=1562b67321\"></script>\n    <link rel=\"stylesheet\" type=\"text/css\" href=\"/public/cards.min.css?v=1562b67321\">\n    <script defer src=\"/public/comment-counts.min.js?v=1562b67321\" data-ghost-comments-counts-api=\"https://www.wheresyoured.at/members/api/comments/counts/\"></script>\n    <script defer src=\"/public/member-attribution.min.js?v=1562b67321\"></script><style>:root {--ghost-accent-color: #dd0000;}</style>\n    <script defer=\"defer\" data-domain=\"wheresyoured.at\" src=\"https://plausible.io/js/script.hash.outbound-links.js\"></script>\n<meta name =“robots” content=“max-image-preview:large”>\n\n<style>\n  .header { height: auto; }\n  .header__inner > *:not(.header__brand) { display: none!important; }\n  .header__brand { flex:1!important; margin: 0!important; justify-content:center; }\n  .header__brand img { height: auto; max-width: 100%; border-radius: var(--global-radius); }\n\n  .home-layout { max-width: 720px;margin: 0 auto; }\n  .home-layout .hero { margin: 2rem 0 3rem; }\n  .home-layout .hero__media { flex: 1; display: none; }\n  .home-layout .hero__media img { aspect-ratio: 1/1; }\n  .home-layout .hero__content { flex: 2; }\n  .home-layout .hero__title { font-size: calc(var(--font-size-base)*2 + .75vw); line-height: 1.1; }\n  .home-layout[data-layout=\"hero-with-image-below\"] .hero__content { min-height: 0; }\n  \n  .post-card { padding: 1.5rem; }\n  .post-feed article.post-card:nth-of-type(odd) { background: rgba(0,0,0,0.05); }\n  \n  @media only screen and (min-width: 48em) {\n    /* .header { --global-header-height: 96px; } */\n    .header__brand img { height: 120px; max-width: none; }\n    /* .home-layout .hero__media { display: flex; } */\n  }\n  \n  .hero__content .header__menu { display: flex!important; margin-top: 2rem; }\n  .hero__content .header__menu .nav { justify-content: center; flex-wrap: wrap; }\n</style>\n  </head>\n  <body class=\"post-template \">\n    <div class=\"progress-bar\"></div>\n    \n      <header class=\"header js-header\" data-header=\"normal\">\n  <div class=\"container wrapper flex is-rel header__inner\">\n    <button class=\"btn-toggle menu__toggle js-menu-open\"\n      type=\"button\" title=\"Menu\" aria-label=\"Menu\">\n        <span></span>\n        <span></span>\n    </button>\n\n<a class=\"header__brand\" href=\"https://www.wheresyoured.at\">        <img class=\"header__logo\"\n          src=\"/content/images/size/w600/2024/01/wide-with-letters-1.jpeg\"\n          alt=\"Ed Zitron&#x27;s Where&#x27;s Your Ed At\"/>\n</a>\n    <nav class=\"header__menu flex-1 flex-cc\">\n      <ul class=\"nav\">\n    <li class=\"nav-home\"><a href=\"https://www.wheresyoured.at/\">Home</a></li>\n    <li class=\"nav-about\"><a href=\"https://www.wheresyoured.at/about/\">About</a></li>\n    <li class=\"nav-better-offline\"><a href=\"http://linktr.ee/betteroffline\">Better Offline</a></li>\n</ul>\n\n    </nav>\n\n      <button class=\"btn-toggle header-search__toggle\" data-ghost-search title=\"Search\" aria-label=\"Search\">\n        <i class=\"icon icon-search\">\n  <svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-search\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n  <path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n  <circle cx=\"10\" cy=\"10\" r=\"7\" />\n  <line x1=\"21\" y1=\"21\" x2=\"15\" y2=\"15\" />\n</svg>\n\n\n\n</i>      </button>\n    \n\n        <a href=\"/signin/\" class=\"btn signin-link radius\" data-portal=\"signin\">Log In</a>\n        <a href=\"/signup/\" class=\"btn signup-link btn--brand radius\" data-portal=\"signup\">Subscribe</a>\n      \n\n    <div class=\"member-menu js-member-menu\">\n      <a href=\"/signup/\" data-portal=\"signup\" class=\"signup-link\">\n        <i class=\"icon icon-arrow-up-right icon--sm\">\n  <svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-arrow-up-right\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n  <path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n  <line x1=\"17\" y1=\"7\" x2=\"7\" y2=\"17\" />\n  <polyline points=\"8 7 17 7 17 16\" />\n</svg>\n\n\n\n</i>Sign up\n      </a>\n\n      <a href=\"/signin/\" data-portal=\"signin\" class=\"signin-link\">\n        <i class=\"icon icon-login icon--sm\">\n  <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"feather feather-log-in\">\n  <path d=\"M15 3h4a2 2 0 0 1 2 2v14a2 2 0 0 1-2 2h-4\"></path>\n  <polyline points=\"10 17 15 12 10 7\"></polyline>\n  <line x1=\"15\" y1=\"12\" x2=\"3\" y2=\"12\"></line>\n</svg>\n</i>Sign in\n      </a>\n</div>  </div>\n</header>\n\n      <div class=\"menu js-menu\">\n  <div class=\"menu__header flex content-start\">\n    <button class=\"btn-toggle menu__toggle is-active js-menu-close\"\n      type=\"button\" title=\"Menu\" aria-label=\"Menu\">\n        <span></span>\n        <span></span>\n    </button>\n\n      <button class=\"btn-toggle header-search__toggle\" data-ghost-search title=\"Search\" aria-label=\"Search\">\n        <i class=\"icon icon-search\">\n  <svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-search\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n  <path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n  <circle cx=\"10\" cy=\"10\" r=\"7\" />\n  <line x1=\"21\" y1=\"21\" x2=\"15\" y2=\"15\" />\n</svg>\n\n\n\n</i>      </button>\n\n\n  </div>\n\n  <nav class=\"menu__navigation\">\n    <ul class=\"nav\">\n    <li class=\"nav-home\"><a href=\"https://www.wheresyoured.at/\">Home</a></li>\n    <li class=\"nav-about\"><a href=\"https://www.wheresyoured.at/about/\">About</a></li>\n    <li class=\"nav-better-offline\"><a href=\"http://linktr.ee/betteroffline\">Better Offline</a></li>\n</ul>\n\n\n      <ul class=\"nav\">\n    <li class=\"nav-sign-up\"><a href=\"#/portal/\">Sign up</a></li>\n</ul>\n\n  </nav>\n\n  <div class=\"menu__actions m-b flex w-100\">\n        <a href=\"/signin/\" data-portal=\"signin\" class=\"btn signin-link btn--bordered radius m-r\">\n          <i class=\"icon icon-login icon--sm\">\n  <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"feather feather-log-in\">\n  <path d=\"M15 3h4a2 2 0 0 1 2 2v14a2 2 0 0 1-2 2h-4\"></path>\n  <polyline points=\"10 17 15 12 10 7\"></polyline>\n  <line x1=\"15\" y1=\"12\" x2=\"3\" y2=\"12\"></line>\n</svg>\n</i>Log in\n        </a>\n        <a href=\"/signup/\" data-portal=\"signup\" class=\"btn signup-link btn--brand radius\">\n          <i class=\"icon icon-arrow-up-right icon--sm\">\n  <svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-arrow-up-right\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n  <path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n  <line x1=\"17\" y1=\"7\" x2=\"7\" y2=\"17\" />\n  <polyline points=\"8 7 17 7 17 16\" />\n</svg>\n\n\n\n</i>Subscribe\n        </a>\n  </div>\n</div>\n    <main class=\"main\">\n      \n\n  <div class=\"container wrapper\">\n  \n      <div class=\"post-hero is-post\" \n    data-feature-image=\"false\" data-image-style=\"default\">\n    <div class=\"post-hero__content flex flex-col\">\n\n\n      <h1 class=\"post-hero__title\">Godot Isn&#x27;t Making it</h1>\n\n\n        <div class=\"post-hero__info\">\n          <span class=\"post-hero__authors\"><a href=\"/author/edward/\">Edward Zitron</a></span>\n          <time class=\"post-hero__date\" datetime=\"2024-12-03\">Dec 3, 2024</time> \n          <span class=\"post-hero__readtime\">23 min read</span>\n        </div> \n    </div>\n\n  </div>\n\n    <article class=\"post no-image content post-access-public\">\n      <p><em>Before we get going — please enjoy my speech from Web Summit, </em><a href=\"https://www.youtube.com/watch?v=7Slib2bbMs4&ref=wheresyoured.at\"><em><u>Why Are All Tech Products Now Shit</u></em></a><em>? I didn’t write the title.</em></p><hr><blockquote>What if what we're seeing today isn't a glimpse of the future, but the new terms of the present? What if artificial intelligence isn't actually capable of doing much more than what we're seeing today, and what if there's no clear timeline when it'll be able to do more? What if this entire hype cycle has been built, goosed by a compliant media ready and willing to take career-embellishers at their word?<br><br><a href=\"https://www.wheresyoured.at/peakai/\"><u>Me, in March 2024.</u></a></blockquote><p>I have been warning you for the best part of a year that generative AI has no killer apps and had no way of justifying its valuations (<a href=\"https://www.wheresyoured.at/sam-altman-fried/#:~:text=This%20industry%20is%20money,good%20for%20the%20environment.\"><u>February</u></a>), that generative AI had already peaked (<a href=\"https://www.wheresyoured.at/peakai/#:~:text=Unless%2C%20of%20course,at%20their%20word%3F\"><u>March</u></a>), and I have pleaded with people to consider an eventuality where the jump from GPT-4 to GPT-5 was not significant, in part due to a lack of training data (<a href=\"https://www.wheresyoured.at/bubble-trouble/#:~:text=How%20do%20you,as%20a%20result%3F\"><u>April</u></a>).&nbsp;</p><p>I shared concerns in<a href=\"https://www.wheresyoured.at/pop-culture/\"> <u>July</u></a> that the transformer-based-architecture underpinning generative AI was a dead end, and that there were few ways we'd progress past the products we'd already seen, in part due to both the limits of training data and the limits of models that <em>use said </em>training data. In<a href=\"https://www.wheresyoured.at/burst-damage/\"> <u>August</u></a>, I summarized the Pale Horses of the AI Apocalypse — events, many that have since come to pass, that would signify that the end is indeed nigh — and again added that GPT-5 would likely \"not change the game enough to matter, let alone [add] a new architecture to build future (and more capable) models on.\"</p><p>Throughout these pieces I have repeatedly made the point that — separate to any lack of a core value proposition, training data drought, or unsustainable economics — generative AI is a dead end due to the limitations of probabilistic models that hallucinate, where they authoritatively state things that aren't true. The hallucination problem is one that is nowhere closer to being solved — and, at least with the current technology — may never go away, and it makes it a non-starter for a great many business tasks, where you need a high level of reliability.</p><p>I have —<a href=\"https://www.wheresyoured.at/peakai/#:~:text=What%20if%20what%20we%27re%20seeing%20today%20isn%27t%20a%20glimpse%20of%20the%20future%2C%20but%20the%20new%20terms%20of%20the%20present%3F\"> <u>since March</u></a> — expressed great dismay about the credulousness of the media in their acceptance of the \"inevitable\" ways in which generative AI will change society, despite a lack of any truly meaningful product that might justify an environmentally-destructive industry<a href=\"https://www.wheresyoured.at/oai-business/\"> <u>led by a company that burns more than $5 billion a year</u></a> and<a href=\"https://www.bloomberg.com/professional/insights/technology/big-tech-2025-capex-may-hit-200-billion-as-gen-ai-demand-booms/?ref=wheresyoured.at\"> <u>big tech firms spending $200 billion on data centers</u></a><a href=\"https://www.martechcube.com/report-49-of-consumers-unlikely-to-buy-generative-ai-enabled-products/?ref=wheresyoured.at\"> <u>for products</u></a><a href=\"https://www.ciodive.com/news/ChatGPT-anniversary-enterprise-strategy-evolution-generative-AI/732951/?ref=wheresyoured.at\"> <u>that people don't want</u></a>.</p><p>The reason I'm repeating myself is that it's <em>important to note how obvious the problems with generative AI have been, and for how long.</em></p><p>And you're going to need context for everything I'm about to throw at you.</p><blockquote><strong>Sidebar: </strong>To explain exactly what happened here, it's worth going over how these models work and are trained. I’ll keep it simple as it's a reminder.<br><br>A transformer-based generative AI model such as GPT — the technology behind ChatGPT — generates answers using \"inference,\" which means it draws conclusions based off of its \"training,\" which requires feeding it masses of training data (mostly text and images scraped from the internet). Both of these processes require you to use high-end GPUs (graphics processing units), and <em>lots</em> of them.<br><br>The theory was (is?) that the more training data and compute you throw at these models, the better they get. I have hypothesized for a while they'd have diminishing returns — both from running out of training data and based on the limitations of transformer-based models.&nbsp;<br><br>And there, as they say, is the rub.</blockquote><p>A few weeks ago, Bloomberg reported that<a href=\"https://www.bloomberg.com/news/articles/2024-11-13/openai-google-and-anthropic-are-struggling-to-build-more-advanced-ai?ref=wheresyoured.at\"> <u>OpenAI, Google, and Anthropic are struggling to build more advanced AI</u></a>, and that OpenAI's \"Orion\" model — otherwise known as GPT-5 — \"did not hit the company's desired performance,\" and that \"Orion is so far not considered to be as big a step up\" as it was from GPT-3.5 to GPT-4, its current model. You'll be shocked to hear the reason is that because \"it’s become increasingly difficult to find new, untapped sources of high-quality, human-made training data that can be used to build more advanced AI systems,\"<a href=\"https://www.wheresyoured.at/bubble-trouble/#:~:text=This%20scenario%20is%20likely%20if%20the%20next%20generations%20of%20ChatGPT%20or%20Claude%20fail%20to%20make%20significant%20leaps%20in%20their%20capabilities%2C%20and%20as%20I%27ve%20said%20above%2C%20their%20ability%20to%20do%20so%20is%20predicated%20on%20more%20training%20data%20and%20compute%20power%20than%20currently%20exists.\"> <u>something I said would happen in March</u></a>, while also adding that the \"AGI bubble is bursting a little bit,\"<a href=\"https://www.wheresyoured.at/put-up-or-shut-up/#:~:text=They%E2%80%99re%20not%20getting%20%E2%80%9Creasoning%2C%E2%80%9D%20nor%20are%20they%20getting%20%E2%80%9Csentience%2C%E2%80%9D%20nor%20are%20they%20%E2%80%9Cpart%20of%20the%20path%20to%20superintelligence.%E2%80%9D%C2%A0\"> <u>something I said more forcefully in July</u></a>.</p><p>I also want to stop and stare daggers at one particular point:</p><blockquote>These issues challenge the gospel that has taken hold in Silicon Valley in recent years, particularly since OpenAI released ChatGPT two years ago. Much of the tech industry has bet on so-called scaling laws that say more computing power, data and larger models will inevitably pave the way for greater leaps forward in the power of AI.</blockquote><p>The only people taking this as \"gospel\" have been members of the media unwilling to ask the tough questions and AI founders that don't know what the fuck they're talking about (or that intend to mislead). Generative AI's products have effectively been trapped in amber for over a year. There have been no meaningful, industry-defining products, because,<a href=\"https://www.wheresyoured.at/pop-culture/#:~:text=No%2C%20really%2C%20what%20does%20%22more%22%20actually%20mean%3F%20While%20one%20might%20argue%20that%20it%27ll%20mean%20faster%20generative%20processes%2C\"> <u>as economist Daron Acemoglu said back in May</u></a>, \"more powerful\" models do not unlock new features, or really change the experience, nor what you can build with transformer-based models. Or, put another way, a slightly better <a href=\"https://en.wikipedia.org/wiki/White_elephant?ref=wheresyoured.at\"><u>white elephant</u></a> is still a white elephant.&nbsp;</p><p>Despite the billions of dollars burned and thousands of glossy headlines, it's difficult to point to any truly important generative-AI-powered product.<a href=\"https://www.washingtonpost.com/technology/2024/10/28/apple-intelligence-ios-181/?ref=wheresyoured.at\"> <u>Even Apple Intelligence, the only thing that Apple really had to add to the latest iPhone, is utterly dull, and largely based on on-device models</u></a>.</p><p>Yes, there are people that use ChatGPT —<a href=\"https://www.reuters.com/technology/artificial-intelligence/openai-says-chatgpts-weekly-users-have-grown-200-million-2024-08-29/?ref=wheresyoured.at\"> <u>200 million of them a week, allegedly</u></a>, losing the company money with every prompt — but there is little to suggest that there's widespread adoption of actual generative AI software.<a href=\"https://www.theinformation.com/articles/microsoft-customers-pause-on-office-ai-assistant-due-to-budgets-bugs?rc=kz8jh3&ref=wheresyoured.at\"> <u>The Information reported in September that between 0.1% and 1% of the 440 million of Microsoft's business customers were paying for its AI-powered Copilot</u></a>, and in late October, Microsoft claimed that \"<a href=\"https://www.axios.com/2024/10/30/microsoft-ai-earnings-2024?ref=wheresyoured.at\"><u>AI is on pace to be a $10 billion-a-year business</u></a>,\" which sounds good until you consider a few things:</p><ol><li>Microsoft has no \"AI business\" unit, which means that this annual \"$10 billion\" (or $2.5 billion a quarter) revenue figure is split across providing cloud compute services on Azure, selling Copilot to dumb people with Microsoft 365 subscriptions, selling Github Copilot, and basically anything else with \"AI\" on it. Microsoft is cherry-picking a number based on non-specific criteria and claiming it's a big deal, when it's actually pretty pathetic<a href=\"https://www.forbes.com/sites/petercohan/2024/07/31/microsoft-stock-drops-as-ai-capital-expenditures-surge-to-56-billion/?ref=wheresyoured.at\"> <u>considering its capital expenditures will likely hit over $60 billion in 2024</u></a>.</li><li>Note the word \"revenue,\" not \"profit.\" How much is Microsoft spending to make $10 billion a year?<a href=\"https://www.wheresyoured.at/oai-business/#:~:text=To%20be%20abundantly%20clear%2C%20as%20it%20stands%2C%20OpenAI%20currently%20spends%20%242.35%20to%20make%20%241.\"> <u>OpenAI currently spends $2.35 to make $1</u></a>, and<a href=\"https://www.cnbc.com/2024/10/30/microsoft-cfo-says-openai-investment-will-cut-into-profit-this-quarter.html?ref=wheresyoured.at\"> <u>Microsoft CFO Amy Hood said that OpenAI would cut into Microsoft's profits this October</u></a>, losing it a remarkable $1.5 billion, \"mainly because of an expected loss from OpenAI\" according to CNBC. A year ago,<a href=\"https://www.techradar.com/pro/microsoft-is-reportedly-losing-huge-amounts-of-money-on-github-copilot?ref=wheresyoured.at\"> <u>the Wall Street Journal reported in October 2023</u></a> that Microsoft was losing an average of $20 per-user-per month on GitHub Copilot — a product with over a million users. If true, this suggests losses of at least $200 million (based on documents I've reviewed, it has 1.8 million users as of a month ago, but I went on the lower end) a year.</li><li>Microsoft has still yet to break out exactly how much generative AI is increasing revenue in specific business units. Generally, if a company is doing well at something, they take great pains to make that clear. Instead, Microsoft chose in August to<a href=\"https://www.cnbc.com/2024/08/21/microsoft-changes-reporting-to-boost-cloud-consumption-visibility.html?ref=wheresyoured.at\"> <u>\"revamp\" its reporting structure to \"give better visibility into cloud consumption revenue,\"</u></a> which is something you do if you, say, anticipate<a href=\"https://www.cnbc.com/2024/10/31/microsoft-stock-has-worst-day-in-two-years-on-disappointing-forecast.html?ref=wheresyoured.at\"> <u>you're going to have your worst day of trading in years after your next earnings as Microsoft did in October</u></a>.</li></ol><p>I must be clear that every single one of these investments and products has been hyped with the whisper that they would get exponentially better over time, and<a href=\"https://www.bloomberg.com/professional/insights/technology/big-tech-2025-capex-may-hit-200-billion-as-gen-ai-demand-booms/?ref=wheresyoured.at\"> <u>that eventually the $200 billion in capital expenditures</u></a> would spit out remarkable productivity improvements and fascinating new products that consumers and enterprises would buy in droves. Instead, big tech has found itself peddling increasingly-more-expensive iterations of near-identical Large Language Models — a direct result of them all having to use the same training data, which it’s now running out of.</p><hr><p>The other assumption — those so-called scaling laws — has been that by simply building bigger data centers with more GPUs (the expensive, power-hungry graphics processing units used to both run and train these models) and throwing as much training data at them as possible, they'd simply start sprouting new capabilities, despite there being little proof that they'd do so. Microsoft, Meta, Amazon, and Google have all burned billions on the assumption that doing so would create something — be it a human-level \"artificial general intelligence\" or, I dunno, a product that would justify the costs — and it's become painfully obvious that it isn't going to work.</p><p>As we speak, outlets are already desperate to try and prove that this isn't a problem. The Information,<a href=\"https://www.theinformation.com/articles/goodbye-gpt-hello-reasoning-o?rc=kz8jh3&ref=wheresyoured.at\"> <u>in a similar story</u></a> to Bloomberg's, attempted to put lipstick on the pig of generative AI, framing the lack of meaningful progress with GPT-5 as fine, because OpenAI can combine its GPT-5 Model with its o-1 \"reasoning\" model, which will then do something of some sort, such as \"write a lot more very difficult code\" according to OpenAI CEO and <a href=\"https://www.wheresyoured.at/false-prophet/\"><u>career liar</u></a> Sam Altman,<a href=\"https://www.gizchina.com/2024/05/17/sam-altman-says-gpt-5-function-may-be-similar-to-a-virtual-brain/?ref=wheresyoured.at\"> <u>who intimated that GPT-5 may function like a \"virtual brain\" in May</u></a>.</p><p>Chief Valley Cheerleader Casey Newton <a href=\"https://www.platformer.news/openai-google-scaling-laws-anthropic-ai/?ref=wheresyoured.at\"><u>wrote on Platformer last week that</u></a> diminishing returns in training models \"may not matter as much as you would guess,\" with his evidence being that Anthropic, who he claims \"has not been prone to hyperbole,\" do not think that scaling laws are ending. To be clear, in a 14,000 op-ed that Newton wrote<a href=\"https://www.platformer.news/anthropic-dario-amodei-doomer-accelerationism/?ref=wheresyoured.at\"> <u>two</u></a><a href=\"https://www.platformer.news/anthropic-responsible-scaling-laws/?ref=wheresyoured.at\"> <u>pieces</u></a> about, Anthropic CEO Dario Amodei said that \"<a href=\"https://darioamodei.com/machines-of-loving-grace?ref=wheresyoured.at#taking-stock:~:text=In%20summary%2C%20AI%2Daccelerated%20neuroscience%20is%20likely%20to%20vastly%20improve%20treatments%20for%2C%20or%20even%20cure%2C%20most%20mental%20illness%20as\"><u>AI-accelerated neuroscience is likely to vastly improve treatments for, or even cure, most mental illness</u></a>,\" the kind of hyperbole that should have you tarred and feathered in public.</p><p>So, let me summarize:</p><ul><li>The main technology behind the entire \"artificial intelligence\" boom is generative AI — transformer-based models like OpenAI's GPT-4 (and soon GPT-5) — and said technology has peaked, with diminishing returns from the only ways of making them \"better\" (feeding them training data and throwing tons of compute at them) suggesting that what we may have, as I've said before, reached <a href=\"https://www.wheresyoured.at/peakai/\"><u>Peak AI</u></a>.</li><li>Generative AI is incredibly unprofitable. OpenAI, the biggest player in the industry, <a href=\"https://www.wheresyoured.at/oai-business/\"><u>is on course to lose more than $5 billion this year</u></a>, with competitor Anthropic (which also makes its own transformer-based model, Claude) <a href=\"https://www.theinformation.com/briefings/anthropic-projected-to-burn-more-than-2-7-billion-in-cash-this-year?rc=kz8jh3&ref=wheresyoured.at\"><u>on course to lose more than $2.7 billion this year</u></a>.</li><li>Every single big tech company has thrown billions — <a href=\"https://www.cnbc.com/2024/10/31/amazon-ceo-pledges-ai-investments-will-pay-off-as-capex-surges-81percent.html?ref=wheresyoured.at\"><u>as much as $75 billion in Amazon's case in 2024 alone</u></a> — at building the data centers and acquiring the GPUs to populate said data centers specifically so they can train their models or other companies' models, or serve customers that would integrate generative AI into their businesses, something that does not appear to be happening at scale.<ul><li>Their investments could theoretically be used for other products, but these data centers are heavily focused on generative AI. <a href=\"https://www.businessinsider.com/microsoft-gpu-targets-1-8-million-ai-chips-this-year-2024-4?ref=wheresyoured.at\"><u>Business Insider reports that Microsoft intends to amass 1.8 <em>million</em> GPUs by the end of 2024</u></a>, costing it tens of billions of dollars.</li></ul></li><li>Worse still, many of the companies integrating generative AI do so by connecting to models made by either OpenAI or Anthropic, both of whom are running unprofitable businesses, and likely charging nowhere near enough to cover their costs. <a href=\"https://www.wheresyoured.at/subprimeai/\"><u>As I wrote in the Subprime AI Crisis in September</u></a>, in the event that these companies start charging what they actually need to, I hypothesize it will multiply the costs of their customers to the point that they can't afford to run their businesses — or, at the very least, will have to remove or scale back generative AI functionality in their products.</li></ul><p>The entire tech industry has become oriented around a dead-end technology that requires burning billions of dollars to provide inessential products that cost them more money to serve than anybody would ever pay. Their big strategy was to throw even <em>more</em> money at the problem until one of these transformer-based models created a new, more useful product — despite the fact that every iteration of GPT and other models has been, well, iterative. There has never been any proof (<a href=\"https://whoisnnamdi.substack.com/p/ai-benchmarking-broken?ref=platformer.news\"><u>other than benchmarks that are increasingly easier to game</u></a>) that GPT or other models would become conscious, nor that these models would do more than they do today, or three months ago, or even a year ago.</p><hr><p>Yet things can, believe it or not, get worse.</p><p><a href=\"https://www.reuters.com/technology/artificial-intelligence/sp-500-earnings-put-investor-focus-tech-ai-2024-10-10/?ref=wheresyoured.at#:~:text=AI%2Drelated%20companies%20have%20dominated,31.\"><u>The AI boom helped the S&amp;P 500 hit record high levels in 2024</u></a>, largely thanks to chip giant NVIDIA, a company that makes both the GPUs necessary to train and run generative AI models and the software architecture behind them. Part of NVIDIA's remarkable growth has been its ability to capitalize on the CUDA architecture — the software layer that lets you do complex computing with GPUs, rather than simply use them to render video games in increasingly higher resolution — and, of course, continually create new GPUs to sell for tens of thousands of dollars to tech companies that want to burn billions of dollars on generative AI, leading the company's stock to pop more than 179% over the last year.</p><p>Back in May, NVIDIA CEO and professional carnival barker Jensen Huang said that the company was now \"<a href=\"https://www.theverge.com/2024/5/22/24162860/nvidia-ai-chip-every-year-blackwell-rubin?ref=wheresyoured.at\"><u>on a one-year rhythm</u></a>\" in AI GPU production, with its latest \"Blackwell\" GPUs (specifically the B100, B200 and GB200 models used for generative AI) supposedly due at the end of 2024,<a href=\"https://www.theinformation.com/articles/nvidias-new-ai-chip-is-delayed-impacting-microsoft-google-meta?rc=kz8jh3&ref=wheresyoured.at\"> <u>but are now delayed until at least March 2025</u></a>.Before we go any further, it's worth noting that when I say \"GPU,\" I don't mean the one you'd find in a gaming PC, but a much larger chip put in a specialized server with multiple <em>other</em> GPUs, all integrated with specialized casing, cooling, and networking infrastructure. In simple terms, the things necessary to make sure all these chips work together efficiently, and also stop them from overheating, <em>because they get extremely hot and are running at full speed, all the time.</em></p><p>The initial delay of the new Blackwell chips was caused by a (<a href=\"https://www.reuters.com/technology/artificial-intelligence/nvidias-design-flaw-with-blackwell-ai-chips-now-fixed-ceo-says-2024-10-23/?ref=wheresyoured.at\"><u>now-fixed</u></a>) design flaw in production, but as I've suggested above, the problem isn't <em>just</em> creating the chips — it's making sure they actually work, at scale, for the jobs they're bought for.&nbsp;</p><p>But what if that, too, wasn't possible?</p><p>A few days ago,<a href=\"https://www.theinformation.com/articles/nvidia-customers-worry-about-snag-with-new-ai-chip-servers?rc=kz8jh3&ref=wheresyoured.at\"> <u>The Information reported</u></a> that NVIDIA is grappling with the oldest problem in computing — how to cool the fucking things. According to the report, NVIDIA has been asking suppliers to change the design of its 3,000-pound, 75-GPU server&nbsp; racks \"several times\" to overcome overheating problems, which The Information calls \"the most complicated design NVIDIA had ever come up with.\" According to the report,&nbsp; a few months after revealing the racks, engineers found that they...didn't work properly, even with Nvidia’s smaller 36-chip racks, and have been scrambling to fix it ever since.</p><p>While one can dazzle investors with buzzwords and charts, the laws of physics are a far harsher mistress, and if NVIDIA is struggling mere months before the first installations are to begin, it's unclear how it practically launches this generation of chips, let alone continues its yearly cadence. The Information reports that these changes have been made late in the production process, which is scaring customers that desperately need them so that their models can continue to do something they'll work out later. To quote The Information:</p><blockquote>Two executives at large cloud providers that have ordered the new chips said they are concerned that such last-minute difficulties might push back the timeline for when they can get their GPU clusters up and running next year.</blockquote><p>The fact that NVIDIA is having such significant difficulties with thermal performance is very, very bad. These chips are incredibly expensive —<a href=\"https://siliconangle.com/2024/11/17/nvidias-upcoming-blackwell-gpus-overheat-server-racks-worrying-customers-reports-say/?ref=wheresyoured.at#:~:text=The%20GB200%20Grace%20Blackwell%20superchips,at%20more%20than%20%243%20million.\"> <u>as much as $70,000 a piece</u></a> — and will be running, as I've mentioned, at full speed, generating an incredible amount of heat that must be dissipated, while sat next to anywhere from 35 to 71 other chips, which will in turn be densely packed so that you can cram more servers into a data center. New, more powerful chips require entirely new methods to rack-mount, operate and cool them, and all of these parts must operate in sync, as overheating GPUs <em>will</em> die. While these units are <em>big</em>, some of their internal components are microscopic in size, and unless properly cooled, their circuits will start to crumble when roasted by a guy typing \"Garfield with Gun\" into ChatGPT.</p><p>Remember, Blackwell is supposed to represent a major leap forward in performance. If NVIDIA doesn’t solve its cooling problem — and solve it well — its customers will undoubtedly encounter thermal throttling, where the chip reduces speed in order to avoid causing permanent damage. It could eliminate any performance gains obtained from the new architecture and new manufacturing process, despite costing <em>much, much more</em> than its predecessor.&nbsp;</p><p>NVIDIA's problem isn't just bringing these thermal performance issues under control, but both keeping them under control <em>and</em> being able to educate their customers on how to do so. NVIDIA has,<a href=\"https://www.theinformation.com/articles/nvidias-jensen-huang-is-on-top-of-the-world-so-why-is-he-worried?rc=kz8jh3&ref=wheresyoured.at\"> <u>according to The Information</u></a>, repeatedly tried to influence its customers' server integrations to follow its designs because it thinks it will \"lead to better performance,\" but in this case, one has to worry if NVIDIA's Blackwell chips can be reliably cooled.</p><p>While NVIDIA might be able to fix this problem in isolation within its racks, it remains to be seen how this works at scale as they ship and integrate hundreds of thousands of Blackwell GPUs starting in the front half of 2025.&nbsp;</p><p>Things also get a little worse when you realize <em>how</em> these chips are being installed — in giant “supercomputer” data centers where tens of thousands, or as many as a hundred thousand in the case of Elon Musk’s “colossus” data center — of GPUs run in concert to power generative AI models. <a href=\"https://www.wsj.com/tech/ai/nvidia-chips-ai-race-96d21d09?ref=wheresyoured.at\"><u>The Wall Street Journal reported a few weeks ago </u></a>that building these vast data centers creates entirely new engineering challenges, with one expert saying that big tech companies could be using <em>as much as half of their capital expenditures </em>on replacing parts that have broken down, in large part because these clusters are running their GPUs at full speed, at all times.&nbsp;</p><p>Remember, the capital expenditures on generative AI and the associated infrastructure have gone over $200 billion in the last year. If half of that’s dedicated to replacing broken gear, what happens when there’s no path to profitability?</p><p>In any case, NVIDIA doesn’t care. It’s already made billions of dollars selling Blackwell GPUs —<a href=\"https://www.techrepublic.com/article/nvidia-blackwell-gpus-sold-out-demand-surges/?ref=wheresyoured.at\"> <u>they're sold out for a year, after all</u></a> — and will continue to do so for now, but any manufacturing or cooling issues will likely be costly.</p><p>And even then, at some point somebody has to ask the question: why do we need all these GPUs if we've reached peak AI? Despite the remarkable \"power\" of these chips, NVIDIA's entire enterprise GPU business model centers around the idea that throwing more power at these problems will finally create some solutions.</p><p>What if that isn't the case?</p><hr><p>The tech industry is over-leveraged, having doubled, tripled, <em>quadrupled</em> down on generative AI — a technology that doesn't do much more than it did a few months ago and won't do much more than it can do now. Every single big tech company has piled tens of billions of dollars into building out massive data centers with the intent of \"capturing AI demand,\" yet never seemed to think whether they were actually building things that people wanted, or would pay for, or would somehow make the company money.</p><p>While some have claimed that \"agents are the next frontier,\" the reality is that agents may be the <em>last</em> generative AI product — multiple Large Language Models and integrations bouncing off of each other in an attempt to simulate what a human might do at a cost that won't be sustainable for the majority of businesses.<a href=\"https://www.platformer.news/anthropic-ai-agents-computer-use-consequences/?ref=wheresyoured.at\"> <u>While Anthropic's demo of its model allegedly controlling a few browser windows with a prompt might have seemed impressive to credulous people like Casey Newton</u></a>, these were controlled demos which Anthropic added were \"slow\" and \"made lots of mistakes.\"&nbsp; Hey,<a href=\"https://www.wheresyoured.at/peakai/#:~:text=OpenAI%20will%20fix-,hallucinations,-%2C%20something%20that%20the\"> <u>almost like it's hallucinating! I sure hope they fix that <em>totally unfixable problem</em></u></a><em>.</em></p><p>Even if it does, Anthropic has now successfully replaced...an entry-level data worker position at an indeterminate and likely unprofitable price. And in many organizations, those jobs had <em>already </em>been outsourced, or automated, or staffed with cheaper contractors.&nbsp;</p><p>The obscenity of this mass delusion is nauseating — a monolith to bad decision-making and the herd mentality of tech's most powerful people, as well as an outright attempt to manipulate the media into believing something was possible that wasn't. And the media bought it, hook, line, and sinker.</p><p>Hundreds of billions of dollars have been wasted building giant data centers to crunch numbers for software that has no real product-market fit, all while trying to hammer it into various shapes to make it pretend that it's alive, conscious, or even a useful product.&nbsp;</p><p>There is no path, from what I can see, to turn generative AI and its associated products into anything resembling sustainable businesses, and the only path that big tech appeared to have was to throw as much money, power, and data at the problem as possible, an avenue that appears to be another dead end.</p><p>And worse still, nothing has really <em>come out</em> of this movement. I've used a handful of AI products that I've found useful — an AI powered journal, for example — but these are not the products that one associates with \"revolutions,\" but useful tools that would have been a welcome surprise if they didn't require burning billions of dollars, blowing past emissions targets and stealing the creative works of millions of people to train them.</p><hr><p>I truly don't know what happens next, but I'll walk you through what I'm thinking.</p><p>If we're truly at the diminishing returns stage of transformer-based models, it will be extremely difficult to justify buying further iterations of NVIDIA GPUs past Blackwell. The entire generative AI movement lives and dies by the idea that more compute power and more training data makes these things better, and if that's no longer the case, there's little reason to keep buying bigger and better. After all, what's the point?&nbsp;</p><p>Even now, what exactly happens when Microsoft or Google has racks-worth of Blackwell GPUs? The models aren't going to get better.</p><p>This also makes the lives of OpenAI and Anthropic that much more difficult. Sam Altman<a href=\"https://www.wheresyoured.at/false-prophet/\"> <u>has grown rich and powerful lying about how GPT will somehow lead to AGI</u></a>, but at this point, what exactly is OpenAI meant to do? The only way it’s ever been able to develop new models is by throwing masses of compute and training data at the problem, and its only other choice is to start stapling its reasoning model onto its main Large Language Model, at which point <em>something </em>happens, something so good that literally nobody working for OpenAI or in the media appears to be able to tell you what it is.</p><p>Putting that aside,<a href=\"https://www.wheresyoured.at/oai-business/\"> <u>OpenAI is also a terrible business</u></a> that has to burn $5 billion to make $3.4 billion, with no proof that it’s capable of bringing down costs. The constant refrain I hear from VCs and AI fantasists is that \"chips will bring down the cost of inference,\" yet I don't see any proof of that happening, nor do I think it'll happen quickly enough for these companies to turn things around.</p><p>And you can feel the desperation, too. OpenAI is <a href=\"https://techcrunch.com/2024/12/02/ads-might-be-coming-to-chatgpt-despite-sam-altman-not-being-a-fan/?ref=wheresyoured.at\"><u>reportedly looking at ads as a means to narrow the gap between its revenues and losses</u></a>. As I pointed out in <a href=\"https://www.wheresyoured.at/burst-damage/\"><u>Burst Damage</u></a>, introducing an advertising revenue stream would require significant upfront investment, both in terms of technology and talent. OpenAI would need a way to target ads, and a team to sell advertising — or, instead, use a third-party ad network that would take a significant bite out of its revenue.&nbsp;</p><p>It’s unclear how much OpenAI could charge advertisers, or what percentage of its reported 200 million weekly users have an ad-blocker installed. Or, for that matter, whether ads would provide a perverse incentive for OpenAI to enshittify an already unreliable product.&nbsp;</p><p>Facebook and Google — as I’ve previously noted — have made their products manifestly worse in order to increase the amount of time people spend on their sites, and thus, the number of ads they see. In the case of Facebook, it<a href=\"https://www.wheresyoured.at/killingfacebook/\"><u> buried your newsfeed under a deluge of AI-generated sludge and “recommended content.</u></a>” Google, meanwhile, has <a href=\"https://www.wheresyoured.at/the-men-who-killed-google/\"><u>progressively degraded the quality of its search results in order to increase the volume of queries it received as a means of making sure users saw more ads</u></a>.&nbsp;</p><p>OpenAI could, just as easily, fall into the same temptation. Most people who use ChatGPT are trying to accomplish a specific task — like writing a term paper, or researching a topic, or whatever — and then they leave. And so, the amount of ads they’d conceivably see each will undoubtedly be comparatively low compared to a social network or search engine. Would OpenAI try to get users to stick around longer — to write more prompts — by crippling the performance of its models?&nbsp;</p><p>Even if OpenAI listens to its better angels, the reality still stands: ads won’t dam the rising tide of red ink that promises to eventually drown the company.&nbsp;</p><p>This is a truly dismal situation where the only options are to stop now, or continue burning money until the heat gets too much. It cost $100 million to train GPT-4o, and<a href=\"https://www.tomshardware.com/tech-industry/artificial-intelligence/ai-models-that-cost-dollar1-billion-to-train-are-in-development-dollar100-billion-models-coming-soon-largest-current-models-take-only-dollar100-million-to-train-anthropic-ceo?ref=wheresyoured.at\"> <u>Anthropic CEO Dario Amodei estimated a few months ago that training future models will cost $1 billion to $10 billion</u></a>,<a href=\"https://x.com/danielnewmanUV/status/1795434545287770212?ref=wheresyoured.at\"> <u>with one researcher claiming that training OpenAI's GPT-5 will cost around $1 billion</u></a>.</p><p>And that’s before mentioning any, to quote a Rumsfeldism, “<a href=\"https://en.wikipedia.org/wiki/There_are_unknown_unknowns?ref=wheresyoured.at\"><u>unknown unknowns</u></a>.” Trump’s election, at the risk of sounding like a cliché, changes everything and in ways we don’t yet fully understand. <a href=\"https://www.wsj.com/tech/elon-musk-business-rivals-altman-openai-f5fccd36?ref=wheresyoured.at\"><u>According to the Wall Street Journal</u></a>, Musk has successfully ingratiated himself with Trump, thanks to his early and full-throated support of his campaign. He’s now reportedly living in Mar a Lago, sitting on calls with world leaders, and whispering in Trump’s ear as he builds his cabinet.&nbsp;</p><p>And, as The Journal claims, his enemies fear that he could use his position of influence to harm them or their businesses — chiefly Sam Altman, who is “persona non grata” in Musk’s world, largely due to the new for-profit direction of OpenAI. While it’s likely that these companies will fail due to inevitable organic realities (like running out of money, or not having a product that generates a profit), Musk’s enemies must now contend with a new enemy — one with the full backing of the Federal government, and that neither forgives nor forgets.</p><p>And, crucially, one that’s not afraid to bend ethical or moral laws to further his own interests — or to inflict pain on those perceived as having slighted him.&nbsp;</p><p>Even if Musk doesn’t use his newfound political might to hurt Altman and OpenAI, he could still pursue the company as a private citizen. Last Friday, he filed an injunction requesting a halt to OpenAI’s transformation from an ostensible non-profit to a for-profit business. Even if he ultimately fails, should Musk manage to drag the process out, or delay it temporarily, it could strike a terminal blow for OpenAI.&nbsp;</p><p>That’s because in its most recent fundraise, OpenAI agreed that it would convert its recent $6.6bn equity investment into high-interest debt, should it fail to successfully convert into a for-profit business within a two-year period. This was a tight deadline to begin with, and it can’t afford any delays. The interest payments on that debt would massively increase its cash burn, and it would undoubtedly find it hard to obtain further outside investment.&nbsp;</p><p>Outside of a miracle, we are about to enter an era of desperation in the generative AI space. We're two years in, and we have no killer apps — no industry-defining products — other than ChatGPT, a product that burns billions of dollars and nobody can really describe. Neither Microsoft, nor Meta, nor Google or Amazon seem to be able to come up with a profitable use case, let alone one their users actually like, nor have any of the people that have raised billions of dollars in venture capital for anything with \"AI\" taped to the side — and<a href=\"https://www.theinformation.com/articles/recent-venture-deals-show-ai-valuations-may-be-cooling?rc=kz8jh3&ref=wheresyoured.at\"> <u>investor interest in AI is cooling</u></a>.</p><p>It's unclear how much further this farce continues, if only because it isn't obvious what it is that anybody gets by investing in future rounds in OpenAI, Anthropic, or any other generative AI company. At some point they must make money, and the entire dream has been built around the idea that all of these GPUs and all of this money would eventually spit out something revolutionary.</p><p>Yet what we have is clunky, ugly, messy, larcenous, environmentally-destructive and mediocre. Generative AI was a reckless pursuit, one that shows a total lack of creativity and sense in the minds of big tech and venture capital, one where there was never anything really <em>impressive</em> other than the amount of money it could burn and the amount of times Sam Altman could say something stupid and get quoted for it.</p><p>I'll be honest with you, I have no idea what happens here. The future was always one that demanded that big tech spent more to make even bigger models that would at some point become useful, and that isn't happening. In pursuit of doing so, big tech invested hundreds of billions of dollars into infrastructure specifically to follow one goal, and put AI front and center at their businesses, claiming it was the future without ever considering what they'd do if it wasn't.</p><p>The revenue isn't coming. The products aren't coming. \"Orion,\" OpenAI's next model, will underwhelm, as will its competitors' models, and at some point somebody is going to blink in one of the hyperscalers, and the AI era will be over. Almost every single generative AI company that you’ve heard of is deeply unprofitable, and there are few innovations coming to save them from the atrophy of the foundation models.</p><p>I feel sad and exhausted as I write this, drained as I look at the many times I’ve tried to warn people, frustrated at the many members of the media that failed to push back against the overpromises and outright lies of people like Sam Altman, and full of dread as I consider the economic ramifications of this industry collapsing. Once the AI bubble pops, <a href=\"https://www.wheresyoured.at/rotcombubble/\"><u>there are no other hyper-growth markets left</u></a>, which will in turn lead to a bloodbath in big tech stocks as they realize that <a href=\"https://www.wheresyoured.at/the-rot-economy/\"><u>they’re out of big ideas to convince the street that they’re going to grow forever</u></a>.</p><p>There are some that will boast about “being right” here, and yes, there is some satisfaction in being so. Nevertheless, knowing that the result of this bubble bursting will be massive layoffs, a dearth in venture capital funding, and a much more fragile tech ecosystem.&nbsp;</p><p><a href=\"https://www.wheresyoured.at/bubble-trouble/\"><u>I’ll end with a quote from Bubble Trouble, a piece I wrote in Apri</u></a>l:&nbsp;</p><blockquote>How do you solve all of these incredibly difficult problems? What does OpenAI or Anthropic do when they run out of data, and synthetic data doesn't fill the gap, or worse, massively degrades the quality of their output? What does Sam Altman do if GPT-5 — like GPT-4 — doesn't significantly improve its performance and he can't find enough compute to take the next step? What do OpenAI and Anthropic do when they realize they will likely never turn a profit? What does Microsoft, or Amazon, or Google do if demand never really takes off, and they're left with billions of dollars of underutilized data centers? What does Nvidia do if the demand for its chips drops off a cliff as a result?<br><br>I don't know why more people aren't screaming from the rooftops about how unsustainable the AI boom is, and the impossibility of some of the challenges it faces. There is no way to create enough data to train these models, and little that we've seen so far suggests that generative AI will make anybody but Nvidia money. We're reaching the point where physics — things like heat and electricity — are getting in the way of progressing much further, and it's hard to stomach investing more considering where we're at right now is, once you cut through the noise, fairly god damn mediocre. There is no iPhone moment coming, I'm afraid.</blockquote><p>I was right then and I’m right now. Generative AI isn’t a revolution, it’s an evolution of a tech industry overtaken by growth-hungry management consultant types that neither know the problems that real people face nor how to fix them. It’s a sickening waste, a monument to the corrupting force of growth, and a sign that the people in power no longer work for you, the customer, but for the venture capitalists and the markets.</p><p>I also want to be clear that none of these companies ever had a plan. They believed that if they threw enough GPUs together they would turn generative AI – probabilistic models for generating stuff — into some sort of sentient computer. It’s much easier, and more comfortable, to look at the world as a series of conspiracies and grand strategies, and far scarier to see it for what it is — extremely rich and powerful people that are willing to bet insanely large amounts of money on what amounts to a few PDFs and their gut.&nbsp;</p><p>This is not big tech’s big plan to excuse building more data centers — it’s the death throes of twenty years of growth-at-all-costs thinking, because throwing a bunch of money at more servers and more engineers always seemed to create more growth. In practice, this means that the people in charge and the strategies they employ are borne not of an interest in improving the lives of their customers, but in increasing revenue growth, which means the products they create aren’t really about solving any problem other than “what will make somebody give me more money,” which doesn’t necessarily mean “provide them with a service.”</p><p>Generative AI is the perfect monster of <a href=\"https://www.wheresyoured.at/the-rot-economy/\"><u>the Rot Economy</u></a> — a technology that lacks any real purpose sold as if it could do literally anything, one without a real business model or killer app, proliferated because big tech no longer innovates, but rather clones and monopolizes. Yes, this much money <em>can</em> be this stupid, and yes, they will burn billions in pursuit of a non-specific dream that involves charging you money and trapping you in their ecosystem.</p><p>I’m not trying to be a doomsayer, just like I wasn’t trying to be one in March. I believe all of this is going nowhere, and that at some point Google, Microsoft, or Meta is going to blink and pull back on their capital expenditures. And before then, you’re going to get a lot of desperate stories about how “AI gains can be found outside of training new models” to try and keep the party going, despite reality flicking the lights on and off and threatening to call the police.&nbsp;</p><p>I fear for the future for many reasons, but I always have hope, because I believe that there are still good people in the tech industry and that customers are seeing the light. Bluesky feels different — growing rapidly, competing with both Threads and Twitter, all while selling an honest product and an open protocol.&nbsp;</p><p>There are other ideas for the future that aren’t borne of the scuzzy mindset of billionaire shitheels like Sundar Pichai and Sam Altman, and they can — and will — grow out of the ruins created by these kleptocrats.&nbsp;</p>\n    </article>\n\n        <div class=\"post-share content-width m-b-lg\">\n  <span class=\"section-title sm\">Share</span>\n  <div class=\"social-share \">\n    <a class=\"social-share__item twitter js-share\" target=\"_blank\"\n        href=\"https://twitter.com/share?text=Godot%20Isn't%20Making%20it&amp;url=https://www.wheresyoured.at/godot-isnt-making-it/\"\n        title=\"Share on Twitter\" aria-label=\"Share on Twitter\">\n      <i class=\"icon icon-twitter\">\n  <svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-brand-twitter\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n  <path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n  <path d=\"M22 4.01c-1 .49 -1.98 .689 -3 .99c-1.121 -1.265 -2.783 -1.335 -4.38 -.737s-2.643 2.06 -2.62 3.737v1c-3.245 .083 -6.135 -1.395 -8 -4c0 0 -4.182 7.433 4 11c-1.872 1.247 -3.739 2.088 -6 2c3.308 1.803 6.913 2.423 10.034 1.517c3.58 -1.04 6.522 -3.723 7.651 -7.742a13.84 13.84 0 0 0 .497 -3.753c-.002 -.249 1.51 -2.772 1.818 -4.013z\" />\n</svg>\n\n\n\n</i>    </a>\n    <a class=\"social-share__item facebook js-share\" target=\"_blank\"\n        href=\"https://www.facebook.com/sharer.php?u=https://www.wheresyoured.at/godot-isnt-making-it/\"\n        title=\"Share on Facebook\" aria-label=\"Share on Facebook\">\n      <i class=\"icon icon-facebook\">\n  <svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-brand-facebook\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n  <path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n  <path d=\"M7 10v4h3v7h4v-7h3l1 -4h-4v-2a1 1 0 0 1 1 -1h3v-4h-3a5 5 0 0 0 -5 5v2h-3\" />\n</svg>\n\n\n\n</i>    </a>\n    <a class=\"social-share__item linkedin js-share\" target=\"_blank\"\n        href=\"https://www.linkedin.com/shareArticle?mini=true&url=https://www.wheresyoured.at/godot-isnt-making-it/&title=Godot%20Isn't%20Making%20it&summary=Godot%20Isn't%20Making%20it\"\n        title=\"Share on Linkedin\" aria-label=\"Share on Linkedin\">\n      <i class=\"icon icon-linkedin\">\n  <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\" stroke-width=\"2\" stroke-linecap=\"round\" stroke-linejoin=\"round\" class=\"feather feather-linkedin\">\n  <path d=\"M16 8a6 6 0 0 1 6 6v7h-4v-7a2 2 0 0 0-2-2 2 2 0 0 0-2 2v7h-4v-7a6 6 0 0 1 6-6z\"></path>\n  <rect x=\"2\" y=\"9\" width=\"4\" height=\"12\"></rect>\n  <circle cx=\"4\" cy=\"4\" r=\"2\"></circle>\n</svg>\n</i>    </a>\n    <a class=\"social-share__item mail\"\n        href=\"mailto:?subject=Godot%20Isn't%20Making%20it&body=https://www.wheresyoured.at/godot-isnt-making-it/&nbsp;Godot%20Isn't%20Making%20it\"\n        title=\"Share by email\" aria-label=\"Share by email\">\n      <i class=\"icon icon-mail\">\n  <svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-mail\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"1.5\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n  <path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n  <rect x=\"3\" y=\"5\" width=\"18\" height=\"14\" rx=\"2\" />\n  <polyline points=\"3 7 12 13 21 7\" />\n</svg>\n</i>    </a>\n    <button class=\"copy-link copy js-copy-link\" data-url=\"https://www.wheresyoured.at/godot-isnt-making-it/\"\n        title=\"Copy to clipboard\" data-label=\"Copied!\" aria-label=\"Copy to clipboard\">\n      <i class=\"icon icon-copy\">\n  <svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-copy\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"1.5\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n  <path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n  <rect x=\"8\" y=\"8\" width=\"12\" height=\"12\" rx=\"2\" />\n  <path d=\"M16 8v-2a2 2 0 0 0 -2 -2h-8a2 2 0 0 0 -2 2v8a2 2 0 0 0 2 2h2\" />\n</svg>\n</i>    </button>\n  </div>\n</div>\n\n        \n        <div class=\"post-authors content-width m-t-lg\">\n  <span class=\"section-title sm\">About the author</span>\n      <div class=\"author-card author-edward wide m-b-lg has-image\">\n\n<a class=\"author-card__media flex flex-cc\" href=\"https://www.wheresyoured.at/author/edward/\">      <img class=\"lazyload author-card__img z-index-1\" \n        data-srcset=\"https://www.gravatar.com/avatar/257728ef58ec6562631bc7ebf24dd007?s&#x3D;250&amp;r&#x3D;x&amp;d&#x3D;mp 100w,\n            https://www.gravatar.com/avatar/257728ef58ec6562631bc7ebf24dd007?s&#x3D;250&amp;r&#x3D;x&amp;d&#x3D;mp 300w\"\n        srcset=\"data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==\"\n        data-sizes=\"auto\"\n        data-src=\"https://www.gravatar.com/avatar/257728ef58ec6562631bc7ebf24dd007?s&#x3D;250&amp;r&#x3D;x&amp;d&#x3D;mp\"\n        src=\"https://www.gravatar.com/avatar/257728ef58ec6562631bc7ebf24dd007?s&#x3D;250&amp;r&#x3D;x&amp;d&#x3D;mp\"\n        alt=\"Edward Zitron\"\n      />\n</a>\n  <div class=\"author-card__content flex-1 flex flex-col text-acc\">\n    <div class=\"author-card__profile flex flex-wrap items-center m-b-sm\">\n      <h3 class=\"author-card__name fw-700 m-b-0\">\n        <a href=\"https://www.wheresyoured.at/author/edward/\">Edward Zitron</a>\n      </h3>\n      \n      <div class=\"author-card__social flex flex-1\">\n      </div>\n    </div>\n    \n    \n    \n      <a class=\"author-card__count fw-500 text-09\" href=\"https://www.wheresyoured.at/author/edward/\">View all</a>\n  </div>\n</div>\n</div>  \n        <div class=\"ctx-module-container ctx_shortcode_placement ctx-clearfix\"></div>\n         \n    <div class=\"post-comments content-width m-b-lg\">\n      <div class=\"section-title sm\">Comments</div>\n      <div class=\"comments bg-default radius flex flex-col p-lg Native\" id=\"comments\">\n            \n        <script defer src=\"https://cdn.jsdelivr.net/ghost/comments-ui@~0.23/umd/comments-ui.min.js\" data-locale=\"en\" data-ghost-comments=\"https://www.wheresyoured.at/\" data-api=\"https://ed-zitrons-wheres-your-ed-at.ghost.io/ghost/api/content/\" data-admin=\"https://ed-zitrons-wheres-your-ed-at.ghost.io/ghost/\" data-key=\"e36e7d7220258a9362c249dff6\" data-title=\"\" data-count=\"false\" data-post-id=\"673b864a68b71000011145c6\" data-color-scheme=\"auto\" data-avatar-saturation=\"60\" data-accent-color=\"#dd0000\" data-comments-enabled=\"all\" data-publication=\"Ed Zitron's Where's Your Ed At\" crossorigin=\"anonymous\"></script>\n    \n\n\n      </div>\n    </div>\n\n        </div>\n  \n\n    </main>\n\n            <section class=\"container wrapper section section-cta is-rel flex flex-cc radius m-b-0 is-post\" \n      data-bg-accent=\"none\">\n        <div class=\"section-cta__content flex flex-col flex-cc is-rel z-index-1 max-w-40\">\n          <h2 class=\"section-cta__title\">Welcome to Where&#x27;s Your Ed At!</h2>\n          <p id=\"cta-input-label\" class=\"section-cta__description opacity-075\">Subscribe today. It&#x27;s free. Please. </p>\n          \n          <form class=\"subscribe-form\" \n  data-members-form=\"signup\" data-style=\"inline\">\n  <input data-members-email class=\"bg-opaque\" \n    type=\"email\" autocomplete=\"email\" placeholder=\"Your email address\" \n    aria-labelledby=\"cta-input-label\" required/> \n  <button class=\"btn btn--brand btn--gradient uppercase\" type=\"submit\">\n    <span>Subscribe</span>\n  </button>\n  <div class=\"msg-success\">Great! Check your inbox and click the link.</div>\n  <div class=\"msg-error\">Sorry, something went wrong. Please try again.</div>\n</form>        </div>\n      </section>\n\n      <footer class=\"footer\">\n  <div class=\"container wrapper\">\n\n    <div class=\"footer__brand m-b-lg flex flex-wrap\">\n        <img class=\"footer__logo lazyload\"\n          src=\"/content/images/size/w300/2024/01/wide-with-letters-1.jpeg\"\n          alt=\"Ed Zitron&#x27;s Where&#x27;s Your Ed At\"/>\n\n      <span class=\"flex-1\"></span>\n\n      <div class=\"footer__social flex flex-cc\">\n        \n  <a href=\"https://twitter.com/edzitron\" class=\"twitter\" aria-label=\"Twitter\"><i class=\"icon icon-twitter icon--md\">\n  <svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-brand-twitter\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n  <path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n  <path d=\"M22 4.01c-1 .49 -1.98 .689 -3 .99c-1.121 -1.265 -2.783 -1.335 -4.38 -.737s-2.643 2.06 -2.62 3.737v1c-3.245 .083 -6.135 -1.395 -8 -4c0 0 -4.182 7.433 4 11c-1.872 1.247 -3.739 2.088 -6 2c3.308 1.803 6.913 2.423 10.034 1.517c3.58 -1.04 6.522 -3.723 7.651 -7.742a13.84 13.84 0 0 0 .497 -3.753c-.002 -.249 1.51 -2.772 1.818 -4.013z\" />\n</svg>\n\n\n\n</i></a>\n\n<a href=\"https://www.wheresyoured.at/rss\" class=\"rss\" aria-label=\"RSS\"><i class=\"icon icon-rss icon--md\">\n  <svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-rss\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n  <path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n  <circle cx=\"5\" cy=\"19\" r=\"1\" />\n  <path d=\"M4 4a16 16 0 0 1 16 16\" />\n  <path d=\"M4 11a9 9 0 0 1 9 9\" />\n</svg>\n\n\n\n</i></a>\n\n\n\n\n\n\n\n\n\n\n\n      </div>\n    </div>\n\n    <ul class=\"nav\">\n    <li class=\"nav-home\"><a href=\"https://www.wheresyoured.at/\">Home</a></li>\n    <li class=\"nav-about\"><a href=\"https://www.wheresyoured.at/about/\">About</a></li>\n    <li class=\"nav-better-offline\"><a href=\"http://linktr.ee/betteroffline\">Better Offline</a></li>\n</ul>\n\n\n      <ul class=\"nav\">\n    <li class=\"nav-sign-up\"><a href=\"#/portal/\">Sign up</a></li>\n</ul>\n\n\n    <div class=\"footer__bottom\">\n      <div class=\"footer__copy\">\n        <span>&copy;2024&nbsp;<a href=\"https://www.wheresyoured.at\">Ed Zitron&#x27;s Where&#x27;s Your Ed At</a>.</span>\n        <span>Published with&nbsp;<a href=\"https://ghost.org\">Ghost</a>&nbsp;&&nbsp;<a href=\"https://brightthemes.com/themes/tuuli/\">Tuuli</a>.</span>\n      </div>\n\n      <div class=\"color-scheme flex flex-cc radius-half\">\n  <span class=\"color-scheme-symbol\"></span>\n  <select class=\"color-scheme-select radius-half js-color-scheme-select\" aria-label=\"Change color scheme\">\n    <option value=\"system\" >System</option>\n    <option value=\"light\" selected>Light</option>\n    <option value=\"dark\">Dark</option>\n    <option value=\"midnight\">Midnight</option>\n    <option value=\"ivory\">Ivory</option>\n    <option value=\"skyblue\">Skyblue</option>\n  </select>\n  <i class=\"icon icon-select\">\n  <svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-select\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n  <path d=\"M17 8.517L12 3 7 8.517M7 15.48l5 5.517 5-5.517\"></path>\n</svg>\n\n\n\n</i></div>    </div>\n\n  </div>\n</footer>\n\n    <dialog class=\"notification\">\n  <i class=\"icon icon-success notification-icon\">\n  <svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-circle-check\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n  <path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n  <circle cx=\"12\" cy=\"12\" r=\"9\" />\n  <path d=\"M9 12l2 2l4 -4\" />\n</svg>\n\n\n\n</i>  <i class=\"icon icon-error notification-icon\">\n  <svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-alert-octagon\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n  <path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n  <path d=\"M8.7 3h6.6c.3 0 .5 .1 .7 .3l4.7 4.7c.2 .2 .3 .4 .3 .7v6.6c0 .3 -.1 .5 -.3 .7l-4.7 4.7c-.2 .2 -.4 .3 -.7 .3h-6.6c-.3 0 -.5 -.1 -.7 -.3l-4.7 -4.7c-.2 -.2 -.3 -.4 -.3 -.7v-6.6c0 -.3 .1 -.5 .3 -.7l4.7 -4.7c.2 -.2 .4 -.3 .7 -.3z\" />\n  <line x1=\"12\" y1=\"8\" x2=\"12\" y2=\"12\" />\n  <line x1=\"12\" y1=\"16\" x2=\"12.01\" y2=\"16\" />\n</svg>\n\n\n\n</i>  <i class=\"icon icon-warning notification-icon\">\n  <svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-alert-triangle\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"2\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n  <path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n  <path d=\"M12 9v2m0 4v.01\" />\n  <path d=\"M5 19h14a2 2 0 0 0 1.84 -2.75l-7.1 -12.25a2 2 0 0 0 -3.5 0l-7.1 12.25a2 2 0 0 0 1.75 2.75\" />\n</svg>\n\n\n\n</i>  <p class=\"notification-msg signup-success\">Great! You’ve successfully signed up.</p> \n  <p class=\"notification-msg signin-success\">Welcome back! You&#x27;ve successfully signed in.</p> \n  <p class=\"notification-msg subscribe-success\">You&#x27;ve successfully subscribed to Ed Zitron&#x27;s Where&#x27;s Your Ed At.</p> \n  <p class=\"notification-msg link-expired\">Your link has expired.</p> \n  <p class=\"notification-msg checkout-success\">Success! Check your email for magic link to sign-in.</p> \n  <p class=\"notification-msg billing-success\">Success! Your billing info has been updated.</p> \n  <p class=\"notification-msg billing-cancel\">Your billing was not updated.</p> \n  <button class=\"notification-close js-notification-close\" aria-label=\"Close\" onclick=\"closeNotification(event.currentTarget.parentNode);\">\n    <i class=\"icon icon-x\">\n  <svg xmlns=\"http://www.w3.org/2000/svg\" class=\"icon icon-tabler icon-tabler-x\" width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" stroke-width=\"1.5\" stroke=\"currentColor\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\">\n  <path stroke=\"none\" d=\"M0 0h24v24H0z\" fill=\"none\"/>\n  <line x1=\"18\" y1=\"6\" x2=\"6\" y2=\"18\" />\n  <line x1=\"6\" y1=\"6\" x2=\"18\" y2=\"18\" />\n</svg>\n</i>  </button>\n</dialog>\n\n      \n    \n\n    \n\n      <script>\n    // Copy button\n    const copyBtn = document.querySelector('.js-copy-link');\n    if (copyBtn) {\n      copyBtn.onclick = function(event) {\n        copyToClipboard(event.currentTarget, event.currentTarget.getAttribute('data-url'));\n      }\n    }\n    \n    /** \n    * Copy to clipboard\n    * @src - source element\n    * @str - string to copy\n    */ \n    const copyToClipboard = function(src, str) {\n      const el = document.createElement('textarea');\n      el.value = str;\n      el.setAttribute('readonly', '');\n      el.style.position = 'absolute';\n      el.style.left = '-9999px';\n      document.body.appendChild(el);\n      el.select();\n      document.execCommand('copy');\n      document.body.removeChild(el);\n\n      src.classList.add('has-tooltip');\n      src.setAttribute('data-label', 'Copied!');\n\n      src.onmouseleave = function() { \n        src.classList.remove('has-tooltip');\n        setTimeout(function(){\n          src.setAttribute('data-label', '');\n        }, 500); \n      }\n    };\n  </script>\n\n  <script>\n    // Give the parameter a variable name\n    const qsParams = new URLSearchParams(window.location.search);\n    const isAction = qsParams.has('action');\n    const isStripe = qsParams.has('stripe');\n    const success = qsParams.get('success');\n    const action = qsParams.get('action');\n    const stripe = qsParams.get('stripe');\n\n    if (qsParams && isAction) {\n      if (success === \"true\") {\n        switch (action) {\n          case 'subscribe':\n            openNotification('subscribe-success');\n            break;\n          case 'signup': \n            openNotification('signup-success');\n            break;\n          case 'signin':\n            openNotification('signin-success');\n            break;\n          default:\n            break;\n        }\n      } else {\n        openNotification('link-expired');\n      }\n    }\n\n    if (qsParams && isStripe) {\n      switch (stripe) {\n        case 'success':\n          openNotification('checkout-success');\n          break;\n        case 'billing-update-success':\n          openNotification('billing-success');\n          break;\n        case 'billing-update-cancel':\n          openNotification('billing-cancel');\n          break;\n        default:\n          break;\n      }\n    }\n\n    /**\n    * Handle Notifications\n    */\n    function openNotification(type) {\n      const notification = document.querySelector('dialog.notification');\n      if (notification) { \n        notification.setAttribute('data-msg-type', type);\n        notification.show();\n        setTimeout(function(){ closeNotification(notification); }, 3000);\n      }\n    }\n    \n    /**\n    * Clean URI\n    */\n    function clearURI() {\n      window.history.replaceState({}, '', `${window.location.pathname}`);\n    }\n\n    function closeNotification(notification) {\n      notification.close();\n      clearURI();\n      setTimeout(function(){ notification.removeAttribute('data-msg-type') }, 500);\n    }\n  </script>\n\n\n    <script>\n  const menu = document.querySelector('.header__menu')\n  const heroContent = document.querySelector('.hero__content')\n  if (menu && heroContent) {\n    heroContent.appendChild(menu)\n  }\n</script>\n<script>\n!function(w,d,id,ns,s){var c=w[ns]=w[ns]||{};if(c.ready||(c.q=[],c.ready=function(){c.q.push(arguments)}),!d.getElementById(id)){var e=d.createElement(s);e.id=id,e.defer=true,e.src=\"https://assets.context.ly/kit/6.latest/loader.js\";var h=d.getElementsByTagName(s)[0];h.parentNode.insertBefore(e,h)}}(window,document,\"ctx-loader\",\"Contextly\",\"script\");\n</script>\n<script>\nContextly.ready('widgets');\n</script>\n<script>\n  const OutpostPub = {\n    apiDomain: \"https://edzitronswheresyouredatghostio.outpost.pub\",\n    apiKey: \"fe19efab-70d4-4add-a5aa-4a2197a237cb\",\n    siteName: \"Ed Zitron&#x27;s Where&#x27;s Your Ed At\",\n    memberId: \"\",\n    memberEmail: \"\",\n        post: {\n          id: \"673b864a68b71000011145c6\",\n          tags: [\"\"],\n        }\n  }\n</script>\n<script defer src=\"https://assets.outpostpublishingcoop.com/assets/v2/js/outpost-pub.js\"></script>\n  </body>\n</html>\n","oembed":false,"readabilityObject":{"title":"Godot Isn't Making it","content":"<div id=\"readability-page-1\" class=\"page\"><article>\n      <p><em>Before we get going — please enjoy my speech from Web Summit, </em><a href=\"https://www.youtube.com/watch?v=7Slib2bbMs4&amp;ref=wheresyoured.at\"><em><u>Why Are All Tech Products Now Shit</u></em></a><em>? I didn’t write the title.</em></p><hr><blockquote>What if what we're seeing today isn't a glimpse of the future, but the new terms of the present? What if artificial intelligence isn't actually capable of doing much more than what we're seeing today, and what if there's no clear timeline when it'll be able to do more? What if this entire hype cycle has been built, goosed by a compliant media ready and willing to take career-embellishers at their word?<a href=\"https://www.wheresyoured.at/peakai/\"><u>Me, in March 2024.</u></a></blockquote><p>I have been warning you for the best part of a year that generative AI has no killer apps and had no way of justifying its valuations (<a href=\"https://www.wheresyoured.at/sam-altman-fried/#:~:text=This%20industry%20is%20money,good%20for%20the%20environment.\"><u>February</u></a>), that generative AI had already peaked (<a href=\"https://www.wheresyoured.at/peakai/#:~:text=Unless%2C%20of%20course,at%20their%20word%3F\"><u>March</u></a>), and I have pleaded with people to consider an eventuality where the jump from GPT-4 to GPT-5 was not significant, in part due to a lack of training data (<a href=\"https://www.wheresyoured.at/bubble-trouble/#:~:text=How%20do%20you,as%20a%20result%3F\"><u>April</u></a>).&nbsp;</p><p>I shared concerns in<a href=\"https://www.wheresyoured.at/pop-culture/\"> <u>July</u></a> that the transformer-based-architecture underpinning generative AI was a dead end, and that there were few ways we'd progress past the products we'd already seen, in part due to both the limits of training data and the limits of models that <em>use said </em>training data. In<a href=\"https://www.wheresyoured.at/burst-damage/\"> <u>August</u></a>, I summarized the Pale Horses of the AI Apocalypse — events, many that have since come to pass, that would signify that the end is indeed nigh — and again added that GPT-5 would likely \"not change the game enough to matter, let alone [add] a new architecture to build future (and more capable) models on.\"</p><p>Throughout these pieces I have repeatedly made the point that — separate to any lack of a core value proposition, training data drought, or unsustainable economics — generative AI is a dead end due to the limitations of probabilistic models that hallucinate, where they authoritatively state things that aren't true. The hallucination problem is one that is nowhere closer to being solved — and, at least with the current technology — may never go away, and it makes it a non-starter for a great many business tasks, where you need a high level of reliability.</p><p>I have —<a href=\"https://www.wheresyoured.at/peakai/#:~:text=What%20if%20what%20we%27re%20seeing%20today%20isn%27t%20a%20glimpse%20of%20the%20future%2C%20but%20the%20new%20terms%20of%20the%20present%3F\"> <u>since March</u></a> — expressed great dismay about the credulousness of the media in their acceptance of the \"inevitable\" ways in which generative AI will change society, despite a lack of any truly meaningful product that might justify an environmentally-destructive industry<a href=\"https://www.wheresyoured.at/oai-business/\"> <u>led by a company that burns more than $5 billion a year</u></a> and<a href=\"https://www.bloomberg.com/professional/insights/technology/big-tech-2025-capex-may-hit-200-billion-as-gen-ai-demand-booms/?ref=wheresyoured.at\"> <u>big tech firms spending $200 billion on data centers</u></a><a href=\"https://www.martechcube.com/report-49-of-consumers-unlikely-to-buy-generative-ai-enabled-products/?ref=wheresyoured.at\"> <u>for products</u></a><a href=\"https://www.ciodive.com/news/ChatGPT-anniversary-enterprise-strategy-evolution-generative-AI/732951/?ref=wheresyoured.at\"> <u>that people don't want</u></a>.</p><p>The reason I'm repeating myself is that it's <em>important to note how obvious the problems with generative AI have been, and for how long.</em></p><p>And you're going to need context for everything I'm about to throw at you.</p><blockquote><strong>Sidebar: </strong>To explain exactly what happened here, it's worth going over how these models work and are trained. I’ll keep it simple as it's a reminder.<p>A transformer-based generative AI model such as GPT — the technology behind ChatGPT — generates answers using \"inference,\" which means it draws conclusions based off of its \"training,\" which requires feeding it masses of training data (mostly text and images scraped from the internet). Both of these processes require you to use high-end GPUs (graphics processing units), and <em>lots</em> of them.</p><p>The theory was (is?) that the more training data and compute you throw at these models, the better they get. I have hypothesized for a while they'd have diminishing returns — both from running out of training data and based on the limitations of transformer-based models.&nbsp;</p><p>And there, as they say, is the rub.</p></blockquote><p>A few weeks ago, Bloomberg reported that<a href=\"https://www.bloomberg.com/news/articles/2024-11-13/openai-google-and-anthropic-are-struggling-to-build-more-advanced-ai?ref=wheresyoured.at\"> <u>OpenAI, Google, and Anthropic are struggling to build more advanced AI</u></a>, and that OpenAI's \"Orion\" model — otherwise known as GPT-5 — \"did not hit the company's desired performance,\" and that \"Orion is so far not considered to be as big a step up\" as it was from GPT-3.5 to GPT-4, its current model. You'll be shocked to hear the reason is that because \"it’s become increasingly difficult to find new, untapped sources of high-quality, human-made training data that can be used to build more advanced AI systems,\"<a href=\"https://www.wheresyoured.at/bubble-trouble/#:~:text=This%20scenario%20is%20likely%20if%20the%20next%20generations%20of%20ChatGPT%20or%20Claude%20fail%20to%20make%20significant%20leaps%20in%20their%20capabilities%2C%20and%20as%20I%27ve%20said%20above%2C%20their%20ability%20to%20do%20so%20is%20predicated%20on%20more%20training%20data%20and%20compute%20power%20than%20currently%20exists.\"> <u>something I said would happen in March</u></a>, while also adding that the \"AGI bubble is bursting a little bit,\"<a href=\"https://www.wheresyoured.at/put-up-or-shut-up/#:~:text=They%E2%80%99re%20not%20getting%20%E2%80%9Creasoning%2C%E2%80%9D%20nor%20are%20they%20getting%20%E2%80%9Csentience%2C%E2%80%9D%20nor%20are%20they%20%E2%80%9Cpart%20of%20the%20path%20to%20superintelligence.%E2%80%9D%C2%A0\"> <u>something I said more forcefully in July</u></a>.</p><p>I also want to stop and stare daggers at one particular point:</p><blockquote>These issues challenge the gospel that has taken hold in Silicon Valley in recent years, particularly since OpenAI released ChatGPT two years ago. Much of the tech industry has bet on so-called scaling laws that say more computing power, data and larger models will inevitably pave the way for greater leaps forward in the power of AI.</blockquote><p>The only people taking this as \"gospel\" have been members of the media unwilling to ask the tough questions and AI founders that don't know what the fuck they're talking about (or that intend to mislead). Generative AI's products have effectively been trapped in amber for over a year. There have been no meaningful, industry-defining products, because,<a href=\"https://www.wheresyoured.at/pop-culture/#:~:text=No%2C%20really%2C%20what%20does%20%22more%22%20actually%20mean%3F%20While%20one%20might%20argue%20that%20it%27ll%20mean%20faster%20generative%20processes%2C\"> <u>as economist Daron Acemoglu said back in May</u></a>, \"more powerful\" models do not unlock new features, or really change the experience, nor what you can build with transformer-based models. Or, put another way, a slightly better <a href=\"https://en.wikipedia.org/wiki/White_elephant?ref=wheresyoured.at\"><u>white elephant</u></a> is still a white elephant.&nbsp;</p><p>Despite the billions of dollars burned and thousands of glossy headlines, it's difficult to point to any truly important generative-AI-powered product.<a href=\"https://www.washingtonpost.com/technology/2024/10/28/apple-intelligence-ios-181/?ref=wheresyoured.at\"> <u>Even Apple Intelligence, the only thing that Apple really had to add to the latest iPhone, is utterly dull, and largely based on on-device models</u></a>.</p><p>Yes, there are people that use ChatGPT —<a href=\"https://www.reuters.com/technology/artificial-intelligence/openai-says-chatgpts-weekly-users-have-grown-200-million-2024-08-29/?ref=wheresyoured.at\"> <u>200 million of them a week, allegedly</u></a>, losing the company money with every prompt — but there is little to suggest that there's widespread adoption of actual generative AI software.<a href=\"https://www.theinformation.com/articles/microsoft-customers-pause-on-office-ai-assistant-due-to-budgets-bugs?rc=kz8jh3&amp;ref=wheresyoured.at\"> <u>The Information reported in September that between 0.1% and 1% of the 440 million of Microsoft's business customers were paying for its AI-powered Copilot</u></a>, and in late October, Microsoft claimed that \"<a href=\"https://www.axios.com/2024/10/30/microsoft-ai-earnings-2024?ref=wheresyoured.at\"><u>AI is on pace to be a $10 billion-a-year business</u></a>,\" which sounds good until you consider a few things:</p><ol><li>Microsoft has no \"AI business\" unit, which means that this annual \"$10 billion\" (or $2.5 billion a quarter) revenue figure is split across providing cloud compute services on Azure, selling Copilot to dumb people with Microsoft 365 subscriptions, selling Github Copilot, and basically anything else with \"AI\" on it. Microsoft is cherry-picking a number based on non-specific criteria and claiming it's a big deal, when it's actually pretty pathetic<a href=\"https://www.forbes.com/sites/petercohan/2024/07/31/microsoft-stock-drops-as-ai-capital-expenditures-surge-to-56-billion/?ref=wheresyoured.at\"> <u>considering its capital expenditures will likely hit over $60 billion in 2024</u></a>.</li><li>Note the word \"revenue,\" not \"profit.\" How much is Microsoft spending to make $10 billion a year?<a href=\"https://www.wheresyoured.at/oai-business/#:~:text=To%20be%20abundantly%20clear%2C%20as%20it%20stands%2C%20OpenAI%20currently%20spends%20%242.35%20to%20make%20%241.\"> <u>OpenAI currently spends $2.35 to make $1</u></a>, and<a href=\"https://www.cnbc.com/2024/10/30/microsoft-cfo-says-openai-investment-will-cut-into-profit-this-quarter.html?ref=wheresyoured.at\"> <u>Microsoft CFO Amy Hood said that OpenAI would cut into Microsoft's profits this October</u></a>, losing it a remarkable $1.5 billion, \"mainly because of an expected loss from OpenAI\" according to CNBC. A year ago,<a href=\"https://www.techradar.com/pro/microsoft-is-reportedly-losing-huge-amounts-of-money-on-github-copilot?ref=wheresyoured.at\"> <u>the Wall Street Journal reported in October 2023</u></a> that Microsoft was losing an average of $20 per-user-per month on GitHub Copilot — a product with over a million users. If true, this suggests losses of at least $200 million (based on documents I've reviewed, it has 1.8 million users as of a month ago, but I went on the lower end) a year.</li><li>Microsoft has still yet to break out exactly how much generative AI is increasing revenue in specific business units. Generally, if a company is doing well at something, they take great pains to make that clear. Instead, Microsoft chose in August to<a href=\"https://www.cnbc.com/2024/08/21/microsoft-changes-reporting-to-boost-cloud-consumption-visibility.html?ref=wheresyoured.at\"> <u>\"revamp\" its reporting structure to \"give better visibility into cloud consumption revenue,\"</u></a> which is something you do if you, say, anticipate<a href=\"https://www.cnbc.com/2024/10/31/microsoft-stock-has-worst-day-in-two-years-on-disappointing-forecast.html?ref=wheresyoured.at\"> <u>you're going to have your worst day of trading in years after your next earnings as Microsoft did in October</u></a>.</li></ol><p>I must be clear that every single one of these investments and products has been hyped with the whisper that they would get exponentially better over time, and<a href=\"https://www.bloomberg.com/professional/insights/technology/big-tech-2025-capex-may-hit-200-billion-as-gen-ai-demand-booms/?ref=wheresyoured.at\"> <u>that eventually the $200 billion in capital expenditures</u></a> would spit out remarkable productivity improvements and fascinating new products that consumers and enterprises would buy in droves. Instead, big tech has found itself peddling increasingly-more-expensive iterations of near-identical Large Language Models — a direct result of them all having to use the same training data, which it’s now running out of.</p><hr><p>The other assumption — those so-called scaling laws — has been that by simply building bigger data centers with more GPUs (the expensive, power-hungry graphics processing units used to both run and train these models) and throwing as much training data at them as possible, they'd simply start sprouting new capabilities, despite there being little proof that they'd do so. Microsoft, Meta, Amazon, and Google have all burned billions on the assumption that doing so would create something — be it a human-level \"artificial general intelligence\" or, I dunno, a product that would justify the costs — and it's become painfully obvious that it isn't going to work.</p><p>As we speak, outlets are already desperate to try and prove that this isn't a problem. The Information,<a href=\"https://www.theinformation.com/articles/goodbye-gpt-hello-reasoning-o?rc=kz8jh3&amp;ref=wheresyoured.at\"> <u>in a similar story</u></a> to Bloomberg's, attempted to put lipstick on the pig of generative AI, framing the lack of meaningful progress with GPT-5 as fine, because OpenAI can combine its GPT-5 Model with its o-1 \"reasoning\" model, which will then do something of some sort, such as \"write a lot more very difficult code\" according to OpenAI CEO and <a href=\"https://www.wheresyoured.at/false-prophet/\"><u>career liar</u></a> Sam Altman,<a href=\"https://www.gizchina.com/2024/05/17/sam-altman-says-gpt-5-function-may-be-similar-to-a-virtual-brain/?ref=wheresyoured.at\"> <u>who intimated that GPT-5 may function like a \"virtual brain\" in May</u></a>.</p><p>Chief Valley Cheerleader Casey Newton <a href=\"https://www.platformer.news/openai-google-scaling-laws-anthropic-ai/?ref=wheresyoured.at\"><u>wrote on Platformer last week that</u></a> diminishing returns in training models \"may not matter as much as you would guess,\" with his evidence being that Anthropic, who he claims \"has not been prone to hyperbole,\" do not think that scaling laws are ending. To be clear, in a 14,000 op-ed that Newton wrote<a href=\"https://www.platformer.news/anthropic-dario-amodei-doomer-accelerationism/?ref=wheresyoured.at\"> <u>two</u></a><a href=\"https://www.platformer.news/anthropic-responsible-scaling-laws/?ref=wheresyoured.at\"> <u>pieces</u></a> about, Anthropic CEO Dario Amodei said that \"<a href=\"https://darioamodei.com/machines-of-loving-grace?ref=wheresyoured.at#taking-stock:~:text=In%20summary%2C%20AI%2Daccelerated%20neuroscience%20is%20likely%20to%20vastly%20improve%20treatments%20for%2C%20or%20even%20cure%2C%20most%20mental%20illness%20as\"><u>AI-accelerated neuroscience is likely to vastly improve treatments for, or even cure, most mental illness</u></a>,\" the kind of hyperbole that should have you tarred and feathered in public.</p><p>So, let me summarize:</p><ul><li>The main technology behind the entire \"artificial intelligence\" boom is generative AI — transformer-based models like OpenAI's GPT-4 (and soon GPT-5) — and said technology has peaked, with diminishing returns from the only ways of making them \"better\" (feeding them training data and throwing tons of compute at them) suggesting that what we may have, as I've said before, reached <a href=\"https://www.wheresyoured.at/peakai/\"><u>Peak AI</u></a>.</li><li>Generative AI is incredibly unprofitable. OpenAI, the biggest player in the industry, <a href=\"https://www.wheresyoured.at/oai-business/\"><u>is on course to lose more than $5 billion this year</u></a>, with competitor Anthropic (which also makes its own transformer-based model, Claude) <a href=\"https://www.theinformation.com/briefings/anthropic-projected-to-burn-more-than-2-7-billion-in-cash-this-year?rc=kz8jh3&amp;ref=wheresyoured.at\"><u>on course to lose more than $2.7 billion this year</u></a>.</li><li>Every single big tech company has thrown billions — <a href=\"https://www.cnbc.com/2024/10/31/amazon-ceo-pledges-ai-investments-will-pay-off-as-capex-surges-81percent.html?ref=wheresyoured.at\"><u>as much as $75 billion in Amazon's case in 2024 alone</u></a> — at building the data centers and acquiring the GPUs to populate said data centers specifically so they can train their models or other companies' models, or serve customers that would integrate generative AI into their businesses, something that does not appear to be happening at scale.<ul><li>Their investments could theoretically be used for other products, but these data centers are heavily focused on generative AI. <a href=\"https://www.businessinsider.com/microsoft-gpu-targets-1-8-million-ai-chips-this-year-2024-4?ref=wheresyoured.at\"><u>Business Insider reports that Microsoft intends to amass 1.8 <em>million</em> GPUs by the end of 2024</u></a>, costing it tens of billions of dollars.</li></ul></li><li>Worse still, many of the companies integrating generative AI do so by connecting to models made by either OpenAI or Anthropic, both of whom are running unprofitable businesses, and likely charging nowhere near enough to cover their costs. <a href=\"https://www.wheresyoured.at/subprimeai/\"><u>As I wrote in the Subprime AI Crisis in September</u></a>, in the event that these companies start charging what they actually need to, I hypothesize it will multiply the costs of their customers to the point that they can't afford to run their businesses — or, at the very least, will have to remove or scale back generative AI functionality in their products.</li></ul><p>The entire tech industry has become oriented around a dead-end technology that requires burning billions of dollars to provide inessential products that cost them more money to serve than anybody would ever pay. Their big strategy was to throw even <em>more</em> money at the problem until one of these transformer-based models created a new, more useful product — despite the fact that every iteration of GPT and other models has been, well, iterative. There has never been any proof (<a href=\"https://whoisnnamdi.substack.com/p/ai-benchmarking-broken?ref=platformer.news\"><u>other than benchmarks that are increasingly easier to game</u></a>) that GPT or other models would become conscious, nor that these models would do more than they do today, or three months ago, or even a year ago.</p><hr><p>Yet things can, believe it or not, get worse.</p><p><a href=\"https://www.reuters.com/technology/artificial-intelligence/sp-500-earnings-put-investor-focus-tech-ai-2024-10-10/?ref=wheresyoured.at#:~:text=AI%2Drelated%20companies%20have%20dominated,31.\"><u>The AI boom helped the S&amp;P 500 hit record high levels in 2024</u></a>, largely thanks to chip giant NVIDIA, a company that makes both the GPUs necessary to train and run generative AI models and the software architecture behind them. Part of NVIDIA's remarkable growth has been its ability to capitalize on the CUDA architecture — the software layer that lets you do complex computing with GPUs, rather than simply use them to render video games in increasingly higher resolution — and, of course, continually create new GPUs to sell for tens of thousands of dollars to tech companies that want to burn billions of dollars on generative AI, leading the company's stock to pop more than 179% over the last year.</p><p>Back in May, NVIDIA CEO and professional carnival barker Jensen Huang said that the company was now \"<a href=\"https://www.theverge.com/2024/5/22/24162860/nvidia-ai-chip-every-year-blackwell-rubin?ref=wheresyoured.at\"><u>on a one-year rhythm</u></a>\" in AI GPU production, with its latest \"Blackwell\" GPUs (specifically the B100, B200 and GB200 models used for generative AI) supposedly due at the end of 2024,<a href=\"https://www.theinformation.com/articles/nvidias-new-ai-chip-is-delayed-impacting-microsoft-google-meta?rc=kz8jh3&amp;ref=wheresyoured.at\"> <u>but are now delayed until at least March 2025</u></a>.Before we go any further, it's worth noting that when I say \"GPU,\" I don't mean the one you'd find in a gaming PC, but a much larger chip put in a specialized server with multiple <em>other</em> GPUs, all integrated with specialized casing, cooling, and networking infrastructure. In simple terms, the things necessary to make sure all these chips work together efficiently, and also stop them from overheating, <em>because they get extremely hot and are running at full speed, all the time.</em></p><p>The initial delay of the new Blackwell chips was caused by a (<a href=\"https://www.reuters.com/technology/artificial-intelligence/nvidias-design-flaw-with-blackwell-ai-chips-now-fixed-ceo-says-2024-10-23/?ref=wheresyoured.at\"><u>now-fixed</u></a>) design flaw in production, but as I've suggested above, the problem isn't <em>just</em> creating the chips — it's making sure they actually work, at scale, for the jobs they're bought for.&nbsp;</p><p>But what if that, too, wasn't possible?</p><p>A few days ago,<a href=\"https://www.theinformation.com/articles/nvidia-customers-worry-about-snag-with-new-ai-chip-servers?rc=kz8jh3&amp;ref=wheresyoured.at\"> <u>The Information reported</u></a> that NVIDIA is grappling with the oldest problem in computing — how to cool the fucking things. According to the report, NVIDIA has been asking suppliers to change the design of its 3,000-pound, 75-GPU server&nbsp; racks \"several times\" to overcome overheating problems, which The Information calls \"the most complicated design NVIDIA had ever come up with.\" According to the report,&nbsp; a few months after revealing the racks, engineers found that they...didn't work properly, even with Nvidia’s smaller 36-chip racks, and have been scrambling to fix it ever since.</p><p>While one can dazzle investors with buzzwords and charts, the laws of physics are a far harsher mistress, and if NVIDIA is struggling mere months before the first installations are to begin, it's unclear how it practically launches this generation of chips, let alone continues its yearly cadence. The Information reports that these changes have been made late in the production process, which is scaring customers that desperately need them so that their models can continue to do something they'll work out later. To quote The Information:</p><blockquote>Two executives at large cloud providers that have ordered the new chips said they are concerned that such last-minute difficulties might push back the timeline for when they can get their GPU clusters up and running next year.</blockquote><p>The fact that NVIDIA is having such significant difficulties with thermal performance is very, very bad. These chips are incredibly expensive —<a href=\"https://siliconangle.com/2024/11/17/nvidias-upcoming-blackwell-gpus-overheat-server-racks-worrying-customers-reports-say/?ref=wheresyoured.at#:~:text=The%20GB200%20Grace%20Blackwell%20superchips,at%20more%20than%20%243%20million.\"> <u>as much as $70,000 a piece</u></a> — and will be running, as I've mentioned, at full speed, generating an incredible amount of heat that must be dissipated, while sat next to anywhere from 35 to 71 other chips, which will in turn be densely packed so that you can cram more servers into a data center. New, more powerful chips require entirely new methods to rack-mount, operate and cool them, and all of these parts must operate in sync, as overheating GPUs <em>will</em> die. While these units are <em>big</em>, some of their internal components are microscopic in size, and unless properly cooled, their circuits will start to crumble when roasted by a guy typing \"Garfield with Gun\" into ChatGPT.</p><p>Remember, Blackwell is supposed to represent a major leap forward in performance. If NVIDIA doesn’t solve its cooling problem — and solve it well — its customers will undoubtedly encounter thermal throttling, where the chip reduces speed in order to avoid causing permanent damage. It could eliminate any performance gains obtained from the new architecture and new manufacturing process, despite costing <em>much, much more</em> than its predecessor.&nbsp;</p><p>NVIDIA's problem isn't just bringing these thermal performance issues under control, but both keeping them under control <em>and</em> being able to educate their customers on how to do so. NVIDIA has,<a href=\"https://www.theinformation.com/articles/nvidias-jensen-huang-is-on-top-of-the-world-so-why-is-he-worried?rc=kz8jh3&amp;ref=wheresyoured.at\"> <u>according to The Information</u></a>, repeatedly tried to influence its customers' server integrations to follow its designs because it thinks it will \"lead to better performance,\" but in this case, one has to worry if NVIDIA's Blackwell chips can be reliably cooled.</p><p>While NVIDIA might be able to fix this problem in isolation within its racks, it remains to be seen how this works at scale as they ship and integrate hundreds of thousands of Blackwell GPUs starting in the front half of 2025.&nbsp;</p><p>Things also get a little worse when you realize <em>how</em> these chips are being installed — in giant “supercomputer” data centers where tens of thousands, or as many as a hundred thousand in the case of Elon Musk’s “colossus” data center — of GPUs run in concert to power generative AI models. <a href=\"https://www.wsj.com/tech/ai/nvidia-chips-ai-race-96d21d09?ref=wheresyoured.at\"><u>The Wall Street Journal reported a few weeks ago </u></a>that building these vast data centers creates entirely new engineering challenges, with one expert saying that big tech companies could be using <em>as much as half of their capital expenditures </em>on replacing parts that have broken down, in large part because these clusters are running their GPUs at full speed, at all times.&nbsp;</p><p>Remember, the capital expenditures on generative AI and the associated infrastructure have gone over $200 billion in the last year. If half of that’s dedicated to replacing broken gear, what happens when there’s no path to profitability?</p><p>In any case, NVIDIA doesn’t care. It’s already made billions of dollars selling Blackwell GPUs —<a href=\"https://www.techrepublic.com/article/nvidia-blackwell-gpus-sold-out-demand-surges/?ref=wheresyoured.at\"> <u>they're sold out for a year, after all</u></a> — and will continue to do so for now, but any manufacturing or cooling issues will likely be costly.</p><p>And even then, at some point somebody has to ask the question: why do we need all these GPUs if we've reached peak AI? Despite the remarkable \"power\" of these chips, NVIDIA's entire enterprise GPU business model centers around the idea that throwing more power at these problems will finally create some solutions.</p><p>What if that isn't the case?</p><hr><p>The tech industry is over-leveraged, having doubled, tripled, <em>quadrupled</em> down on generative AI — a technology that doesn't do much more than it did a few months ago and won't do much more than it can do now. Every single big tech company has piled tens of billions of dollars into building out massive data centers with the intent of \"capturing AI demand,\" yet never seemed to think whether they were actually building things that people wanted, or would pay for, or would somehow make the company money.</p><p>While some have claimed that \"agents are the next frontier,\" the reality is that agents may be the <em>last</em> generative AI product — multiple Large Language Models and integrations bouncing off of each other in an attempt to simulate what a human might do at a cost that won't be sustainable for the majority of businesses.<a href=\"https://www.platformer.news/anthropic-ai-agents-computer-use-consequences/?ref=wheresyoured.at\"> <u>While Anthropic's demo of its model allegedly controlling a few browser windows with a prompt might have seemed impressive to credulous people like Casey Newton</u></a>, these were controlled demos which Anthropic added were \"slow\" and \"made lots of mistakes.\"&nbsp; Hey,<a href=\"https://www.wheresyoured.at/peakai/#:~:text=OpenAI%20will%20fix-,hallucinations,-%2C%20something%20that%20the\"> <u>almost like it's hallucinating! I sure hope they fix that <em>totally unfixable problem</em></u></a><em>.</em></p><p>Even if it does, Anthropic has now successfully replaced...an entry-level data worker position at an indeterminate and likely unprofitable price. And in many organizations, those jobs had <em>already </em>been outsourced, or automated, or staffed with cheaper contractors.&nbsp;</p><p>The obscenity of this mass delusion is nauseating — a monolith to bad decision-making and the herd mentality of tech's most powerful people, as well as an outright attempt to manipulate the media into believing something was possible that wasn't. And the media bought it, hook, line, and sinker.</p><p>Hundreds of billions of dollars have been wasted building giant data centers to crunch numbers for software that has no real product-market fit, all while trying to hammer it into various shapes to make it pretend that it's alive, conscious, or even a useful product.&nbsp;</p><p>There is no path, from what I can see, to turn generative AI and its associated products into anything resembling sustainable businesses, and the only path that big tech appeared to have was to throw as much money, power, and data at the problem as possible, an avenue that appears to be another dead end.</p><p>And worse still, nothing has really <em>come out</em> of this movement. I've used a handful of AI products that I've found useful — an AI powered journal, for example — but these are not the products that one associates with \"revolutions,\" but useful tools that would have been a welcome surprise if they didn't require burning billions of dollars, blowing past emissions targets and stealing the creative works of millions of people to train them.</p><hr><p>I truly don't know what happens next, but I'll walk you through what I'm thinking.</p><p>If we're truly at the diminishing returns stage of transformer-based models, it will be extremely difficult to justify buying further iterations of NVIDIA GPUs past Blackwell. The entire generative AI movement lives and dies by the idea that more compute power and more training data makes these things better, and if that's no longer the case, there's little reason to keep buying bigger and better. After all, what's the point?&nbsp;</p><p>Even now, what exactly happens when Microsoft or Google has racks-worth of Blackwell GPUs? The models aren't going to get better.</p><p>This also makes the lives of OpenAI and Anthropic that much more difficult. Sam Altman<a href=\"https://www.wheresyoured.at/false-prophet/\"> <u>has grown rich and powerful lying about how GPT will somehow lead to AGI</u></a>, but at this point, what exactly is OpenAI meant to do? The only way it’s ever been able to develop new models is by throwing masses of compute and training data at the problem, and its only other choice is to start stapling its reasoning model onto its main Large Language Model, at which point <em>something </em>happens, something so good that literally nobody working for OpenAI or in the media appears to be able to tell you what it is.</p><p>Putting that aside,<a href=\"https://www.wheresyoured.at/oai-business/\"> <u>OpenAI is also a terrible business</u></a> that has to burn $5 billion to make $3.4 billion, with no proof that it’s capable of bringing down costs. The constant refrain I hear from VCs and AI fantasists is that \"chips will bring down the cost of inference,\" yet I don't see any proof of that happening, nor do I think it'll happen quickly enough for these companies to turn things around.</p><p>And you can feel the desperation, too. OpenAI is <a href=\"https://techcrunch.com/2024/12/02/ads-might-be-coming-to-chatgpt-despite-sam-altman-not-being-a-fan/?ref=wheresyoured.at\"><u>reportedly looking at ads as a means to narrow the gap between its revenues and losses</u></a>. As I pointed out in <a href=\"https://www.wheresyoured.at/burst-damage/\"><u>Burst Damage</u></a>, introducing an advertising revenue stream would require significant upfront investment, both in terms of technology and talent. OpenAI would need a way to target ads, and a team to sell advertising — or, instead, use a third-party ad network that would take a significant bite out of its revenue.&nbsp;</p><p>It’s unclear how much OpenAI could charge advertisers, or what percentage of its reported 200 million weekly users have an ad-blocker installed. Or, for that matter, whether ads would provide a perverse incentive for OpenAI to enshittify an already unreliable product.&nbsp;</p><p>Facebook and Google — as I’ve previously noted — have made their products manifestly worse in order to increase the amount of time people spend on their sites, and thus, the number of ads they see. In the case of Facebook, it<a href=\"https://www.wheresyoured.at/killingfacebook/\"><u> buried your newsfeed under a deluge of AI-generated sludge and “recommended content.</u></a>” Google, meanwhile, has <a href=\"https://www.wheresyoured.at/the-men-who-killed-google/\"><u>progressively degraded the quality of its search results in order to increase the volume of queries it received as a means of making sure users saw more ads</u></a>.&nbsp;</p><p>OpenAI could, just as easily, fall into the same temptation. Most people who use ChatGPT are trying to accomplish a specific task — like writing a term paper, or researching a topic, or whatever — and then they leave. And so, the amount of ads they’d conceivably see each will undoubtedly be comparatively low compared to a social network or search engine. Would OpenAI try to get users to stick around longer — to write more prompts — by crippling the performance of its models?&nbsp;</p><p>Even if OpenAI listens to its better angels, the reality still stands: ads won’t dam the rising tide of red ink that promises to eventually drown the company.&nbsp;</p><p>This is a truly dismal situation where the only options are to stop now, or continue burning money until the heat gets too much. It cost $100 million to train GPT-4o, and<a href=\"https://www.tomshardware.com/tech-industry/artificial-intelligence/ai-models-that-cost-dollar1-billion-to-train-are-in-development-dollar100-billion-models-coming-soon-largest-current-models-take-only-dollar100-million-to-train-anthropic-ceo?ref=wheresyoured.at\"> <u>Anthropic CEO Dario Amodei estimated a few months ago that training future models will cost $1 billion to $10 billion</u></a>,<a href=\"https://x.com/danielnewmanUV/status/1795434545287770212?ref=wheresyoured.at\"> <u>with one researcher claiming that training OpenAI's GPT-5 will cost around $1 billion</u></a>.</p><p>And that’s before mentioning any, to quote a Rumsfeldism, “<a href=\"https://en.wikipedia.org/wiki/There_are_unknown_unknowns?ref=wheresyoured.at\"><u>unknown unknowns</u></a>.” Trump’s election, at the risk of sounding like a cliché, changes everything and in ways we don’t yet fully understand. <a href=\"https://www.wsj.com/tech/elon-musk-business-rivals-altman-openai-f5fccd36?ref=wheresyoured.at\"><u>According to the Wall Street Journal</u></a>, Musk has successfully ingratiated himself with Trump, thanks to his early and full-throated support of his campaign. He’s now reportedly living in Mar a Lago, sitting on calls with world leaders, and whispering in Trump’s ear as he builds his cabinet.&nbsp;</p><p>And, as The Journal claims, his enemies fear that he could use his position of influence to harm them or their businesses — chiefly Sam Altman, who is “persona non grata” in Musk’s world, largely due to the new for-profit direction of OpenAI. While it’s likely that these companies will fail due to inevitable organic realities (like running out of money, or not having a product that generates a profit), Musk’s enemies must now contend with a new enemy — one with the full backing of the Federal government, and that neither forgives nor forgets.</p><p>And, crucially, one that’s not afraid to bend ethical or moral laws to further his own interests — or to inflict pain on those perceived as having slighted him.&nbsp;</p><p>Even if Musk doesn’t use his newfound political might to hurt Altman and OpenAI, he could still pursue the company as a private citizen. Last Friday, he filed an injunction requesting a halt to OpenAI’s transformation from an ostensible non-profit to a for-profit business. Even if he ultimately fails, should Musk manage to drag the process out, or delay it temporarily, it could strike a terminal blow for OpenAI.&nbsp;</p><p>That’s because in its most recent fundraise, OpenAI agreed that it would convert its recent $6.6bn equity investment into high-interest debt, should it fail to successfully convert into a for-profit business within a two-year period. This was a tight deadline to begin with, and it can’t afford any delays. The interest payments on that debt would massively increase its cash burn, and it would undoubtedly find it hard to obtain further outside investment.&nbsp;</p><p>Outside of a miracle, we are about to enter an era of desperation in the generative AI space. We're two years in, and we have no killer apps — no industry-defining products — other than ChatGPT, a product that burns billions of dollars and nobody can really describe. Neither Microsoft, nor Meta, nor Google or Amazon seem to be able to come up with a profitable use case, let alone one their users actually like, nor have any of the people that have raised billions of dollars in venture capital for anything with \"AI\" taped to the side — and<a href=\"https://www.theinformation.com/articles/recent-venture-deals-show-ai-valuations-may-be-cooling?rc=kz8jh3&amp;ref=wheresyoured.at\"> <u>investor interest in AI is cooling</u></a>.</p><p>It's unclear how much further this farce continues, if only because it isn't obvious what it is that anybody gets by investing in future rounds in OpenAI, Anthropic, or any other generative AI company. At some point they must make money, and the entire dream has been built around the idea that all of these GPUs and all of this money would eventually spit out something revolutionary.</p><p>Yet what we have is clunky, ugly, messy, larcenous, environmentally-destructive and mediocre. Generative AI was a reckless pursuit, one that shows a total lack of creativity and sense in the minds of big tech and venture capital, one where there was never anything really <em>impressive</em> other than the amount of money it could burn and the amount of times Sam Altman could say something stupid and get quoted for it.</p><p>I'll be honest with you, I have no idea what happens here. The future was always one that demanded that big tech spent more to make even bigger models that would at some point become useful, and that isn't happening. In pursuit of doing so, big tech invested hundreds of billions of dollars into infrastructure specifically to follow one goal, and put AI front and center at their businesses, claiming it was the future without ever considering what they'd do if it wasn't.</p><p>The revenue isn't coming. The products aren't coming. \"Orion,\" OpenAI's next model, will underwhelm, as will its competitors' models, and at some point somebody is going to blink in one of the hyperscalers, and the AI era will be over. Almost every single generative AI company that you’ve heard of is deeply unprofitable, and there are few innovations coming to save them from the atrophy of the foundation models.</p><p>I feel sad and exhausted as I write this, drained as I look at the many times I’ve tried to warn people, frustrated at the many members of the media that failed to push back against the overpromises and outright lies of people like Sam Altman, and full of dread as I consider the economic ramifications of this industry collapsing. Once the AI bubble pops, <a href=\"https://www.wheresyoured.at/rotcombubble/\"><u>there are no other hyper-growth markets left</u></a>, which will in turn lead to a bloodbath in big tech stocks as they realize that <a href=\"https://www.wheresyoured.at/the-rot-economy/\"><u>they’re out of big ideas to convince the street that they’re going to grow forever</u></a>.</p><p>There are some that will boast about “being right” here, and yes, there is some satisfaction in being so. Nevertheless, knowing that the result of this bubble bursting will be massive layoffs, a dearth in venture capital funding, and a much more fragile tech ecosystem.&nbsp;</p><p><a href=\"https://www.wheresyoured.at/bubble-trouble/\"><u>I’ll end with a quote from Bubble Trouble, a piece I wrote in Apri</u></a>l:&nbsp;</p><blockquote>How do you solve all of these incredibly difficult problems? What does OpenAI or Anthropic do when they run out of data, and synthetic data doesn't fill the gap, or worse, massively degrades the quality of their output? What does Sam Altman do if GPT-5 — like GPT-4 — doesn't significantly improve its performance and he can't find enough compute to take the next step? What do OpenAI and Anthropic do when they realize they will likely never turn a profit? What does Microsoft, or Amazon, or Google do if demand never really takes off, and they're left with billions of dollars of underutilized data centers? What does Nvidia do if the demand for its chips drops off a cliff as a result?<p>I don't know why more people aren't screaming from the rooftops about how unsustainable the AI boom is, and the impossibility of some of the challenges it faces. There is no way to create enough data to train these models, and little that we've seen so far suggests that generative AI will make anybody but Nvidia money. We're reaching the point where physics — things like heat and electricity — are getting in the way of progressing much further, and it's hard to stomach investing more considering where we're at right now is, once you cut through the noise, fairly god damn mediocre. There is no iPhone moment coming, I'm afraid.</p></blockquote><p>I was right then and I’m right now. Generative AI isn’t a revolution, it’s an evolution of a tech industry overtaken by growth-hungry management consultant types that neither know the problems that real people face nor how to fix them. It’s a sickening waste, a monument to the corrupting force of growth, and a sign that the people in power no longer work for you, the customer, but for the venture capitalists and the markets.</p><p>I also want to be clear that none of these companies ever had a plan. They believed that if they threw enough GPUs together they would turn generative AI – probabilistic models for generating stuff — into some sort of sentient computer. It’s much easier, and more comfortable, to look at the world as a series of conspiracies and grand strategies, and far scarier to see it for what it is — extremely rich and powerful people that are willing to bet insanely large amounts of money on what amounts to a few PDFs and their gut.&nbsp;</p><p>This is not big tech’s big plan to excuse building more data centers — it’s the death throes of twenty years of growth-at-all-costs thinking, because throwing a bunch of money at more servers and more engineers always seemed to create more growth. In practice, this means that the people in charge and the strategies they employ are borne not of an interest in improving the lives of their customers, but in increasing revenue growth, which means the products they create aren’t really about solving any problem other than “what will make somebody give me more money,” which doesn’t necessarily mean “provide them with a service.”</p><p>Generative AI is the perfect monster of <a href=\"https://www.wheresyoured.at/the-rot-economy/\"><u>the Rot Economy</u></a> — a technology that lacks any real purpose sold as if it could do literally anything, one without a real business model or killer app, proliferated because big tech no longer innovates, but rather clones and monopolizes. Yes, this much money <em>can</em> be this stupid, and yes, they will burn billions in pursuit of a non-specific dream that involves charging you money and trapping you in their ecosystem.</p><p>I’m not trying to be a doomsayer, just like I wasn’t trying to be one in March. I believe all of this is going nowhere, and that at some point Google, Microsoft, or Meta is going to blink and pull back on their capital expenditures. And before then, you’re going to get a lot of desperate stories about how “AI gains can be found outside of training new models” to try and keep the party going, despite reality flicking the lights on and off and threatening to call the police.&nbsp;</p><p>I fear for the future for many reasons, but I always have hope, because I believe that there are still good people in the tech industry and that customers are seeing the light. Bluesky feels different — growing rapidly, competing with both Threads and Twitter, all while selling an honest product and an open protocol.&nbsp;</p><p>There are other ideas for the future that aren’t borne of the scuzzy mindset of billionaire shitheels like Sundar Pichai and Sam Altman, and they can — and will — grow out of the ruins created by these kleptocrats.&nbsp;</p>\n    </article></div>","textContent":"\n      Before we get going — please enjoy my speech from Web Summit, Why Are All Tech Products Now Shit? I didn’t write the title.What if what we're seeing today isn't a glimpse of the future, but the new terms of the present? What if artificial intelligence isn't actually capable of doing much more than what we're seeing today, and what if there's no clear timeline when it'll be able to do more? What if this entire hype cycle has been built, goosed by a compliant media ready and willing to take career-embellishers at their word?Me, in March 2024.I have been warning you for the best part of a year that generative AI has no killer apps and had no way of justifying its valuations (February), that generative AI had already peaked (March), and I have pleaded with people to consider an eventuality where the jump from GPT-4 to GPT-5 was not significant, in part due to a lack of training data (April). I shared concerns in July that the transformer-based-architecture underpinning generative AI was a dead end, and that there were few ways we'd progress past the products we'd already seen, in part due to both the limits of training data and the limits of models that use said training data. In August, I summarized the Pale Horses of the AI Apocalypse — events, many that have since come to pass, that would signify that the end is indeed nigh — and again added that GPT-5 would likely \"not change the game enough to matter, let alone [add] a new architecture to build future (and more capable) models on.\"Throughout these pieces I have repeatedly made the point that — separate to any lack of a core value proposition, training data drought, or unsustainable economics — generative AI is a dead end due to the limitations of probabilistic models that hallucinate, where they authoritatively state things that aren't true. The hallucination problem is one that is nowhere closer to being solved — and, at least with the current technology — may never go away, and it makes it a non-starter for a great many business tasks, where you need a high level of reliability.I have — since March — expressed great dismay about the credulousness of the media in their acceptance of the \"inevitable\" ways in which generative AI will change society, despite a lack of any truly meaningful product that might justify an environmentally-destructive industry led by a company that burns more than $5 billion a year and big tech firms spending $200 billion on data centers for products that people don't want.The reason I'm repeating myself is that it's important to note how obvious the problems with generative AI have been, and for how long.And you're going to need context for everything I'm about to throw at you.Sidebar: To explain exactly what happened here, it's worth going over how these models work and are trained. I’ll keep it simple as it's a reminder.A transformer-based generative AI model such as GPT — the technology behind ChatGPT — generates answers using \"inference,\" which means it draws conclusions based off of its \"training,\" which requires feeding it masses of training data (mostly text and images scraped from the internet). Both of these processes require you to use high-end GPUs (graphics processing units), and lots of them.The theory was (is?) that the more training data and compute you throw at these models, the better they get. I have hypothesized for a while they'd have diminishing returns — both from running out of training data and based on the limitations of transformer-based models. And there, as they say, is the rub.A few weeks ago, Bloomberg reported that OpenAI, Google, and Anthropic are struggling to build more advanced AI, and that OpenAI's \"Orion\" model — otherwise known as GPT-5 — \"did not hit the company's desired performance,\" and that \"Orion is so far not considered to be as big a step up\" as it was from GPT-3.5 to GPT-4, its current model. You'll be shocked to hear the reason is that because \"it’s become increasingly difficult to find new, untapped sources of high-quality, human-made training data that can be used to build more advanced AI systems,\" something I said would happen in March, while also adding that the \"AGI bubble is bursting a little bit,\" something I said more forcefully in July.I also want to stop and stare daggers at one particular point:These issues challenge the gospel that has taken hold in Silicon Valley in recent years, particularly since OpenAI released ChatGPT two years ago. Much of the tech industry has bet on so-called scaling laws that say more computing power, data and larger models will inevitably pave the way for greater leaps forward in the power of AI.The only people taking this as \"gospel\" have been members of the media unwilling to ask the tough questions and AI founders that don't know what the fuck they're talking about (or that intend to mislead). Generative AI's products have effectively been trapped in amber for over a year. There have been no meaningful, industry-defining products, because, as economist Daron Acemoglu said back in May, \"more powerful\" models do not unlock new features, or really change the experience, nor what you can build with transformer-based models. Or, put another way, a slightly better white elephant is still a white elephant. Despite the billions of dollars burned and thousands of glossy headlines, it's difficult to point to any truly important generative-AI-powered product. Even Apple Intelligence, the only thing that Apple really had to add to the latest iPhone, is utterly dull, and largely based on on-device models.Yes, there are people that use ChatGPT — 200 million of them a week, allegedly, losing the company money with every prompt — but there is little to suggest that there's widespread adoption of actual generative AI software. The Information reported in September that between 0.1% and 1% of the 440 million of Microsoft's business customers were paying for its AI-powered Copilot, and in late October, Microsoft claimed that \"AI is on pace to be a $10 billion-a-year business,\" which sounds good until you consider a few things:Microsoft has no \"AI business\" unit, which means that this annual \"$10 billion\" (or $2.5 billion a quarter) revenue figure is split across providing cloud compute services on Azure, selling Copilot to dumb people with Microsoft 365 subscriptions, selling Github Copilot, and basically anything else with \"AI\" on it. Microsoft is cherry-picking a number based on non-specific criteria and claiming it's a big deal, when it's actually pretty pathetic considering its capital expenditures will likely hit over $60 billion in 2024.Note the word \"revenue,\" not \"profit.\" How much is Microsoft spending to make $10 billion a year? OpenAI currently spends $2.35 to make $1, and Microsoft CFO Amy Hood said that OpenAI would cut into Microsoft's profits this October, losing it a remarkable $1.5 billion, \"mainly because of an expected loss from OpenAI\" according to CNBC. A year ago, the Wall Street Journal reported in October 2023 that Microsoft was losing an average of $20 per-user-per month on GitHub Copilot — a product with over a million users. If true, this suggests losses of at least $200 million (based on documents I've reviewed, it has 1.8 million users as of a month ago, but I went on the lower end) a year.Microsoft has still yet to break out exactly how much generative AI is increasing revenue in specific business units. Generally, if a company is doing well at something, they take great pains to make that clear. Instead, Microsoft chose in August to \"revamp\" its reporting structure to \"give better visibility into cloud consumption revenue,\" which is something you do if you, say, anticipate you're going to have your worst day of trading in years after your next earnings as Microsoft did in October.I must be clear that every single one of these investments and products has been hyped with the whisper that they would get exponentially better over time, and that eventually the $200 billion in capital expenditures would spit out remarkable productivity improvements and fascinating new products that consumers and enterprises would buy in droves. Instead, big tech has found itself peddling increasingly-more-expensive iterations of near-identical Large Language Models — a direct result of them all having to use the same training data, which it’s now running out of.The other assumption — those so-called scaling laws — has been that by simply building bigger data centers with more GPUs (the expensive, power-hungry graphics processing units used to both run and train these models) and throwing as much training data at them as possible, they'd simply start sprouting new capabilities, despite there being little proof that they'd do so. Microsoft, Meta, Amazon, and Google have all burned billions on the assumption that doing so would create something — be it a human-level \"artificial general intelligence\" or, I dunno, a product that would justify the costs — and it's become painfully obvious that it isn't going to work.As we speak, outlets are already desperate to try and prove that this isn't a problem. The Information, in a similar story to Bloomberg's, attempted to put lipstick on the pig of generative AI, framing the lack of meaningful progress with GPT-5 as fine, because OpenAI can combine its GPT-5 Model with its o-1 \"reasoning\" model, which will then do something of some sort, such as \"write a lot more very difficult code\" according to OpenAI CEO and career liar Sam Altman, who intimated that GPT-5 may function like a \"virtual brain\" in May.Chief Valley Cheerleader Casey Newton wrote on Platformer last week that diminishing returns in training models \"may not matter as much as you would guess,\" with his evidence being that Anthropic, who he claims \"has not been prone to hyperbole,\" do not think that scaling laws are ending. To be clear, in a 14,000 op-ed that Newton wrote two pieces about, Anthropic CEO Dario Amodei said that \"AI-accelerated neuroscience is likely to vastly improve treatments for, or even cure, most mental illness,\" the kind of hyperbole that should have you tarred and feathered in public.So, let me summarize:The main technology behind the entire \"artificial intelligence\" boom is generative AI — transformer-based models like OpenAI's GPT-4 (and soon GPT-5) — and said technology has peaked, with diminishing returns from the only ways of making them \"better\" (feeding them training data and throwing tons of compute at them) suggesting that what we may have, as I've said before, reached Peak AI.Generative AI is incredibly unprofitable. OpenAI, the biggest player in the industry, is on course to lose more than $5 billion this year, with competitor Anthropic (which also makes its own transformer-based model, Claude) on course to lose more than $2.7 billion this year.Every single big tech company has thrown billions — as much as $75 billion in Amazon's case in 2024 alone — at building the data centers and acquiring the GPUs to populate said data centers specifically so they can train their models or other companies' models, or serve customers that would integrate generative AI into their businesses, something that does not appear to be happening at scale.Their investments could theoretically be used for other products, but these data centers are heavily focused on generative AI. Business Insider reports that Microsoft intends to amass 1.8 million GPUs by the end of 2024, costing it tens of billions of dollars.Worse still, many of the companies integrating generative AI do so by connecting to models made by either OpenAI or Anthropic, both of whom are running unprofitable businesses, and likely charging nowhere near enough to cover their costs. As I wrote in the Subprime AI Crisis in September, in the event that these companies start charging what they actually need to, I hypothesize it will multiply the costs of their customers to the point that they can't afford to run their businesses — or, at the very least, will have to remove or scale back generative AI functionality in their products.The entire tech industry has become oriented around a dead-end technology that requires burning billions of dollars to provide inessential products that cost them more money to serve than anybody would ever pay. Their big strategy was to throw even more money at the problem until one of these transformer-based models created a new, more useful product — despite the fact that every iteration of GPT and other models has been, well, iterative. There has never been any proof (other than benchmarks that are increasingly easier to game) that GPT or other models would become conscious, nor that these models would do more than they do today, or three months ago, or even a year ago.Yet things can, believe it or not, get worse.The AI boom helped the S&P 500 hit record high levels in 2024, largely thanks to chip giant NVIDIA, a company that makes both the GPUs necessary to train and run generative AI models and the software architecture behind them. Part of NVIDIA's remarkable growth has been its ability to capitalize on the CUDA architecture — the software layer that lets you do complex computing with GPUs, rather than simply use them to render video games in increasingly higher resolution — and, of course, continually create new GPUs to sell for tens of thousands of dollars to tech companies that want to burn billions of dollars on generative AI, leading the company's stock to pop more than 179% over the last year.Back in May, NVIDIA CEO and professional carnival barker Jensen Huang said that the company was now \"on a one-year rhythm\" in AI GPU production, with its latest \"Blackwell\" GPUs (specifically the B100, B200 and GB200 models used for generative AI) supposedly due at the end of 2024, but are now delayed until at least March 2025.Before we go any further, it's worth noting that when I say \"GPU,\" I don't mean the one you'd find in a gaming PC, but a much larger chip put in a specialized server with multiple other GPUs, all integrated with specialized casing, cooling, and networking infrastructure. In simple terms, the things necessary to make sure all these chips work together efficiently, and also stop them from overheating, because they get extremely hot and are running at full speed, all the time.The initial delay of the new Blackwell chips was caused by a (now-fixed) design flaw in production, but as I've suggested above, the problem isn't just creating the chips — it's making sure they actually work, at scale, for the jobs they're bought for. But what if that, too, wasn't possible?A few days ago, The Information reported that NVIDIA is grappling with the oldest problem in computing — how to cool the fucking things. According to the report, NVIDIA has been asking suppliers to change the design of its 3,000-pound, 75-GPU server  racks \"several times\" to overcome overheating problems, which The Information calls \"the most complicated design NVIDIA had ever come up with.\" According to the report,  a few months after revealing the racks, engineers found that they...didn't work properly, even with Nvidia’s smaller 36-chip racks, and have been scrambling to fix it ever since.While one can dazzle investors with buzzwords and charts, the laws of physics are a far harsher mistress, and if NVIDIA is struggling mere months before the first installations are to begin, it's unclear how it practically launches this generation of chips, let alone continues its yearly cadence. The Information reports that these changes have been made late in the production process, which is scaring customers that desperately need them so that their models can continue to do something they'll work out later. To quote The Information:Two executives at large cloud providers that have ordered the new chips said they are concerned that such last-minute difficulties might push back the timeline for when they can get their GPU clusters up and running next year.The fact that NVIDIA is having such significant difficulties with thermal performance is very, very bad. These chips are incredibly expensive — as much as $70,000 a piece — and will be running, as I've mentioned, at full speed, generating an incredible amount of heat that must be dissipated, while sat next to anywhere from 35 to 71 other chips, which will in turn be densely packed so that you can cram more servers into a data center. New, more powerful chips require entirely new methods to rack-mount, operate and cool them, and all of these parts must operate in sync, as overheating GPUs will die. While these units are big, some of their internal components are microscopic in size, and unless properly cooled, their circuits will start to crumble when roasted by a guy typing \"Garfield with Gun\" into ChatGPT.Remember, Blackwell is supposed to represent a major leap forward in performance. If NVIDIA doesn’t solve its cooling problem — and solve it well — its customers will undoubtedly encounter thermal throttling, where the chip reduces speed in order to avoid causing permanent damage. It could eliminate any performance gains obtained from the new architecture and new manufacturing process, despite costing much, much more than its predecessor. NVIDIA's problem isn't just bringing these thermal performance issues under control, but both keeping them under control and being able to educate their customers on how to do so. NVIDIA has, according to The Information, repeatedly tried to influence its customers' server integrations to follow its designs because it thinks it will \"lead to better performance,\" but in this case, one has to worry if NVIDIA's Blackwell chips can be reliably cooled.While NVIDIA might be able to fix this problem in isolation within its racks, it remains to be seen how this works at scale as they ship and integrate hundreds of thousands of Blackwell GPUs starting in the front half of 2025. Things also get a little worse when you realize how these chips are being installed — in giant “supercomputer” data centers where tens of thousands, or as many as a hundred thousand in the case of Elon Musk’s “colossus” data center — of GPUs run in concert to power generative AI models. The Wall Street Journal reported a few weeks ago that building these vast data centers creates entirely new engineering challenges, with one expert saying that big tech companies could be using as much as half of their capital expenditures on replacing parts that have broken down, in large part because these clusters are running their GPUs at full speed, at all times. Remember, the capital expenditures on generative AI and the associated infrastructure have gone over $200 billion in the last year. If half of that’s dedicated to replacing broken gear, what happens when there’s no path to profitability?In any case, NVIDIA doesn’t care. It’s already made billions of dollars selling Blackwell GPUs — they're sold out for a year, after all — and will continue to do so for now, but any manufacturing or cooling issues will likely be costly.And even then, at some point somebody has to ask the question: why do we need all these GPUs if we've reached peak AI? Despite the remarkable \"power\" of these chips, NVIDIA's entire enterprise GPU business model centers around the idea that throwing more power at these problems will finally create some solutions.What if that isn't the case?The tech industry is over-leveraged, having doubled, tripled, quadrupled down on generative AI — a technology that doesn't do much more than it did a few months ago and won't do much more than it can do now. Every single big tech company has piled tens of billions of dollars into building out massive data centers with the intent of \"capturing AI demand,\" yet never seemed to think whether they were actually building things that people wanted, or would pay for, or would somehow make the company money.While some have claimed that \"agents are the next frontier,\" the reality is that agents may be the last generative AI product — multiple Large Language Models and integrations bouncing off of each other in an attempt to simulate what a human might do at a cost that won't be sustainable for the majority of businesses. While Anthropic's demo of its model allegedly controlling a few browser windows with a prompt might have seemed impressive to credulous people like Casey Newton, these were controlled demos which Anthropic added were \"slow\" and \"made lots of mistakes.\"  Hey, almost like it's hallucinating! I sure hope they fix that totally unfixable problem.Even if it does, Anthropic has now successfully replaced...an entry-level data worker position at an indeterminate and likely unprofitable price. And in many organizations, those jobs had already been outsourced, or automated, or staffed with cheaper contractors. The obscenity of this mass delusion is nauseating — a monolith to bad decision-making and the herd mentality of tech's most powerful people, as well as an outright attempt to manipulate the media into believing something was possible that wasn't. And the media bought it, hook, line, and sinker.Hundreds of billions of dollars have been wasted building giant data centers to crunch numbers for software that has no real product-market fit, all while trying to hammer it into various shapes to make it pretend that it's alive, conscious, or even a useful product. There is no path, from what I can see, to turn generative AI and its associated products into anything resembling sustainable businesses, and the only path that big tech appeared to have was to throw as much money, power, and data at the problem as possible, an avenue that appears to be another dead end.And worse still, nothing has really come out of this movement. I've used a handful of AI products that I've found useful — an AI powered journal, for example — but these are not the products that one associates with \"revolutions,\" but useful tools that would have been a welcome surprise if they didn't require burning billions of dollars, blowing past emissions targets and stealing the creative works of millions of people to train them.I truly don't know what happens next, but I'll walk you through what I'm thinking.If we're truly at the diminishing returns stage of transformer-based models, it will be extremely difficult to justify buying further iterations of NVIDIA GPUs past Blackwell. The entire generative AI movement lives and dies by the idea that more compute power and more training data makes these things better, and if that's no longer the case, there's little reason to keep buying bigger and better. After all, what's the point? Even now, what exactly happens when Microsoft or Google has racks-worth of Blackwell GPUs? The models aren't going to get better.This also makes the lives of OpenAI and Anthropic that much more difficult. Sam Altman has grown rich and powerful lying about how GPT will somehow lead to AGI, but at this point, what exactly is OpenAI meant to do? The only way it’s ever been able to develop new models is by throwing masses of compute and training data at the problem, and its only other choice is to start stapling its reasoning model onto its main Large Language Model, at which point something happens, something so good that literally nobody working for OpenAI or in the media appears to be able to tell you what it is.Putting that aside, OpenAI is also a terrible business that has to burn $5 billion to make $3.4 billion, with no proof that it’s capable of bringing down costs. The constant refrain I hear from VCs and AI fantasists is that \"chips will bring down the cost of inference,\" yet I don't see any proof of that happening, nor do I think it'll happen quickly enough for these companies to turn things around.And you can feel the desperation, too. OpenAI is reportedly looking at ads as a means to narrow the gap between its revenues and losses. As I pointed out in Burst Damage, introducing an advertising revenue stream would require significant upfront investment, both in terms of technology and talent. OpenAI would need a way to target ads, and a team to sell advertising — or, instead, use a third-party ad network that would take a significant bite out of its revenue. It’s unclear how much OpenAI could charge advertisers, or what percentage of its reported 200 million weekly users have an ad-blocker installed. Or, for that matter, whether ads would provide a perverse incentive for OpenAI to enshittify an already unreliable product. Facebook and Google — as I’ve previously noted — have made their products manifestly worse in order to increase the amount of time people spend on their sites, and thus, the number of ads they see. In the case of Facebook, it buried your newsfeed under a deluge of AI-generated sludge and “recommended content.” Google, meanwhile, has progressively degraded the quality of its search results in order to increase the volume of queries it received as a means of making sure users saw more ads. OpenAI could, just as easily, fall into the same temptation. Most people who use ChatGPT are trying to accomplish a specific task — like writing a term paper, or researching a topic, or whatever — and then they leave. And so, the amount of ads they’d conceivably see each will undoubtedly be comparatively low compared to a social network or search engine. Would OpenAI try to get users to stick around longer — to write more prompts — by crippling the performance of its models? Even if OpenAI listens to its better angels, the reality still stands: ads won’t dam the rising tide of red ink that promises to eventually drown the company. This is a truly dismal situation where the only options are to stop now, or continue burning money until the heat gets too much. It cost $100 million to train GPT-4o, and Anthropic CEO Dario Amodei estimated a few months ago that training future models will cost $1 billion to $10 billion, with one researcher claiming that training OpenAI's GPT-5 will cost around $1 billion.And that’s before mentioning any, to quote a Rumsfeldism, “unknown unknowns.” Trump’s election, at the risk of sounding like a cliché, changes everything and in ways we don’t yet fully understand. According to the Wall Street Journal, Musk has successfully ingratiated himself with Trump, thanks to his early and full-throated support of his campaign. He’s now reportedly living in Mar a Lago, sitting on calls with world leaders, and whispering in Trump’s ear as he builds his cabinet. And, as The Journal claims, his enemies fear that he could use his position of influence to harm them or their businesses — chiefly Sam Altman, who is “persona non grata” in Musk’s world, largely due to the new for-profit direction of OpenAI. While it’s likely that these companies will fail due to inevitable organic realities (like running out of money, or not having a product that generates a profit), Musk’s enemies must now contend with a new enemy — one with the full backing of the Federal government, and that neither forgives nor forgets.And, crucially, one that’s not afraid to bend ethical or moral laws to further his own interests — or to inflict pain on those perceived as having slighted him. Even if Musk doesn’t use his newfound political might to hurt Altman and OpenAI, he could still pursue the company as a private citizen. Last Friday, he filed an injunction requesting a halt to OpenAI’s transformation from an ostensible non-profit to a for-profit business. Even if he ultimately fails, should Musk manage to drag the process out, or delay it temporarily, it could strike a terminal blow for OpenAI. That’s because in its most recent fundraise, OpenAI agreed that it would convert its recent $6.6bn equity investment into high-interest debt, should it fail to successfully convert into a for-profit business within a two-year period. This was a tight deadline to begin with, and it can’t afford any delays. The interest payments on that debt would massively increase its cash burn, and it would undoubtedly find it hard to obtain further outside investment. Outside of a miracle, we are about to enter an era of desperation in the generative AI space. We're two years in, and we have no killer apps — no industry-defining products — other than ChatGPT, a product that burns billions of dollars and nobody can really describe. Neither Microsoft, nor Meta, nor Google or Amazon seem to be able to come up with a profitable use case, let alone one their users actually like, nor have any of the people that have raised billions of dollars in venture capital for anything with \"AI\" taped to the side — and investor interest in AI is cooling.It's unclear how much further this farce continues, if only because it isn't obvious what it is that anybody gets by investing in future rounds in OpenAI, Anthropic, or any other generative AI company. At some point they must make money, and the entire dream has been built around the idea that all of these GPUs and all of this money would eventually spit out something revolutionary.Yet what we have is clunky, ugly, messy, larcenous, environmentally-destructive and mediocre. Generative AI was a reckless pursuit, one that shows a total lack of creativity and sense in the minds of big tech and venture capital, one where there was never anything really impressive other than the amount of money it could burn and the amount of times Sam Altman could say something stupid and get quoted for it.I'll be honest with you, I have no idea what happens here. The future was always one that demanded that big tech spent more to make even bigger models that would at some point become useful, and that isn't happening. In pursuit of doing so, big tech invested hundreds of billions of dollars into infrastructure specifically to follow one goal, and put AI front and center at their businesses, claiming it was the future without ever considering what they'd do if it wasn't.The revenue isn't coming. The products aren't coming. \"Orion,\" OpenAI's next model, will underwhelm, as will its competitors' models, and at some point somebody is going to blink in one of the hyperscalers, and the AI era will be over. Almost every single generative AI company that you’ve heard of is deeply unprofitable, and there are few innovations coming to save them from the atrophy of the foundation models.I feel sad and exhausted as I write this, drained as I look at the many times I’ve tried to warn people, frustrated at the many members of the media that failed to push back against the overpromises and outright lies of people like Sam Altman, and full of dread as I consider the economic ramifications of this industry collapsing. Once the AI bubble pops, there are no other hyper-growth markets left, which will in turn lead to a bloodbath in big tech stocks as they realize that they’re out of big ideas to convince the street that they’re going to grow forever.There are some that will boast about “being right” here, and yes, there is some satisfaction in being so. Nevertheless, knowing that the result of this bubble bursting will be massive layoffs, a dearth in venture capital funding, and a much more fragile tech ecosystem. I’ll end with a quote from Bubble Trouble, a piece I wrote in April: How do you solve all of these incredibly difficult problems? What does OpenAI or Anthropic do when they run out of data, and synthetic data doesn't fill the gap, or worse, massively degrades the quality of their output? What does Sam Altman do if GPT-5 — like GPT-4 — doesn't significantly improve its performance and he can't find enough compute to take the next step? What do OpenAI and Anthropic do when they realize they will likely never turn a profit? What does Microsoft, or Amazon, or Google do if demand never really takes off, and they're left with billions of dollars of underutilized data centers? What does Nvidia do if the demand for its chips drops off a cliff as a result?I don't know why more people aren't screaming from the rooftops about how unsustainable the AI boom is, and the impossibility of some of the challenges it faces. There is no way to create enough data to train these models, and little that we've seen so far suggests that generative AI will make anybody but Nvidia money. We're reaching the point where physics — things like heat and electricity — are getting in the way of progressing much further, and it's hard to stomach investing more considering where we're at right now is, once you cut through the noise, fairly god damn mediocre. There is no iPhone moment coming, I'm afraid.I was right then and I’m right now. Generative AI isn’t a revolution, it’s an evolution of a tech industry overtaken by growth-hungry management consultant types that neither know the problems that real people face nor how to fix them. It’s a sickening waste, a monument to the corrupting force of growth, and a sign that the people in power no longer work for you, the customer, but for the venture capitalists and the markets.I also want to be clear that none of these companies ever had a plan. They believed that if they threw enough GPUs together they would turn generative AI – probabilistic models for generating stuff — into some sort of sentient computer. It’s much easier, and more comfortable, to look at the world as a series of conspiracies and grand strategies, and far scarier to see it for what it is — extremely rich and powerful people that are willing to bet insanely large amounts of money on what amounts to a few PDFs and their gut. This is not big tech’s big plan to excuse building more data centers — it’s the death throes of twenty years of growth-at-all-costs thinking, because throwing a bunch of money at more servers and more engineers always seemed to create more growth. In practice, this means that the people in charge and the strategies they employ are borne not of an interest in improving the lives of their customers, but in increasing revenue growth, which means the products they create aren’t really about solving any problem other than “what will make somebody give me more money,” which doesn’t necessarily mean “provide them with a service.”Generative AI is the perfect monster of the Rot Economy — a technology that lacks any real purpose sold as if it could do literally anything, one without a real business model or killer app, proliferated because big tech no longer innovates, but rather clones and monopolizes. Yes, this much money can be this stupid, and yes, they will burn billions in pursuit of a non-specific dream that involves charging you money and trapping you in their ecosystem.I’m not trying to be a doomsayer, just like I wasn’t trying to be one in March. I believe all of this is going nowhere, and that at some point Google, Microsoft, or Meta is going to blink and pull back on their capital expenditures. And before then, you’re going to get a lot of desperate stories about how “AI gains can be found outside of training new models” to try and keep the party going, despite reality flicking the lights on and off and threatening to call the police. I fear for the future for many reasons, but I always have hope, because I believe that there are still good people in the tech industry and that customers are seeing the light. Bluesky feels different — growing rapidly, competing with both Threads and Twitter, all while selling an honest product and an open protocol. There are other ideas for the future that aren’t borne of the scuzzy mindset of billionaire shitheels like Sundar Pichai and Sam Altman, and they can — and will — grow out of the ruins created by these kleptocrats. \n    ","length":35633,"excerpt":"Before we get going — please enjoy my speech from Web Summit, Why Are All Tech Products Now Shit? I didn’t write the title.\n\nWhat if what we're seeing today isn't a glimpse of the future, but the new terms of the present? What if artificial intelligence isn't actually capable of doing much more than what we're seeing today, and what if there's no clear timeline when it'll be able to do more? What if this entire hype cycle has been built, goosed by a compliant media ready and willing to take care","byline":"Edward Zitron","dir":null,"siteName":"Ed Zitron's Where's Your Ed At","lang":"en"},"finalizedMeta":{"title":"Godot Isn&#x27;t Making it","description":"Before we get going — please enjoy my speech from Web Summit, Why Are All Tech Products Now Shit? I didn’t write the title.\n\nWhat if what we&#x27;re seeing today isn&#x27;t a glimpse of the future, but the new terms of the present? What if artificial intelligence isn&#x27;t actually capable of doing much more than what we&#x27;re seeing today, and what if there&#x27;s no clear timeline when it&#x27;ll be able to do more? What if this entire hype cycle has been built, goosed by a compliant media ready and willing to take care","author":"Edward Zitron","creator":"Edward Zitron","publisher":"Ed Zitron&#x27;s Where&#x27;s Your Ed At","date":"2024-12-03T20:55:22.000Z","topics":[]},"jsonLd":{"@type":"Article","headline":"Godot Isn&#x27;t Making it","description":"Before we get going — please enjoy my speech from Web Summit, Why Are All Tech Products Now Shit? I didn’t write the title.\n\nWhat if what we&#x27;re seeing today isn&#x27;t a glimpse of the future, but the new terms of the present? What if artificial intelligence isn&#x27;t actually capable of doing much more than what we&#x27;re seeing today, and what if there&#x27;s no clear timeline when it&#x27;ll be able to do more? What if this entire hype cycle has been built, goosed by a compliant media ready and willing to take care","image":[],"mainEntityOfPage":"https://www.wheresyoured.at/godot-isnt-making-it/","datePublished":"2024-12-03T20:55:22.000Z","dateModified":"2024-12-03T20:55:22.000Z","isAccessibleForFree":false,"isPartOf":{"@type":[],"name":false,"productID":false},"discussionUrl":false,"license":false,"author":{"@type":"Person","name":"Edward Zitron","image":{"@type":"ImageObject","url":"https://www.gravatar.com/avatar/257728ef58ec6562631bc7ebf24dd007?s=250&r=x&d=mp","width":250,"height":250},"url":"https://www.wheresyoured.at/author/edward/","sameAs":[]},"publisher":{"@type":"Organization","name":"Ed Zitron&#x27;s Where&#x27;s Your Ed At","url":"https://www.wheresyoured.at/","logo":{"@type":"ImageObject","url":"https://www.wheresyoured.at/content/images/2024/01/wide-with-letters-1.jpeg"}},"editor":{"@type":false,"name":false,"description":false,"sameAs":false,"image":{"@type":false,"url":false},"givenName":false,"familyName":false,"alternateName":false,"publishingPrinciples":false},"@context":"https://schema.org","url":"https://www.wheresyoured.at/godot-isnt-making-it/"},"twitterObj":false,"status":200,"metadata":{"author":false,"title":"Godot Isn't Making it","description":false,"canonical":"https://www.wheresyoured.at/godot-isnt-making-it/","keywords":[],"image":"/content/images/size/w600/2024/01/wide-with-letters-1.jpeg","firstParagraph":"Before we get going — please enjoy my speech from Web Summit, Why Are All Tech Products Now Shit? I didn’t write the title."},"dublinCore":{},"opengraph":{"title":"Godot Isn't Making it","description":"Before we get going — please enjoy my speech from Web Summit, Why Are All Tech Products Now Shit? I didn’t write the title.\n\nWhat if what we're seeing today isn't a glimpse of the future, but the new terms of the present? What if artificial intelligence isn't actually capable","url":"https://www.wheresyoured.at/godot-isnt-making-it/","site_name":"Ed Zitron's Where's Your Ed At","locale":false,"type":"article","typeObject":{"published_time":"2024-12-03T20:55:22.000Z","modified_time":"2024-12-03T20:55:22.000Z","author":false,"publisher":false,"section":false,"tag":[]},"image":"https://www.wheresyoured.at/content/images/2024/01/wyea--1.jpeg","image:width":"1200","image:height":"1200"},"twitter":{"site":"@edzitron","description":"Before we get going — please enjoy my speech from Web Summit, Why Are All Tech Products Now Shit? I didn’t write the title.\n\nWhat if what we're seeing today isn't a glimpse of the future, but the new terms of the present? What if artificial intelligence isn't actually capable","card":"summary_large_image","creator":false,"title":"Godot Isn't Making it","image":"https://www.wheresyoured.at/content/images/2024/01/wyea--1.jpeg","url":"https://www.wheresyoured.at/godot-isnt-making-it/","label1":"Written by","data1":"Edward Zitron"},"archivedData":{"link":"https://web.archive.org/web/20241204200151/https://www.wheresyoured.at/godot-isnt-making-it/","wayback":"https://web.archive.org/web/20241204200151/https://www.wheresyoured.at/godot-isnt-making-it/"}}}