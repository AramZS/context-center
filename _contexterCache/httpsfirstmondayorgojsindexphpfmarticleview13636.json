{"initialLink":"https://firstmonday.org/ojs/index.php/fm/article/view/13636","sanitizedLink":"https://firstmonday.org/ojs/index.php/fm/article/view/13636","finalLink":"https://firstmonday.org/ojs/index.php/fm/article/view/13636","htmlEmbed":"<script>window.contexterSetup=window.contexterSetup||function(){window.contexterSetupComplete=!0;class ContexterLink extends HTMLAnchorElement{constructor(){super()}connectedCallback(){this.setAttribute(\"target\",\"_blank\")}}customElements.define(\"contexter-link\",ContexterLink,{extends:\"a\"}),customElements.define(\"contexter-inner\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__inner\"}}),customElements.define(\"contexter-thumbnail\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__thumbnail\"}}),customElements.define(\"contexter-byline\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__byline\"}}),customElements.define(\"contexter-keywordset\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__keywordset\"}}),customElements.define(\"contexter-linkset\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__linkset\"}}),customElements.define(\"contexter-meta\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__meta\"}}),customElements.define(\"contexter-summary\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"p-summary entry-summary\"}}),customElements.define(\"contexter-box-head\",class extends HTMLElement{constructor(){super()}connectedCallback(){this.className=\"contexter-box__head\"}}),customElements.define(\"contexter-box-inner\",class extends HTMLElement{constructor(){super()}connectedCallback(){}});class ContexterBox extends HTMLElement{constructor(){super(),this.first=!0,this.shadow=this.attachShadow({mode:\"open\"})}connectedCallback(){if(this.first){this.first=!1;var style=document.createElement(\"style\"),lightDomStyle=(style.innerHTML=`:host {--background: #f5f6f7;--border: darkblue;--blue: #0000ee;--font-color: black;--inner-border: black;font-family: Franklin,Arial,Helvetica,sans-serif;font-size: 14px;background: var(--background);width: 600px;color: var(--font-color);min-height: 90px;display: block;padding: 8px;border: 1px solid var(--border);cursor: pointer;box-sizing: border-box;margin: 6px;contain: content;margin: 6px auto;}// can only select top-level nodes with slotted::slotted(*) {max-width: 100%;display:block;}::slotted([slot=thumbnail]) {max-width: 100%;display:block;}::slotted([slot=header]) {width: 100%;font-size: 1.25rem;font-weight: bold;display:block;margin-bottom: 6px;}::slotted([slot=author]) {max-width: 50%;font-size: 12px;display:inline-block;float: left;}::slotted([slot=time]) {max-width: 50%;font-size: 12px;display:inline-block;float: right;}::slotted([slot=summary]) {width: 100%;margin-top: 6px;padding: 10px 2px;border-top: 1px solid var(--inner-border);font-size: 15px;display:inline-block;margin-bottom: 6px;}contexter-meta {height: auto;margin-bottom: 4px;width: 100%;display: grid;position: relative;min-height: 16px;grid-template-columns: repeat(2, 1fr);}::slotted([slot=keywords]) {width: 80%;padding: 2px 4px;border-top: 1px solid var(--inner-border);font-size: 11px;display: block;float: right;font-style: italic;text-align: right;grid-column: 2/2;grid-row: 1;align-self: end;justify-self: end;}::slotted([slot=keywords]):empty {border-top: 0px solid var(--inner-border);}::slotted([slot=archive-link]) {font-size: 1em;display: inline;}::slotted([slot=archive-link])::after {content: \"|\";display: inline;color: var(--font-color);text-decoration: none;margin: 0 .5em;}::slotted([slot=read-link]) {font-size: 1em;display: inline;}contexter-linkset {width: 80%;padding: 2px 4px;font-size: 13px;float: left;font-weight: bold;grid-row: 1;grid-column: 1/2;align-self: end;justify-self: start;}/* Extra small devices (phones, 600px and down) */@media only screen and (max-width: 600px) {:host {width: 310px;}}/* Small devices (portrait tablets and large phones, 600px and up) */@media only screen and (min-width: 600px) {...}/* Medium devices (landscape tablets, 768px and up) */@media only screen and (min-width: 768px) {...}/* Large devices (laptops/desktops, 992px and up) */@media only screen and (min-width: 992px) {...}/* Extra large devices (large laptops and desktops, 1200px and up) */@media only screen and (min-width: 1200px) {...}@media (prefers-color-scheme: dark){:host {--background: #354150;--border: #1f2b37;--blue: #55b0ff;--font-color: #ffffff;--inner-border: #787a7c;background: var(--background);border: 1px solid var(--border)}}`,document.createElement(\"style\"));lightDomStyle.innerHTML=`contexter-box {contain: content;}contexter-box .read-link {font-weight: bold;}contexter-box a {color: #0000ee;}contexter-box img {width: 100%;border: 0;padding: 0;margin: 0;}/* Extra small devices (phones, 600px and down) */@media only screen and (max-width: 600px) {...}/* Small devices (portrait tablets and large phones, 600px and up) */@media only screen and (min-width: 600px) {...}/* Medium devices (landscape tablets, 768px and up) */@media only screen and (min-width: 768px) {...}/* Large devices (laptops/desktops, 992px and up) */@media only screen and (min-width: 992px) {...}/* Extra large devices (large laptops and desktops, 1200px and up) */@media only screen and (min-width: 1200px) {...}@media (prefers-color-scheme: dark){contexter-box a {color: #55b0ff;}}`,this.appendChild(lightDomStyle),this.shadow.appendChild(style);const innerContainer=document.createElement(\"contexter-box-inner\"),innerSlotThumbnail=(this.shadow.appendChild(innerContainer),document.createElement(\"slot\")),innerSlotHeader=(innerSlotThumbnail.name=\"thumbnail\",innerContainer.appendChild(innerSlotThumbnail),document.createElement(\"slot\")),innerSlotAuthor=(innerSlotHeader.name=\"header\",innerContainer.appendChild(innerSlotHeader),document.createElement(\"slot\")),innerSlotTime=(innerSlotAuthor.name=\"author\",innerContainer.appendChild(innerSlotAuthor),document.createElement(\"slot\")),innerSlotSummary=(innerSlotTime.name=\"time\",innerContainer.appendChild(innerSlotTime),document.createElement(\"slot\")),metaContainer=(innerSlotSummary.name=\"summary\",innerContainer.appendChild(innerSlotSummary),document.createElement(\"contexter-meta\")),innerSlotInfo=(innerContainer.appendChild(metaContainer),document.createElement(\"slot\")),linkContainer=(innerSlotInfo.name=\"keywords\",metaContainer.appendChild(innerSlotInfo),document.createElement(\"contexter-linkset\")),innerSlotArchiveLink=(metaContainer.appendChild(linkContainer),document.createElement(\"slot\")),innerSlotReadLink=(innerSlotArchiveLink.name=\"archive-link\",linkContainer.appendChild(innerSlotArchiveLink),document.createElement(\"slot\"));innerSlotReadLink.name=\"read-link\",linkContainer.appendChild(innerSlotReadLink),this.className=\"contexter-box\",this.onclick=e=>{if(!e.target.className.includes(\"read-link\")&&!e.target.className.includes(\"title-link\")){const mainLinks=this.querySelectorAll(\"a.main-link\");mainLinks[0].click()}}}}}customElements.define(\"contexter-box\",ContexterBox)},window.contexterSetupComplete||window.contexterSetup();</script><contexter-box class=\"link-card h-entry hentry\" itemscope=\"\" itemtype=\"https://schema.org/CreativeWork\"><contexter-thumbnail class=\"thumbnail\" slot=\"thumbnail\"></contexter-thumbnail><contexter-box-head slot=\"header\" class=\"p-name entry-title\" itemprop=\"headline\"><contexter-box-head slot=\"header\" class=\"p-name entry-title\" itemprop=\"headline\"><a is=\"contexter-link\" href=\"https://firstmonday.org/ojs/index.php/fm/article/view/13636\" itemprop=\"url\">The TESCREAL bundle: Eugenics and the promise of utopia through artificial general intelligence| First Monday</a></contexter-box-head></contexter-box-head><time class=\"dt-published published\" slot=\"time\" itemprop=\"datePublished\" datetime=\"2024-07-10T15:45:19.992Z\">7/10/2024</time><contexter-summary class=\"p-summary entry-summary\" itemprop=\"abstract\" slot=\"summary\"><p>The stated goal of many organizations in the field of artificial intelligence (AI) is to develop artificial general intelligence (AGI), an imagined system with more intelligence than anything we have ever seen. Without seriously questioning whether such a system can and should be built, researchers are working to create “safe AGI” that is “beneficial for all of humanity.” We argue that, unlike systems with specific applications which can be evaluated following standard engineering principles, undefined systems like “AGI” cannot be appropriately tested for safety. Why, then, is building AGI often framed as an unquestioned goal in the field of AI? In this paper, we argue that the normative framework that motivates much of this goal is rooted in the Anglo-American eugenics tradition of the twentieth century. As a result, many of the very same discriminatory attitudes that animated eugenicists in the past (e.g., racism, xenophobia, classism, ableism, and sexism) remain widespread within the movement to build AGI, resulting in systems that harm marginalized groups and centralize power, while using the language of “safety” and “benefiting humanity” to evade accountability. We conclude by urging researchers to work on defined tasks for which we can develop safety protocols, rather than attempting to build a presumably all-knowing system such as AGI.</p></contexter-summary><contexter-keywordset itemprop=\"keywords\" slot=\"keywords\"></contexter-keywordset><a href=\"https://web.archive.org/web/20240602052154/https://firstmonday.org/ojs/index.php/fm/article/view/13636\" is=\"contexter-link\" target=\"_blank\" rel=\"timemap\" class=\"read-link archive-link\" itemprop=\"archivedAt\" slot=\"archive-link\">Archived</a><a is=\"contexter-link\" href=\"https://firstmonday.org/ojs/index.php/fm/article/view/13636\" class=\"read-link main-link\" itemprop=\"sameAs\" slot=\"read-link\">Read</a></contexter-box>","linkId":"e41794420cbeeec33af83792dc3e6c21ffe14386","data":{"originalLink":"https://firstmonday.org/ojs/index.php/fm/article/view/13636","sanitizedLink":"https://firstmonday.org/ojs/index.php/fm/article/view/13636","canonical":"https://firstmonday.org/ojs/index.php/fm/article/view/13636","htmlText":"<!DOCTYPE html>\n<html lang=\"en-US\" xml:lang=\"en-US\">\n<head>\n\t<meta charset=\"utf-8\">\n\t<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n\t<title>\n\t\tThe TESCREAL bundle: Eugenics and the promise of utopia through artificial general intelligence\n\t\t\t\t\t\t\t| First Monday\n\t\t\t</title>\n\n\t\n<link rel=\"icon\" href=\"https://firstmonday.org/ojs/public/journals/3/favicon_en_US.gif\">\n<meta name=\"generator\" content=\"Open Journal Systems 3.3.0.13\">\n<link rel=\"schema.DC\" href=\"http://purl.org/dc/elements/1.1/\" />\n<meta name=\"DC.Coverage\" xml:lang=\"en\" content=\"\"/>\n<meta name=\"DC.Creator.PersonalName\" content=\"Timnit Gebru\"/>\n<meta name=\"DC.Creator.PersonalName\" content=\"Émile P. Torres\"/>\n<meta name=\"DC.Date.created\" scheme=\"ISO8601\" content=\"2024-04-14\"/>\n<meta name=\"DC.Date.dateSubmitted\" scheme=\"ISO8601\" content=\"2024-03-30\"/>\n<meta name=\"DC.Date.issued\" scheme=\"ISO8601\" content=\"2024-04-14\"/>\n<meta name=\"DC.Date.modified\" scheme=\"ISO8601\" content=\"2024-04-23\"/>\n<meta name=\"DC.Description\" xml:lang=\"en\" content=\"The stated goal of many organizations in the field of artificial intelligence (AI) is to develop artificial general intelligence (AGI), an imagined system with more intelligence than anything we have ever seen. Without seriously questioning whether such a system can and should be built, researchers are working to create “safe AGI” that is “beneficial for all of humanity.” We argue that, unlike systems with specific applications which can be evaluated following standard engineering principles, undefined systems like “AGI” cannot be appropriately tested for safety. Why, then, is building AGI often framed as an unquestioned goal in the field of AI? In this paper, we argue that the normative framework that motivates much of this goal is rooted in the Anglo-American eugenics tradition of the twentieth century. As a result, many of the very same discriminatory attitudes that animated eugenicists in the past (e.g., racism, xenophobia, classism, ableism, and sexism) remain widespread within the movement to build AGI, resulting in systems that harm marginalized groups and centralize power, while using the language of “safety” and “benefiting humanity” to evade accountability. We conclude by urging researchers to work on defined tasks for which we can develop safety protocols, rather than attempting to build a presumably all-knowing system such as AGI.\"/>\n<meta name=\"DC.Format\" scheme=\"IMT\" content=\"text/html\"/>\n<meta name=\"DC.Format\" scheme=\"IMT\" content=\"application/pdf\"/>\n<meta name=\"DC.Identifier\" content=\"13636\"/>\n<meta name=\"DC.Identifier.DOI\" content=\"10.5210/fm.v29i4.13636\"/>\n<meta name=\"DC.Identifier.URI\" content=\"https://firstmonday.org/ojs/index.php/fm/article/view/13636\"/>\n<meta name=\"DC.Language\" scheme=\"ISO639-1\" content=\"en\"/>\n<meta name=\"DC.Rights\" content=\"Copyright (c) 2024 First Monday\"/>\n<meta name=\"DC.Rights\" content=\"http://creativecommons.org/licenses/by-nc-sa/4.0/\"/>\n<meta name=\"DC.Source\" content=\"First Monday\"/>\n<meta name=\"DC.Source.ISSN\" content=\"1396-0466\"/>\n<meta name=\"DC.Source.URI\" content=\"https://firstmonday.org/ojs/index.php/fm\"/>\n<meta name=\"DC.Title\" content=\"The TESCREAL bundle: Eugenics and the promise of utopia through artificial general intelligence\"/>\n<meta name=\"DC.Type\" content=\"Text.Serial.Journal\"/>\n<meta name=\"DC.Type\" xml:lang=\"en\" content=\"\"/>\n<meta name=\"DC.Type.articleType\" content=\"Articles\"/>\n<meta name=\"gs_meta_revision\" content=\"1.1\"/>\n<meta name=\"citation_journal_title\" content=\"First Monday\"/>\n<meta name=\"citation_journal_abbrev\" content=\"FM\"/>\n<meta name=\"citation_issn\" content=\"1396-0466\"/> \n<meta name=\"citation_author\" content=\"Timnit Gebru\"/>\n<meta name=\"citation_author\" content=\"Émile P. Torres\"/>\n<meta name=\"citation_title\" content=\"The TESCREAL bundle: Eugenics and the promise of utopia through artificial general intelligence\"/>\n<meta name=\"citation_language\" content=\"en\"/>\n<meta name=\"citation_date\" content=\"2024/04/14\"/>\n<meta name=\"citation_doi\" content=\"10.5210/fm.v29i4.13636\"/>\n<meta name=\"citation_abstract_html_url\" content=\"https://firstmonday.org/ojs/index.php/fm/article/view/13636\"/>\n<meta name=\"citation_fulltext_html_url\" content=\"https://firstmonday.org/ojs/index.php/fm/article/view/13636/11599\"/>\n<meta name=\"citation_pdf_url\" content=\"https://firstmonday.org/ojs/index.php/fm/article/download/13636/11606\"/>\n<link rel=\"alternate\" type=\"application/atom+xml\" href=\"https://firstmonday.org/ojs/index.php/fm/gateway/plugin/AnnouncementFeedGatewayPlugin/atom\">\n<link rel=\"alternate\" type=\"application/rdf+xml\" href=\"https://firstmonday.org/ojs/index.php/fm/gateway/plugin/AnnouncementFeedGatewayPlugin/rss\">\n<link rel=\"alternate\" type=\"application/rss+xml\" href=\"https://firstmonday.org/ojs/index.php/fm/gateway/plugin/AnnouncementFeedGatewayPlugin/rss2\">\n<link rel=\"alternate\" type=\"application/atom+xml\" href=\"https://firstmonday.org/ojs/index.php/fm/gateway/plugin/WebFeedGatewayPlugin/atom\">\n<link rel=\"alternate\" type=\"application/rdf+xml\" href=\"https://firstmonday.org/ojs/index.php/fm/gateway/plugin/WebFeedGatewayPlugin/rss\">\n<link rel=\"alternate\" type=\"application/rss+xml\" href=\"https://firstmonday.org/ojs/index.php/fm/gateway/plugin/WebFeedGatewayPlugin/rss2\">\n\t<link rel=\"stylesheet\" href=\"https://firstmonday.org/ojs/index.php/fm/$$$call$$$/page/page/css?name=stylesheet\" type=\"text/css\" /><link rel=\"stylesheet\" href=\"https://firstmonday.org/ojs/index.php/fm/$$$call$$$/page/page/css?name=font\" type=\"text/css\" /><link rel=\"stylesheet\" href=\"https://firstmonday.org/ojs/lib/pkp/styles/fontawesome/fontawesome.css?v=3.3.0.13\" type=\"text/css\" /><link rel=\"stylesheet\" href=\"https://firstmonday.org/ojs/public/journals/3/styleSheet.css?d=\" type=\"text/css\" />\n</head>\n<body class=\"pkp_page_article pkp_op_view has_site_logo\" dir=\"ltr\">\n\n\t<div class=\"pkp_structure_page\">\n\n\t\t\t\t<header class=\"pkp_structure_head\" id=\"headerNavigationContainer\" role=\"banner\">\n\t\t\t\t\t\t <nav class=\"cmp_skip_to_content\" aria-label=\"Jump to content links\">\n\t<a href=\"#pkp_content_main\">Skip to main content</a>\n\t<a href=\"#siteNav\">Skip to main navigation menu</a>\n\t\t<a href=\"#pkp_content_footer\">Skip to site footer</a>\n</nav>\n\n\t\t\t<div class=\"pkp_head_wrapper\">\n\n\t\t\t\t<div class=\"pkp_site_name_wrapper\">\n\t\t\t\t\t<button class=\"pkp_site_nav_toggle\">\n\t\t\t\t\t\t<span>Open Menu</span>\n\t\t\t\t\t</button>\n\t\t\t\t\t\t\t\t\t\t<div class=\"pkp_site_name\">\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<a href=\"\t\t\t\t\t\thttps://firstmonday.org/ojs/index.php/fm/index\n\t\t\t\t\t\" class=\"is_img\">\n\t\t\t\t\t\t\t<img src=\"https://firstmonday.org/ojs/public/journals/3/pageHeaderLogoImage_en_US.gif\" width=\"252\" height=\"102\"  />\n\t\t\t\t\t\t</a>\n\t\t\t\t\t\t\t\t\t\t</div>\n\t\t\t\t</div>\n\n\t\t\t\t\n\t\t\t\t<nav class=\"pkp_site_nav_menu\" aria-label=\"Site Navigation\">\n\t\t\t\t\t<a id=\"siteNav\"></a>\n\t\t\t\t\t<div class=\"pkp_navigation_primary_row\">\n\t\t\t\t\t\t<div class=\"pkp_navigation_primary_wrapper\">\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<ul id=\"navigationPrimary\" class=\"pkp_navigation_primary pkp_nav_list\">\n\t\t\t\t\t\t\t\t<li class=\"\">\n\t\t\t\t<a href=\"https://firstmonday.org/ojs/index.php/fm/about\">\n\t\t\t\t\tAbout\n\t\t\t\t</a>\n\t\t\t\t\t\t\t\t\t<ul>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<li class=\"\">\n\t\t\t\t\t\t\t\t\t<a href=\"https://firstmonday.org/ojs/index.php/fm/about\">\n\t\t\t\t\t\t\t\t\t\tAbout the Journal\n\t\t\t\t\t\t\t\t\t</a>\n\t\t\t\t\t\t\t\t</li>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<li class=\"\">\n\t\t\t\t\t\t\t\t\t<a href=\"https://firstmonday.org/ojs/index.php/fm/about/editorialTeam\">\n\t\t\t\t\t\t\t\t\t\tEditorial Team\n\t\t\t\t\t\t\t\t\t</a>\n\t\t\t\t\t\t\t\t</li>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<li class=\"\">\n\t\t\t\t\t\t\t\t\t<a href=\"https://firstmonday.org/ojs/index.php/fm/about/privacy\">\n\t\t\t\t\t\t\t\t\t\tPrivacy Statement\n\t\t\t\t\t\t\t\t\t</a>\n\t\t\t\t\t\t\t\t</li>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<li class=\"\">\n\t\t\t\t\t\t\t\t\t<a href=\"https://firstmonday.org/ojs/index.php/fm/about/contact\">\n\t\t\t\t\t\t\t\t\t\tContact\n\t\t\t\t\t\t\t\t\t</a>\n\t\t\t\t\t\t\t\t</li>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</ul>\n\t\t\t\t\t\t\t</li>\n\t\t\t\t\t\t\t\t<li class=\"\">\n\t\t\t\t<a href=\"https://firstmonday.org/ojs/index.php/fm/search/search\">\n\t\t\t\t\tSearch\n\t\t\t\t</a>\n\t\t\t\t\t\t\t</li>\n\t\t\t\t\t\t\t\t<li class=\"\">\n\t\t\t\t<a href=\"https://firstmonday.org/ojs/index.php/fm/issue/current\">\n\t\t\t\t\tCurrent\n\t\t\t\t</a>\n\t\t\t\t\t\t\t</li>\n\t\t\t\t\t\t\t\t<li class=\"\">\n\t\t\t\t<a href=\"https://firstmonday.org/ojs/index.php/fm/issue/archive\">\n\t\t\t\t\tArchives\n\t\t\t\t</a>\n\t\t\t\t\t\t\t</li>\n\t\t\t\t\t\t\t\t<li class=\"\">\n\t\t\t\t<a href=\"https://firstmonday.org/ojs/index.php/fm/announcement\">\n\t\t\t\t\tAnnouncements\n\t\t\t\t</a>\n\t\t\t\t\t\t\t</li>\n\t\t\t\t\t\t\t\t<li class=\"\">\n\t\t\t\t<a href=\"https://firstmonday.org/ojs/index.php/fm/about/submissions\">\n\t\t\t\t\tSubmissions\n\t\t\t\t</a>\n\t\t\t\t\t\t\t</li>\n\t\t\t</ul>\n\n\t\t\t\t\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<div class=\"pkp_navigation_search_wrapper\">\n\t\t\t\t\t\t\t\t\t<a href=\"https://firstmonday.org/ojs/index.php/fm/search\" class=\"pkp_search pkp_search_desktop\">\n\t\t\t\t\t\t\t\t\t\t<span class=\"fa fa-search\" aria-hidden=\"true\"></span>\n\t\t\t\t\t\t\t\t\t\tSearch\n\t\t\t\t\t\t\t\t\t</a>\n\t\t\t\t\t\t\t\t</div>\n\t\t\t\t\t\t\t\t\t\t\t\t\t</div>\n\t\t\t\t\t</div>\n\t\t\t\t\t<div class=\"pkp_navigation_user_wrapper\" id=\"navigationUserWrapper\">\n\t\t\t\t\t\t\t<ul id=\"navigationUser\" class=\"pkp_navigation_user pkp_nav_list\">\n\t\t\t\t\t\t\t\t<li class=\"profile\">\n\t\t\t\t<a href=\"https://firstmonday.org/ojs/index.php/fm/user/register\">\n\t\t\t\t\tRegister\n\t\t\t\t</a>\n\t\t\t\t\t\t\t</li>\n\t\t\t\t\t\t\t\t<li class=\"profile\">\n\t\t\t\t<a href=\"https://firstmonday.org/ojs/index.php/fm/login\">\n\t\t\t\t\tLogin\n\t\t\t\t</a>\n\t\t\t\t\t\t\t</li>\n\t\t\t\t\t\t\t\t\t\t</ul>\n\n\t\t\t\t\t</div>\n\t\t\t\t</nav>\n\t\t\t</div><!-- .pkp_head_wrapper -->\n\t\t</header><!-- .pkp_structure_head -->\n\n\t\t\t\t\t\t<div class=\"pkp_structure_content has_sidebar\">\n\t\t\t<div class=\"pkp_structure_main\" role=\"main\">\n\t\t\t\t<a id=\"pkp_content_main\"></a>\n\n<div class=\"page page_article\">\n\t\t\t<nav class=\"cmp_breadcrumbs\" role=\"navigation\" aria-label=\"You are here:\">\n\t<ol>\n\t\t<li>\n\t\t\t<a href=\"https://firstmonday.org/ojs/index.php/fm/index\">\n\t\t\t\tHome\n\t\t\t</a>\n\t\t\t<span class=\"separator\">/</span>\n\t\t</li>\n\t\t<li>\n\t\t\t<a href=\"https://firstmonday.org/ojs/index.php/fm/issue/archive\">\n\t\t\t\tArchives\n\t\t\t</a>\n\t\t\t<span class=\"separator\">/</span>\n\t\t</li>\n\t\t\t\t\t<li>\n\t\t\t\t<a href=\"https://firstmonday.org/ojs/index.php/fm/issue/view/749\">\n\t\t\t\t\tVolume 29, Number 4 - 1 April 2024\n\t\t\t\t</a>\n\t\t\t\t<span class=\"separator\">/</span>\n\t\t\t</li>\n\t\t\t\t<li class=\"current\" aria-current=\"page\">\n\t\t\t<span aria-current=\"page\">\n\t\t\t\t\t\t\t\t\tArticles\n\t\t\t\t\t\t\t</span>\n\t\t</li>\n\t</ol>\n</nav>\n\t\n\t\t  \t <article class=\"obj_article_details\">\n\n\t\t\n\t<h1 class=\"page_title\">\n\t\tThe TESCREAL bundle: Eugenics and the promise of utopia through artificial general intelligence\n\t</h1>\n\n\t\n\t<div class=\"row\">\n\t\t<div class=\"main_entry\">\n\n\t\t\t\t\t\t\t<section class=\"item authors\">\n\t\t\t\t\t<h2 class=\"pkp_screen_reader\">Authors</h2>\n\t\t\t\t\t<ul class=\"authors\">\n\t\t\t\t\t\t\t\t\t\t\t<li>\n\t\t\t\t\t\t\t<span class=\"name\">\n\t\t\t\t\t\t\t\tTimnit Gebru\n\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</li>\n\t\t\t\t\t\t\t\t\t\t\t<li>\n\t\t\t\t\t\t\t<span class=\"name\">\n\t\t\t\t\t\t\t\tÉmile P. Torres\n\t\t\t\t\t\t\t</span>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</li>\n\t\t\t\t\t\t\t\t\t\t</ul>\n\t\t\t\t</section>\n\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<section class=\"item doi\">\n\t\t\t\t\t\t<h2 class=\"label\">\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tDOI:\n\t\t\t\t\t\t</h2>\n\t\t\t\t\t\t<span class=\"value\">\n\t\t\t\t\t\t\t<a href=\"https://doi.org/10.5210/fm.v29i4.13636\">\n\t\t\t\t\t\t\t\thttps://doi.org/10.5210/fm.v29i4.13636\n\t\t\t\t\t\t\t</a>\n\t\t\t\t\t\t</span>\n\t\t\t\t\t</section>\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t<section class=\"item abstract\">\n\t\t\t\t\t<h2 class=\"label\">Abstract</h2>\n\t\t\t\t\t<p>The stated goal of many organizations in the field of artificial intelligence (AI) is to develop artificial general intelligence (AGI), an imagined system with more intelligence than anything we have ever seen. Without seriously questioning whether such a system can and should be built, researchers are working to create “safe AGI” that is “beneficial for all of humanity.” We argue that, unlike systems with specific applications which can be evaluated following standard engineering principles, undefined systems like “AGI” cannot be appropriately tested for safety. Why, then, is building AGI often framed as an unquestioned goal in the field of AI? In this paper, we argue that the normative framework that motivates much of this goal is rooted in the Anglo-American eugenics tradition of the twentieth century. As a result, many of the very same discriminatory attitudes that animated eugenicists in the past (<em>e.g.</em>, racism, xenophobia, classism, ableism, and sexism) remain widespread within the movement to build AGI, resulting in systems that harm marginalized groups and centralize power, while using the language of “safety” and “benefiting humanity” to evade accountability. We conclude by urging researchers to work on defined tasks for which we can develop safety protocols, rather than attempting to build a presumably all-knowing system such as AGI.</p>\n\t\t\t\t</section>\n\t\t\t\n\t\t\t\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\n\t\t</div><!-- .main_entry -->\n\n\t\t<div class=\"entry_details\">\n\n\t\t\t\t\t\t\t\t\t\t<div class=\"item cover_image\">\n\t\t\t\t\t<div class=\"sub_item\">\n\t\t\t\t\t\t\t\t\t\t\t\t\t<a href=\"https://firstmonday.org/ojs/index.php/fm/issue/view/749\">\n\t\t\t\t\t\t\t\t<img src=\"https://firstmonday.org/ojs/public/journals/3/cover_issue_749_en_US.png\" alt=\"Power and Profit by Clarote &amp; AI4Media\">\n\t\t\t\t\t\t\t</a>\n\t\t\t\t\t\t\t\t\t\t\t</div>\n\t\t\t\t</div>\n\t\t\t\n\t\t\t\t\t\t\t\t\t\t<div class=\"item galleys\">\n\t\t\t\t\t<h2 class=\"pkp_screen_reader\">\n\t\t\t\t\t\tDownloads\n\t\t\t\t\t</h2>\n\t\t\t\t\t<ul class=\"value galleys_links\">\n\t\t\t\t\t\t\t\t\t\t\t\t\t<li>\n\t\t\t\t\t\t\t\t\n\t\n\t\t\t\t\t\t\t\n\n<a class=\"obj_galley_link file\" href=\"https://firstmonday.org/ojs/index.php/fm/article/view/13636/11599\">\n\n\t\t\n\tHTML\n\n\t</a>\n\t\t\t\t\t\t\t</li>\n\t\t\t\t\t\t\t\t\t\t\t\t\t<li>\n\t\t\t\t\t\t\t\t\n\t\n\t\t\t\t\t\t\t\n\n<a class=\"obj_galley_link pdf\" href=\"https://firstmonday.org/ojs/index.php/fm/article/view/13636/11606\">\n\n\t\t\n\tPDF\n\n\t</a>\n\t\t\t\t\t\t\t</li>\n\t\t\t\t\t\t\t\t\t\t\t</ul>\n\t\t\t\t</div>\n\t\t\t\t\t\t\n\t\t\t\t\t\t<div class=\"item published\">\n\t\t\t\t<section class=\"sub_item\">\n\t\t\t\t\t<h2 class=\"label\">\n\t\t\t\t\t\tPublished\n\t\t\t\t\t</h2>\n\t\t\t\t\t<div class=\"value\">\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<span>2024-04-14</span>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</div>\n\t\t\t\t</section>\n\t\t\t\t\t\t\t</div>\n\t\t\t\n\t\t\t\t\t\t\t\t\t\t<div class=\"item citation\">\n\t\t\t\t\t<section class=\"sub_item citation_display\">\n\t\t\t\t\t\t<h2 class=\"label\">\n\t\t\t\t\t\t\tHow to Cite\n\t\t\t\t\t\t</h2>\n\t\t\t\t\t\t<div class=\"value\">\n\t\t\t\t\t\t\t<div id=\"citationOutput\" role=\"region\" aria-live=\"polite\">\n\t\t\t\t\t\t\t\t<div class=\"csl-bib-body\">\n  <div class=\"csl-entry\">Gebru, T., &#38; Torres, Émile P. (2024). The TESCREAL bundle: Eugenics and the promise of utopia through artificial general intelligence. <i>First Monday</i>, <i>29</i>(4). https://doi.org/10.5210/fm.v29i4.13636</div>\n</div>\n\t\t\t\t\t\t\t</div>\n\t\t\t\t\t\t\t<div class=\"citation_formats\">\n\t\t\t\t\t\t\t\t<button class=\"cmp_button citation_formats_button\" aria-controls=\"cslCitationFormats\" aria-expanded=\"false\" data-csl-dropdown=\"true\">\n\t\t\t\t\t\t\t\t\tMore Citation Formats\n\t\t\t\t\t\t\t\t</button>\n\t\t\t\t\t\t\t\t<div id=\"cslCitationFormats\" class=\"citation_formats_list\" aria-hidden=\"true\">\n\t\t\t\t\t\t\t\t\t<ul class=\"citation_formats_styles\">\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<li>\n\t\t\t\t\t\t\t\t\t\t\t\t<a\n\t\t\t\t\t\t\t\t\t\t\t\t\taria-controls=\"citationOutput\"\n\t\t\t\t\t\t\t\t\t\t\t\t\thref=\"https://firstmonday.org/ojs/index.php/fm/citationstylelanguage/get/acm-sig-proceedings?submissionId=13636&amp;publicationId=17745\"\n\t\t\t\t\t\t\t\t\t\t\t\t\tdata-load-citation\n\t\t\t\t\t\t\t\t\t\t\t\t\tdata-json-href=\"https://firstmonday.org/ojs/index.php/fm/citationstylelanguage/get/acm-sig-proceedings?submissionId=13636&amp;publicationId=17745&amp;return=json\"\n\t\t\t\t\t\t\t\t\t\t\t\t>\n\t\t\t\t\t\t\t\t\t\t\t\t\tACM\n\t\t\t\t\t\t\t\t\t\t\t\t</a>\n\t\t\t\t\t\t\t\t\t\t\t</li>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<li>\n\t\t\t\t\t\t\t\t\t\t\t\t<a\n\t\t\t\t\t\t\t\t\t\t\t\t\taria-controls=\"citationOutput\"\n\t\t\t\t\t\t\t\t\t\t\t\t\thref=\"https://firstmonday.org/ojs/index.php/fm/citationstylelanguage/get/acs-nano?submissionId=13636&amp;publicationId=17745\"\n\t\t\t\t\t\t\t\t\t\t\t\t\tdata-load-citation\n\t\t\t\t\t\t\t\t\t\t\t\t\tdata-json-href=\"https://firstmonday.org/ojs/index.php/fm/citationstylelanguage/get/acs-nano?submissionId=13636&amp;publicationId=17745&amp;return=json\"\n\t\t\t\t\t\t\t\t\t\t\t\t>\n\t\t\t\t\t\t\t\t\t\t\t\t\tACS\n\t\t\t\t\t\t\t\t\t\t\t\t</a>\n\t\t\t\t\t\t\t\t\t\t\t</li>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<li>\n\t\t\t\t\t\t\t\t\t\t\t\t<a\n\t\t\t\t\t\t\t\t\t\t\t\t\taria-controls=\"citationOutput\"\n\t\t\t\t\t\t\t\t\t\t\t\t\thref=\"https://firstmonday.org/ojs/index.php/fm/citationstylelanguage/get/apa?submissionId=13636&amp;publicationId=17745\"\n\t\t\t\t\t\t\t\t\t\t\t\t\tdata-load-citation\n\t\t\t\t\t\t\t\t\t\t\t\t\tdata-json-href=\"https://firstmonday.org/ojs/index.php/fm/citationstylelanguage/get/apa?submissionId=13636&amp;publicationId=17745&amp;return=json\"\n\t\t\t\t\t\t\t\t\t\t\t\t>\n\t\t\t\t\t\t\t\t\t\t\t\t\tAPA\n\t\t\t\t\t\t\t\t\t\t\t\t</a>\n\t\t\t\t\t\t\t\t\t\t\t</li>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<li>\n\t\t\t\t\t\t\t\t\t\t\t\t<a\n\t\t\t\t\t\t\t\t\t\t\t\t\taria-controls=\"citationOutput\"\n\t\t\t\t\t\t\t\t\t\t\t\t\thref=\"https://firstmonday.org/ojs/index.php/fm/citationstylelanguage/get/associacao-brasileira-de-normas-tecnicas?submissionId=13636&amp;publicationId=17745\"\n\t\t\t\t\t\t\t\t\t\t\t\t\tdata-load-citation\n\t\t\t\t\t\t\t\t\t\t\t\t\tdata-json-href=\"https://firstmonday.org/ojs/index.php/fm/citationstylelanguage/get/associacao-brasileira-de-normas-tecnicas?submissionId=13636&amp;publicationId=17745&amp;return=json\"\n\t\t\t\t\t\t\t\t\t\t\t\t>\n\t\t\t\t\t\t\t\t\t\t\t\t\tABNT\n\t\t\t\t\t\t\t\t\t\t\t\t</a>\n\t\t\t\t\t\t\t\t\t\t\t</li>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<li>\n\t\t\t\t\t\t\t\t\t\t\t\t<a\n\t\t\t\t\t\t\t\t\t\t\t\t\taria-controls=\"citationOutput\"\n\t\t\t\t\t\t\t\t\t\t\t\t\thref=\"https://firstmonday.org/ojs/index.php/fm/citationstylelanguage/get/chicago-author-date?submissionId=13636&amp;publicationId=17745\"\n\t\t\t\t\t\t\t\t\t\t\t\t\tdata-load-citation\n\t\t\t\t\t\t\t\t\t\t\t\t\tdata-json-href=\"https://firstmonday.org/ojs/index.php/fm/citationstylelanguage/get/chicago-author-date?submissionId=13636&amp;publicationId=17745&amp;return=json\"\n\t\t\t\t\t\t\t\t\t\t\t\t>\n\t\t\t\t\t\t\t\t\t\t\t\t\tChicago\n\t\t\t\t\t\t\t\t\t\t\t\t</a>\n\t\t\t\t\t\t\t\t\t\t\t</li>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<li>\n\t\t\t\t\t\t\t\t\t\t\t\t<a\n\t\t\t\t\t\t\t\t\t\t\t\t\taria-controls=\"citationOutput\"\n\t\t\t\t\t\t\t\t\t\t\t\t\thref=\"https://firstmonday.org/ojs/index.php/fm/citationstylelanguage/get/harvard-cite-them-right?submissionId=13636&amp;publicationId=17745\"\n\t\t\t\t\t\t\t\t\t\t\t\t\tdata-load-citation\n\t\t\t\t\t\t\t\t\t\t\t\t\tdata-json-href=\"https://firstmonday.org/ojs/index.php/fm/citationstylelanguage/get/harvard-cite-them-right?submissionId=13636&amp;publicationId=17745&amp;return=json\"\n\t\t\t\t\t\t\t\t\t\t\t\t>\n\t\t\t\t\t\t\t\t\t\t\t\t\tHarvard\n\t\t\t\t\t\t\t\t\t\t\t\t</a>\n\t\t\t\t\t\t\t\t\t\t\t</li>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<li>\n\t\t\t\t\t\t\t\t\t\t\t\t<a\n\t\t\t\t\t\t\t\t\t\t\t\t\taria-controls=\"citationOutput\"\n\t\t\t\t\t\t\t\t\t\t\t\t\thref=\"https://firstmonday.org/ojs/index.php/fm/citationstylelanguage/get/ieee?submissionId=13636&amp;publicationId=17745\"\n\t\t\t\t\t\t\t\t\t\t\t\t\tdata-load-citation\n\t\t\t\t\t\t\t\t\t\t\t\t\tdata-json-href=\"https://firstmonday.org/ojs/index.php/fm/citationstylelanguage/get/ieee?submissionId=13636&amp;publicationId=17745&amp;return=json\"\n\t\t\t\t\t\t\t\t\t\t\t\t>\n\t\t\t\t\t\t\t\t\t\t\t\t\tIEEE\n\t\t\t\t\t\t\t\t\t\t\t\t</a>\n\t\t\t\t\t\t\t\t\t\t\t</li>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<li>\n\t\t\t\t\t\t\t\t\t\t\t\t<a\n\t\t\t\t\t\t\t\t\t\t\t\t\taria-controls=\"citationOutput\"\n\t\t\t\t\t\t\t\t\t\t\t\t\thref=\"https://firstmonday.org/ojs/index.php/fm/citationstylelanguage/get/modern-language-association?submissionId=13636&amp;publicationId=17745\"\n\t\t\t\t\t\t\t\t\t\t\t\t\tdata-load-citation\n\t\t\t\t\t\t\t\t\t\t\t\t\tdata-json-href=\"https://firstmonday.org/ojs/index.php/fm/citationstylelanguage/get/modern-language-association?submissionId=13636&amp;publicationId=17745&amp;return=json\"\n\t\t\t\t\t\t\t\t\t\t\t\t>\n\t\t\t\t\t\t\t\t\t\t\t\t\tMLA\n\t\t\t\t\t\t\t\t\t\t\t\t</a>\n\t\t\t\t\t\t\t\t\t\t\t</li>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<li>\n\t\t\t\t\t\t\t\t\t\t\t\t<a\n\t\t\t\t\t\t\t\t\t\t\t\t\taria-controls=\"citationOutput\"\n\t\t\t\t\t\t\t\t\t\t\t\t\thref=\"https://firstmonday.org/ojs/index.php/fm/citationstylelanguage/get/turabian-fullnote-bibliography?submissionId=13636&amp;publicationId=17745\"\n\t\t\t\t\t\t\t\t\t\t\t\t\tdata-load-citation\n\t\t\t\t\t\t\t\t\t\t\t\t\tdata-json-href=\"https://firstmonday.org/ojs/index.php/fm/citationstylelanguage/get/turabian-fullnote-bibliography?submissionId=13636&amp;publicationId=17745&amp;return=json\"\n\t\t\t\t\t\t\t\t\t\t\t\t>\n\t\t\t\t\t\t\t\t\t\t\t\t\tTurabian\n\t\t\t\t\t\t\t\t\t\t\t\t</a>\n\t\t\t\t\t\t\t\t\t\t\t</li>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<li>\n\t\t\t\t\t\t\t\t\t\t\t\t<a\n\t\t\t\t\t\t\t\t\t\t\t\t\taria-controls=\"citationOutput\"\n\t\t\t\t\t\t\t\t\t\t\t\t\thref=\"https://firstmonday.org/ojs/index.php/fm/citationstylelanguage/get/vancouver?submissionId=13636&amp;publicationId=17745\"\n\t\t\t\t\t\t\t\t\t\t\t\t\tdata-load-citation\n\t\t\t\t\t\t\t\t\t\t\t\t\tdata-json-href=\"https://firstmonday.org/ojs/index.php/fm/citationstylelanguage/get/vancouver?submissionId=13636&amp;publicationId=17745&amp;return=json\"\n\t\t\t\t\t\t\t\t\t\t\t\t>\n\t\t\t\t\t\t\t\t\t\t\t\t\tVancouver\n\t\t\t\t\t\t\t\t\t\t\t\t</a>\n\t\t\t\t\t\t\t\t\t\t\t</li>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</ul>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<div class=\"label\">\n\t\t\t\t\t\t\t\t\t\t\tDownload Citation\n\t\t\t\t\t\t\t\t\t\t</div>\n\t\t\t\t\t\t\t\t\t\t<ul class=\"citation_formats_styles\">\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<li>\n\t\t\t\t\t\t\t\t\t\t\t\t\t<a href=\"https://firstmonday.org/ojs/index.php/fm/citationstylelanguage/download/ris?submissionId=13636&amp;publicationId=17745\">\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t<span class=\"fa fa-download\"></span>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tEndnote/Zotero/Mendeley (RIS)\n\t\t\t\t\t\t\t\t\t\t\t\t\t</a>\n\t\t\t\t\t\t\t\t\t\t\t\t</li>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<li>\n\t\t\t\t\t\t\t\t\t\t\t\t\t<a href=\"https://firstmonday.org/ojs/index.php/fm/citationstylelanguage/download/bibtex?submissionId=13636&amp;publicationId=17745\">\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t<span class=\"fa fa-download\"></span>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tBibTeX\n\t\t\t\t\t\t\t\t\t\t\t\t\t</a>\n\t\t\t\t\t\t\t\t\t\t\t\t</li>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</ul>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t</div>\n\t\t\t\t\t\t\t</div>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t</section>\n\t\t\t\t</div>\n\t\t\t\n\t\t\t\t\t\t\t\t\t\t<div class=\"item issue\">\n\n\t\t\t\t\t\t\t\t\t\t\t<section class=\"sub_item\">\n\t\t\t\t\t\t\t<h2 class=\"label\">\n\t\t\t\t\t\t\t\tIssue\n\t\t\t\t\t\t\t</h2>\n\t\t\t\t\t\t\t<div class=\"value\">\n\t\t\t\t\t\t\t\t<a class=\"title\" href=\"https://firstmonday.org/ojs/index.php/fm/issue/view/749\">\n\t\t\t\t\t\t\t\t\tVolume 29, Number 4 - 1 April 2024\n\t\t\t\t\t\t\t\t</a>\n\t\t\t\t\t\t\t</div>\n\t\t\t\t\t\t</section>\n\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t<section class=\"sub_item\">\n\t\t\t\t\t\t\t<h2 class=\"label\">\n\t\t\t\t\t\t\t\tSection\n\t\t\t\t\t\t\t</h2>\n\t\t\t\t\t\t\t<div class=\"value\">\n\t\t\t\t\t\t\t\tArticles\n\t\t\t\t\t\t\t</div>\n\t\t\t\t\t\t</section>\n\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t</div>\n\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t<div class=\"item copyright\">\n\t\t\t\t\t<h2 class=\"label\">\n\t\t\t\t\t\tLicense\n\t\t\t\t\t</h2>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<p>Copyright (c) 2024 First Monday</p>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t<a rel=\"license\" href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/\"><img alt=\"Creative Commons License\" src=\"//i.creativecommons.org/l/by-nc-sa/4.0/88x31.png\" /></a><p>This work is licensed under a <a rel=\"license\" href=\"https://creativecommons.org/licenses/by-nc-sa/4.0/\">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.</p>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<p>Authors retain copyright to their work published in <em>First Monday</em>. Please see the footer of each article for details.</p>\n\t\t\t\t</div>\n\t\t\t\n\t\t\t\n\n\t\t</div><!-- .entry_details -->\n\t</div><!-- .row -->\n\n</article>\n\n\t\n\n</div><!-- .page -->\n\n\t</div><!-- pkp_structure_main -->\n\n\t\t\t\t\t\t\t\t\t<div class=\"pkp_structure_sidebar left\" role=\"complementary\" aria-label=\"Sidebar\">\n\t\t\t\t<div class=\"pkp_block block_developed_by\">\n\t<h2 class=\"pkp_screen_reader\">\n\t\tDeveloped By\n\t</h2>\n\n\t<div class=\"content\">\n\t\t<a href=\"http://pkp.sfu.ca/ojs/\">\n\t\t\tOpen Journal Systems\n\t\t</a>\n\t</div>\n</div>\n\n\t\t\t</div><!-- pkp_sidebar.left -->\n\t\t\t</div><!-- pkp_structure_content -->\n\n<div class=\"pkp_structure_footer_wrapper\" role=\"contentinfo\">\n\t<a id=\"pkp_content_footer\"></a>\n\n\t<div class=\"pkp_structure_footer\">\n\n\t\t\t\t\t<div class=\"pkp_footer_content\">\n\t\t\t\t<p>A Great Cities Initiative of the University of Illinois at Chicago <a href=\"http://library.uic.edu/\">University Library</a>.</p>\n<p>© <em>First Monday</em>, 1995-2024. ISSN 1396-0466.</p>\n\t\t\t</div>\n\t\t\n\t\t<div class=\"pkp_brand_footer\" role=\"complementary\">\n\t\t\t<a href=\"https://firstmonday.org/ojs/index.php/fm/about/aboutThisPublishingSystem\">\n\t\t\t\t<img alt=\"More information about the publishing system, Platform and Workflow by OJS/PKP.\" src=\"https://firstmonday.org/ojs/templates/images/ojs_brand.png\">\n\t\t\t</a>\n\t\t</div>\n\t</div>\n</div><!-- pkp_structure_footer_wrapper -->\n\n</div><!-- pkp_structure_page -->\n\n<script src=\"https://firstmonday.org/ojs/lib/pkp/lib/vendor/components/jquery/jquery.min.js?v=3.3.0.13\" type=\"text/javascript\"></script><script src=\"https://firstmonday.org/ojs/lib/pkp/lib/vendor/components/jqueryui/jquery-ui.min.js?v=3.3.0.13\" type=\"text/javascript\"></script><script src=\"https://firstmonday.org/ojs/plugins/themes/default/js/lib/popper/popper.js?v=3.3.0.13\" type=\"text/javascript\"></script><script src=\"https://firstmonday.org/ojs/plugins/themes/default/js/lib/bootstrap/util.js?v=3.3.0.13\" type=\"text/javascript\"></script><script src=\"https://firstmonday.org/ojs/plugins/themes/default/js/lib/bootstrap/dropdown.js?v=3.3.0.13\" type=\"text/javascript\"></script><script src=\"https://firstmonday.org/ojs/plugins/themes/default/js/main.js?v=3.3.0.13\" type=\"text/javascript\"></script><script src=\"https://firstmonday.org/ojs/plugins/generic/citationStyleLanguage/js/articleCitation.js?v=3.3.0.13\" type=\"text/javascript\"></script><script type=\"text/javascript\">\n(function (w, d, s, l, i) { w[l] = w[l] || []; var f = d.getElementsByTagName(s)[0],\nj = d.createElement(s), dl = l != 'dataLayer' ? '&l=' + l : ''; j.async = true; \nj.src = 'https://www.googletagmanager.com/gtag/js?id=' + i + dl; f.parentNode.insertBefore(j, f); \nfunction gtag(){dataLayer.push(arguments)}; gtag('js', new Date()); gtag('config', i); })\n(window, document, 'script', 'dataLayer', 'G-YKHCLJFMMR');\n</script>\n\n\n</body>\n</html>\n","oembed":false,"readabilityObject":{"title":"The TESCREAL bundle: Eugenics and the promise of utopia through artificial general intelligence","content":"<div id=\"readability-page-1\" class=\"page\"><div class=\"page\">\n\t\t\t\n\t\n\t\t  \t <article>\n\n\t\t\n\t\n\n\t\n\t<div>\n\t\t<div>\n\n\t\t\t\t\t\t\t<section>\n\t\t\t\t\t<h2>Authors</h2>\n\t\t\t\t\t\n\t\t\t\t</section>\n\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t<section>\n\t\t\t\t\t\t<h2>\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tDOI:\n\t\t\t\t\t\t</h2>\n\t\t\t\t\t\t<span>\n\t\t\t\t\t\t\t<a href=\"https://doi.org/10.5210/fm.v29i4.13636\">\n\t\t\t\t\t\t\t\thttps://doi.org/10.5210/fm.v29i4.13636\n\t\t\t\t\t\t\t</a>\n\t\t\t\t\t\t</span>\n\t\t\t\t\t</section>\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t<section>\n\t\t\t\t\t<h2>Abstract</h2>\n\t\t\t\t\t<p>The stated goal of many organizations in the field of artificial intelligence (AI) is to develop artificial general intelligence (AGI), an imagined system with more intelligence than anything we have ever seen. Without seriously questioning whether such a system can and should be built, researchers are working to create “safe AGI” that is “beneficial for all of humanity.” We argue that, unlike systems with specific applications which can be evaluated following standard engineering principles, undefined systems like “AGI” cannot be appropriately tested for safety. Why, then, is building AGI often framed as an unquestioned goal in the field of AI? In this paper, we argue that the normative framework that motivates much of this goal is rooted in the Anglo-American eugenics tradition of the twentieth century. As a result, many of the very same discriminatory attitudes that animated eugenicists in the past (<em>e.g.</em>, racism, xenophobia, classism, ableism, and sexism) remain widespread within the movement to build AGI, resulting in systems that harm marginalized groups and centralize power, while using the language of “safety” and “benefiting humanity” to evade accountability. We conclude by urging researchers to work on defined tasks for which we can develop safety protocols, rather than attempting to build a presumably all-knowing system such as AGI.</p>\n\t\t\t\t</section>\n\t\t\t\n\t\t\t\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\n\t\t</div><!-- .main_entry -->\n\n\t\t<div>\n\n\t\t\t\t\t\t\t\t\t\t<div>\n\t\t\t\t\t<p><a href=\"https://firstmonday.org/ojs/index.php/fm/issue/view/749\">\n\t\t\t\t\t\t\t\t<img src=\"https://firstmonday.org/ojs/public/journals/3/cover_issue_749_en_US.png\" alt=\"Power and Profit by Clarote &amp; AI4Media\">\n\t\t\t\t\t\t\t</a>\n\t\t\t\t\t\t\t\t\t\t\t</p>\n\t\t\t\t</div>\n\t\t\t\n\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\n\t\t\t\t\t\t\n\t\t\t\n\t\t\t\t\t\t\t\t\t\t<section>\n\t\t\t\t\t\t<h2>\n\t\t\t\t\t\t\tHow to Cite\n\t\t\t\t\t\t</h2>\n\t\t\t\t\t\t<div id=\"citationOutput\" role=\"region\" aria-live=\"polite\">\n  <p>Gebru, T., &amp; Torres, Émile P. (2024). The TESCREAL bundle: Eugenics and the promise of utopia through artificial general intelligence. <i>First Monday</i>, <i>29</i>(4). https://doi.org/10.5210/fm.v29i4.13636</p>\n</div>\n\t\t\t\t\t</section>\n\t\t\t\n\t\t\t\t\t\t\t\t\t\t\n\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\n\t\t\t\n\t\t\t\n\n\t\t</div><!-- .entry_details -->\n\t</div><!-- .row -->\n\n</article>\n\n\t\n\n</div></div>","textContent":"\n\t\t\t\n\t\n\t\t  \t \n\n\t\t\n\t\n\n\t\n\t\n\t\t\n\n\t\t\t\t\t\t\t\n\t\t\t\t\tAuthors\n\t\t\t\t\t\n\t\t\t\t\n\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tDOI:\n\t\t\t\t\t\t\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\thttps://doi.org/10.5210/fm.v29i4.13636\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\tAbstract\n\t\t\t\t\tThe stated goal of many organizations in the field of artificial intelligence (AI) is to develop artificial general intelligence (AGI), an imagined system with more intelligence than anything we have ever seen. Without seriously questioning whether such a system can and should be built, researchers are working to create “safe AGI” that is “beneficial for all of humanity.” We argue that, unlike systems with specific applications which can be evaluated following standard engineering principles, undefined systems like “AGI” cannot be appropriately tested for safety. Why, then, is building AGI often framed as an unquestioned goal in the field of AI? In this paper, we argue that the normative framework that motivates much of this goal is rooted in the Anglo-American eugenics tradition of the twentieth century. As a result, many of the very same discriminatory attitudes that animated eugenicists in the past (e.g., racism, xenophobia, classism, ableism, and sexism) remain widespread within the movement to build AGI, resulting in systems that harm marginalized groups and centralize power, while using the language of “safety” and “benefiting humanity” to evade accountability. We conclude by urging researchers to work on defined tasks for which we can develop safety protocols, rather than attempting to build a presumably all-knowing system such as AGI.\n\t\t\t\t\n\t\t\t\n\t\t\t\n\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\n\t\t\n\n\t\t\n\n\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\n\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\n\t\t\t\n\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\n\t\t\t\t\t\t\n\t\t\t\n\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\n\t\t\t\t\t\t\tHow to Cite\n\t\t\t\t\t\t\n\t\t\t\t\t\t\n  Gebru, T., & Torres, Émile P. (2024). The TESCREAL bundle: Eugenics and the promise of utopia through artificial general intelligence. First Monday, 29(4). https://doi.org/10.5210/fm.v29i4.13636\n\n\t\t\t\t\t\n\t\t\t\n\t\t\t\t\t\t\t\t\t\t\n\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\n\t\t\t\n\t\t\t\n\n\t\t\n\t\n\n\n\n\t\n\n","length":2081,"excerpt":"The stated goal of many organizations in the field of artificial intelligence (AI) is to develop artificial general intelligence (AGI), an imagined system with more intelligence than anything we have ever seen. Without seriously questioning whether such a system can and should be built, researchers are working to create “safe AGI” that is “beneficial for all of humanity.” We argue that, unlike systems with specific applications which can be evaluated following standard engineering principles, undefined systems like “AGI” cannot be appropriately tested for safety. Why, then, is building AGI often framed as an unquestioned goal in the field of AI? In this paper, we argue that the normative framework that motivates much of this goal is rooted in the Anglo-American eugenics tradition of the twentieth century. As a result, many of the very same discriminatory attitudes that animated eugenicists in the past (e.g., racism, xenophobia, classism, ableism, and sexism) remain widespread within the movement to build AGI, resulting in systems that harm marginalized groups and centralize power, while using the language of “safety” and “benefiting humanity” to evade accountability. We conclude by urging researchers to work on defined tasks for which we can develop safety protocols, rather than attempting to build a presumably all-knowing system such as AGI.","byline":"Timnit Gebru\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t\tÉmile P. Torres","dir":"ltr","siteName":null,"lang":"en-US"},"finalizedMeta":{"title":"\n\t\tThe TESCREAL bundle: Eugenics and the promise of utopia through artificial general intelligence\n\t\t\t\t\t\t\t| First Monday\n\t\t\t","description":"The stated goal of many organizations in the field of artificial intelligence (AI) is to develop artificial general intelligence (AGI), an imagined system with more intelligence than anything we have ever seen. Without seriously questioning whether such a system can and should be built, researchers are working to create “safe AGI” that is “beneficial for all of humanity.” We argue that, unlike systems with specific applications which can be evaluated following standard engineering principles, undefined systems like “AGI” cannot be appropriately tested for safety. Why, then, is building AGI often framed as an unquestioned goal in the field of AI? In this paper, we argue that the normative framework that motivates much of this goal is rooted in the Anglo-American eugenics tradition of the twentieth century. As a result, many of the very same discriminatory attitudes that animated eugenicists in the past (e.g., racism, xenophobia, classism, ableism, and sexism) remain widespread within the movement to build AGI, resulting in systems that harm marginalized groups and centralize power, while using the language of “safety” and “benefiting humanity” to evade accountability. We conclude by urging researchers to work on defined tasks for which we can develop safety protocols, rather than attempting to build a presumably all-knowing system such as AGI.","author":false,"creator":"","publisher":false,"date":"2024-07-10T15:45:19.992Z","topics":[]},"jsonLd":{"@type":false,"headline":false,"description":false,"image":[],"mainEntityOfPage":{"@type":false,"@id":false},"datePublished":false,"dateModified":false,"isAccessibleForFree":false,"isPartOf":{"@type":[],"name":false,"productID":false},"discussionUrl":false,"license":false,"author":{"@type":false,"name":false,"description":false,"sameAs":false,"image":{"@type":false,"url":false},"givenName":false,"familyName":false,"alternateName":false,"publishingPrinciples":false},"publisher":{"@type":false,"name":false,"description":false,"sameAs":false,"logo":{"@type":false,"url":false},"publishingPrinciples":false},"editor":{"@type":false,"name":false,"description":false,"sameAs":false,"image":{"@type":false,"url":false},"givenName":false,"familyName":false,"alternateName":false,"publishingPrinciples":false}},"twitterObj":false,"status":200,"metadata":{"author":false,"title":"\n\t\tThe TESCREAL bundle: Eugenics and the promise of utopia through artificial general intelligence\n\t\t\t\t\t\t\t| First Monday\n\t\t\t","description":false,"canonical":"https://firstmonday.org/ojs/index.php/fm/article/view/13636","keywords":[],"image":"https://firstmonday.org/ojs/public/journals/3/pageHeaderLogoImage_en_US.gif","firstParagraph":"The stated goal of many organizations in the field of artificial intelligence (AI) is to develop artificial general intelligence (AGI), an imagined system with more intelligence than anything we have ever seen. Without seriously questioning whether such a system can and should be built, researchers are working to create “safe AGI” that is “beneficial for all of humanity.” We argue that, unlike systems with specific applications which can be evaluated following standard engineering principles, undefined systems like “AGI” cannot be appropriately tested for safety. Why, then, is building AGI often framed as an unquestioned goal in the field of AI? In this paper, we argue that the normative framework that motivates much of this goal is rooted in the Anglo-American eugenics tradition of the twentieth century. As a result, many of the very same discriminatory attitudes that animated eugenicists in the past (e.g., racism, xenophobia, classism, ableism, and sexism) remain widespread within the movement to build AGI, resulting in systems that harm marginalized groups and centralize power, while using the language of “safety” and “benefiting humanity” to evade accountability. We conclude by urging researchers to work on defined tasks for which we can develop safety protocols, rather than attempting to build a presumably all-knowing system such as AGI."},"dublinCore":{"Coverage":"","Creator.PersonalName":["Timnit Gebru","Émile P. Torres"],"Date.created":"2024-04-14","Date.dateSubmitted":"2024-03-30","Date.issued":"2024-04-14","Date.modified":"2024-04-23","Description":"The stated goal of many organizations in the field of artificial intelligence (AI) is to develop artificial general intelligence (AGI), an imagined system with more intelligence than anything we have ever seen. Without seriously questioning whether such a system can and should be built, researchers are working to create “safe AGI” that is “beneficial for all of humanity.” We argue that, unlike systems with specific applications which can be evaluated following standard engineering principles, undefined systems like “AGI” cannot be appropriately tested for safety. Why, then, is building AGI often framed as an unquestioned goal in the field of AI? In this paper, we argue that the normative framework that motivates much of this goal is rooted in the Anglo-American eugenics tradition of the twentieth century. As a result, many of the very same discriminatory attitudes that animated eugenicists in the past (e.g., racism, xenophobia, classism, ableism, and sexism) remain widespread within the movement to build AGI, resulting in systems that harm marginalized groups and centralize power, while using the language of “safety” and “benefiting humanity” to evade accountability. We conclude by urging researchers to work on defined tasks for which we can develop safety protocols, rather than attempting to build a presumably all-knowing system such as AGI.","Format":["text/html","application/pdf"],"Identifier":"13636","Identifier.DOI":"10.5210/fm.v29i4.13636","Identifier.URI":"https://firstmonday.org/ojs/index.php/fm/article/view/13636","Language":"en","Rights":["Copyright (c) 2024 First Monday","http://creativecommons.org/licenses/by-nc-sa/4.0/"],"Source":"First Monday","Source.ISSN":"1396-0466","Source.URI":"https://firstmonday.org/ojs/index.php/fm","Title":"The TESCREAL bundle: Eugenics and the promise of utopia through artificial general intelligence","Type":["Text.Serial.Journal",""],"Type.articleType":"Articles"},"opengraph":{"title":false,"description":false,"url":false,"site_name":false,"locale":false,"type":false,"typeObject":{"published_time":false,"modified_time":false,"author":false,"publisher":false,"section":false,"tag":[]},"image":false},"twitter":{"site":false,"description":false,"card":false,"creator":false,"title":false,"image":false},"archivedData":{"link":"https://web.archive.org/web/20240602052154/https://firstmonday.org/ojs/index.php/fm/article/view/13636","wayback":"https://web.archive.org/web/20240602052154/https://firstmonday.org/ojs/index.php/fm/article/view/13636"}}}