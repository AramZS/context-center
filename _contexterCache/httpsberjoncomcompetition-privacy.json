{"initialLink":"https://berjon.com/competition-privacy/","sanitizedLink":"https://berjon.com/competition-privacy/","finalLink":"https://berjon.com/competition-privacy/","htmlEmbed":"<script>window.contexterSetup=window.contexterSetup||function(){window.contexterSetupComplete=!0;class ContexterLink extends HTMLAnchorElement{constructor(){super()}connectedCallback(){this.setAttribute(\"target\",\"_blank\")}}customElements.define(\"contexter-link\",ContexterLink,{extends:\"a\"}),customElements.define(\"contexter-inner\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__inner\"}}),customElements.define(\"contexter-thumbnail\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__thumbnail\"}}),customElements.define(\"contexter-byline\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__byline\"}}),customElements.define(\"contexter-keywordset\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__keywordset\"}}),customElements.define(\"contexter-linkset\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__linkset\"}}),customElements.define(\"contexter-meta\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__meta\"}}),customElements.define(\"contexter-summary\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"p-summary entry-summary\"}}),customElements.define(\"contexter-box-head\",class extends HTMLElement{constructor(){super()}connectedCallback(){this.className=\"contexter-box__head\"}}),customElements.define(\"contexter-box-inner\",class extends HTMLElement{constructor(){super()}connectedCallback(){}});class ContexterBox extends HTMLElement{constructor(){super(),this.first=!0,this.shadow=this.attachShadow({mode:\"open\"})}connectedCallback(){if(this.first){this.first=!1;var style=document.createElement(\"style\"),lightDomStyle=(style.innerHTML=`:host {--background: #f5f6f7;--border: darkblue;--blue: #0000ee;--font-color: black;--inner-border: black;font-family: Franklin,Arial,Helvetica,sans-serif;font-size: 14px;background: var(--background);width: 600px;color: var(--font-color);min-height: 90px;display: block;padding: 8px;border: 1px solid var(--border);cursor: pointer;box-sizing: border-box;margin: 6px;contain: content;margin: 6px auto;}// can only select top-level nodes with slotted::slotted(*) {max-width: 100%;display:block;}::slotted([slot=thumbnail]) {max-width: 100%;display:block;}::slotted([slot=header]) {width: 100%;font-size: 1.25rem;font-weight: bold;display:block;margin-bottom: 6px;}::slotted([slot=author]) {max-width: 50%;font-size: 12px;display:inline-block;float: left;}::slotted([slot=time]) {max-width: 50%;font-size: 12px;display:inline-block;float: right;}::slotted([slot=summary]) {width: 100%;margin-top: 6px;padding: 10px 2px;border-top: 1px solid var(--inner-border);font-size: 15px;display:inline-block;margin-bottom: 6px;}contexter-meta {height: auto;margin-bottom: 4px;width: 100%;display: grid;position: relative;min-height: 16px;grid-template-columns: repeat(2, 1fr);}::slotted([slot=keywords]) {width: 80%;padding: 2px 4px;border-top: 1px solid var(--inner-border);font-size: 11px;display: block;float: right;font-style: italic;text-align: right;grid-column: 2/2;grid-row: 1;align-self: end;justify-self: end;}::slotted([slot=keywords]):empty {border-top: 0px solid var(--inner-border);}::slotted([slot=archive-link]) {font-size: 1em;display: inline;}::slotted([slot=archive-link])::after {content: \"|\";display: inline;color: var(--font-color);text-decoration: none;margin: 0 .5em;}::slotted([slot=read-link]) {font-size: 1em;display: inline;}contexter-linkset {width: 80%;padding: 2px 4px;font-size: 13px;float: left;font-weight: bold;grid-row: 1;grid-column: 1/2;align-self: end;justify-self: start;}/* Extra small devices (phones, 600px and down) */@media only screen and (max-width: 600px) {:host {width: 310px;}}/* Small devices (portrait tablets and large phones, 600px and up) */@media only screen and (min-width: 600px) {...}/* Medium devices (landscape tablets, 768px and up) */@media only screen and (min-width: 768px) {...}/* Large devices (laptops/desktops, 992px and up) */@media only screen and (min-width: 992px) {...}/* Extra large devices (large laptops and desktops, 1200px and up) */@media only screen and (min-width: 1200px) {...}@media (prefers-color-scheme: dark){:host {--background: #354150;--border: #1f2b37;--blue: #55b0ff;--font-color: #ffffff;--inner-border: #787a7c;background: var(--background);border: 1px solid var(--border)}}`,document.createElement(\"style\"));lightDomStyle.innerHTML=`contexter-box {contain: content;}contexter-box .read-link {font-weight: bold;}contexter-box a {color: #0000ee;}contexter-box img {width: 100%;border: 0;padding: 0;margin: 0;}/* Extra small devices (phones, 600px and down) */@media only screen and (max-width: 600px) {...}/* Small devices (portrait tablets and large phones, 600px and up) */@media only screen and (min-width: 600px) {...}/* Medium devices (landscape tablets, 768px and up) */@media only screen and (min-width: 768px) {...}/* Large devices (laptops/desktops, 992px and up) */@media only screen and (min-width: 992px) {...}/* Extra large devices (large laptops and desktops, 1200px and up) */@media only screen and (min-width: 1200px) {...}@media (prefers-color-scheme: dark){contexter-box a {color: #55b0ff;}}`,this.appendChild(lightDomStyle),this.shadow.appendChild(style);const innerContainer=document.createElement(\"contexter-box-inner\"),innerSlotThumbnail=(this.shadow.appendChild(innerContainer),document.createElement(\"slot\")),innerSlotHeader=(innerSlotThumbnail.name=\"thumbnail\",innerContainer.appendChild(innerSlotThumbnail),document.createElement(\"slot\")),innerSlotAuthor=(innerSlotHeader.name=\"header\",innerContainer.appendChild(innerSlotHeader),document.createElement(\"slot\")),innerSlotTime=(innerSlotAuthor.name=\"author\",innerContainer.appendChild(innerSlotAuthor),document.createElement(\"slot\")),innerSlotSummary=(innerSlotTime.name=\"time\",innerContainer.appendChild(innerSlotTime),document.createElement(\"slot\")),metaContainer=(innerSlotSummary.name=\"summary\",innerContainer.appendChild(innerSlotSummary),document.createElement(\"contexter-meta\")),innerSlotInfo=(innerContainer.appendChild(metaContainer),document.createElement(\"slot\")),linkContainer=(innerSlotInfo.name=\"keywords\",metaContainer.appendChild(innerSlotInfo),document.createElement(\"contexter-linkset\")),innerSlotArchiveLink=(metaContainer.appendChild(linkContainer),document.createElement(\"slot\")),innerSlotReadLink=(innerSlotArchiveLink.name=\"archive-link\",linkContainer.appendChild(innerSlotArchiveLink),document.createElement(\"slot\"));innerSlotReadLink.name=\"read-link\",linkContainer.appendChild(innerSlotReadLink),this.className=\"contexter-box\",this.onclick=e=>{if(!e.target.className.includes(\"read-link\")&&!e.target.className.includes(\"title-link\")){const mainLinks=this.querySelectorAll(\"a.main-link\");mainLinks[0].click()}}}}}customElements.define(\"contexter-box\",ContexterBox)},window.contexterSetupComplete||window.contexterSetup();</script><contexter-box class=\"link-card h-entry hentry\" itemscope=\"\" itemtype=\"https://schema.org/CreativeWork\"><contexter-thumbnail class=\"thumbnail\" slot=\"thumbnail\"></contexter-thumbnail><contexter-box-head slot=\"header\" class=\"p-name entry-title\" itemprop=\"headline\"><contexter-box-head slot=\"header\" class=\"p-name entry-title\" itemprop=\"headline\"><a is=\"contexter-link\" href=\"https://berjon.com/competition-privacy/\" itemprop=\"url\">Competition &amp; Privacy: It's Both Or Nothing</a></contexter-box-head></contexter-box-head><time class=\"dt-published published\" slot=\"time\" itemprop=\"datePublished\" datetime=\"2022-04-05T17:38:37.115Z\">3/5/2022</time><contexter-summary class=\"p-summary entry-summary\" itemprop=\"abstract\" slot=\"summary\"><p>If you've spent any amount of time discussing reforms to improve privacy online, you've likely encountered the Big Knob Theory. Like Covid it comes in variants, but its core tenet can be summarised thus: there exists (metaphorically) a Big Knob that can either be turned towards \"privacy\" or towards \"competition\" — but it's very much a zero-sum game and you can't have both. It's a popular position; but is it true?</p></contexter-summary><contexter-keywordset itemprop=\"keywords\" slot=\"keywords\"></contexter-keywordset><a href=\"https://web.archive.org/web/20220405173903/https://berjon.com/competition-privacy/\" is=\"contexter-link\" target=\"_blank\" rel=\"timemap\" class=\"read-link archive-link\" itemprop=\"archivedAt\" slot=\"archive-link\">Archived</a><a is=\"contexter-link\" href=\"https://berjon.com/competition-privacy/\" class=\"read-link main-link\" itemprop=\"sameAs\" slot=\"read-link\">Read</a></contexter-box>","linkId":"7a8f899b63c175ebd943e33837126eedcd74fcb4","data":{"originalLink":"https://berjon.com/competition-privacy/","sanitizedLink":"https://berjon.com/competition-privacy/","canonical":"https://berjon.com/competition-privacy/","htmlText":"<!DOCTYPE html>\n    <html lang=\"en\" dir=\"ltr\">\n      <head>\n        <meta charset=\"utf-8\">\n        <meta name=\"viewport\" content=\"width=device-width\">\n        <title>Competition &amp; Privacy: It's Both Or Nothing</title>\n        <link rel=\"icon\" href=\"/EF6079.png\">\n        <link rel=\"stylesheet\" href=\"/berjon.min.css\">\n        \n        <link rel=\"alternate\" type=\"application/atom+xml\" href=\"/feed.atom\" title=\"Robin Berjon — Feed\">\n        <meta name=\"monetization\" content=\"$ilp.uphold.com/jPPaqHeeaWxU\">\n        <meta name=\"twitter:card\" content=\"summary_large_image\">\n        <meta name=\"twitter:site\" content=\"@robinberjon\">\n        \n        <meta name=\"twitter:title\" property=\"og:title\" content=\"Competition &amp;amp; Privacy: It&#x27;s Both Or Nothing\">\n        <meta name=\"twitter:description\" property=\"og:description\" content=\"If you&#x27;ve spent any amount of time discussing reforms to improve privacy online, you&#x27;ve likely encountered the Big Knob Theory. Like Covid it comes in variants, but its core tenet can be summarised thus: there exists (metaphorically) a Big Knob that can either be turned towards &quot;privacy&quot; or towards &quot;competition&quot; — but it&#x27;s very much a zero-sum game and you can&#x27;t have both. It&#x27;s a popular position; but is it true?\">\n        <meta name=\"twitter:image\" property=\"og:image\" content=\"https://berjon.com/competition-privacy/houston.jpg\">\n        \n        <meta name=\"twitter:url\" property=\"og:url\" content=\"https://berjon.com/competition-privacy/\">\n        <meta property=\"og:site_name\" content=\"Robin Berjon\">\n        <meta property=\"og:type\" content=\"blog\">\n        <meta property=\"og:locale\" content=\"en_UK\">\n        <meta name=\"theme-color\" content=\"#EF6079\">\n        <style nonce=\"bDhuMzQ4RFlsWg==\">\n          body {\n            --primary-colour: #EF6079;\n            --secondary-colour: #EF6079;\n          }\n          \n        </style>\n      </head>\n      <body>\n        <header>\n          <p><a href=\"/\">Robin Berjon</a></p>\n        </header>\n        <main>\n          <article>\n      <header>\n        <p>Digging into the Big Knob Theory</p>\n        <h1>Competition &amp; Privacy: It's Both Or Nothing</h1>\n        <div class=\"meta\">\n          <ul><li><span>\n    <a href=\"/people/robin\">Robin Berjon</a>\n  </span></li></ul>\n          <time datetime=\"2021-12-13T00:00:00.000Z\">2021-12-13</time>\n        </div>\n      </header>\n      <img src=\"/competition-privacy/houston.jpg\"   alt=\"\" role=\"presentation\">\n      <p>If you've spent any amount of time discussing reforms to improve privacy online, you've likely\n  encountered the <em>Big Knob Theory</em>. Like Covid it comes in variants, but its core tenet can\n  be summarised thus: there exists (metaphorically) a Big Knob that can either be turned towards\n  \"privacy\" or towards \"competition\" — but it's very much a zero-sum game and you can't have both.\n</p>\n<p>Big Knob Theory (BKT) is often a strongly-held view of its proponents, many of whom take it\n  simply as self-evident. More surprisingly, it is also a view commonly held by those who wished\n  things were different. You can often find them deploring the fact that they would very much like\n  to fix our privacy predicament, but can't because it would empower companies that already have too\n  much power.</p>\n<p>If it's true, and certainly if as clearly true as it is taken to be, there should be solid\n  evidence and arguments to support it. Upon closer inspection, however, it turns out that the case\n  for the Big Knob Theory is far from being that obvious.</p>\n<p>Let's try to formulate the situation a little more rigorously so that we have a basic framework\n  with which to pick through the evidence.</p>\n<p>The simplest understanding of privacy that lends itself to some degree of empirical verification\n  is the <em>Vegas Rule</em>: what happens in a given context stays in that context. In practical\n  terms, this means that whatever a person does on a given site or app cannot be learnt by a party\n  other than that site or app in such a way that the third party can then reuse that information\n  elsewhere. (In technical terms, the first party is the sole data controller.) On crucial points is\n  that, under the Vegas Rule, contexts are defined as different products or services, irrespective\n  of whether they are owned in common. Whatever happens at the Vegas Hilton will not be known at the\n  front desk of any other Hilton, and data gathered about you by your email service will not be used\n  by other services owned by the same company. This definition of privacy maps well to contextual\n  integrity and to people's expectations. We can understand it as measuring the fluidity of data\n  flows.</p>\n<p>Competition in data or data-adjacent markets can be measured with <a\n    href=\"https://en.wikipedia.org/wiki/Herfindahl%E2%80%93Hirschman_index\">HHI</a> or similar\n  metrics. (Margins can also serve as a proxy measure of how contestable the market is.)</p>\n<p>With these starting points, <strong>an explicit formulation of the Big Knob Theory</strong> would\n  be that <em>data and data-adjacent markets will be more competitive in proportion to the fluidity\n    of personal data flows between contexts, and less competitive when contexts are siloed.</em>\n  What support can we find for this theory?</p>\n<h2>Arguments for the <em>Big Knob Theory</em></h2>\n<p>A very common argument mentioned in support of the BKT could be captured succinctly as the\n  \"<strong>Safari CPMs</strong>\". The idea is that we can observe in the market that ad prices\n  (CPMs) are measured to be significantly lower in Safari, a browser that protects privacy, than in\n  Chrome, a browser that doesn't. But what this shows is only that if, <em>in the same market</em>,\n  some parts have fluid data flows and others do not, then the money will flow to the former. Buyers\n  who are willing to pay for decreased privacy will pay more in a system like Chrome that has a low\n  level of security for personal data. It says nothing about the impact of data fluidity as it\n  impacts the entire market.</p>\n<p>The other primary argument for the BKT looks at <strong>the GDPR as a natural\n    experiment</strong>. It comes in multiple flavours.</p>\n<p>Some, like <em><a\n      href=\"https://www.applicoinc.com/blog/how-gdpr-is-helping-big-tech-and-hurting-the-competition/\">How\n      GDPR is Helping Big Tech and Hurting the Competition</a></em>, look at the impact of the GDPR\n  on Google's market share. The argument proceeds as follows: the GDPR happened, but Google's market\n  share increased anyway; therefore, privacy is bad for competition. This makes two fundamental\n  assumptions: 1) that the GDPR improves privacy and 2) that the GDPR is being enforced against\n  platforms. Both assumptions, unfortunately, are wrong. The GDPR, as implemented today,\n  unfortunately includes consent as a big loophole. This has enabled pretty much everyone to\n  broadcast personal data just as much as they did prior to the GDPR simply by adding the annoyance\n  of consent banners. Europe has seen very little improvement in privacy from the GDPR. (And there\n  is reason to believe that GDPR-style consent, in addition to being useless for privacy, also <a\n    href=\"https://ide.mit.edu/sites/default/files/publications/2011.12_Campbell_Goldfarb_Tucker_Privacy%20Regulation%20and%20Market%20Structure_313.pdf\">helps\n    larger companies</a>.) Additionally, the platforms are registered in Ireland, and Ireland is\n  acting as the data equivalent of an uncooperative tax haven. Even if the GDPR improved privacy, it\n  wouldn't apply to companies whose European operations are centred in Ireland.</p>\n<p>Others, like <em><a\n      href=\"https://deliverypdf.ssrn.com/delivery.php?ID=288029089119124074065078023012027091103043056088031004087023084093070127089007100068017098101006051012034021078001125074029014122090028033029003085121008099072103015084017084101112001099031102070086120105083068094124124083067095083106122031027117096001&amp;EXT=pdf&amp;INDEX=TRUE\">Privacy\n      &amp; market concentration: Intended &amp; unintended consequences of the GDPR</a></em>, look\n  at the market share of small vendors under the GDPR. Right after the GDPR comes into effect, the\n  number of third-party vendors used in websites that operate under the GDPR drops 15% (with smaller\n  vendors dropping more) before returning to the same level six months later (the abstract somehow\n  fails to mention this last point). The theory here is that sites fear enforcement and so reduce\n  their vendors — mostly the small ones that are less adept at compliance — but over time that fear\n  of enforcement fades and the volume of third-party vendors returns.</p>\n<p>Unfortunately, the paper doesn't factor in the realities of operating a website. Sites manage\n  third-party vendors like this: marketers regularly want to test new vendors, and have them added\n  to the site. When a vendor doesn't pan out, marketers are supposed to ask for its removal but that\n  often fails (for lack of a forcing function) and stray trackers remain on the site with no\n  purpose. When the GDPR happened (which for many was a last-minute race), pretty much every website\n  out there had to produce a list of all its trackers, and asked marketing to explain which ones did\n  what and who to contact to get data processing addenda in place. That's a great forcing function\n  to spot vendors you no longer need, which alone suffices to explain the short-lived drop in the\n  number of vendors. It also explains why the drop was short (better than the suggestion that people\n  stopped fearing GDPR enforcement after 6 months) and why the replacement vendors are mostly\n  different ones from those that had been removed (as noted in the paper). It's hard to overestimate\n  the spring cleaning effect: practitioners found and shut down <em>entire websites</em> that should\n  no longer have been running; a 15% drop in the number of vendors is in fact relatively small.</p>\n<p>A great overview of this strand of thinking can be found in <em><a\n      href=\"https://deliverypdf.ssrn.com/delivery.php?ID=509005100118099013025126110000090101062011084076070069105107082101120101072089000104001126060041109056096073068103013083088004029022075093060100011004006073081088052035024091084096091066000027106006110070030002097004097029098065068000010067117089025&amp;EXT=pdf&amp;INDEX=TRUE\">The\n      Competitive Effects of the GDPR</a></em>. In fact, this paper offers simultaneously a good\n  summary of what is valuable in looking at the GDPR as a natural experiment and of why that line of\n  inquiry does not support the Big Knob Theory. This paper (and others in this vein) tend to show\n  that bureaucratic compliance regimes benefit large firms, as does consent-based processing. It's\n  quite interesting to see that this kind of \"notice and choice\" isn't great from a competition\n  perspective because it's also bad from a privacy standpoint.</p>\n<p>It's worth a quick pause here because, to many, particularly outside of the privacy space, the\n  GDPR has become synonymous with privacy. Sadly, that is hardly the case. The GDPR is first and\n  foremost a thorough implementation of the fair information practices (FIPs), a privacy paradigm\n  that is perfect if you are processing data in the 1970s. It is privacy that works for lawyers and\n  compliance teams, heavily focused on procedural, bureaucratic solutions such as privacy policies,\n  inventories, and consent. While the FIPs can be useful, and should be part of the privacy toolbox\n  so long as their bureaucratic overhead is kept in check, there are simpler and more effective\n  measures to improve privacy (for instance a ban on third-party data controllers) that aren't in\n  the GDPR.</p>\n<p>It is great that there are papers analysing the impact of the GDPR; but to the extent that they\n  equate the GDPR with privacy, they are extending themselves beyond their empirical reach. The GDPR\n  did not significantly and durably reduce the fluidity of data flows but it did increase the\n  overhead of data processing in a way that favours companies with greater cover-your-ass expertise.\n  Even if these papers do not, in fact, support the theory that improved privacy harms competition,\n  they do strengthen the case against transparency and choice regimes.</p>\n<p>I read a number of other papers (notably the references from those cited above) but the above\n  points cover the spectrum of arguments that I've found in favour of the Big Knob Theory. While\n  none actually supports the BKT itself, the related points they make can be helpful, notably in\n  showing that certain bad ways of regulating privacy are also bad for competition.</p>\n<h2>How Privacy Improves Data Markets</h2>\n<p>In <em><a href=\"https://scholarship.law.columbia.edu/faculty_scholarship/1077/\">Incomplete\n      Law</a></em>, Pistor &amp; Xu recount a history of the legal status of electricity. In the\n  late 19th century, when the electrification of houses started to become more common, some\n  enterprising people decided that they might as well just hook their household up straight to the\n  grid without officially signing up for anything or paying anyone. Today, it is obvious to most\n  that this is purely and simply theft. That view, however, was not so readily apparent to the\n  courts. The German Supreme Court found that electricity could <em>not</em> be considered an asset\n  in the sense that the law understood it, and only assets could be stolen — therefore, helping\n  yourself to electricity couldn't be theft. American courts decidedly differently, but the matter\n  remained contentious and was debated in New York courts until 1978.</p>\n<p>We are facing a similar moment of confusion during which the status of data is challenging both\n  our legal and economics traditions. Data is <em>much</em> weirder a commodity than electricity. It\n  isn't easily excludable — copies are cheap and can be difficult to prevent — but it is\n  nevertheless rivalrous (if you're the only one to know that I plan to buy expensive shoes, you can\n  make a lot more money from shoe sellers with that information than you would if everyone knew).\n  When traded, it becomes even weirder. The market itself is an information device. The interplay\n  between the market as an information device with information itself being traded in that market is\n  not straightforward.</p>\n<p>As we increasingly apply ourselves to it, we're figuring it out. I have good hope that the 2020s\n  will be the decade in which we begin to understand enough of digital society that we can start\n  making it work <em>for</em> people.</p>\n<p>Starting from the basics: as Neil Richards explains in <em><a\n      href=\"https://bookshop.org/books/why-privacy-matters/9780190939045\">Why Privacy\n      Matters</a></em>, \"<em>We live in a society in which information is power, and 'privacy' is\n    the work we use to talk about the struggles over personal information, personal power, and\n    personal control.</em>\" Concentrations of data are concentrations of power, and from that alone\n  we can hypothesise that those who extract the most data will wield the most power. What's more,\n  this has the potential to create a feedback loop in which the power of data is used to capture\n  further data, leading to greater data concentration. Just looking at first principles, privacy is\n  the fight for more equitable and balanced power in the digital world. More equitable and more\n  balanced power is good for competition, too. Is there any evidence for this that goes beyond basic\n  principles?</p>\n<p>As it happens, there is. I found good indications in the literature that the broad sharing of\n  data across contexts has <em>anticompetitive</em> effects. Put differently, to the extent that\n  there is a Big Knob somewhere, it would seem to go from \"<em>No Privacy and No Competition</em>\"\n  to \"<em>Privacy &amp; Competition</em>.\" Given that we live in a world that is described\n  particularly well by the former setting, this idea at least passes a smell test that the Big Knob\n  Theory fails.</p>\n<p>Quick interlude: since we have a catchy name for the BKT, we should also conjure one up for its\n  inverse. Let's go with <em>Data Accumulates Power, which Privacy Equitably Redistributes</em>. If\n  you're looking, it's the DAPPER theory.</p>\n<p>Policymakers broadly tend to think that DAPPER may be true. The European Commission's <em><a\n      href=\"https://ec.europa.eu/competition/publications/reports/kd0419345enn.pdf\">Competition\n      policy for the digital era</a></em> suspects that \"<em>when it comes to dominant firms, access\n    to more data may tend to strengthen dominance or allow an incumbent to leverage market\n    power.</em>\" The OECD's <em><a\n      href=\"https://www.oecd-ilibrary.org/science-and-technology/exploring-the-economics-of-personal-data_5k486qtxldmq-en\">Exploring\n      the Economics of Personal Data</a></em> points out that the \"<em>monetary, economic and social\n    value of personal data is likely to be governed by non-linear, increasing returns to scale. The\n    value of an individual record, alone, may be very low but the value and usability of the record\n    increases as the number of records to compare it with increases. These network effects have\n    implications for policy because the value of the same record in a large database could be much\n    more efficiently leveraged than the same record in a much smaller data set. This could have\n    implications for competition and for other key policy items such as the portability of\n    data</em>\" and their <em><a\n      href=\"https://www.oecd.org/sti/data-driven-innovation-9789264229358-en.htm\">Data-Driven\n      Innovation</a></em> report had similar notes. The Stigler Center's report on <em><a\n      href=\"https://research.chicagobooth.edu/-/media/research/stigler/pdfs/digital-platforms---committee-report---stigler-center.pdf?la=en&amp;hash=2D23583FF8BCC560B7FEF7A81E1F95C1DDC5225E\">Digital\n      Platforms</a></em> notes that \"<em>high and increasing returns to the use of data</em>\" tend\n  to \"<em>push these markets towards monopolization by a single company.</em>\" You can find similar\n  indications in the CMA's <em><a\n      href=\"https://www.gov.uk/cma-cases/online-platforms-and-digital-advertising-market-study\">Online\n      platforms and digital advertising</a></em> final report, the <em><a\n      href=\"https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/785547/unlocking_digital_competition_furman_review_web.pdf\">Furman\n      Review</a></em>, or the <em><a\n      href=\"https://www.gov.uk/government/publications/the-cairncross-review-a-sustainable-future-for-journalism\">Cairncross\n      Review</a></em>.</p>\n<p>Turning further towards academic sources, one great book is the classic barn-burner <em><a\n      href=\"https://bookshop.org/books/big-data-and-competition-policy/9780198788140\">Big Data and\n      Competition Policy</a></em>. One perspective that Grunes &amp; Stucke describe is the \"Vs\" of\n  data valuation. Data can be seen to have some degree of relatively intrinsic value (eg. data\n  relative to a group's willingness to pay will fetch a greater price than knowing the number of\n  sticks in my backyard), but other important aspects also determine what can be extracted from\n  data:</p>\n<ol>\n  <li><strong>Volume</strong>: The more data you have about one person, or the more people you have\n    that kind of data about, the better the inferences, segmentation, etc.</li>\n  <li><strong>Variety</strong>: Knowing location <em>and</em> reading history is more valuable than\n    the sum of the value of either taken separately, knowing the reading history from two sites is\n    of higher value than one, etc.</li>\n  <li><strong>Veracity</strong>: Data the correctness of which is better established (including by\n    obtaining it from several places) is more valuable.</li>\n  <li><strong>Velocity</strong>: Most of the time, the faster you know the better.</li>\n</ol>\n<p>Of these aspects, volume and variety are particularly important: because the value of their sum\n  is greater than the sum of the parts’ values, whoever has more data, especially from more varied\n  sources, will structurally tend to outcompete whoever has less. <strong>Because of this, broad\n    sharing of data enables increased returns to scale and scope, leading to dominance,\n    winner-take-all, and competition for the market rather than in the market.</strong></p>\n<p>Another very interesting source is <em><a\n      href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2918726\">Competing with Big\n      Data</a></em>. The authors develop a model in which, under typical situations of broad access\n  to cross-contextual data, data-driven markets will almost always tip. And worse, because this data\n  is already intermixed without respect for context, it can be leveraged into <em>other</em>\n  markets. (Sticking to the Vegas Rule, the power gained from surveilling people in Vegas can be\n  used to increase one's power in Atlantic City.)</p>\n<p>I would like to emphasise again that a clear understanding of privacy is essential to\n  understanding the value of these models. Privacy is grounded in people-centric contexts that exist\n  independently from whatever structures of joint corporate ownership may exist. When Google Chrome\n  sells your data to Google Search, it isn't any less a violation of privacy than when Axciom sells\n  your data to Facebook. The structural competition problems created by the sharing of data across\n  contexts exist equally well in the case of tracking by third parties and in the case of internal\n  sharing by large corporations.</p>\n<p>Such problems of data sharing across different markets are analysed excellently in <em><a\n      href=\"https://deliverypdf.ssrn.com/delivery.php?ID=256097088074026091112091079025028081116048056043070018004100101070072118118091066100062035127024024056008088075074027108117077019069008041042095121084070087109026009057126003009064095031066117087112065000081067084024090001028092021068103017125003&amp;EXT=pdf&amp;INDEX=TRUE\">Data-driven\n      Envelopment with Privacy-Policy Tying</a></em>. Condorelli &amp; Padilla build a simple theory\n  in which a firm that has a dominant position in a market where data is key will use the profits\n  from that market to enter one or more secondary data-rich markets and engage in predatory pricing\n  there (often simply opting for free products). In turn, the data from the secondary market will\n  bolster dominance in the primary market, leading to a vicious cycle of entrenchment. They\n  illustrate the structure simply:</p><img\n  alt=\"A diagram illustrating cross-market leveraging of data\"\n  src=\"/competition-privacy/Untitled.png\">\n<p>Crucially, this model only works if the firm is able (thanks to technology) and allowed (thanks\n  to law and the practices of its privacy policy) to exploit data captured in one market in another.\n  I find this model particularly appealing because it strongly matches the behaviour of dominant\n  firms in the real world.</p>\n<p>It's worth noting that in some models, data sharing <em>can</em> be pro-competitive, but you\n  basically have to share <em>all</em> the data. Intuitively, if you nullify the advantages from\n  data collection you eliminate competition issues in data. This works in <em><a\n      href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2918726\">Competing with Big\n      Data</a></em> and with the \"Vs\" model too: if everyone has all the data, then there are no\n  structural advantages to volume or variety. Even if the privacy issues weren't insuperable (which\n  they are), building the infrastructure to grant everyone access to all the world's personal data\n  would present a huge challenge.</p>\n<p>As we can see, there are good reasons to believe that sharing data across contexts creates\n  competition issues — the DAPPER theory seems to hold water, and what's more to match the reality\n  of how dominant firms behave. Is there anything that we can do about this?</p>\n<h2>Some Potential Solutions</h2>\n<p>My primary purpose here was to share my own travel through the literature to indicate that,\n  indeed, we have solid reasons to believe that sharing data across contexts <em>creates</em>\n  competition issues and that the Big Knob Theory, while we can learn from it in refusing\n  transparency and choice frameworks, generally seems unfounded. I can, however, share a few\n  pointers towards what I think could be solutions.</p>\n<p>The first step is that we should <strong>pursue strong context silos whenever possible</strong>\n  so as to avoid the structural issues that stem from cross-context sharing. One simple policy\n  prescription is to <strong>ban third-party data controllers</strong> (with perhaps a tiny set of\n  very narrow and strictly enforced exemptions). There is little business benefit to them and they\n  produce great privacy harm. It is important to note that, as per the joint CMA/ICO statement\n  <em><a\n      href=\"https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/987358/Joint_CMA_ICO_Public_statement_-_final_V2_180521.pdf\">Competition\n      and data protection in digital markets</a></em> (notably §79), intra-company transfers between\n  different services should be similarly outlawed. CPRA-like regimes should treat different services\n  as different businesses in their definition of \"sale\" as that more accurately reflects reality and\n  privacy impacts.</p>\n<p>Another important step would be to <strong>enforce strongly against self-preferential practices\n    that create differential access to data</strong>. I think specifically of cases in which a\n  company uses its operating system, app store, or browser to prevent others from sharing across\n  contexts, but avails itself of data coming from interactions with these systems. This remains a\n  problem when the effects are indirect, for instance observing behaviour on the sites of\n  competitors in the ad market to improve search services. Increasing the scale of the latter is\n  anticompetitive in the former. This would include enforcing <em><a\n      href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3180174\">The Separation of Platforms\n      and Commerce</a></em>.</p>\n<p>Of course, <strong>building privacy-preserving alternatives</strong> (so long as they don't make\n  it possible to exploit data dominance in other ways) to today's data-hungry services can help a\n  lot. More generally, we can consider better ways of structuring data-adjacent markets: instead of\n  pooling all the personal data collected from smaller sites into ever-bigger companies that then\n  gain the ability to outcompete smaller ones, we should set the data market up in such a way that\n  it trades in <em>insights derived locally from the data</em>. This enables greater innovation at\n  the edges by empowering publishers to put their greater local knowledge of their own audiences to\n  work and to monetise that instead of the raw material. This approach strongly aligns competition\n  objectives with improved data protection by severely limiting the need for sharing personal data.\n  It is a key component of several ongoing proposals to reform online advertising, such as\n  Microsoft’s <em><a\n      href=\"https://github.com/WICG/privacy-preserving-ads/blob/main/Parakeet.md\">PARAKEET</a></em>\n  or The New York Times’s <em><a href=\"https://darobin.github.io/garuda/\">GARUDA</a></em>. (I wrote\n  about a high-level overview of the general idea in <em><a\n      href=\"https://www.warc.com/newsandopinion/opinion/The_New_York_Times_Identity_isnt_about_identifiers_its_about_people/4320\">Identity\n      isn’t about identifiers – it’s about people</a></em>.)</p>\n<p>In order to support strong technical privacy at the edges, where data enters the system, we\n  should deploy <strong>a fiduciary regime for all user agents</strong> (browsers, operating\n  systems, voice assistants, and many more). See <em><a\n      href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3827421\">The Fiduciary Duties of\n      User Agents</a></em>, which I hope to update soon.</p>\n<p>The details vary, but overall the direction is simple: many of the best competition remedies that\n  we have at our disposal in digital markets are privacy remedies. Whichever way you come at it, the\n  future looks DAPPER.</p>\n\n    </article>\n        </main>\n        <footer>\n          <nav>\n            <ul>\n              <li><a href=\"/\">home</a></li\n              ><li><a href=\"/about/\">about</a></li>\n            </ul>\n            <ul>\n              <li><a href=\"/2009/\">2009</a></li\n              ><li><a href=\"/2010/\">2010</a></li\n              ><li><a href=\"/2011/\">2011</a></li\n              ><li><a href=\"/2012/\">2012</a></li\n              ><li><a href=\"/2013/\">2013</a></li\n              ><li><a href=\"/2014/\">2014</a></li\n              ><li><a href=\"/2015/\">2015</a></li\n              ><li><a href=\"/2016/\">2016</a></li\n              ><li><a href=\"/2018/\">2018</a></li\n              ><li><a href=\"/2021/\">2021</a></li>\n              </ul>\n          </nav>\n          <p class=\"disclaimer\">\n            The opinions published on this site are mine and mine alone. It is disingenuous to tie\n            them to my employer one way or another.\n          </p>\n        </footer>\n      </body>\n    </html>\n  ","oembed":false,"readabilityObject":{"title":"Competition & Privacy: It's Both Or Nothing","content":"<div id=\"readability-page-1\" class=\"page\"><div>\n          <article>\n      <header>\n        <p>Digging into the Big Knob Theory</p>\n        \n        \n      </header>\n      <img src=\"/competition-privacy/houston.jpg\" alt=\"\" role=\"presentation\">\n      <p>If you've spent any amount of time discussing reforms to improve privacy online, you've likely\n  encountered the <em>Big Knob Theory</em>. Like Covid it comes in variants, but its core tenet can\n  be summarised thus: there exists (metaphorically) a Big Knob that can either be turned towards\n  \"privacy\" or towards \"competition\" — but it's very much a zero-sum game and you can't have both.\n</p>\n<p>Big Knob Theory (BKT) is often a strongly-held view of its proponents, many of whom take it\n  simply as self-evident. More surprisingly, it is also a view commonly held by those who wished\n  things were different. You can often find them deploring the fact that they would very much like\n  to fix our privacy predicament, but can't because it would empower companies that already have too\n  much power.</p>\n<p>If it's true, and certainly if as clearly true as it is taken to be, there should be solid\n  evidence and arguments to support it. Upon closer inspection, however, it turns out that the case\n  for the Big Knob Theory is far from being that obvious.</p>\n<p>Let's try to formulate the situation a little more rigorously so that we have a basic framework\n  with which to pick through the evidence.</p>\n<p>The simplest understanding of privacy that lends itself to some degree of empirical verification\n  is the <em>Vegas Rule</em>: what happens in a given context stays in that context. In practical\n  terms, this means that whatever a person does on a given site or app cannot be learnt by a party\n  other than that site or app in such a way that the third party can then reuse that information\n  elsewhere. (In technical terms, the first party is the sole data controller.) On crucial points is\n  that, under the Vegas Rule, contexts are defined as different products or services, irrespective\n  of whether they are owned in common. Whatever happens at the Vegas Hilton will not be known at the\n  front desk of any other Hilton, and data gathered about you by your email service will not be used\n  by other services owned by the same company. This definition of privacy maps well to contextual\n  integrity and to people's expectations. We can understand it as measuring the fluidity of data\n  flows.</p>\n<p>Competition in data or data-adjacent markets can be measured with <a href=\"https://en.wikipedia.org/wiki/Herfindahl%E2%80%93Hirschman_index\">HHI</a> or similar\n  metrics. (Margins can also serve as a proxy measure of how contestable the market is.)</p>\n<p>With these starting points, <strong>an explicit formulation of the Big Knob Theory</strong> would\n  be that <em>data and data-adjacent markets will be more competitive in proportion to the fluidity\n    of personal data flows between contexts, and less competitive when contexts are siloed.</em>\n  What support can we find for this theory?</p>\n<h2>Arguments for the <em>Big Knob Theory</em></h2>\n<p>A very common argument mentioned in support of the BKT could be captured succinctly as the\n  \"<strong>Safari CPMs</strong>\". The idea is that we can observe in the market that ad prices\n  (CPMs) are measured to be significantly lower in Safari, a browser that protects privacy, than in\n  Chrome, a browser that doesn't. But what this shows is only that if, <em>in the same market</em>,\n  some parts have fluid data flows and others do not, then the money will flow to the former. Buyers\n  who are willing to pay for decreased privacy will pay more in a system like Chrome that has a low\n  level of security for personal data. It says nothing about the impact of data fluidity as it\n  impacts the entire market.</p>\n<p>The other primary argument for the BKT looks at <strong>the GDPR as a natural\n    experiment</strong>. It comes in multiple flavours.</p>\n<p>Some, like <em><a href=\"https://www.applicoinc.com/blog/how-gdpr-is-helping-big-tech-and-hurting-the-competition/\">How\n      GDPR is Helping Big Tech and Hurting the Competition</a></em>, look at the impact of the GDPR\n  on Google's market share. The argument proceeds as follows: the GDPR happened, but Google's market\n  share increased anyway; therefore, privacy is bad for competition. This makes two fundamental\n  assumptions: 1) that the GDPR improves privacy and 2) that the GDPR is being enforced against\n  platforms. Both assumptions, unfortunately, are wrong. The GDPR, as implemented today,\n  unfortunately includes consent as a big loophole. This has enabled pretty much everyone to\n  broadcast personal data just as much as they did prior to the GDPR simply by adding the annoyance\n  of consent banners. Europe has seen very little improvement in privacy from the GDPR. (And there\n  is reason to believe that GDPR-style consent, in addition to being useless for privacy, also <a href=\"https://ide.mit.edu/sites/default/files/publications/2011.12_Campbell_Goldfarb_Tucker_Privacy%20Regulation%20and%20Market%20Structure_313.pdf\">helps\n    larger companies</a>.) Additionally, the platforms are registered in Ireland, and Ireland is\n  acting as the data equivalent of an uncooperative tax haven. Even if the GDPR improved privacy, it\n  wouldn't apply to companies whose European operations are centred in Ireland.</p>\n<p>Others, like <em><a href=\"https://deliverypdf.ssrn.com/delivery.php?ID=288029089119124074065078023012027091103043056088031004087023084093070127089007100068017098101006051012034021078001125074029014122090028033029003085121008099072103015084017084101112001099031102070086120105083068094124124083067095083106122031027117096001&amp;EXT=pdf&amp;INDEX=TRUE\">Privacy\n      &amp; market concentration: Intended &amp; unintended consequences of the GDPR</a></em>, look\n  at the market share of small vendors under the GDPR. Right after the GDPR comes into effect, the\n  number of third-party vendors used in websites that operate under the GDPR drops 15% (with smaller\n  vendors dropping more) before returning to the same level six months later (the abstract somehow\n  fails to mention this last point). The theory here is that sites fear enforcement and so reduce\n  their vendors — mostly the small ones that are less adept at compliance — but over time that fear\n  of enforcement fades and the volume of third-party vendors returns.</p>\n<p>Unfortunately, the paper doesn't factor in the realities of operating a website. Sites manage\n  third-party vendors like this: marketers regularly want to test new vendors, and have them added\n  to the site. When a vendor doesn't pan out, marketers are supposed to ask for its removal but that\n  often fails (for lack of a forcing function) and stray trackers remain on the site with no\n  purpose. When the GDPR happened (which for many was a last-minute race), pretty much every website\n  out there had to produce a list of all its trackers, and asked marketing to explain which ones did\n  what and who to contact to get data processing addenda in place. That's a great forcing function\n  to spot vendors you no longer need, which alone suffices to explain the short-lived drop in the\n  number of vendors. It also explains why the drop was short (better than the suggestion that people\n  stopped fearing GDPR enforcement after 6 months) and why the replacement vendors are mostly\n  different ones from those that had been removed (as noted in the paper). It's hard to overestimate\n  the spring cleaning effect: practitioners found and shut down <em>entire websites</em> that should\n  no longer have been running; a 15% drop in the number of vendors is in fact relatively small.</p>\n<p>A great overview of this strand of thinking can be found in <em><a href=\"https://deliverypdf.ssrn.com/delivery.php?ID=509005100118099013025126110000090101062011084076070069105107082101120101072089000104001126060041109056096073068103013083088004029022075093060100011004006073081088052035024091084096091066000027106006110070030002097004097029098065068000010067117089025&amp;EXT=pdf&amp;INDEX=TRUE\">The\n      Competitive Effects of the GDPR</a></em>. In fact, this paper offers simultaneously a good\n  summary of what is valuable in looking at the GDPR as a natural experiment and of why that line of\n  inquiry does not support the Big Knob Theory. This paper (and others in this vein) tend to show\n  that bureaucratic compliance regimes benefit large firms, as does consent-based processing. It's\n  quite interesting to see that this kind of \"notice and choice\" isn't great from a competition\n  perspective because it's also bad from a privacy standpoint.</p>\n<p>It's worth a quick pause here because, to many, particularly outside of the privacy space, the\n  GDPR has become synonymous with privacy. Sadly, that is hardly the case. The GDPR is first and\n  foremost a thorough implementation of the fair information practices (FIPs), a privacy paradigm\n  that is perfect if you are processing data in the 1970s. It is privacy that works for lawyers and\n  compliance teams, heavily focused on procedural, bureaucratic solutions such as privacy policies,\n  inventories, and consent. While the FIPs can be useful, and should be part of the privacy toolbox\n  so long as their bureaucratic overhead is kept in check, there are simpler and more effective\n  measures to improve privacy (for instance a ban on third-party data controllers) that aren't in\n  the GDPR.</p>\n<p>It is great that there are papers analysing the impact of the GDPR; but to the extent that they\n  equate the GDPR with privacy, they are extending themselves beyond their empirical reach. The GDPR\n  did not significantly and durably reduce the fluidity of data flows but it did increase the\n  overhead of data processing in a way that favours companies with greater cover-your-ass expertise.\n  Even if these papers do not, in fact, support the theory that improved privacy harms competition,\n  they do strengthen the case against transparency and choice regimes.</p>\n<p>I read a number of other papers (notably the references from those cited above) but the above\n  points cover the spectrum of arguments that I've found in favour of the Big Knob Theory. While\n  none actually supports the BKT itself, the related points they make can be helpful, notably in\n  showing that certain bad ways of regulating privacy are also bad for competition.</p>\n<h2>How Privacy Improves Data Markets</h2>\n<p>In <em><a href=\"https://scholarship.law.columbia.edu/faculty_scholarship/1077/\">Incomplete\n      Law</a></em>, Pistor &amp; Xu recount a history of the legal status of electricity. In the\n  late 19th century, when the electrification of houses started to become more common, some\n  enterprising people decided that they might as well just hook their household up straight to the\n  grid without officially signing up for anything or paying anyone. Today, it is obvious to most\n  that this is purely and simply theft. That view, however, was not so readily apparent to the\n  courts. The German Supreme Court found that electricity could <em>not</em> be considered an asset\n  in the sense that the law understood it, and only assets could be stolen — therefore, helping\n  yourself to electricity couldn't be theft. American courts decidedly differently, but the matter\n  remained contentious and was debated in New York courts until 1978.</p>\n<p>We are facing a similar moment of confusion during which the status of data is challenging both\n  our legal and economics traditions. Data is <em>much</em> weirder a commodity than electricity. It\n  isn't easily excludable — copies are cheap and can be difficult to prevent — but it is\n  nevertheless rivalrous (if you're the only one to know that I plan to buy expensive shoes, you can\n  make a lot more money from shoe sellers with that information than you would if everyone knew).\n  When traded, it becomes even weirder. The market itself is an information device. The interplay\n  between the market as an information device with information itself being traded in that market is\n  not straightforward.</p>\n<p>As we increasingly apply ourselves to it, we're figuring it out. I have good hope that the 2020s\n  will be the decade in which we begin to understand enough of digital society that we can start\n  making it work <em>for</em> people.</p>\n<p>Starting from the basics: as Neil Richards explains in <em><a href=\"https://bookshop.org/books/why-privacy-matters/9780190939045\">Why Privacy\n      Matters</a></em>, \"<em>We live in a society in which information is power, and 'privacy' is\n    the work we use to talk about the struggles over personal information, personal power, and\n    personal control.</em>\" Concentrations of data are concentrations of power, and from that alone\n  we can hypothesise that those who extract the most data will wield the most power. What's more,\n  this has the potential to create a feedback loop in which the power of data is used to capture\n  further data, leading to greater data concentration. Just looking at first principles, privacy is\n  the fight for more equitable and balanced power in the digital world. More equitable and more\n  balanced power is good for competition, too. Is there any evidence for this that goes beyond basic\n  principles?</p>\n<p>As it happens, there is. I found good indications in the literature that the broad sharing of\n  data across contexts has <em>anticompetitive</em> effects. Put differently, to the extent that\n  there is a Big Knob somewhere, it would seem to go from \"<em>No Privacy and No Competition</em>\"\n  to \"<em>Privacy &amp; Competition</em>.\" Given that we live in a world that is described\n  particularly well by the former setting, this idea at least passes a smell test that the Big Knob\n  Theory fails.</p>\n<p>Quick interlude: since we have a catchy name for the BKT, we should also conjure one up for its\n  inverse. Let's go with <em>Data Accumulates Power, which Privacy Equitably Redistributes</em>. If\n  you're looking, it's the DAPPER theory.</p>\n<p>Policymakers broadly tend to think that DAPPER may be true. The European Commission's <em><a href=\"https://ec.europa.eu/competition/publications/reports/kd0419345enn.pdf\">Competition\n      policy for the digital era</a></em> suspects that \"<em>when it comes to dominant firms, access\n    to more data may tend to strengthen dominance or allow an incumbent to leverage market\n    power.</em>\" The OECD's <em><a href=\"https://www.oecd-ilibrary.org/science-and-technology/exploring-the-economics-of-personal-data_5k486qtxldmq-en\">Exploring\n      the Economics of Personal Data</a></em> points out that the \"<em>monetary, economic and social\n    value of personal data is likely to be governed by non-linear, increasing returns to scale. The\n    value of an individual record, alone, may be very low but the value and usability of the record\n    increases as the number of records to compare it with increases. These network effects have\n    implications for policy because the value of the same record in a large database could be much\n    more efficiently leveraged than the same record in a much smaller data set. This could have\n    implications for competition and for other key policy items such as the portability of\n    data</em>\" and their <em><a href=\"https://www.oecd.org/sti/data-driven-innovation-9789264229358-en.htm\">Data-Driven\n      Innovation</a></em> report had similar notes. The Stigler Center's report on <em><a href=\"https://research.chicagobooth.edu/-/media/research/stigler/pdfs/digital-platforms---committee-report---stigler-center.pdf?la=en&amp;hash=2D23583FF8BCC560B7FEF7A81E1F95C1DDC5225E\">Digital\n      Platforms</a></em> notes that \"<em>high and increasing returns to the use of data</em>\" tend\n  to \"<em>push these markets towards monopolization by a single company.</em>\" You can find similar\n  indications in the CMA's <em><a href=\"https://www.gov.uk/cma-cases/online-platforms-and-digital-advertising-market-study\">Online\n      platforms and digital advertising</a></em> final report, the <em><a href=\"https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/785547/unlocking_digital_competition_furman_review_web.pdf\">Furman\n      Review</a></em>, or the <em><a href=\"https://www.gov.uk/government/publications/the-cairncross-review-a-sustainable-future-for-journalism\">Cairncross\n      Review</a></em>.</p>\n<p>Turning further towards academic sources, one great book is the classic barn-burner <em><a href=\"https://bookshop.org/books/big-data-and-competition-policy/9780198788140\">Big Data and\n      Competition Policy</a></em>. One perspective that Grunes &amp; Stucke describe is the \"Vs\" of\n  data valuation. Data can be seen to have some degree of relatively intrinsic value (eg. data\n  relative to a group's willingness to pay will fetch a greater price than knowing the number of\n  sticks in my backyard), but other important aspects also determine what can be extracted from\n  data:</p>\n<ol>\n  <li><strong>Volume</strong>: The more data you have about one person, or the more people you have\n    that kind of data about, the better the inferences, segmentation, etc.</li>\n  <li><strong>Variety</strong>: Knowing location <em>and</em> reading history is more valuable than\n    the sum of the value of either taken separately, knowing the reading history from two sites is\n    of higher value than one, etc.</li>\n  <li><strong>Veracity</strong>: Data the correctness of which is better established (including by\n    obtaining it from several places) is more valuable.</li>\n  <li><strong>Velocity</strong>: Most of the time, the faster you know the better.</li>\n</ol>\n<p>Of these aspects, volume and variety are particularly important: because the value of their sum\n  is greater than the sum of the parts’ values, whoever has more data, especially from more varied\n  sources, will structurally tend to outcompete whoever has less. <strong>Because of this, broad\n    sharing of data enables increased returns to scale and scope, leading to dominance,\n    winner-take-all, and competition for the market rather than in the market.</strong></p>\n<p>Another very interesting source is <em><a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2918726\">Competing with Big\n      Data</a></em>. The authors develop a model in which, under typical situations of broad access\n  to cross-contextual data, data-driven markets will almost always tip. And worse, because this data\n  is already intermixed without respect for context, it can be leveraged into <em>other</em>\n  markets. (Sticking to the Vegas Rule, the power gained from surveilling people in Vegas can be\n  used to increase one's power in Atlantic City.)</p>\n<p>I would like to emphasise again that a clear understanding of privacy is essential to\n  understanding the value of these models. Privacy is grounded in people-centric contexts that exist\n  independently from whatever structures of joint corporate ownership may exist. When Google Chrome\n  sells your data to Google Search, it isn't any less a violation of privacy than when Axciom sells\n  your data to Facebook. The structural competition problems created by the sharing of data across\n  contexts exist equally well in the case of tracking by third parties and in the case of internal\n  sharing by large corporations.</p>\n<p>Such problems of data sharing across different markets are analysed excellently in <em><a href=\"https://deliverypdf.ssrn.com/delivery.php?ID=256097088074026091112091079025028081116048056043070018004100101070072118118091066100062035127024024056008088075074027108117077019069008041042095121084070087109026009057126003009064095031066117087112065000081067084024090001028092021068103017125003&amp;EXT=pdf&amp;INDEX=TRUE\">Data-driven\n      Envelopment with Privacy-Policy Tying</a></em>. Condorelli &amp; Padilla build a simple theory\n  in which a firm that has a dominant position in a market where data is key will use the profits\n  from that market to enter one or more secondary data-rich markets and engage in predatory pricing\n  there (often simply opting for free products). In turn, the data from the secondary market will\n  bolster dominance in the primary market, leading to a vicious cycle of entrenchment. They\n  illustrate the structure simply:</p><img alt=\"A diagram illustrating cross-market leveraging of data\" src=\"/competition-privacy/Untitled.png\">\n<p>Crucially, this model only works if the firm is able (thanks to technology) and allowed (thanks\n  to law and the practices of its privacy policy) to exploit data captured in one market in another.\n  I find this model particularly appealing because it strongly matches the behaviour of dominant\n  firms in the real world.</p>\n<p>It's worth noting that in some models, data sharing <em>can</em> be pro-competitive, but you\n  basically have to share <em>all</em> the data. Intuitively, if you nullify the advantages from\n  data collection you eliminate competition issues in data. This works in <em><a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2918726\">Competing with Big\n      Data</a></em> and with the \"Vs\" model too: if everyone has all the data, then there are no\n  structural advantages to volume or variety. Even if the privacy issues weren't insuperable (which\n  they are), building the infrastructure to grant everyone access to all the world's personal data\n  would present a huge challenge.</p>\n<p>As we can see, there are good reasons to believe that sharing data across contexts creates\n  competition issues — the DAPPER theory seems to hold water, and what's more to match the reality\n  of how dominant firms behave. Is there anything that we can do about this?</p>\n<h2>Some Potential Solutions</h2>\n<p>My primary purpose here was to share my own travel through the literature to indicate that,\n  indeed, we have solid reasons to believe that sharing data across contexts <em>creates</em>\n  competition issues and that the Big Knob Theory, while we can learn from it in refusing\n  transparency and choice frameworks, generally seems unfounded. I can, however, share a few\n  pointers towards what I think could be solutions.</p>\n<p>The first step is that we should <strong>pursue strong context silos whenever possible</strong>\n  so as to avoid the structural issues that stem from cross-context sharing. One simple policy\n  prescription is to <strong>ban third-party data controllers</strong> (with perhaps a tiny set of\n  very narrow and strictly enforced exemptions). There is little business benefit to them and they\n  produce great privacy harm. It is important to note that, as per the joint CMA/ICO statement\n  <em><a href=\"https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/987358/Joint_CMA_ICO_Public_statement_-_final_V2_180521.pdf\">Competition\n      and data protection in digital markets</a></em> (notably §79), intra-company transfers between\n  different services should be similarly outlawed. CPRA-like regimes should treat different services\n  as different businesses in their definition of \"sale\" as that more accurately reflects reality and\n  privacy impacts.</p>\n<p>Another important step would be to <strong>enforce strongly against self-preferential practices\n    that create differential access to data</strong>. I think specifically of cases in which a\n  company uses its operating system, app store, or browser to prevent others from sharing across\n  contexts, but avails itself of data coming from interactions with these systems. This remains a\n  problem when the effects are indirect, for instance observing behaviour on the sites of\n  competitors in the ad market to improve search services. Increasing the scale of the latter is\n  anticompetitive in the former. This would include enforcing <em><a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3180174\">The Separation of Platforms\n      and Commerce</a></em>.</p>\n<p>Of course, <strong>building privacy-preserving alternatives</strong> (so long as they don't make\n  it possible to exploit data dominance in other ways) to today's data-hungry services can help a\n  lot. More generally, we can consider better ways of structuring data-adjacent markets: instead of\n  pooling all the personal data collected from smaller sites into ever-bigger companies that then\n  gain the ability to outcompete smaller ones, we should set the data market up in such a way that\n  it trades in <em>insights derived locally from the data</em>. This enables greater innovation at\n  the edges by empowering publishers to put their greater local knowledge of their own audiences to\n  work and to monetise that instead of the raw material. This approach strongly aligns competition\n  objectives with improved data protection by severely limiting the need for sharing personal data.\n  It is a key component of several ongoing proposals to reform online advertising, such as\n  Microsoft’s <em><a href=\"https://github.com/WICG/privacy-preserving-ads/blob/main/Parakeet.md\">PARAKEET</a></em>\n  or The New York Times’s <em><a href=\"https://darobin.github.io/garuda/\">GARUDA</a></em>. (I wrote\n  about a high-level overview of the general idea in <em><a href=\"https://www.warc.com/newsandopinion/opinion/The_New_York_Times_Identity_isnt_about_identifiers_its_about_people/4320\">Identity\n      isn’t about identifiers – it’s about people</a></em>.)</p>\n<p>In order to support strong technical privacy at the edges, where data enters the system, we\n  should deploy <strong>a fiduciary regime for all user agents</strong> (browsers, operating\n  systems, voice assistants, and many more). See <em><a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3827421\">The Fiduciary Duties of\n      User Agents</a></em>, which I hope to update soon.</p>\n<p>The details vary, but overall the direction is simple: many of the best competition remedies that\n  we have at our disposal in digital markets are privacy remedies. Whichever way you come at it, the\n  future looks DAPPER.</p>\n\n    </article>\n        </div></div>","textContent":"\n          \n      \n        Digging into the Big Knob Theory\n        \n        \n      \n      \n      If you've spent any amount of time discussing reforms to improve privacy online, you've likely\n  encountered the Big Knob Theory. Like Covid it comes in variants, but its core tenet can\n  be summarised thus: there exists (metaphorically) a Big Knob that can either be turned towards\n  \"privacy\" or towards \"competition\" — but it's very much a zero-sum game and you can't have both.\n\nBig Knob Theory (BKT) is often a strongly-held view of its proponents, many of whom take it\n  simply as self-evident. More surprisingly, it is also a view commonly held by those who wished\n  things were different. You can often find them deploring the fact that they would very much like\n  to fix our privacy predicament, but can't because it would empower companies that already have too\n  much power.\nIf it's true, and certainly if as clearly true as it is taken to be, there should be solid\n  evidence and arguments to support it. Upon closer inspection, however, it turns out that the case\n  for the Big Knob Theory is far from being that obvious.\nLet's try to formulate the situation a little more rigorously so that we have a basic framework\n  with which to pick through the evidence.\nThe simplest understanding of privacy that lends itself to some degree of empirical verification\n  is the Vegas Rule: what happens in a given context stays in that context. In practical\n  terms, this means that whatever a person does on a given site or app cannot be learnt by a party\n  other than that site or app in such a way that the third party can then reuse that information\n  elsewhere. (In technical terms, the first party is the sole data controller.) On crucial points is\n  that, under the Vegas Rule, contexts are defined as different products or services, irrespective\n  of whether they are owned in common. Whatever happens at the Vegas Hilton will not be known at the\n  front desk of any other Hilton, and data gathered about you by your email service will not be used\n  by other services owned by the same company. This definition of privacy maps well to contextual\n  integrity and to people's expectations. We can understand it as measuring the fluidity of data\n  flows.\nCompetition in data or data-adjacent markets can be measured with HHI or similar\n  metrics. (Margins can also serve as a proxy measure of how contestable the market is.)\nWith these starting points, an explicit formulation of the Big Knob Theory would\n  be that data and data-adjacent markets will be more competitive in proportion to the fluidity\n    of personal data flows between contexts, and less competitive when contexts are siloed.\n  What support can we find for this theory?\nArguments for the Big Knob Theory\nA very common argument mentioned in support of the BKT could be captured succinctly as the\n  \"Safari CPMs\". The idea is that we can observe in the market that ad prices\n  (CPMs) are measured to be significantly lower in Safari, a browser that protects privacy, than in\n  Chrome, a browser that doesn't. But what this shows is only that if, in the same market,\n  some parts have fluid data flows and others do not, then the money will flow to the former. Buyers\n  who are willing to pay for decreased privacy will pay more in a system like Chrome that has a low\n  level of security for personal data. It says nothing about the impact of data fluidity as it\n  impacts the entire market.\nThe other primary argument for the BKT looks at the GDPR as a natural\n    experiment. It comes in multiple flavours.\nSome, like How\n      GDPR is Helping Big Tech and Hurting the Competition, look at the impact of the GDPR\n  on Google's market share. The argument proceeds as follows: the GDPR happened, but Google's market\n  share increased anyway; therefore, privacy is bad for competition. This makes two fundamental\n  assumptions: 1) that the GDPR improves privacy and 2) that the GDPR is being enforced against\n  platforms. Both assumptions, unfortunately, are wrong. The GDPR, as implemented today,\n  unfortunately includes consent as a big loophole. This has enabled pretty much everyone to\n  broadcast personal data just as much as they did prior to the GDPR simply by adding the annoyance\n  of consent banners. Europe has seen very little improvement in privacy from the GDPR. (And there\n  is reason to believe that GDPR-style consent, in addition to being useless for privacy, also helps\n    larger companies.) Additionally, the platforms are registered in Ireland, and Ireland is\n  acting as the data equivalent of an uncooperative tax haven. Even if the GDPR improved privacy, it\n  wouldn't apply to companies whose European operations are centred in Ireland.\nOthers, like Privacy\n      & market concentration: Intended & unintended consequences of the GDPR, look\n  at the market share of small vendors under the GDPR. Right after the GDPR comes into effect, the\n  number of third-party vendors used in websites that operate under the GDPR drops 15% (with smaller\n  vendors dropping more) before returning to the same level six months later (the abstract somehow\n  fails to mention this last point). The theory here is that sites fear enforcement and so reduce\n  their vendors — mostly the small ones that are less adept at compliance — but over time that fear\n  of enforcement fades and the volume of third-party vendors returns.\nUnfortunately, the paper doesn't factor in the realities of operating a website. Sites manage\n  third-party vendors like this: marketers regularly want to test new vendors, and have them added\n  to the site. When a vendor doesn't pan out, marketers are supposed to ask for its removal but that\n  often fails (for lack of a forcing function) and stray trackers remain on the site with no\n  purpose. When the GDPR happened (which for many was a last-minute race), pretty much every website\n  out there had to produce a list of all its trackers, and asked marketing to explain which ones did\n  what and who to contact to get data processing addenda in place. That's a great forcing function\n  to spot vendors you no longer need, which alone suffices to explain the short-lived drop in the\n  number of vendors. It also explains why the drop was short (better than the suggestion that people\n  stopped fearing GDPR enforcement after 6 months) and why the replacement vendors are mostly\n  different ones from those that had been removed (as noted in the paper). It's hard to overestimate\n  the spring cleaning effect: practitioners found and shut down entire websites that should\n  no longer have been running; a 15% drop in the number of vendors is in fact relatively small.\nA great overview of this strand of thinking can be found in The\n      Competitive Effects of the GDPR. In fact, this paper offers simultaneously a good\n  summary of what is valuable in looking at the GDPR as a natural experiment and of why that line of\n  inquiry does not support the Big Knob Theory. This paper (and others in this vein) tend to show\n  that bureaucratic compliance regimes benefit large firms, as does consent-based processing. It's\n  quite interesting to see that this kind of \"notice and choice\" isn't great from a competition\n  perspective because it's also bad from a privacy standpoint.\nIt's worth a quick pause here because, to many, particularly outside of the privacy space, the\n  GDPR has become synonymous with privacy. Sadly, that is hardly the case. The GDPR is first and\n  foremost a thorough implementation of the fair information practices (FIPs), a privacy paradigm\n  that is perfect if you are processing data in the 1970s. It is privacy that works for lawyers and\n  compliance teams, heavily focused on procedural, bureaucratic solutions such as privacy policies,\n  inventories, and consent. While the FIPs can be useful, and should be part of the privacy toolbox\n  so long as their bureaucratic overhead is kept in check, there are simpler and more effective\n  measures to improve privacy (for instance a ban on third-party data controllers) that aren't in\n  the GDPR.\nIt is great that there are papers analysing the impact of the GDPR; but to the extent that they\n  equate the GDPR with privacy, they are extending themselves beyond their empirical reach. The GDPR\n  did not significantly and durably reduce the fluidity of data flows but it did increase the\n  overhead of data processing in a way that favours companies with greater cover-your-ass expertise.\n  Even if these papers do not, in fact, support the theory that improved privacy harms competition,\n  they do strengthen the case against transparency and choice regimes.\nI read a number of other papers (notably the references from those cited above) but the above\n  points cover the spectrum of arguments that I've found in favour of the Big Knob Theory. While\n  none actually supports the BKT itself, the related points they make can be helpful, notably in\n  showing that certain bad ways of regulating privacy are also bad for competition.\nHow Privacy Improves Data Markets\nIn Incomplete\n      Law, Pistor & Xu recount a history of the legal status of electricity. In the\n  late 19th century, when the electrification of houses started to become more common, some\n  enterprising people decided that they might as well just hook their household up straight to the\n  grid without officially signing up for anything or paying anyone. Today, it is obvious to most\n  that this is purely and simply theft. That view, however, was not so readily apparent to the\n  courts. The German Supreme Court found that electricity could not be considered an asset\n  in the sense that the law understood it, and only assets could be stolen — therefore, helping\n  yourself to electricity couldn't be theft. American courts decidedly differently, but the matter\n  remained contentious and was debated in New York courts until 1978.\nWe are facing a similar moment of confusion during which the status of data is challenging both\n  our legal and economics traditions. Data is much weirder a commodity than electricity. It\n  isn't easily excludable — copies are cheap and can be difficult to prevent — but it is\n  nevertheless rivalrous (if you're the only one to know that I plan to buy expensive shoes, you can\n  make a lot more money from shoe sellers with that information than you would if everyone knew).\n  When traded, it becomes even weirder. The market itself is an information device. The interplay\n  between the market as an information device with information itself being traded in that market is\n  not straightforward.\nAs we increasingly apply ourselves to it, we're figuring it out. I have good hope that the 2020s\n  will be the decade in which we begin to understand enough of digital society that we can start\n  making it work for people.\nStarting from the basics: as Neil Richards explains in Why Privacy\n      Matters, \"We live in a society in which information is power, and 'privacy' is\n    the work we use to talk about the struggles over personal information, personal power, and\n    personal control.\" Concentrations of data are concentrations of power, and from that alone\n  we can hypothesise that those who extract the most data will wield the most power. What's more,\n  this has the potential to create a feedback loop in which the power of data is used to capture\n  further data, leading to greater data concentration. Just looking at first principles, privacy is\n  the fight for more equitable and balanced power in the digital world. More equitable and more\n  balanced power is good for competition, too. Is there any evidence for this that goes beyond basic\n  principles?\nAs it happens, there is. I found good indications in the literature that the broad sharing of\n  data across contexts has anticompetitive effects. Put differently, to the extent that\n  there is a Big Knob somewhere, it would seem to go from \"No Privacy and No Competition\"\n  to \"Privacy & Competition.\" Given that we live in a world that is described\n  particularly well by the former setting, this idea at least passes a smell test that the Big Knob\n  Theory fails.\nQuick interlude: since we have a catchy name for the BKT, we should also conjure one up for its\n  inverse. Let's go with Data Accumulates Power, which Privacy Equitably Redistributes. If\n  you're looking, it's the DAPPER theory.\nPolicymakers broadly tend to think that DAPPER may be true. The European Commission's Competition\n      policy for the digital era suspects that \"when it comes to dominant firms, access\n    to more data may tend to strengthen dominance or allow an incumbent to leverage market\n    power.\" The OECD's Exploring\n      the Economics of Personal Data points out that the \"monetary, economic and social\n    value of personal data is likely to be governed by non-linear, increasing returns to scale. The\n    value of an individual record, alone, may be very low but the value and usability of the record\n    increases as the number of records to compare it with increases. These network effects have\n    implications for policy because the value of the same record in a large database could be much\n    more efficiently leveraged than the same record in a much smaller data set. This could have\n    implications for competition and for other key policy items such as the portability of\n    data\" and their Data-Driven\n      Innovation report had similar notes. The Stigler Center's report on Digital\n      Platforms notes that \"high and increasing returns to the use of data\" tend\n  to \"push these markets towards monopolization by a single company.\" You can find similar\n  indications in the CMA's Online\n      platforms and digital advertising final report, the Furman\n      Review, or the Cairncross\n      Review.\nTurning further towards academic sources, one great book is the classic barn-burner Big Data and\n      Competition Policy. One perspective that Grunes & Stucke describe is the \"Vs\" of\n  data valuation. Data can be seen to have some degree of relatively intrinsic value (eg. data\n  relative to a group's willingness to pay will fetch a greater price than knowing the number of\n  sticks in my backyard), but other important aspects also determine what can be extracted from\n  data:\n\n  Volume: The more data you have about one person, or the more people you have\n    that kind of data about, the better the inferences, segmentation, etc.\n  Variety: Knowing location and reading history is more valuable than\n    the sum of the value of either taken separately, knowing the reading history from two sites is\n    of higher value than one, etc.\n  Veracity: Data the correctness of which is better established (including by\n    obtaining it from several places) is more valuable.\n  Velocity: Most of the time, the faster you know the better.\n\nOf these aspects, volume and variety are particularly important: because the value of their sum\n  is greater than the sum of the parts’ values, whoever has more data, especially from more varied\n  sources, will structurally tend to outcompete whoever has less. Because of this, broad\n    sharing of data enables increased returns to scale and scope, leading to dominance,\n    winner-take-all, and competition for the market rather than in the market.\nAnother very interesting source is Competing with Big\n      Data. The authors develop a model in which, under typical situations of broad access\n  to cross-contextual data, data-driven markets will almost always tip. And worse, because this data\n  is already intermixed without respect for context, it can be leveraged into other\n  markets. (Sticking to the Vegas Rule, the power gained from surveilling people in Vegas can be\n  used to increase one's power in Atlantic City.)\nI would like to emphasise again that a clear understanding of privacy is essential to\n  understanding the value of these models. Privacy is grounded in people-centric contexts that exist\n  independently from whatever structures of joint corporate ownership may exist. When Google Chrome\n  sells your data to Google Search, it isn't any less a violation of privacy than when Axciom sells\n  your data to Facebook. The structural competition problems created by the sharing of data across\n  contexts exist equally well in the case of tracking by third parties and in the case of internal\n  sharing by large corporations.\nSuch problems of data sharing across different markets are analysed excellently in Data-driven\n      Envelopment with Privacy-Policy Tying. Condorelli & Padilla build a simple theory\n  in which a firm that has a dominant position in a market where data is key will use the profits\n  from that market to enter one or more secondary data-rich markets and engage in predatory pricing\n  there (often simply opting for free products). In turn, the data from the secondary market will\n  bolster dominance in the primary market, leading to a vicious cycle of entrenchment. They\n  illustrate the structure simply:\nCrucially, this model only works if the firm is able (thanks to technology) and allowed (thanks\n  to law and the practices of its privacy policy) to exploit data captured in one market in another.\n  I find this model particularly appealing because it strongly matches the behaviour of dominant\n  firms in the real world.\nIt's worth noting that in some models, data sharing can be pro-competitive, but you\n  basically have to share all the data. Intuitively, if you nullify the advantages from\n  data collection you eliminate competition issues in data. This works in Competing with Big\n      Data and with the \"Vs\" model too: if everyone has all the data, then there are no\n  structural advantages to volume or variety. Even if the privacy issues weren't insuperable (which\n  they are), building the infrastructure to grant everyone access to all the world's personal data\n  would present a huge challenge.\nAs we can see, there are good reasons to believe that sharing data across contexts creates\n  competition issues — the DAPPER theory seems to hold water, and what's more to match the reality\n  of how dominant firms behave. Is there anything that we can do about this?\nSome Potential Solutions\nMy primary purpose here was to share my own travel through the literature to indicate that,\n  indeed, we have solid reasons to believe that sharing data across contexts creates\n  competition issues and that the Big Knob Theory, while we can learn from it in refusing\n  transparency and choice frameworks, generally seems unfounded. I can, however, share a few\n  pointers towards what I think could be solutions.\nThe first step is that we should pursue strong context silos whenever possible\n  so as to avoid the structural issues that stem from cross-context sharing. One simple policy\n  prescription is to ban third-party data controllers (with perhaps a tiny set of\n  very narrow and strictly enforced exemptions). There is little business benefit to them and they\n  produce great privacy harm. It is important to note that, as per the joint CMA/ICO statement\n  Competition\n      and data protection in digital markets (notably §79), intra-company transfers between\n  different services should be similarly outlawed. CPRA-like regimes should treat different services\n  as different businesses in their definition of \"sale\" as that more accurately reflects reality and\n  privacy impacts.\nAnother important step would be to enforce strongly against self-preferential practices\n    that create differential access to data. I think specifically of cases in which a\n  company uses its operating system, app store, or browser to prevent others from sharing across\n  contexts, but avails itself of data coming from interactions with these systems. This remains a\n  problem when the effects are indirect, for instance observing behaviour on the sites of\n  competitors in the ad market to improve search services. Increasing the scale of the latter is\n  anticompetitive in the former. This would include enforcing The Separation of Platforms\n      and Commerce.\nOf course, building privacy-preserving alternatives (so long as they don't make\n  it possible to exploit data dominance in other ways) to today's data-hungry services can help a\n  lot. More generally, we can consider better ways of structuring data-adjacent markets: instead of\n  pooling all the personal data collected from smaller sites into ever-bigger companies that then\n  gain the ability to outcompete smaller ones, we should set the data market up in such a way that\n  it trades in insights derived locally from the data. This enables greater innovation at\n  the edges by empowering publishers to put their greater local knowledge of their own audiences to\n  work and to monetise that instead of the raw material. This approach strongly aligns competition\n  objectives with improved data protection by severely limiting the need for sharing personal data.\n  It is a key component of several ongoing proposals to reform online advertising, such as\n  Microsoft’s PARAKEET\n  or The New York Times’s GARUDA. (I wrote\n  about a high-level overview of the general idea in Identity\n      isn’t about identifiers – it’s about people.)\nIn order to support strong technical privacy at the edges, where data enters the system, we\n  should deploy a fiduciary regime for all user agents (browsers, operating\n  systems, voice assistants, and many more). See The Fiduciary Duties of\n      User Agents, which I hope to update soon.\nThe details vary, but overall the direction is simple: many of the best competition remedies that\n  we have at our disposal in digital markets are privacy remedies. Whichever way you come at it, the\n  future looks DAPPER.\n\n    \n        ","length":21663,"excerpt":"If you've spent any amount of time discussing reforms to improve privacy online, you've likely encountered the Big Knob Theory. Like Covid it comes in variants, but its core tenet can be summarised thus: there exists (metaphorically) a Big Knob that can either be turned towards \"privacy\" or towards \"competition\" — but it's very much a zero-sum game and you can't have both. It's a popular position; but is it true?","byline":null,"dir":"ltr","siteName":"Robin Berjon","lang":"en"},"finalizedMeta":{"title":"Competition &amp; Privacy: It's Both Or Nothing","description":"If you've spent any amount of time discussing reforms to improve privacy online, you've likely encountered the Big Knob Theory. Like Covid it comes in variants, but its core tenet can be summarised thus: there exists (metaphorically) a Big Knob that can either be turned towards \"privacy\" or towards \"competition\" — but it's very much a zero-sum game and you can't have both. It's a popular position; but is it true?","author":false,"creator":"","publisher":false,"date":"2022-04-05T17:38:37.115Z","topics":[]},"jsonLd":{"@type":false,"headline":false,"description":false,"image":[],"mainEntityOfPage":{"@type":false,"@id":false},"datePublished":false,"dateModified":false,"isAccessibleForFree":false,"isPartOf":{"@type":[],"name":false,"productID":false},"discussionUrl":false,"license":false,"author":{"@type":false,"name":false,"description":false,"sameAs":false,"image":{"@type":false,"url":false},"givenName":false,"familyName":false,"alternateName":false,"publishingPrinciples":false},"publisher":{"@type":false,"name":false,"description":false,"sameAs":false,"logo":{"@type":false,"url":false},"publishingPrinciples":false},"editor":{"@type":false,"name":false,"description":false,"sameAs":false,"image":{"@type":false,"url":false},"givenName":false,"familyName":false,"alternateName":false,"publishingPrinciples":false}},"twitterObj":false,"status":200,"metadata":{"author":false,"title":"Competition & Privacy: It's Both Or Nothing","description":false,"canonical":"https://berjon.com/competition-privacy/","keywords":[],"image":"/competition-privacy/houston.jpg","firstParagraph":"Robin Berjon"},"dublinCore":{},"opengraph":{"title":"Competition &amp; Privacy: It's Both Or Nothing","description":"If you've spent any amount of time discussing reforms to improve privacy online, you've likely encountered the Big Knob Theory. Like Covid it comes in variants, but its core tenet can be summarised thus: there exists (metaphorically) a Big Knob that can either be turned towards \"privacy\" or towards \"competition\" — but it's very much a zero-sum game and you can't have both. It's a popular position; but is it true?","url":"https://berjon.com/competition-privacy/","site_name":"Robin Berjon","locale":"en_UK","type":"blog","typeObject":{"published_time":false,"modified_time":false,"author":false,"publisher":false,"section":false,"tag":[]},"image":"https://berjon.com/competition-privacy/houston.jpg"},"twitter":{"site":"@robinberjon","description":"If you've spent any amount of time discussing reforms to improve privacy online, you've likely encountered the Big Knob Theory. Like Covid it comes in variants, but its core tenet can be summarised thus: there exists (metaphorically) a Big Knob that can either be turned towards \"privacy\" or towards \"competition\" — but it's very much a zero-sum game and you can't have both. It's a popular position; but is it true?","card":"summary_large_image","creator":false,"title":"Competition &amp; Privacy: It's Both Or Nothing","image":"https://berjon.com/competition-privacy/houston.jpg","url":"https://berjon.com/competition-privacy/"},"archivedData":{"link":"https://web.archive.org/web/20220405173903/https://berjon.com/competition-privacy/","wayback":"https://web.archive.org/web/20220405173903/https://berjon.com/competition-privacy/"}}}