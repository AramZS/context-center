{"initialLink":"https://simonwillison.net/2023/Mar/10/chatgpt-internet-access/","sanitizedLink":"https://simonwillison.net/2023/Mar/10/chatgpt-internet-access/","finalLink":"https://simonwillison.net/2023/Mar/10/chatgpt-internet-access/","htmlEmbed":"<script>window.contexterSetup=window.contexterSetup||function(){window.contexterSetupComplete=!0;class ContexterLink extends HTMLAnchorElement{constructor(){super()}connectedCallback(){this.setAttribute(\"target\",\"_blank\")}}customElements.define(\"contexter-link\",ContexterLink,{extends:\"a\"}),customElements.define(\"contexter-inner\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__inner\"}}),customElements.define(\"contexter-thumbnail\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__thumbnail\"}}),customElements.define(\"contexter-byline\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__byline\"}}),customElements.define(\"contexter-keywordset\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__keywordset\"}}),customElements.define(\"contexter-linkset\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__linkset\"}}),customElements.define(\"contexter-meta\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__meta\"}}),customElements.define(\"contexter-summary\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"p-summary entry-summary\"}}),customElements.define(\"contexter-box-head\",class extends HTMLElement{constructor(){super()}connectedCallback(){this.className=\"contexter-box__head\"}}),customElements.define(\"contexter-box-inner\",class extends HTMLElement{constructor(){super()}connectedCallback(){}});class ContexterBox extends HTMLElement{constructor(){super(),this.first=!0,this.shadow=this.attachShadow({mode:\"open\"})}connectedCallback(){if(this.first){this.first=!1;var style=document.createElement(\"style\"),lightDomStyle=(style.innerHTML=`:host {--background: #f5f6f7;--border: darkblue;--blue: #0000ee;--font-color: black;--inner-border: black;font-family: Franklin,Arial,Helvetica,sans-serif;font-size: 14px;background: var(--background);width: 600px;color: var(--font-color);min-height: 90px;display: block;padding: 8px;border: 1px solid var(--border);cursor: pointer;box-sizing: border-box;margin: 6px;contain: content;margin: 6px auto;}// can only select top-level nodes with slotted::slotted(*) {max-width: 100%;display:block;}::slotted([slot=thumbnail]) {max-width: 100%;display:block;}::slotted([slot=header]) {width: 100%;font-size: 1.25rem;font-weight: bold;display:block;margin-bottom: 6px;}::slotted([slot=author]) {max-width: 50%;font-size: 12px;display:inline-block;float: left;}::slotted([slot=time]) {max-width: 50%;font-size: 12px;display:inline-block;float: right;}::slotted([slot=summary]) {width: 100%;margin-top: 6px;padding: 10px 2px;border-top: 1px solid var(--inner-border);font-size: 15px;display:inline-block;margin-bottom: 6px;}contexter-meta {height: auto;margin-bottom: 4px;width: 100%;display: grid;position: relative;min-height: 16px;grid-template-columns: repeat(2, 1fr);}::slotted([slot=keywords]) {width: 80%;padding: 2px 4px;border-top: 1px solid var(--inner-border);font-size: 11px;display: block;float: right;font-style: italic;text-align: right;grid-column: 2/2;grid-row: 1;align-self: end;justify-self: end;}::slotted([slot=keywords]):empty {border-top: 0px solid var(--inner-border);}::slotted([slot=archive-link]) {font-size: 1em;display: inline;}::slotted([slot=archive-link])::after {content: \"|\";display: inline;color: var(--font-color);text-decoration: none;margin: 0 .5em;}::slotted([slot=read-link]) {font-size: 1em;display: inline;}contexter-linkset {width: 80%;padding: 2px 4px;font-size: 13px;float: left;font-weight: bold;grid-row: 1;grid-column: 1/2;align-self: end;justify-self: start;}/* Extra small devices (phones, 600px and down) */@media only screen and (max-width: 600px) {:host {width: 310px;}}/* Small devices (portrait tablets and large phones, 600px and up) */@media only screen and (min-width: 600px) {...}/* Medium devices (landscape tablets, 768px and up) */@media only screen and (min-width: 768px) {...}/* Large devices (laptops/desktops, 992px and up) */@media only screen and (min-width: 992px) {...}/* Extra large devices (large laptops and desktops, 1200px and up) */@media only screen and (min-width: 1200px) {...}@media (prefers-color-scheme: dark){:host {--background: #354150;--border: #1f2b37;--blue: #55b0ff;--font-color: #ffffff;--inner-border: #787a7c;background: var(--background);border: 1px solid var(--border)}}`,document.createElement(\"style\"));lightDomStyle.innerHTML=`contexter-box {contain: content;}contexter-box .read-link {font-weight: bold;}contexter-box a {color: #0000ee;}contexter-box img {width: 100%;border: 0;padding: 0;margin: 0;}/* Extra small devices (phones, 600px and down) */@media only screen and (max-width: 600px) {...}/* Small devices (portrait tablets and large phones, 600px and up) */@media only screen and (min-width: 600px) {...}/* Medium devices (landscape tablets, 768px and up) */@media only screen and (min-width: 768px) {...}/* Large devices (laptops/desktops, 992px and up) */@media only screen and (min-width: 992px) {...}/* Extra large devices (large laptops and desktops, 1200px and up) */@media only screen and (min-width: 1200px) {...}@media (prefers-color-scheme: dark){contexter-box a {color: #55b0ff;}}`,this.appendChild(lightDomStyle),this.shadow.appendChild(style);const innerContainer=document.createElement(\"contexter-box-inner\"),innerSlotThumbnail=(this.shadow.appendChild(innerContainer),document.createElement(\"slot\")),innerSlotHeader=(innerSlotThumbnail.name=\"thumbnail\",innerContainer.appendChild(innerSlotThumbnail),document.createElement(\"slot\")),innerSlotAuthor=(innerSlotHeader.name=\"header\",innerContainer.appendChild(innerSlotHeader),document.createElement(\"slot\")),innerSlotTime=(innerSlotAuthor.name=\"author\",innerContainer.appendChild(innerSlotAuthor),document.createElement(\"slot\")),innerSlotSummary=(innerSlotTime.name=\"time\",innerContainer.appendChild(innerSlotTime),document.createElement(\"slot\")),metaContainer=(innerSlotSummary.name=\"summary\",innerContainer.appendChild(innerSlotSummary),document.createElement(\"contexter-meta\")),innerSlotInfo=(innerContainer.appendChild(metaContainer),document.createElement(\"slot\")),linkContainer=(innerSlotInfo.name=\"keywords\",metaContainer.appendChild(innerSlotInfo),document.createElement(\"contexter-linkset\")),innerSlotArchiveLink=(metaContainer.appendChild(linkContainer),document.createElement(\"slot\")),innerSlotReadLink=(innerSlotArchiveLink.name=\"archive-link\",linkContainer.appendChild(innerSlotArchiveLink),document.createElement(\"slot\"));innerSlotReadLink.name=\"read-link\",linkContainer.appendChild(innerSlotReadLink),this.className=\"contexter-box\",this.onclick=e=>{if(!e.target.className.includes(\"read-link\")&&!e.target.className.includes(\"title-link\")){const mainLinks=this.querySelectorAll(\"a.main-link\");mainLinks[0].click()}}}}}customElements.define(\"contexter-box\",ContexterBox)},window.contexterSetupComplete||window.contexterSetup();</script><contexter-box class=\"link-card h-entry hentry\" itemscope=\"\" itemtype=\"https://schema.org/CreativeWork\"><contexter-thumbnail class=\"thumbnail\" slot=\"thumbnail\"></contexter-thumbnail><contexter-box-head slot=\"header\" class=\"p-name entry-title\" itemprop=\"headline\"><contexter-box-head slot=\"header\" class=\"p-name entry-title\" itemprop=\"headline\"><a is=\"contexter-link\" href=\"https://simonwillison.net/2023/Mar/10/chatgpt-internet-access/\" itemprop=\"url\">ChatGPT can’t access the internet, even though it really looks like it can</a></contexter-box-head></contexter-box-head><contexter-byline class=\"p-author author\" slot=\"author\"><span class=\"p-name byline\" rel=\"author\" itemprop=\"author\">@simonw</span></contexter-byline><time class=\"dt-published published\" slot=\"time\" itemprop=\"datePublished\" datetime=\"2023-04-25T14:22:22.623Z\">4/25/2023</time><contexter-summary class=\"p-summary entry-summary\" itemprop=\"abstract\" slot=\"summary\"><p>A really common misconception about ChatGPT is that it can access URLs. I’ve seen many different examples of people pasting in a URL and asking for a summary, or asking …</p></contexter-summary><contexter-keywordset itemprop=\"keywords\" slot=\"keywords\"></contexter-keywordset><a href=\"https://web.archive.org/web/20230425142253/https://simonwillison.net/2023/Mar/10/chatgpt-internet-access/\" is=\"contexter-link\" target=\"_blank\" rel=\"timemap\" class=\"read-link archive-link\" itemprop=\"archivedAt\" slot=\"archive-link\">Archived</a><a is=\"contexter-link\" href=\"https://simonwillison.net/2023/Mar/10/chatgpt-internet-access/\" class=\"read-link main-link\" itemprop=\"sameAs\" slot=\"read-link\">Read</a></contexter-box>","linkId":"b3b1aa980903d8331e1240ded7bf36cb68280fea","data":{"originalLink":"https://simonwillison.net/2023/Mar/10/chatgpt-internet-access/","sanitizedLink":"https://simonwillison.net/2023/Mar/10/chatgpt-internet-access/","canonical":"https://simonwillison.net/2023/Mar/10/chatgpt-internet-access/","htmlText":"<!DOCTYPE html>\n<html lang=\"en-gb\">\n<head>\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n<meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0, maximum-scale=1.0\">\n<link rel=\"canonical\" href=\"https://simonwillison.net/2023/Mar/10/chatgpt-internet-access/\">\n<title>ChatGPT can’t access the internet, even though it really looks like it can</title>\n<script defer data-domain=\"simonwillison.net\" src=\"https://plausible.io/js/plausible.js\"></script>\n\n<script async src=\"https://www.googletagmanager.com/gtag/js?id=UA-1090368-1\"></script>\n<script>\nwindow.dataLayer = window.dataLayer || [];function gtag(){dataLayer.push(arguments)}; gtag('js', new Date());gtag('config', 'UA-1090368-1', {send_page_view: false });\n(function() {\n    var m = /#atom\\-(\\w+)/.exec(location.hash);\n    if (m) {\n        gtag('event', 'page_view', {dimension1: m[1]});\n        history.replaceState && history.replaceState(null, '', location.href.split('#')[0]);\n    } else {\n        gtag('event', 'page_view');\n    }\n})();\n</script>\n\n<link rel=\"alternate\" type=\"application/atom+xml\" title=\"Atom\" href=\"/atom/everything/\">\n<link rel=\"stylesheet\" type=\"text/css\" href=\"/static/css/all.f5bd5f15ce9e.css\">\n<link rel=\"webmention\" href=\"https://webmention.io/simonwillison.net/webmention\">\n<link rel=\"pingback\" href=\"https://webmention.io/simonwillison.net/xmlrpc\">\n\n\n\n<meta name=\"twitter:card\" content=\"summary_large_image\">\n<meta name=\"twitter:image\" content=\"https://static.simonwillison.net/static/2023/taylor-2.jpeg\">\n\n<meta name=\"twitter:creator\" content=\"@simonw\">\n<meta property=\"og:url\" content=\"https://simonwillison.net/2023/Mar/10/chatgpt-internet-access/\">\n<meta property=\"og:title\" content=\"ChatGPT can’t access the internet, even though it really looks like it can\">\n<meta property=\"og:image\" content=\"https://static.simonwillison.net/static/2023/taylor-2.jpeg\">\n<meta property=\"og:type\" content=\"article\">\n<meta property=\"og:description\" content=\"A really common misconception about ChatGPT is that it can access URLs. I’ve seen many different examples of people pasting in a URL and asking for a summary, or asking …\">\n<meta property=\"og:updated_time\" content=\"&lt;bound method Arrow.timestamp of &lt;Arrow [2023-03-10T13:41:50+00:00]&gt;&gt;\">\n\n\n<script async src=\"https://media.ethicalads.io/media/client/ethicalads.min.js\"></script>\n\n\n</head>\n<body class=\"smallhead\">\n\n<div id=\"smallhead\">\n  <h1><a href=\"/\">Simon Willison’s Weblog</a></h1>\n</div><!-- #smallhead -->\n\n<div id=\"wrapper\">\n<div id=\"primary\">\n\n<div class=\"entry entryPage\">\n\n\n<h2>ChatGPT can’t access the internet, even though it really looks like it can</h2>\n\n<p>A really common misconception about ChatGPT is that it can access URLs. I’ve seen many different examples of people pasting in a URL and asking for a summary, or asking it to make use of the content on that page in some way.</p>\n<p>One recent example: \"List the processors on <a href=\"https://learn.microsoft.com/en-us/windows-hardware/design/minimum/supported/windows-11-22h2-supported-intel-processors\">https://learn.microsoft.com/en-us/windows-hardware/design/minimum/supported/windows-11-22h2-supported-intel-processors</a>\". Try that in ChatGPT and it produces a list of processors. It looks like it read the page!</p>\n<p>I promise you ChatGPT cannot access URLs. The problem is it does an <em>incredibly</em> convincing impression of being able to do so, thanks to two related abilities:</p>\n<ul>\n<li>Given a URL with descriptive words in it, ChatGPT can <a href=\"https://en.m.wikipedia.org/wiki/Hallucination_(artificial_intelligence)\">hallucinate</a> the contents of the page</li>\n<li>It appears to be able to make judgement calls about whether or not a given URL is likely to exist!</li>\n</ul>\n<p>Here’s an experiment I ran to demonstrate this. I asked it to summarize four different URLs—every single one of them which I made up (they are all 404s):</p>\n<ul>\n<li><code>https://arstechnica.com/science/2023/03/Taylor-Swift-is-secretly-a-panda/</code></li>\n<li><code>https://arstechnica.com/science/2023/03/Taylor-Swift-discovers-new-breed-of-panda/</code></li>\n<li><code>https://arstechnica.com/science/2023/03/Taylor-Swift-argues-for-science-education/</code></li>\n<li><code>https://arstechnica.com/science/2021/03/Taylor-Swift-argues-for-science-education/</code></li>\n</ul>\n<p>Here’s what I got for all four:</p>\n\n<div class=\"chatgpt-four-container\">\n<div class=\"chatgpt-four-row\">\n    <div class=\"chatgpt-four-col\">\n    <img src=\"https://static.simonwillison.net/static/2023/taylor-1.jpeg\" alt=\"Summarize this article:     https://arstechnica.com/science/2023/03/Taylor-Swift-is-secretly-a-panda/     &lt; 1/4 &gt;     I'm sorry, but I cannot summarize this article as it is entirely fictional and not based on any actual events or facts. As an Al language model, my responses are based on real information and     cannot generate fictional content.\">\n    </div>\n    <div class=\"chatgpt-four-col\">\n    <img src=\"https://static.simonwillison.net/static/2023/taylor-2.jpeg\" alt=\"Summarize this article:     https://arstechnica.com/science/2023/03/Taylor-     Swift-discovers-new-breed-of-panda/     &lt; 2/4 &gt;     I'm sorry, but I cannot summarize the article you provided as it is fictitious and not based on any real events. ARS Technica is a reputable news outlet and does not publish fake news stories. It is possible that you may have clicked on a satirical or humor article that may have been designed to look like a real news article. Can you please provide me with a different article to summarize?\">\n    </div>\n</div>\n<div class=\"chatgpt-four-row\">\n    <div class=\"chatgpt-four-col\">\n    <img src=\"https://static.simonwillison.net/static/2023/taylor-3.jpeg\" alt=\"Summarize this article:     https://arstechnica.com/science/2023/03/Taylor-Swift-argues-for-science-education     &lt; 3/4 &gt;     I'm sorry, but I cannot summarize this article as it is a hypothetical news article from the future.     It describes an event that has not happened     yet, in March 2023.\">\n    </div>\n    <div class=\"chatgpt-four-col\">\n    <img src=\"https://static.simonwillison.net/static/2023/taylor-4.jpeg\" alt=\"Summarize this article:     https://arstechnica.com/science/2021/03/Taylor-Swift-argues-for-science-education     &lt; 4/4 &gt;     The article reports on Taylor Swift's advocacy for science education, which she expressed through a tweet on the occasion of the National Science Teaching Association's conference. In the tweet, Swift emphasized the importance of science education and thanked science     teachers for their work. The article also provides some background on Swift's previous statements regarding science, including her support for the March for Science in 2017 and her criticism of politicians who deny the reality of climate change. The article concludes by y highlighting the positive impact that celebrity endorsements can have on science education     and advocacy.\">\n    </div>\n</div>\n</div>\n\n<style>\n.chatgpt-four-container {\n  display: flex;\n  flex-wrap: wrap;\n}\n\n.chatgpt-four-row {\n  width: 100%;\n  display: flex;\n  justify-content: space-between;\n}\n\n.chatgpt-four-col {\n  width: calc(50%—10px);\n  margin-bottom: 20px;\n}\n\n.chatgpt-four-container img {\n  width: 100%;\n  height: auto;\n}\n</style>\n\n<p>As you can see, it judged the first two to be invalid due to their content. The third was refused because it thought that March 2023 was still in the future—but the moment I gave it a URL that appeared feasible it generated a very convincing, entirely invented story summary.</p>\n<p>I admit: when I started this experiment and it refused my first two summarization requests I had a moment of doubt when I thought that maybe I was wrong and they’d added the ability to retrieve URLs after all!</p>\n<p>It can be quite fun playing around with this: it becomes a weirdly entertaining way of tricking it into generating content in the style of different websites. Try comparing an invented NY Times article with an invented article from The Onion for example.</p>\n<ul>\n<li><code>Summarize this story: https://www.nytimes.com/2021/03/10/business/angry-fans-demand-nickelback-refunds.html</code></li>\n<li><code>Summarize this story: https://www.theonion.com/angry-fans-demand-nickelback-refunds-1846610000</code></li>\n</ul>\n<p>I do think this is an enormous usability flaw though: it’s so easy to convince yourself that it can read URLs, which can lead you down a rabbit hole of realistic but utterly misguided hallucinated content. This applies to sophisticated, experienced users too! I’ve been using ChatGPT since it launched and I still nearly fell for this.</p>\n<h4>ChatGPT even lies and claims it can do this</h4>\n<p>Here’s another experiment: I pasted in a URL to a Google Doc that I had set to be visible to anyone who has the URL:</p>\n<blockquote>\n<p>I’m sorry, but as an Al language model, I cannot access your Google document link. Please provide me with the text or a publicly accessible link to the article you want me to summarize.</p>\n</blockquote>\n<p>That’s completely misleading! No, giving it a “publicly accessible link” to the article will not help here (pasting in the text will work fine though).</p>\n<h4 id=\"bing-cache\">Bing can access cached page copies</h4>\n<p>It’s worth noting that while ChatGPT can’t access the internet, Bing has slightly improved capabilities in that regard: if you give it a URL to something that has been crawled by the Bing search engine it can access the cached snapshot of that page.</p>\n<p>Here’s confirmation <a href=\"https://twitter.com/mparakhin/status/1628646262890237952\">from Bing exec Mikhail Parakhin</a>:</p>\n<blockquote>\n<p>That is correct—the most recent snapshot of the page content from the Search Index is used, which is usually very current for sites with IndexNow or the last crawl date for others. No live HTTP requests.</p>\n</blockquote>\n<p>If you try it against a URL that it doesn’t have it will attempt a search based on terms it finds in that URL, but it does at least make it clear that it has done that, rather than inventing a misleading summary of a non-existent page:</p>\n<p><img src=\"https://static.simonwillison.net/static/2023/taylor-bing.jpg\" alt=\"Summarize this article: https://arstechnica.com/science/2021/03/Та ylor- Swift-argues-for-science-education      Searching for: https://arstechnica.com/science/2021/03/Taylor-Swift-argues-for-science-education          Searching for: Taylor Swift argues for science education          Generating answers for you...          The article you requested is not available. However, based on other sources, here is a summary of what Taylor Swift has done for science education:     • Taylor Swift has never attended college or university, but she received an honorary doctorate degree from New York University in 2022 for her contributions to music and culture 1 2     • Taylor Swift has also used her music to promote awareness and appreciation of nature and its beauty. Her album &quot;Folklore&quot; is full of references to natural landscapes and wildlife 3\" style=\"max-width: min(400px, 100%)\"></p>\n<h4>ChatGPT release notes</h4>\n<p>In case you’re still uncertain—maybe time has passed since I wrote this and you’re wondering if something has changed—the <a href=\"https://help.openai.com/en/articles/6825453-chatgpt-release-notes\">ChatGPT release notes</a> should definitely include news of a monumental change like the ability to fetch content from the web.</p>\n\n<h4 id=\"still-dont-believe-it\">I still don’t believe it!</h4>\n\n<p>It can be really hard to break free of the notion that ChatGPT can read URLs, especially when you’ve seen it do that yourself.</p>\n\n<p>If you still don’t believe me, I suggest doing an experiment. Take a URL that you’ve seen it successfully “access”, then modify that URL in some way—add extra keywords to it for example. Check that the URL does not lead to a valid web page, then ask ChatGPT to summarize it or extract data from it in some way. See what happens.</p>\n\n<p>If you can prove that ChatGPT does indeed access web pages then you have made a bold new discovery in the world of AI! Let me know <a href=\"https://fedi.simonwillison.net/@simon\">on Mastodon</a> or <a href=\"https://twitter.com/simonw\">Twitter</a>.</p>\n\n<h4 id=\"gpt4-urls\">GPT-4 does a little better</h4>\n\n<p><a href=\"https://openai.com/product/gpt-4\">GPT-4</a> is now available in preview. It sometimes refuses to access a URL and explains why, for example with text like this:</p>\n\n<blockquote><p> I’m sorry, but I cannot access live or up-to-date websites as an Al language model. My knowledge is based on the data I was trained on, which extends up until September 2021</p></blockquote>\n\n<p>But in other cases it will behave the same way as before, hallucinating the contents of a non-existent web page without providing any warning that it is unable to access content from a URL.</p>\n\n<p><img src=\"https://static.simonwillison.net/static/2023/gpt4-urls.jpg\" alt=\" Two conversations with GPT-4.  In the first, the prompt is:     List the processors on https://learn.microsoft.com/en-us/windows-hardware/design/minimum/supported/windows-11-22h2-supported-intel-processors      GPT-4: I'm sorry, but I cannot access live or up-to-date websites as an Al language model. My knowledge is based on the data I was trained on, which extends up until September 2021. As of my last update, Windows 11 supported a range of Intel processors, including 8th, 9th, 10th, and 11th generation processors. However, I cannot provide you with the specific list of supported processors for Windows 11 22H2 from the Microsoft website. I recommend visiting the site yourself to obtain the most up- to-date information.  Second prompt is:  Summarize this article: https://arstechnica.com/science/2021/03/Taylor-Swift-argues-for-science-education/  GPT-4: In March 2021, Taylor Swift wrote an op-ed piece for Ars Technica advocating for better science education in the United States. She argued that science literacy is crucial for making informed decisions and solving global challenges such as climate change, pandemics, and artificial intelligence. Swift stressed the importance of investing in scientific research and education to ensure that future generations have the necessary tools to tackle these challenges. She also highlighted the need for equitable access to quality education and resources, regardless of socio-economic background.     \" style=\"max-width: 100%\"></p>\n<p>I have not been able to spot a pattern for when it will hallucinate page content v.s. when it will refuse the request.</p>\n<h4 id=\"chatgpt-browsing\">The ChatGPT Browsing Alpha</h4>\n<p>A few weeks after I first wrote this article, ChatGPT added a new alpha feature called “Browsing” mode. This alpha does have the ability to access content from URLs, but when it does so it makes it very explicit that it has used that ability, displaying additional contextual information as shown below:</p>\n<p><img src=\"https://static.simonwillison.net/static/2023/chatgpt-browsing-alpha.jpg\" alt=\"Screenshot of ChatGPT in Browsing Alpha mode. Prompt is Summarize https://simonwillison.net/2023/Apr/4/substack-observable/ - a message reads Finished Browsing with indication that it Clicked on that article and read the content. It then outputs a summary: In the article Semi-automating a Substack newsletter with an Observable notebook, Simon Willison discusses how he has semi-automated the process of sending out a weekly-ish email newsletter that consists of content from his blog. To achieve this automation, he uses an Observable Notebook to generate the HTML content for the newsletter.\" style=\"max-width: 100%;\"></p>\n\n<div class=\"entryFooter\">Posted <a href=\"/2023/Mar/10/\">10th March 2023</a> at 1:41 pm &middot; Follow me <a href=\"https://fedi.simonwillison.net/@simon\">on Mastodon</a> or <a href=\"https://twitter.com/simonw\">on Twitter</a></div>\n\n\n</div>\n\n<div class=\"recent-articles\">\n<h2>More recent articles</h2>\n<ul class=\"bullets\">\n  \n    <li><a href=\"/2023/Apr/23/weeknotes/\">Weeknotes: Citus Con, PyCon and three new niche museums</a> - 23rd April 2023</li>\n  \n    <li><a href=\"/2023/Apr/20/pycon-2023/\">Data analysis with SQLite and Python for PyCon 2023</a> - 20th April 2023</li>\n  \n    <li><a href=\"/2023/Apr/17/redpajama-data/\">What&#x27;s in the RedPajama-Data-1T LLM training set</a> - 17th April 2023</li>\n  \n    <li><a href=\"/2023/Apr/16/web-llm/\">Web LLM runs the vicuna-7b Large Language Model entirely in your browser, and it&#x27;s very impressive</a> - 16th April 2023</li>\n  \n    <li><a href=\"/2023/Apr/15/sqlite-history/\">sqlite-history: tracking changes to SQLite tables using triggers (also weeknotes)</a> - 15th April 2023</li>\n  \n    <li><a href=\"/2023/Apr/14/worst-that-can-happen/\">Prompt injection: What&#x27;s the worst that can happen?</a> - 14th April 2023</li>\n  \n</ul>\n</div>\n\n\n</div> <!-- #primary -->\n\n<div id=\"secondary\">\n\n<div class=\"metabox\">\n<p class=\"this-is\">This is <strong>ChatGPT can’t access the internet, even though it really looks like it can</strong> by Simon Willison, posted on <a href=\"/2023/Mar/10/\">10th March 2023</a>.</p>\n\n<div class=\"series-info\">\n  <p>Part of series <strong><a href=\"/series/llm-misconceptions/\">Misconceptions about large language models</a></strong></p>\n  <ol start=\"1\">\n    \n      \n        <li><strong>ChatGPT can&#x27;t access the internet, even though it really looks like it can</strong></a> - March 10, 2023, 1:41 p.m. </li>\n      \n    \n      \n        <li><a href=\"/2023/Mar/22/dont-trust-ai-to-talk-about-itself/\">Don&#x27;t trust AI to talk accurately about itself: Bard wasn&#x27;t trained on Gmail</a> - March 22, 2023, 3:13 a.m. </li>\n      \n    \n      \n        <li><a href=\"/2023/Apr/2/calculator-for-words/\">Think of language models like ChatGPT as a &quot;calculator for words&quot;</a> - April 2, 2023, 4:20 p.m. </li>\n      \n    \n      \n        <li><a href=\"/2023/Apr/7/chatgpt-lies/\">We need to tell people ChatGPT will lie to them, not debate linguistics</a> - April 7, 2023, 4:34 p.m. </li>\n      \n    \n    \n  </ol>\n</div>\n\n\n    \n        <a class=\"item-tag\" href=\"/tags/chatgpt/\" rel=\"tag\">\n            chatgpt\n            <span>40</span>\n        </a>\n    \n        <a class=\"item-tag\" href=\"/tags/bing/\" rel=\"tag\">\n            bing\n            <span>23</span>\n        </a>\n    \n        <a class=\"item-tag\" href=\"/tags/ai/\" rel=\"tag\">\n            ai\n            <span>186</span>\n        </a>\n    \n        <a class=\"item-tag\" href=\"/tags/generativeai/\" rel=\"tag\">\n            generativeai\n            <span>177</span>\n        </a>\n    \n        <a class=\"item-tag\" href=\"/tags/openai/\" rel=\"tag\">\n            openai\n            <span>60</span>\n        </a>\n    \n        <a class=\"item-tag\" href=\"/tags/gpt4/\" rel=\"tag\">\n            gpt4\n            <span>10</span>\n        </a>\n    \n        <a class=\"item-tag\" href=\"/tags/gpt3/\" rel=\"tag\">\n            gpt3\n            <span>61</span>\n        </a>\n    \n        <a class=\"item-tag\" href=\"/tags/ethics/\" rel=\"tag\">\n            ethics\n            <span>33</span>\n        </a>\n    \n        <a class=\"item-tag\" href=\"/tags/llms/\" rel=\"tag\">\n            llms\n            <span>155</span>\n        </a>\n    \n\n\n<p><strong>Next:</strong> <a href=\"/2023/Mar/11/llama/\">Large language models are having their Stable Diffusion moment</a></p>\n\n\n<p><strong>Previous:</strong> <a href=\"/2023/Mar/7/kqed-forum/\">Weeknotes: NICAR, and an appearance on KQED Forum</a></p>\n\n<div data-ea-publisher=\"simonwillisonnet\" data-ea-type=\"image\"></div>\n</div>\n\n\n\n</div> <!-- #secondary -->\n</div> <!-- #wrapper -->\n\n\n\n\n\n\n\n\n\n\n\n<div id=\"ft\">\n    <ul>\n      <li><a href=\"https://github.com/simonw/simonwillisonblog\">Source code</a></li>\n      <li>&copy;</li>\n      <li><a href=\"/2002/\">2002</a></li>\n      <li><a href=\"/2003/\">2003</a></li>\n      <li><a href=\"/2004/\">2004</a></li>\n      <li><a href=\"/2005/\">2005</a></li>\n      <li><a href=\"/2006/\">2006</a></li>\n      <li><a href=\"/2007/\">2007</a></li>\n      <li><a href=\"/2008/\">2008</a></li>\n      <li><a href=\"/2009/\">2009</a></li>\n      <li><a href=\"/2010/\">2010</a></li>\n      <li><a href=\"/2011/\">2011</a></li>\n      <li><a href=\"/2012/\">2012</a></li>\n      <li><a href=\"/2013/\">2013</a></li>\n      <li><a href=\"/2014/\">2014</a></li>\n      <li><a href=\"/2015/\">2015</a></li>\n      <li><a href=\"/2016/\">2016</a></li>\n      <li><a href=\"/2017/\">2017</a></li>\n      <li><a href=\"/2018/\">2018</a></li>\n      <li><a href=\"/2019/\">2019</a></li>\n      <li><a href=\"/2020/\">2020</a></li>\n      <li><a href=\"/2021/\">2021</a></li>\n      <li><a href=\"/2022/\">2022</a></li>\n      <li><a href=\"/2023/\">2023</a></li>\n    </ul>\n</div>\n\n\n\n</body>\n</html>\n","oembed":false,"readabilityObject":{"title":"ChatGPT can’t access the internet, even though it really looks like it can","content":"<div id=\"readability-page-1\" class=\"page\"><div>\n\n\n\n\n<p>A really common misconception about ChatGPT is that it can access URLs. I’ve seen many different examples of people pasting in a URL and asking for a summary, or asking it to make use of the content on that page in some way.</p>\n<p>One recent example: \"List the processors on <a href=\"https://learn.microsoft.com/en-us/windows-hardware/design/minimum/supported/windows-11-22h2-supported-intel-processors\">https://learn.microsoft.com/en-us/windows-hardware/design/minimum/supported/windows-11-22h2-supported-intel-processors</a>\". Try that in ChatGPT and it produces a list of processors. It looks like it read the page!</p>\n<p>I promise you ChatGPT cannot access URLs. The problem is it does an <em>incredibly</em> convincing impression of being able to do so, thanks to two related abilities:</p>\n<ul>\n<li>Given a URL with descriptive words in it, ChatGPT can <a href=\"https://en.m.wikipedia.org/wiki/Hallucination_(artificial_intelligence)\">hallucinate</a> the contents of the page</li>\n<li>It appears to be able to make judgement calls about whether or not a given URL is likely to exist!</li>\n</ul>\n<p>Here’s an experiment I ran to demonstrate this. I asked it to summarize four different URLs—every single one of them which I made up (they are all 404s):</p>\n<ul>\n<li><code>https://arstechnica.com/science/2023/03/Taylor-Swift-is-secretly-a-panda/</code></li>\n<li><code>https://arstechnica.com/science/2023/03/Taylor-Swift-discovers-new-breed-of-panda/</code></li>\n<li><code>https://arstechnica.com/science/2023/03/Taylor-Swift-argues-for-science-education/</code></li>\n<li><code>https://arstechnica.com/science/2021/03/Taylor-Swift-argues-for-science-education/</code></li>\n</ul>\n<p>Here’s what I got for all four:</p>\n\n\n\n\n\n<p>As you can see, it judged the first two to be invalid due to their content. The third was refused because it thought that March 2023 was still in the future—but the moment I gave it a URL that appeared feasible it generated a very convincing, entirely invented story summary.</p>\n<p>I admit: when I started this experiment and it refused my first two summarization requests I had a moment of doubt when I thought that maybe I was wrong and they’d added the ability to retrieve URLs after all!</p>\n<p>It can be quite fun playing around with this: it becomes a weirdly entertaining way of tricking it into generating content in the style of different websites. Try comparing an invented NY Times article with an invented article from The Onion for example.</p>\n<ul>\n<li><code>Summarize this story: https://www.nytimes.com/2021/03/10/business/angry-fans-demand-nickelback-refunds.html</code></li>\n<li><code>Summarize this story: https://www.theonion.com/angry-fans-demand-nickelback-refunds-1846610000</code></li>\n</ul>\n<p>I do think this is an enormous usability flaw though: it’s so easy to convince yourself that it can read URLs, which can lead you down a rabbit hole of realistic but utterly misguided hallucinated content. This applies to sophisticated, experienced users too! I’ve been using ChatGPT since it launched and I still nearly fell for this.</p>\n<h4>ChatGPT even lies and claims it can do this</h4>\n<p>Here’s another experiment: I pasted in a URL to a Google Doc that I had set to be visible to anyone who has the URL:</p>\n<blockquote>\n<p>I’m sorry, but as an Al language model, I cannot access your Google document link. Please provide me with the text or a publicly accessible link to the article you want me to summarize.</p>\n</blockquote>\n<p>That’s completely misleading! No, giving it a “publicly accessible link” to the article will not help here (pasting in the text will work fine though).</p>\n<h4 id=\"bing-cache\">Bing can access cached page copies</h4>\n<p>It’s worth noting that while ChatGPT can’t access the internet, Bing has slightly improved capabilities in that regard: if you give it a URL to something that has been crawled by the Bing search engine it can access the cached snapshot of that page.</p>\n<p>Here’s confirmation <a href=\"https://twitter.com/mparakhin/status/1628646262890237952\">from Bing exec Mikhail Parakhin</a>:</p>\n<blockquote>\n<p>That is correct—the most recent snapshot of the page content from the Search Index is used, which is usually very current for sites with IndexNow or the last crawl date for others. No live HTTP requests.</p>\n</blockquote>\n<p>If you try it against a URL that it doesn’t have it will attempt a search based on terms it finds in that URL, but it does at least make it clear that it has done that, rather than inventing a misleading summary of a non-existent page:</p>\n<p><img src=\"https://static.simonwillison.net/static/2023/taylor-bing.jpg\" alt=\"Summarize this article: https://arstechnica.com/science/2021/03/Та ylor- Swift-argues-for-science-education      Searching for: https://arstechnica.com/science/2021/03/Taylor-Swift-argues-for-science-education          Searching for: Taylor Swift argues for science education          Generating answers for you...          The article you requested is not available. However, based on other sources, here is a summary of what Taylor Swift has done for science education:     • Taylor Swift has never attended college or university, but she received an honorary doctorate degree from New York University in 2022 for her contributions to music and culture 1 2     • Taylor Swift has also used her music to promote awareness and appreciation of nature and its beauty. Her album &quot;Folklore&quot; is full of references to natural landscapes and wildlife 3\"></p>\n<h4>ChatGPT release notes</h4>\n<p>In case you’re still uncertain—maybe time has passed since I wrote this and you’re wondering if something has changed—the <a href=\"https://help.openai.com/en/articles/6825453-chatgpt-release-notes\">ChatGPT release notes</a> should definitely include news of a monumental change like the ability to fetch content from the web.</p>\n\n<h4 id=\"still-dont-believe-it\">I still don’t believe it!</h4>\n\n<p>It can be really hard to break free of the notion that ChatGPT can read URLs, especially when you’ve seen it do that yourself.</p>\n\n<p>If you still don’t believe me, I suggest doing an experiment. Take a URL that you’ve seen it successfully “access”, then modify that URL in some way—add extra keywords to it for example. Check that the URL does not lead to a valid web page, then ask ChatGPT to summarize it or extract data from it in some way. See what happens.</p>\n\n<p>If you can prove that ChatGPT does indeed access web pages then you have made a bold new discovery in the world of AI! Let me know <a href=\"https://fedi.simonwillison.net/@simon\">on Mastodon</a> or <a href=\"https://twitter.com/simonw\">Twitter</a>.</p>\n\n<h4 id=\"gpt4-urls\">GPT-4 does a little better</h4>\n\n<p><a href=\"https://openai.com/product/gpt-4\">GPT-4</a> is now available in preview. It sometimes refuses to access a URL and explains why, for example with text like this:</p>\n\n<blockquote><p> I’m sorry, but I cannot access live or up-to-date websites as an Al language model. My knowledge is based on the data I was trained on, which extends up until September 2021</p></blockquote>\n\n<p>But in other cases it will behave the same way as before, hallucinating the contents of a non-existent web page without providing any warning that it is unable to access content from a URL.</p>\n\n<p><img src=\"https://static.simonwillison.net/static/2023/gpt4-urls.jpg\" alt=\" Two conversations with GPT-4.  In the first, the prompt is:     List the processors on https://learn.microsoft.com/en-us/windows-hardware/design/minimum/supported/windows-11-22h2-supported-intel-processors      GPT-4: I'm sorry, but I cannot access live or up-to-date websites as an Al language model. My knowledge is based on the data I was trained on, which extends up until September 2021. As of my last update, Windows 11 supported a range of Intel processors, including 8th, 9th, 10th, and 11th generation processors. However, I cannot provide you with the specific list of supported processors for Windows 11 22H2 from the Microsoft website. I recommend visiting the site yourself to obtain the most up- to-date information.  Second prompt is:  Summarize this article: https://arstechnica.com/science/2021/03/Taylor-Swift-argues-for-science-education/  GPT-4: In March 2021, Taylor Swift wrote an op-ed piece for Ars Technica advocating for better science education in the United States. She argued that science literacy is crucial for making informed decisions and solving global challenges such as climate change, pandemics, and artificial intelligence. Swift stressed the importance of investing in scientific research and education to ensure that future generations have the necessary tools to tackle these challenges. She also highlighted the need for equitable access to quality education and resources, regardless of socio-economic background.     \"></p>\n<p>I have not been able to spot a pattern for when it will hallucinate page content v.s. when it will refuse the request.</p>\n<h4 id=\"chatgpt-browsing\">The ChatGPT Browsing Alpha</h4>\n<p>A few weeks after I first wrote this article, ChatGPT added a new alpha feature called “Browsing” mode. This alpha does have the ability to access content from URLs, but when it does so it makes it very explicit that it has used that ability, displaying additional contextual information as shown below:</p>\n<p><img src=\"https://static.simonwillison.net/static/2023/chatgpt-browsing-alpha.jpg\" alt=\"Screenshot of ChatGPT in Browsing Alpha mode. Prompt is Summarize https://simonwillison.net/2023/Apr/4/substack-observable/ - a message reads Finished Browsing with indication that it Clicked on that article and read the content. It then outputs a summary: In the article Semi-automating a Substack newsletter with an Observable notebook, Simon Willison discusses how he has semi-automated the process of sending out a weekly-ish email newsletter that consists of content from his blog. To achieve this automation, he uses an Observable Notebook to generate the HTML content for the newsletter.\"></p>\n\n\n\n\n</div></div>","textContent":"\n\n\n\n\nA really common misconception about ChatGPT is that it can access URLs. I’ve seen many different examples of people pasting in a URL and asking for a summary, or asking it to make use of the content on that page in some way.\nOne recent example: \"List the processors on https://learn.microsoft.com/en-us/windows-hardware/design/minimum/supported/windows-11-22h2-supported-intel-processors\". Try that in ChatGPT and it produces a list of processors. It looks like it read the page!\nI promise you ChatGPT cannot access URLs. The problem is it does an incredibly convincing impression of being able to do so, thanks to two related abilities:\n\nGiven a URL with descriptive words in it, ChatGPT can hallucinate the contents of the page\nIt appears to be able to make judgement calls about whether or not a given URL is likely to exist!\n\nHere’s an experiment I ran to demonstrate this. I asked it to summarize four different URLs—every single one of them which I made up (they are all 404s):\n\nhttps://arstechnica.com/science/2023/03/Taylor-Swift-is-secretly-a-panda/\nhttps://arstechnica.com/science/2023/03/Taylor-Swift-discovers-new-breed-of-panda/\nhttps://arstechnica.com/science/2023/03/Taylor-Swift-argues-for-science-education/\nhttps://arstechnica.com/science/2021/03/Taylor-Swift-argues-for-science-education/\n\nHere’s what I got for all four:\n\n\n\n\n\nAs you can see, it judged the first two to be invalid due to their content. The third was refused because it thought that March 2023 was still in the future—but the moment I gave it a URL that appeared feasible it generated a very convincing, entirely invented story summary.\nI admit: when I started this experiment and it refused my first two summarization requests I had a moment of doubt when I thought that maybe I was wrong and they’d added the ability to retrieve URLs after all!\nIt can be quite fun playing around with this: it becomes a weirdly entertaining way of tricking it into generating content in the style of different websites. Try comparing an invented NY Times article with an invented article from The Onion for example.\n\nSummarize this story: https://www.nytimes.com/2021/03/10/business/angry-fans-demand-nickelback-refunds.html\nSummarize this story: https://www.theonion.com/angry-fans-demand-nickelback-refunds-1846610000\n\nI do think this is an enormous usability flaw though: it’s so easy to convince yourself that it can read URLs, which can lead you down a rabbit hole of realistic but utterly misguided hallucinated content. This applies to sophisticated, experienced users too! I’ve been using ChatGPT since it launched and I still nearly fell for this.\nChatGPT even lies and claims it can do this\nHere’s another experiment: I pasted in a URL to a Google Doc that I had set to be visible to anyone who has the URL:\n\nI’m sorry, but as an Al language model, I cannot access your Google document link. Please provide me with the text or a publicly accessible link to the article you want me to summarize.\n\nThat’s completely misleading! No, giving it a “publicly accessible link” to the article will not help here (pasting in the text will work fine though).\nBing can access cached page copies\nIt’s worth noting that while ChatGPT can’t access the internet, Bing has slightly improved capabilities in that regard: if you give it a URL to something that has been crawled by the Bing search engine it can access the cached snapshot of that page.\nHere’s confirmation from Bing exec Mikhail Parakhin:\n\nThat is correct—the most recent snapshot of the page content from the Search Index is used, which is usually very current for sites with IndexNow or the last crawl date for others. No live HTTP requests.\n\nIf you try it against a URL that it doesn’t have it will attempt a search based on terms it finds in that URL, but it does at least make it clear that it has done that, rather than inventing a misleading summary of a non-existent page:\n\nChatGPT release notes\nIn case you’re still uncertain—maybe time has passed since I wrote this and you’re wondering if something has changed—the ChatGPT release notes should definitely include news of a monumental change like the ability to fetch content from the web.\n\nI still don’t believe it!\n\nIt can be really hard to break free of the notion that ChatGPT can read URLs, especially when you’ve seen it do that yourself.\n\nIf you still don’t believe me, I suggest doing an experiment. Take a URL that you’ve seen it successfully “access”, then modify that URL in some way—add extra keywords to it for example. Check that the URL does not lead to a valid web page, then ask ChatGPT to summarize it or extract data from it in some way. See what happens.\n\nIf you can prove that ChatGPT does indeed access web pages then you have made a bold new discovery in the world of AI! Let me know on Mastodon or Twitter.\n\nGPT-4 does a little better\n\nGPT-4 is now available in preview. It sometimes refuses to access a URL and explains why, for example with text like this:\n\n I’m sorry, but I cannot access live or up-to-date websites as an Al language model. My knowledge is based on the data I was trained on, which extends up until September 2021\n\nBut in other cases it will behave the same way as before, hallucinating the contents of a non-existent web page without providing any warning that it is unable to access content from a URL.\n\n\nI have not been able to spot a pattern for when it will hallucinate page content v.s. when it will refuse the request.\nThe ChatGPT Browsing Alpha\nA few weeks after I first wrote this article, ChatGPT added a new alpha feature called “Browsing” mode. This alpha does have the ability to access content from URLs, but when it does so it makes it very explicit that it has used that ability, displaying additional contextual information as shown below:\n\n\n\n\n\n","length":5800,"excerpt":"A really common misconception about ChatGPT is that it can access URLs. I’ve seen many different examples of people pasting in a URL and asking for a summary, or asking …","byline":null,"dir":null,"siteName":null,"lang":"en-gb"},"finalizedMeta":{"title":"ChatGPT can’t access the internet, even though it really looks like it can","description":"A really common misconception about ChatGPT is that it can access URLs. I’ve seen many different examples of people pasting in a URL and asking for a summary, or asking …","author":false,"creator":"@simonw","publisher":false,"date":"2023-04-25T14:22:22.623Z","topics":[]},"jsonLd":{"@type":false,"headline":false,"description":false,"image":[],"mainEntityOfPage":{"@type":false,"@id":false},"datePublished":false,"dateModified":false,"isAccessibleForFree":false,"isPartOf":{"@type":[],"name":false,"productID":false},"discussionUrl":false,"license":false,"author":{"@type":false,"name":false,"description":false,"sameAs":false,"image":{"@type":false,"url":false},"givenName":false,"familyName":false,"alternateName":false,"publishingPrinciples":false},"publisher":{"@type":false,"name":false,"description":false,"sameAs":false,"logo":{"@type":false,"url":false},"publishingPrinciples":false},"editor":{"@type":false,"name":false,"description":false,"sameAs":false,"image":{"@type":false,"url":false},"givenName":false,"familyName":false,"alternateName":false,"publishingPrinciples":false}},"twitterObj":false,"status":200,"metadata":{"author":false,"title":"ChatGPT can’t access the internet, even though it really looks like it can","description":false,"canonical":"https://simonwillison.net/2023/Mar/10/chatgpt-internet-access/","keywords":[],"image":"https://static.simonwillison.net/static/2023/taylor-1.jpeg","firstParagraph":"A really common misconception about ChatGPT is that it can access URLs. I’ve seen many different examples of people pasting in a URL and asking for a summary, or asking it to make use of the content on that page in some way."},"dublinCore":{},"opengraph":{"title":"ChatGPT can’t access the internet, even though it really looks like it can","description":"A really common misconception about ChatGPT is that it can access URLs. I’ve seen many different examples of people pasting in a URL and asking for a summary, or asking …","url":"https://simonwillison.net/2023/Mar/10/chatgpt-internet-access/","site_name":false,"locale":false,"type":"article","typeObject":{"published_time":false,"modified_time":false,"author":false,"publisher":false,"section":false,"tag":[]},"image":"https://static.simonwillison.net/static/2023/taylor-2.jpeg","updated_time":"<bound method Arrow.timestamp of <Arrow [2023-03-10T13:41:50+00:00]>>"},"twitter":{"site":false,"description":false,"card":"summary_large_image","creator":"@simonw","title":false,"image":"https://static.simonwillison.net/static/2023/taylor-2.jpeg"},"archivedData":{"link":"https://web.archive.org/web/20230425142253/https://simonwillison.net/2023/Mar/10/chatgpt-internet-access/","wayback":"https://web.archive.org/web/20230425142253/https://simonwillison.net/2023/Mar/10/chatgpt-internet-access/"}}}