{"initialLink":"https://www.techpolicy.press/synthetic-media-policy-provenance-and-authentication-expert-insights-and-questions/","sanitizedLink":"https://www.techpolicy.press/synthetic-media-policy-provenance-and-authentication-expert-insights-and-questions/","finalLink":"https://techpolicy.press/synthetic-media-policy-provenance-and-authentication-expert-insights-and-questions","htmlEmbed":"<script>window.contexterSetup=window.contexterSetup||function(){window.contexterSetupComplete=!0;class ContexterLink extends HTMLAnchorElement{constructor(){super()}connectedCallback(){this.setAttribute(\"target\",\"_blank\")}}customElements.define(\"contexter-link\",ContexterLink,{extends:\"a\"}),customElements.define(\"contexter-inner\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__inner\"}}),customElements.define(\"contexter-thumbnail\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__thumbnail\"}}),customElements.define(\"contexter-byline\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__byline\"}}),customElements.define(\"contexter-keywordset\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__keywordset\"}}),customElements.define(\"contexter-linkset\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__linkset\"}}),customElements.define(\"contexter-meta\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__meta\"}}),customElements.define(\"contexter-summary\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"p-summary entry-summary\"}}),customElements.define(\"contexter-box-head\",class extends HTMLElement{constructor(){super()}connectedCallback(){this.className=\"contexter-box__head\"}}),customElements.define(\"contexter-box-inner\",class extends HTMLElement{constructor(){super()}connectedCallback(){}});class ContexterBox extends HTMLElement{constructor(){super(),this.first=!0,this.shadow=this.attachShadow({mode:\"open\"})}connectedCallback(){if(this.first){this.first=!1;var style=document.createElement(\"style\"),lightDomStyle=(style.innerHTML=`:host {--background: #f5f6f7;--border: darkblue;--blue: #0000ee;--font-color: black;--inner-border: black;font-family: Franklin,Arial,Helvetica,sans-serif;font-size: 14px;background: var(--background);width: 600px;color: var(--font-color);min-height: 90px;display: block;padding: 8px;border: 1px solid var(--border);cursor: pointer;box-sizing: border-box;margin: 6px;contain: content;margin: 6px auto;}// can only select top-level nodes with slotted::slotted(*) {max-width: 100%;display:block;}::slotted([slot=thumbnail]) {max-width: 100%;display:block;}::slotted([slot=header]) {width: 100%;font-size: 1.25rem;font-weight: bold;display:block;margin-bottom: 6px;}::slotted([slot=author]) {max-width: 50%;font-size: 12px;display:inline-block;float: left;}::slotted([slot=time]) {max-width: 50%;font-size: 12px;display:inline-block;float: right;}::slotted([slot=summary]) {width: 100%;margin-top: 6px;padding: 10px 2px;border-top: 1px solid var(--inner-border);font-size: 15px;display:inline-block;margin-bottom: 6px;}contexter-meta {height: auto;margin-bottom: 4px;width: 100%;display: grid;position: relative;min-height: 16px;grid-template-columns: repeat(2, 1fr);}::slotted([slot=keywords]) {width: 80%;padding: 2px 4px;border-top: 1px solid var(--inner-border);font-size: 11px;display: block;float: right;font-style: italic;text-align: right;grid-column: 2/2;grid-row: 1;align-self: end;justify-self: end;}::slotted([slot=keywords]):empty {border-top: 0px solid var(--inner-border);}::slotted([slot=archive-link]) {font-size: 1em;display: inline;}::slotted([slot=archive-link])::after {content: \"|\";display: inline;color: var(--font-color);text-decoration: none;margin: 0 .5em;}::slotted([slot=read-link]) {font-size: 1em;display: inline;}contexter-linkset {width: 80%;padding: 2px 4px;font-size: 13px;float: left;font-weight: bold;grid-row: 1;grid-column: 1/2;align-self: end;justify-self: start;}/* Extra small devices (phones, 600px and down) */@media only screen and (max-width: 600px) {:host {width: 310px;}}/* Small devices (portrait tablets and large phones, 600px and up) */@media only screen and (min-width: 600px) {...}/* Medium devices (landscape tablets, 768px and up) */@media only screen and (min-width: 768px) {...}/* Large devices (laptops/desktops, 992px and up) */@media only screen and (min-width: 992px) {...}/* Extra large devices (large laptops and desktops, 1200px and up) */@media only screen and (min-width: 1200px) {...}@media (prefers-color-scheme: dark){:host {--background: #354150;--border: #1f2b37;--blue: #55b0ff;--font-color: #ffffff;--inner-border: #787a7c;background: var(--background);border: 1px solid var(--border)}}`,document.createElement(\"style\"));lightDomStyle.innerHTML=`contexter-box {contain: content;}contexter-box .read-link {font-weight: bold;}contexter-box a {color: #0000ee;}contexter-box img {width: 100%;border: 0;padding: 0;margin: 0;}/* Extra small devices (phones, 600px and down) */@media only screen and (max-width: 600px) {...}/* Small devices (portrait tablets and large phones, 600px and up) */@media only screen and (min-width: 600px) {...}/* Medium devices (landscape tablets, 768px and up) */@media only screen and (min-width: 768px) {...}/* Large devices (laptops/desktops, 992px and up) */@media only screen and (min-width: 992px) {...}/* Extra large devices (large laptops and desktops, 1200px and up) */@media only screen and (min-width: 1200px) {...}@media (prefers-color-scheme: dark){contexter-box a {color: #55b0ff;}}`,this.appendChild(lightDomStyle),this.shadow.appendChild(style);const innerContainer=document.createElement(\"contexter-box-inner\"),innerSlotThumbnail=(this.shadow.appendChild(innerContainer),document.createElement(\"slot\")),innerSlotHeader=(innerSlotThumbnail.name=\"thumbnail\",innerContainer.appendChild(innerSlotThumbnail),document.createElement(\"slot\")),innerSlotAuthor=(innerSlotHeader.name=\"header\",innerContainer.appendChild(innerSlotHeader),document.createElement(\"slot\")),innerSlotTime=(innerSlotAuthor.name=\"author\",innerContainer.appendChild(innerSlotAuthor),document.createElement(\"slot\")),innerSlotSummary=(innerSlotTime.name=\"time\",innerContainer.appendChild(innerSlotTime),document.createElement(\"slot\")),metaContainer=(innerSlotSummary.name=\"summary\",innerContainer.appendChild(innerSlotSummary),document.createElement(\"contexter-meta\")),innerSlotInfo=(innerContainer.appendChild(metaContainer),document.createElement(\"slot\")),linkContainer=(innerSlotInfo.name=\"keywords\",metaContainer.appendChild(innerSlotInfo),document.createElement(\"contexter-linkset\")),innerSlotArchiveLink=(metaContainer.appendChild(linkContainer),document.createElement(\"slot\")),innerSlotReadLink=(innerSlotArchiveLink.name=\"archive-link\",linkContainer.appendChild(innerSlotArchiveLink),document.createElement(\"slot\"));innerSlotReadLink.name=\"read-link\",linkContainer.appendChild(innerSlotReadLink),this.className=\"contexter-box\",this.onclick=e=>{if(!e.target.className.includes(\"read-link\")&&!e.target.className.includes(\"title-link\")){const mainLinks=this.querySelectorAll(\"a.main-link\");mainLinks[0].click()}}}}}customElements.define(\"contexter-box\",ContexterBox)},window.contexterSetupComplete||window.contexterSetup();</script><contexter-box class=\"link-card h-entry hentry\" itemscope=\"\" itemtype=\"https://schema.org/CreativeWork\"><contexter-thumbnail class=\"thumbnail\" slot=\"thumbnail\"></contexter-thumbnail><contexter-box-head slot=\"header\" class=\"p-name entry-title\" itemprop=\"headline\"><contexter-box-head slot=\"header\" class=\"p-name entry-title\" itemprop=\"headline\"><a is=\"contexter-link\" href=\"https://techpolicy.press/synthetic-media-policy-provenance-and-authentication-expert-insights-and-questions\" itemprop=\"url\">Synthetic Media Policy: Provenance and Authentication — Expert Insights and Questions</a></contexter-box-head></contexter-box-head><contexter-byline class=\"p-author author\" slot=\"author\"><span class=\"p-name byline\" rel=\"author\" itemprop=\"author\">Ellen P. Goodman, Kaylee Williams, Justin Hendrix</span></contexter-byline><time class=\"dt-published published\" slot=\"time\" itemprop=\"datePublished\" datetime=\"2025-05-02T02:58:00.000Z\">5/1/2025</time><contexter-summary class=\"p-summary entry-summary\" itemprop=\"abstract\" slot=\"summary\"><p>Policymakers and the public must move beyond “synthetic or authentic” binaries when considering responses to AI-generated media.</p></contexter-summary><contexter-keywordset itemprop=\"keywords\" slot=\"keywords\"></contexter-keywordset><a is=\"contexter-link\" href=\"https://techpolicy.press/synthetic-media-policy-provenance-and-authentication-expert-insights-and-questions\" class=\"read-link main-link\" itemprop=\"sameAs\" slot=\"read-link\">Read</a></contexter-box>","linkId":"0f49a8d5a539470b7cd151701cd971dcea0b5d63","data":{"originalLink":"https://www.techpolicy.press/synthetic-media-policy-provenance-and-authentication-expert-insights-and-questions/","sanitizedLink":"https://www.techpolicy.press/synthetic-media-policy-provenance-and-authentication-expert-insights-and-questions/","canonical":"https://techpolicy.press/synthetic-media-policy-provenance-and-authentication-expert-insights-and-questions","htmlText":"<!DOCTYPE html><html lang=\"en\"><head><title>Synthetic Media Policy: Provenance and Authentication — Expert Insights and Questions | TechPolicy.Press</title><meta name=\"robots\" content=\"index,follow\"/><meta name=\"description\" content=\"Policymakers and the public must move beyond “synthetic or authentic” binaries when considering responses to AI-generated media.\n\"/><meta name=\"twitter:card\" content=\"summary_large_image\"/><meta name=\"twitter:site\" content=\"@TechPolicyPress\"/><meta name=\"twitter:creator\" content=\"@TechPolicyPress\"/><meta property=\"og:title\" content=\"Synthetic Media Policy: Provenance and Authentication — Expert Insights and Questions | TechPolicy.Press\"/><meta property=\"og:description\" content=\"Policymakers and the public must move beyond “synthetic or authentic” binaries when considering responses to AI-generated media.\n\"/><meta property=\"og:url\" content=\"https://techpolicy.press/synthetic-media-policy-provenance-and-authentication-expert-insights-and-questions\"/><meta property=\"og:type\" content=\"article\"/><meta property=\"article:published_time\" content=\"2025-05-02T02:58:00.000Z\"/><meta property=\"article:modified_time\" content=\"2025-05-01T19:09:46Z\"/><meta property=\"article:author\" content=\"http://techpolicy.press/author/ellen-p-goodman\"/><meta property=\"article:author\" content=\"http://techpolicy.press/author/kaylee-williams\"/><meta property=\"article:author\" content=\"http://techpolicy.press/author/justin-hendrix\"/><meta property=\"og:image\" content=\"https://cdn.sanity.io/images/3tzzh18d/production/8f56541566a9236d6fbd6ff606a02bb7fde08386-1200x675.png\"/><meta property=\"og:locale\" content=\"en_US\"/><meta property=\"og:site_name\" content=\"Tech Policy Press\"/><link rel=\"canonical\" href=\"https://techpolicy.press/synthetic-media-policy-provenance-and-authentication-expert-insights-and-questions\"/><script type=\"application/ld+json\">{\"@context\":\"https://schema.org\",\"@type\":\"Article\",\"datePublished\":\"2025-05-02T02:58:00.000Z\",\"description\":\"Policymakers and the public must move beyond “synthetic or authentic” binaries when considering responses to AI-generated media.\\n\",\"mainEntityOfPage\":{\"@type\":\"WebPage\",\"@id\":\"https://techpolicy.press/synthetic-media-policy-provenance-and-authentication-expert-insights-and-questions\"},\"headline\":\"Synthetic Media Policy: Provenance and Authentication — Expert Insights and Questions\",\"dateModified\":\"2025-05-01T19:09:46Z\",\"author\":[{\"@type\":\"Person\",\"name\":\"Ellen P. Goodman\",\"url\":\"https://techpolicy.press/author/ellen-p-goodman\"},{\"@type\":\"Person\",\"name\":\"Kaylee Williams\",\"url\":\"https://techpolicy.press/author/kaylee-williams\"},{\"@type\":\"Person\",\"name\":\"Justin Hendrix\",\"url\":\"https://techpolicy.press/author/justin-hendrix\"}],\"publisher\":{\"@type\":\"Organization\",\"name\":\"Tech Policy Press\",\"logo\":{\"@type\":\"ImageObject\",\"url\":\"https://cdn.sanity.io/images/3tzzh18d/production/697d4cc6122b80fcb64b256d888010c242ce6beb-1200x675.png\"}},\"isAccessibleForFree\":true}</script><meta charSet=\"utf-8\"/><meta name=\"viewport\" content=\"width=device-width, initialScale=1.0\"/><meta name=\"google\" content=\"notranslate\"/><meta name=\"author\" content=\"Ellen P. Goodman, Kaylee Williams, Justin Hendrix\"/><meta name=\"publish_date\" content=\"2025-05-02T02:58:00.000Z\"/><link rel=\"alternate\" type=\"application/rss+xml\" title=\"RSS feed for The Sunday Show\" href=\"https://feeds.captivate.fm/techpolicypress/\"/><link rel=\"alternate\" type=\"application/rss+xml\" title=\"Tech Policy Press » Feed\" href=\"https://techpolicy.press/rss/feed.xml\"/><link rel=\"icon\" href=\"https://cdn.sanity.io/images/3tzzh18d/production/9a2224d300c1699fc1b87235aac36318e2c76cec-867x867.png\"/><meta name=\"next-head-count\" content=\"30\"/><link rel=\"preconnect\" href=\"https://fonts.gstatic.com\" crossorigin /><link rel=\"preload\" href=\"/_next/static/css/76b6c2647651fec1.css\" as=\"style\"/><link rel=\"stylesheet\" href=\"/_next/static/css/76b6c2647651fec1.css\" data-n-g=\"\"/><link rel=\"preload\" href=\"/_next/static/css/907c8b40563e8791.css\" as=\"style\"/><link rel=\"stylesheet\" href=\"/_next/static/css/907c8b40563e8791.css\" data-n-p=\"\"/><noscript data-n-css=\"\"></noscript><script defer=\"\" nomodule=\"\" src=\"/_next/static/chunks/polyfills-78c92fac7aa8fdd8.js\"></script><script src=\"/_next/static/chunks/webpack-3c216928ee00e5f9.js\" defer=\"\"></script><script src=\"/_next/static/chunks/framework-9620da855a94eb57.js\" defer=\"\"></script><script src=\"/_next/static/chunks/main-89688f241e62cd05.js\" defer=\"\"></script><script src=\"/_next/static/chunks/pages/_app-46afd193c62360b9.js\" defer=\"\"></script><script src=\"/_next/static/chunks/29107295-a3480e51fe70b9c7.js\" defer=\"\"></script><script src=\"/_next/static/chunks/219-0069b325e47ba8ea.js\" defer=\"\"></script><script src=\"/_next/static/chunks/798-ca308619095a183b.js\" defer=\"\"></script><script src=\"/_next/static/chunks/618-9a3eb1e35bf3fd01.js\" defer=\"\"></script><script src=\"/_next/static/chunks/pages/%5B...slug%5D-a2ca510dd599acd8.js\" defer=\"\"></script><script src=\"/_next/static/2-BCTHWxu2tBlfW-GrJE7/_buildManifest.js\" defer=\"\"></script><script src=\"/_next/static/2-BCTHWxu2tBlfW-GrJE7/_ssgManifest.js\" defer=\"\"></script><style id=\"jss-server-side\">.jss1 {\n  font-style: italic;\n}\n.jss3 {\n  color: #000 !important;\n  text-decoration: none!important;\n}\n.jss4 {\n  color: unset;\n  text-decoration: none;\n}\n.jss6 {\n  width: 100%;\n  display: block;\n  max-width: 20px;\n  max-height: 20px;\n}\n.jss9 {\n  font-family: 'Lexend', sans-serif;\n  font-weight: 500;\n  text-transform: uppercase;\n}\n.jss9:active, .jss9:focus, .jss9:hover {\n  text-decoration: underline;\n}\n.jss7 {\n  gap: 10px;\n  display: flex;\n  flex-direction: row;\n}\n@media (max-width:599.95px) {\n  .jss7 {\n    align-items: center;\n    flex-direction: column;\n  }\n}\n  .jss8 {\n    display: flex;\n    font-size: 16px;\n    font-family: 'Libre Baskerville', serif;\n    font-weight: 700;\n    line-height: 1.5;\n    flex-direction: column;\n  }\n  .jss8>a:hover {\n    text-decoration: underline;\n  }\n  .jss8:not(:last-child) {\n    border-bottom: 1px solid #E2D7BB77;\n    padding-bottom: 10px;\n  }</style><style data-href=\"https://fonts.googleapis.com/css?family=Roboto:400,400i,500,700,700i&display=swap\">@font-face{font-family:'Roboto';font-style:italic;font-weight:400;font-stretch:normal;font-display:swap;src:url(https://fonts.gstatic.com/l/font?kit=KFOKCnqEu92Fr1Mu53ZEC9_Vu3r1gIhOszmOClHrs6ljXfMMLoHQuAj-lQ&skey=c608c610063635f9&v=v50) format('woff')}@font-face{font-family:'Roboto';font-style:italic;font-weight:700;font-stretch:normal;font-display:swap;src:url(https://fonts.gstatic.com/l/font?kit=KFOKCnqEu92Fr1Mu53ZEC9_Vu3r1gIhOszmOClHrs6ljXfMMLmbXuAj-lQ&skey=c608c610063635f9&v=v50) format('woff')}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-stretch:normal;font-display:swap;src:url(https://fonts.gstatic.com/l/font?kit=KFOMCnqEu92Fr1ME7kSn66aGLdTylUAMQXC89YmC2DPNWubEbVmUiAw&skey=a0a0114a1dcab3ac&v=v50) format('woff')}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-stretch:normal;font-display:swap;src:url(https://fonts.gstatic.com/l/font?kit=KFOMCnqEu92Fr1ME7kSn66aGLdTylUAMQXC89YmC2DPNWub2bVmUiAw&skey=a0a0114a1dcab3ac&v=v50) format('woff')}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-stretch:normal;font-display:swap;src:url(https://fonts.gstatic.com/l/font?kit=KFOMCnqEu92Fr1ME7kSn66aGLdTylUAMQXC89YmC2DPNWuYjalmUiAw&skey=a0a0114a1dcab3ac&v=v50) format('woff')}@font-face{font-family:'Roboto';font-style:italic;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO5CnqEu92Fr1Mu53ZEC9_Vu3r1gIhOszmkC3kaSTbQWt4N.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C8A,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Roboto';font-style:italic;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO5CnqEu92Fr1Mu53ZEC9_Vu3r1gIhOszmkAnkaSTbQWt4N.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Roboto';font-style:italic;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO5CnqEu92Fr1Mu53ZEC9_Vu3r1gIhOszmkCnkaSTbQWt4N.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Roboto';font-style:italic;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO5CnqEu92Fr1Mu53ZEC9_Vu3r1gIhOszmkBXkaSTbQWt4N.woff2) format('woff2');unicode-range:U+0370-0377,U+037A-037F,U+0384-038A,U+038C,U+038E-03A1,U+03A3-03FF}@font-face{font-family:'Roboto';font-style:italic;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO5CnqEu92Fr1Mu53ZEC9_Vu3r1gIhOszmkenkaSTbQWt4N.woff2) format('woff2');unicode-range:U+0302-0303,U+0305,U+0307-0308,U+0310,U+0312,U+0315,U+031A,U+0326-0327,U+032C,U+032F-0330,U+0332-0333,U+0338,U+033A,U+0346,U+034D,U+0391-03A1,U+03A3-03A9,U+03B1-03C9,U+03D1,U+03D5-03D6,U+03F0-03F1,U+03F4-03F5,U+2016-2017,U+2034-2038,U+203C,U+2040,U+2043,U+2047,U+2050,U+2057,U+205F,U+2070-2071,U+2074-208E,U+2090-209C,U+20D0-20DC,U+20E1,U+20E5-20EF,U+2100-2112,U+2114-2115,U+2117-2121,U+2123-214F,U+2190,U+2192,U+2194-21AE,U+21B0-21E5,U+21F1-21F2,U+21F4-2211,U+2213-2214,U+2216-22FF,U+2308-230B,U+2310,U+2319,U+231C-2321,U+2336-237A,U+237C,U+2395,U+239B-23B7,U+23D0,U+23DC-23E1,U+2474-2475,U+25AF,U+25B3,U+25B7,U+25BD,U+25C1,U+25CA,U+25CC,U+25FB,U+266D-266F,U+27C0-27FF,U+2900-2AFF,U+2B0E-2B11,U+2B30-2B4C,U+2BFE,U+3030,U+FF5B,U+FF5D,U+1D400-1D7FF,U+1EE00-1EEFF}@font-face{font-family:'Roboto';font-style:italic;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO5CnqEu92Fr1Mu53ZEC9_Vu3r1gIhOszmkaHkaSTbQWt4N.woff2) format('woff2');unicode-range:U+0001-000C,U+000E-001F,U+007F-009F,U+20DD-20E0,U+20E2-20E4,U+2150-218F,U+2190,U+2192,U+2194-2199,U+21AF,U+21E6-21F0,U+21F3,U+2218-2219,U+2299,U+22C4-22C6,U+2300-243F,U+2440-244A,U+2460-24FF,U+25A0-27BF,U+2800-28FF,U+2921-2922,U+2981,U+29BF,U+29EB,U+2B00-2BFF,U+4DC0-4DFF,U+FFF9-FFFB,U+10140-1018E,U+10190-1019C,U+101A0,U+101D0-101FD,U+102E0-102FB,U+10E60-10E7E,U+1D2C0-1D2D3,U+1D2E0-1D37F,U+1F000-1F0FF,U+1F100-1F1AD,U+1F1E6-1F1FF,U+1F30D-1F30F,U+1F315,U+1F31C,U+1F31E,U+1F320-1F32C,U+1F336,U+1F378,U+1F37D,U+1F382,U+1F393-1F39F,U+1F3A7-1F3A8,U+1F3AC-1F3AF,U+1F3C2,U+1F3C4-1F3C6,U+1F3CA-1F3CE,U+1F3D4-1F3E0,U+1F3ED,U+1F3F1-1F3F3,U+1F3F5-1F3F7,U+1F408,U+1F415,U+1F41F,U+1F426,U+1F43F,U+1F441-1F442,U+1F444,U+1F446-1F449,U+1F44C-1F44E,U+1F453,U+1F46A,U+1F47D,U+1F4A3,U+1F4B0,U+1F4B3,U+1F4B9,U+1F4BB,U+1F4BF,U+1F4C8-1F4CB,U+1F4D6,U+1F4DA,U+1F4DF,U+1F4E3-1F4E6,U+1F4EA-1F4ED,U+1F4F7,U+1F4F9-1F4FB,U+1F4FD-1F4FE,U+1F503,U+1F507-1F50B,U+1F50D,U+1F512-1F513,U+1F53E-1F54A,U+1F54F-1F5FA,U+1F610,U+1F650-1F67F,U+1F687,U+1F68D,U+1F691,U+1F694,U+1F698,U+1F6AD,U+1F6B2,U+1F6B9-1F6BA,U+1F6BC,U+1F6C6-1F6CF,U+1F6D3-1F6D7,U+1F6E0-1F6EA,U+1F6F0-1F6F3,U+1F6F7-1F6FC,U+1F700-1F7FF,U+1F800-1F80B,U+1F810-1F847,U+1F850-1F859,U+1F860-1F887,U+1F890-1F8AD,U+1F8B0-1F8BB,U+1F8C0-1F8C1,U+1F900-1F90B,U+1F93B,U+1F946,U+1F984,U+1F996,U+1F9E9,U+1FA00-1FA6F,U+1FA70-1FA7C,U+1FA80-1FA89,U+1FA8F-1FAC6,U+1FACE-1FADC,U+1FADF-1FAE9,U+1FAF0-1FAF8,U+1FB00-1FBFF}@font-face{font-family:'Roboto';font-style:italic;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO5CnqEu92Fr1Mu53ZEC9_Vu3r1gIhOszmkCXkaSTbQWt4N.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Roboto';font-style:italic;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO5CnqEu92Fr1Mu53ZEC9_Vu3r1gIhOszmkCHkaSTbQWt4N.woff2) format('woff2');unicode-range:U+0100-02BA,U+02BD-02C5,U+02C7-02CC,U+02CE-02D7,U+02DD-02FF,U+0304,U+0308,U+0329,U+1D00-1DBF,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Roboto';font-style:italic;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO5CnqEu92Fr1Mu53ZEC9_Vu3r1gIhOszmkBnkaSTbQWg.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Roboto';font-style:italic;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO5CnqEu92Fr1Mu53ZEC9_Vu3r1gIhOszmkC3kaSTbQWt4N.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C8A,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Roboto';font-style:italic;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO5CnqEu92Fr1Mu53ZEC9_Vu3r1gIhOszmkAnkaSTbQWt4N.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Roboto';font-style:italic;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO5CnqEu92Fr1Mu53ZEC9_Vu3r1gIhOszmkCnkaSTbQWt4N.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Roboto';font-style:italic;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO5CnqEu92Fr1Mu53ZEC9_Vu3r1gIhOszmkBXkaSTbQWt4N.woff2) format('woff2');unicode-range:U+0370-0377,U+037A-037F,U+0384-038A,U+038C,U+038E-03A1,U+03A3-03FF}@font-face{font-family:'Roboto';font-style:italic;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO5CnqEu92Fr1Mu53ZEC9_Vu3r1gIhOszmkenkaSTbQWt4N.woff2) format('woff2');unicode-range:U+0302-0303,U+0305,U+0307-0308,U+0310,U+0312,U+0315,U+031A,U+0326-0327,U+032C,U+032F-0330,U+0332-0333,U+0338,U+033A,U+0346,U+034D,U+0391-03A1,U+03A3-03A9,U+03B1-03C9,U+03D1,U+03D5-03D6,U+03F0-03F1,U+03F4-03F5,U+2016-2017,U+2034-2038,U+203C,U+2040,U+2043,U+2047,U+2050,U+2057,U+205F,U+2070-2071,U+2074-208E,U+2090-209C,U+20D0-20DC,U+20E1,U+20E5-20EF,U+2100-2112,U+2114-2115,U+2117-2121,U+2123-214F,U+2190,U+2192,U+2194-21AE,U+21B0-21E5,U+21F1-21F2,U+21F4-2211,U+2213-2214,U+2216-22FF,U+2308-230B,U+2310,U+2319,U+231C-2321,U+2336-237A,U+237C,U+2395,U+239B-23B7,U+23D0,U+23DC-23E1,U+2474-2475,U+25AF,U+25B3,U+25B7,U+25BD,U+25C1,U+25CA,U+25CC,U+25FB,U+266D-266F,U+27C0-27FF,U+2900-2AFF,U+2B0E-2B11,U+2B30-2B4C,U+2BFE,U+3030,U+FF5B,U+FF5D,U+1D400-1D7FF,U+1EE00-1EEFF}@font-face{font-family:'Roboto';font-style:italic;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO5CnqEu92Fr1Mu53ZEC9_Vu3r1gIhOszmkaHkaSTbQWt4N.woff2) format('woff2');unicode-range:U+0001-000C,U+000E-001F,U+007F-009F,U+20DD-20E0,U+20E2-20E4,U+2150-218F,U+2190,U+2192,U+2194-2199,U+21AF,U+21E6-21F0,U+21F3,U+2218-2219,U+2299,U+22C4-22C6,U+2300-243F,U+2440-244A,U+2460-24FF,U+25A0-27BF,U+2800-28FF,U+2921-2922,U+2981,U+29BF,U+29EB,U+2B00-2BFF,U+4DC0-4DFF,U+FFF9-FFFB,U+10140-1018E,U+10190-1019C,U+101A0,U+101D0-101FD,U+102E0-102FB,U+10E60-10E7E,U+1D2C0-1D2D3,U+1D2E0-1D37F,U+1F000-1F0FF,U+1F100-1F1AD,U+1F1E6-1F1FF,U+1F30D-1F30F,U+1F315,U+1F31C,U+1F31E,U+1F320-1F32C,U+1F336,U+1F378,U+1F37D,U+1F382,U+1F393-1F39F,U+1F3A7-1F3A8,U+1F3AC-1F3AF,U+1F3C2,U+1F3C4-1F3C6,U+1F3CA-1F3CE,U+1F3D4-1F3E0,U+1F3ED,U+1F3F1-1F3F3,U+1F3F5-1F3F7,U+1F408,U+1F415,U+1F41F,U+1F426,U+1F43F,U+1F441-1F442,U+1F444,U+1F446-1F449,U+1F44C-1F44E,U+1F453,U+1F46A,U+1F47D,U+1F4A3,U+1F4B0,U+1F4B3,U+1F4B9,U+1F4BB,U+1F4BF,U+1F4C8-1F4CB,U+1F4D6,U+1F4DA,U+1F4DF,U+1F4E3-1F4E6,U+1F4EA-1F4ED,U+1F4F7,U+1F4F9-1F4FB,U+1F4FD-1F4FE,U+1F503,U+1F507-1F50B,U+1F50D,U+1F512-1F513,U+1F53E-1F54A,U+1F54F-1F5FA,U+1F610,U+1F650-1F67F,U+1F687,U+1F68D,U+1F691,U+1F694,U+1F698,U+1F6AD,U+1F6B2,U+1F6B9-1F6BA,U+1F6BC,U+1F6C6-1F6CF,U+1F6D3-1F6D7,U+1F6E0-1F6EA,U+1F6F0-1F6F3,U+1F6F7-1F6FC,U+1F700-1F7FF,U+1F800-1F80B,U+1F810-1F847,U+1F850-1F859,U+1F860-1F887,U+1F890-1F8AD,U+1F8B0-1F8BB,U+1F8C0-1F8C1,U+1F900-1F90B,U+1F93B,U+1F946,U+1F984,U+1F996,U+1F9E9,U+1FA00-1FA6F,U+1FA70-1FA7C,U+1FA80-1FA89,U+1FA8F-1FAC6,U+1FACE-1FADC,U+1FADF-1FAE9,U+1FAF0-1FAF8,U+1FB00-1FBFF}@font-face{font-family:'Roboto';font-style:italic;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO5CnqEu92Fr1Mu53ZEC9_Vu3r1gIhOszmkCXkaSTbQWt4N.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Roboto';font-style:italic;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO5CnqEu92Fr1Mu53ZEC9_Vu3r1gIhOszmkCHkaSTbQWt4N.woff2) format('woff2');unicode-range:U+0100-02BA,U+02BD-02C5,U+02C7-02CC,U+02CE-02D7,U+02DD-02FF,U+0304,U+0308,U+0329,U+1D00-1DBF,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Roboto';font-style:italic;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO5CnqEu92Fr1Mu53ZEC9_Vu3r1gIhOszmkBnkaSTbQWg.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3GUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C8A,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3iUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3CUBHMdazTgWw.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3-UBHMdazTgWw.woff2) format('woff2');unicode-range:U+0370-0377,U+037A-037F,U+0384-038A,U+038C,U+038E-03A1,U+03A3-03FF}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMawCUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0302-0303,U+0305,U+0307-0308,U+0310,U+0312,U+0315,U+031A,U+0326-0327,U+032C,U+032F-0330,U+0332-0333,U+0338,U+033A,U+0346,U+034D,U+0391-03A1,U+03A3-03A9,U+03B1-03C9,U+03D1,U+03D5-03D6,U+03F0-03F1,U+03F4-03F5,U+2016-2017,U+2034-2038,U+203C,U+2040,U+2043,U+2047,U+2050,U+2057,U+205F,U+2070-2071,U+2074-208E,U+2090-209C,U+20D0-20DC,U+20E1,U+20E5-20EF,U+2100-2112,U+2114-2115,U+2117-2121,U+2123-214F,U+2190,U+2192,U+2194-21AE,U+21B0-21E5,U+21F1-21F2,U+21F4-2211,U+2213-2214,U+2216-22FF,U+2308-230B,U+2310,U+2319,U+231C-2321,U+2336-237A,U+237C,U+2395,U+239B-23B7,U+23D0,U+23DC-23E1,U+2474-2475,U+25AF,U+25B3,U+25B7,U+25BD,U+25C1,U+25CA,U+25CC,U+25FB,U+266D-266F,U+27C0-27FF,U+2900-2AFF,U+2B0E-2B11,U+2B30-2B4C,U+2BFE,U+3030,U+FF5B,U+FF5D,U+1D400-1D7FF,U+1EE00-1EEFF}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMaxKUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0001-000C,U+000E-001F,U+007F-009F,U+20DD-20E0,U+20E2-20E4,U+2150-218F,U+2190,U+2192,U+2194-2199,U+21AF,U+21E6-21F0,U+21F3,U+2218-2219,U+2299,U+22C4-22C6,U+2300-243F,U+2440-244A,U+2460-24FF,U+25A0-27BF,U+2800-28FF,U+2921-2922,U+2981,U+29BF,U+29EB,U+2B00-2BFF,U+4DC0-4DFF,U+FFF9-FFFB,U+10140-1018E,U+10190-1019C,U+101A0,U+101D0-101FD,U+102E0-102FB,U+10E60-10E7E,U+1D2C0-1D2D3,U+1D2E0-1D37F,U+1F000-1F0FF,U+1F100-1F1AD,U+1F1E6-1F1FF,U+1F30D-1F30F,U+1F315,U+1F31C,U+1F31E,U+1F320-1F32C,U+1F336,U+1F378,U+1F37D,U+1F382,U+1F393-1F39F,U+1F3A7-1F3A8,U+1F3AC-1F3AF,U+1F3C2,U+1F3C4-1F3C6,U+1F3CA-1F3CE,U+1F3D4-1F3E0,U+1F3ED,U+1F3F1-1F3F3,U+1F3F5-1F3F7,U+1F408,U+1F415,U+1F41F,U+1F426,U+1F43F,U+1F441-1F442,U+1F444,U+1F446-1F449,U+1F44C-1F44E,U+1F453,U+1F46A,U+1F47D,U+1F4A3,U+1F4B0,U+1F4B3,U+1F4B9,U+1F4BB,U+1F4BF,U+1F4C8-1F4CB,U+1F4D6,U+1F4DA,U+1F4DF,U+1F4E3-1F4E6,U+1F4EA-1F4ED,U+1F4F7,U+1F4F9-1F4FB,U+1F4FD-1F4FE,U+1F503,U+1F507-1F50B,U+1F50D,U+1F512-1F513,U+1F53E-1F54A,U+1F54F-1F5FA,U+1F610,U+1F650-1F67F,U+1F687,U+1F68D,U+1F691,U+1F694,U+1F698,U+1F6AD,U+1F6B2,U+1F6B9-1F6BA,U+1F6BC,U+1F6C6-1F6CF,U+1F6D3-1F6D7,U+1F6E0-1F6EA,U+1F6F0-1F6F3,U+1F6F7-1F6FC,U+1F700-1F7FF,U+1F800-1F80B,U+1F810-1F847,U+1F850-1F859,U+1F860-1F887,U+1F890-1F8AD,U+1F8B0-1F8BB,U+1F8C0-1F8C1,U+1F900-1F90B,U+1F93B,U+1F946,U+1F984,U+1F996,U+1F9E9,U+1FA00-1FA6F,U+1FA70-1FA7C,U+1FA80-1FA89,U+1FA8F-1FAC6,U+1FACE-1FADC,U+1FADF-1FAE9,U+1FAF0-1FAF8,U+1FB00-1FBFF}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3OUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3KUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0100-02BA,U+02BD-02C5,U+02C7-02CC,U+02CE-02D7,U+02DD-02FF,U+0304,U+0308,U+0329,U+1D00-1DBF,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Roboto';font-style:normal;font-weight:400;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3yUBHMdazQ.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3GUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C8A,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3iUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3CUBHMdazTgWw.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3-UBHMdazTgWw.woff2) format('woff2');unicode-range:U+0370-0377,U+037A-037F,U+0384-038A,U+038C,U+038E-03A1,U+03A3-03FF}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMawCUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0302-0303,U+0305,U+0307-0308,U+0310,U+0312,U+0315,U+031A,U+0326-0327,U+032C,U+032F-0330,U+0332-0333,U+0338,U+033A,U+0346,U+034D,U+0391-03A1,U+03A3-03A9,U+03B1-03C9,U+03D1,U+03D5-03D6,U+03F0-03F1,U+03F4-03F5,U+2016-2017,U+2034-2038,U+203C,U+2040,U+2043,U+2047,U+2050,U+2057,U+205F,U+2070-2071,U+2074-208E,U+2090-209C,U+20D0-20DC,U+20E1,U+20E5-20EF,U+2100-2112,U+2114-2115,U+2117-2121,U+2123-214F,U+2190,U+2192,U+2194-21AE,U+21B0-21E5,U+21F1-21F2,U+21F4-2211,U+2213-2214,U+2216-22FF,U+2308-230B,U+2310,U+2319,U+231C-2321,U+2336-237A,U+237C,U+2395,U+239B-23B7,U+23D0,U+23DC-23E1,U+2474-2475,U+25AF,U+25B3,U+25B7,U+25BD,U+25C1,U+25CA,U+25CC,U+25FB,U+266D-266F,U+27C0-27FF,U+2900-2AFF,U+2B0E-2B11,U+2B30-2B4C,U+2BFE,U+3030,U+FF5B,U+FF5D,U+1D400-1D7FF,U+1EE00-1EEFF}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMaxKUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0001-000C,U+000E-001F,U+007F-009F,U+20DD-20E0,U+20E2-20E4,U+2150-218F,U+2190,U+2192,U+2194-2199,U+21AF,U+21E6-21F0,U+21F3,U+2218-2219,U+2299,U+22C4-22C6,U+2300-243F,U+2440-244A,U+2460-24FF,U+25A0-27BF,U+2800-28FF,U+2921-2922,U+2981,U+29BF,U+29EB,U+2B00-2BFF,U+4DC0-4DFF,U+FFF9-FFFB,U+10140-1018E,U+10190-1019C,U+101A0,U+101D0-101FD,U+102E0-102FB,U+10E60-10E7E,U+1D2C0-1D2D3,U+1D2E0-1D37F,U+1F000-1F0FF,U+1F100-1F1AD,U+1F1E6-1F1FF,U+1F30D-1F30F,U+1F315,U+1F31C,U+1F31E,U+1F320-1F32C,U+1F336,U+1F378,U+1F37D,U+1F382,U+1F393-1F39F,U+1F3A7-1F3A8,U+1F3AC-1F3AF,U+1F3C2,U+1F3C4-1F3C6,U+1F3CA-1F3CE,U+1F3D4-1F3E0,U+1F3ED,U+1F3F1-1F3F3,U+1F3F5-1F3F7,U+1F408,U+1F415,U+1F41F,U+1F426,U+1F43F,U+1F441-1F442,U+1F444,U+1F446-1F449,U+1F44C-1F44E,U+1F453,U+1F46A,U+1F47D,U+1F4A3,U+1F4B0,U+1F4B3,U+1F4B9,U+1F4BB,U+1F4BF,U+1F4C8-1F4CB,U+1F4D6,U+1F4DA,U+1F4DF,U+1F4E3-1F4E6,U+1F4EA-1F4ED,U+1F4F7,U+1F4F9-1F4FB,U+1F4FD-1F4FE,U+1F503,U+1F507-1F50B,U+1F50D,U+1F512-1F513,U+1F53E-1F54A,U+1F54F-1F5FA,U+1F610,U+1F650-1F67F,U+1F687,U+1F68D,U+1F691,U+1F694,U+1F698,U+1F6AD,U+1F6B2,U+1F6B9-1F6BA,U+1F6BC,U+1F6C6-1F6CF,U+1F6D3-1F6D7,U+1F6E0-1F6EA,U+1F6F0-1F6F3,U+1F6F7-1F6FC,U+1F700-1F7FF,U+1F800-1F80B,U+1F810-1F847,U+1F850-1F859,U+1F860-1F887,U+1F890-1F8AD,U+1F8B0-1F8BB,U+1F8C0-1F8C1,U+1F900-1F90B,U+1F93B,U+1F946,U+1F984,U+1F996,U+1F9E9,U+1FA00-1FA6F,U+1FA70-1FA7C,U+1FA80-1FA89,U+1FA8F-1FAC6,U+1FACE-1FADC,U+1FADF-1FAE9,U+1FAF0-1FAF8,U+1FB00-1FBFF}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3OUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3KUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0100-02BA,U+02BD-02C5,U+02C7-02CC,U+02CE-02D7,U+02DD-02FF,U+0304,U+0308,U+0329,U+1D00-1DBF,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Roboto';font-style:normal;font-weight:500;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3yUBHMdazQ.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3GUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C8A,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3iUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3CUBHMdazTgWw.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3-UBHMdazTgWw.woff2) format('woff2');unicode-range:U+0370-0377,U+037A-037F,U+0384-038A,U+038C,U+038E-03A1,U+03A3-03FF}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMawCUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0302-0303,U+0305,U+0307-0308,U+0310,U+0312,U+0315,U+031A,U+0326-0327,U+032C,U+032F-0330,U+0332-0333,U+0338,U+033A,U+0346,U+034D,U+0391-03A1,U+03A3-03A9,U+03B1-03C9,U+03D1,U+03D5-03D6,U+03F0-03F1,U+03F4-03F5,U+2016-2017,U+2034-2038,U+203C,U+2040,U+2043,U+2047,U+2050,U+2057,U+205F,U+2070-2071,U+2074-208E,U+2090-209C,U+20D0-20DC,U+20E1,U+20E5-20EF,U+2100-2112,U+2114-2115,U+2117-2121,U+2123-214F,U+2190,U+2192,U+2194-21AE,U+21B0-21E5,U+21F1-21F2,U+21F4-2211,U+2213-2214,U+2216-22FF,U+2308-230B,U+2310,U+2319,U+231C-2321,U+2336-237A,U+237C,U+2395,U+239B-23B7,U+23D0,U+23DC-23E1,U+2474-2475,U+25AF,U+25B3,U+25B7,U+25BD,U+25C1,U+25CA,U+25CC,U+25FB,U+266D-266F,U+27C0-27FF,U+2900-2AFF,U+2B0E-2B11,U+2B30-2B4C,U+2BFE,U+3030,U+FF5B,U+FF5D,U+1D400-1D7FF,U+1EE00-1EEFF}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMaxKUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0001-000C,U+000E-001F,U+007F-009F,U+20DD-20E0,U+20E2-20E4,U+2150-218F,U+2190,U+2192,U+2194-2199,U+21AF,U+21E6-21F0,U+21F3,U+2218-2219,U+2299,U+22C4-22C6,U+2300-243F,U+2440-244A,U+2460-24FF,U+25A0-27BF,U+2800-28FF,U+2921-2922,U+2981,U+29BF,U+29EB,U+2B00-2BFF,U+4DC0-4DFF,U+FFF9-FFFB,U+10140-1018E,U+10190-1019C,U+101A0,U+101D0-101FD,U+102E0-102FB,U+10E60-10E7E,U+1D2C0-1D2D3,U+1D2E0-1D37F,U+1F000-1F0FF,U+1F100-1F1AD,U+1F1E6-1F1FF,U+1F30D-1F30F,U+1F315,U+1F31C,U+1F31E,U+1F320-1F32C,U+1F336,U+1F378,U+1F37D,U+1F382,U+1F393-1F39F,U+1F3A7-1F3A8,U+1F3AC-1F3AF,U+1F3C2,U+1F3C4-1F3C6,U+1F3CA-1F3CE,U+1F3D4-1F3E0,U+1F3ED,U+1F3F1-1F3F3,U+1F3F5-1F3F7,U+1F408,U+1F415,U+1F41F,U+1F426,U+1F43F,U+1F441-1F442,U+1F444,U+1F446-1F449,U+1F44C-1F44E,U+1F453,U+1F46A,U+1F47D,U+1F4A3,U+1F4B0,U+1F4B3,U+1F4B9,U+1F4BB,U+1F4BF,U+1F4C8-1F4CB,U+1F4D6,U+1F4DA,U+1F4DF,U+1F4E3-1F4E6,U+1F4EA-1F4ED,U+1F4F7,U+1F4F9-1F4FB,U+1F4FD-1F4FE,U+1F503,U+1F507-1F50B,U+1F50D,U+1F512-1F513,U+1F53E-1F54A,U+1F54F-1F5FA,U+1F610,U+1F650-1F67F,U+1F687,U+1F68D,U+1F691,U+1F694,U+1F698,U+1F6AD,U+1F6B2,U+1F6B9-1F6BA,U+1F6BC,U+1F6C6-1F6CF,U+1F6D3-1F6D7,U+1F6E0-1F6EA,U+1F6F0-1F6F3,U+1F6F7-1F6FC,U+1F700-1F7FF,U+1F800-1F80B,U+1F810-1F847,U+1F850-1F859,U+1F860-1F887,U+1F890-1F8AD,U+1F8B0-1F8BB,U+1F8C0-1F8C1,U+1F900-1F90B,U+1F93B,U+1F946,U+1F984,U+1F996,U+1F9E9,U+1FA00-1FA6F,U+1FA70-1FA7C,U+1FA80-1FA89,U+1FA8F-1FAC6,U+1FACE-1FADC,U+1FADF-1FAE9,U+1FAF0-1FAF8,U+1FB00-1FBFF}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3OUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+0300-0301,U+0303-0304,U+0308-0309,U+0323,U+0329,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3KUBHMdazTgWw.woff2) format('woff2');unicode-range:U+0100-02BA,U+02BD-02C5,U+02C7-02CC,U+02CE-02D7,U+02DD-02FF,U+0304,U+0308,U+0329,U+1D00-1DBF,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Roboto';font-style:normal;font-weight:700;font-stretch:100%;font-display:swap;src:url(https://fonts.gstatic.com/s/roboto/v50/KFO7CnqEu92Fr1ME7kSn66aGLdTylUAMa3yUBHMdazQ.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}</style><style data-href=\"https://fonts.googleapis.com/css?family=Libre+Baskerville:700&display=swap\">@font-face{font-family:'Libre Baskerville';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/l/font?kit=kmKiZrc3Hgbbcjq75U4uslyuy4kn0qviTgY3KcY&skey=c168ba7fe84b1774&v=v17) format('woff')}@font-face{font-family:'Libre Baskerville';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/librebaskerville/v17/kmKiZrc3Hgbbcjq75U4uslyuy4kn0qviTgY5KcC-wLOjAUw.woff2) format('woff2');unicode-range:U+0100-02BA,U+02BD-02C5,U+02C7-02CC,U+02CE-02D7,U+02DD-02FF,U+0304,U+0308,U+0329,U+1D00-1DBF,U+1E00-1E9F,U+1EF2-1EFF,U+2020,U+20A0-20AB,U+20AD-20C0,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Libre Baskerville';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/librebaskerville/v17/kmKiZrc3Hgbbcjq75U4uslyuy4kn0qviTgY3KcC-wLOj.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+0304,U+0308,U+0329,U+2000-206F,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}</style></head><body><div id=\"__next\"><noscript><img src=\"https://sa.recoding.tech/noscript.gif\" alt=\"\" referrerPolicy=\"no-referrer-when-downgrade\"/></noscript><header class=\"jss2\"><style data-emotion=\"css owsmld\">.css-owsmld{padding:32px;margin-bottom:32px;margin-top:12px;box-shadow:0px 2px 1px -1px rgba(0, 0, 0, 0.2);}</style><div class=\"MuiBox-root css-owsmld\"><style data-emotion=\"css vemis6\">.css-vemis6{box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;width:100%;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;margin-top:-24px;width:calc(100% + 24px);margin-left:-24px;-webkit-box-pack:justify;-webkit-justify-content:space-between;justify-content:space-between;}.css-vemis6>.MuiGrid-item{padding-top:24px;}.css-vemis6>.MuiGrid-item{padding-left:24px;}</style><div class=\"MuiGrid-root MuiGrid-container MuiGrid-spacing-xs-3 css-vemis6\"><style data-emotion=\"css 1y7gpk0\">.css-1y7gpk0{box-sizing:border-box;margin:0;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-flex-basis:83.333333%;-ms-flex-preferred-size:83.333333%;flex-basis:83.333333%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:83.333333%;}@media (min-width:600px){.css-1y7gpk0{-webkit-flex-basis:83.333333%;-ms-flex-preferred-size:83.333333%;flex-basis:83.333333%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:83.333333%;}}@media (min-width:900px){.css-1y7gpk0{-webkit-flex-basis:16.666667%;-ms-flex-preferred-size:16.666667%;flex-basis:16.666667%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:16.666667%;}}@media (min-width:1200px){.css-1y7gpk0{-webkit-flex-basis:16.666667%;-ms-flex-preferred-size:16.666667%;flex-basis:16.666667%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:16.666667%;}}@media (min-width:1536px){.css-1y7gpk0{-webkit-flex-basis:16.666667%;-ms-flex-preferred-size:16.666667%;flex-basis:16.666667%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:16.666667%;}}</style><div class=\"MuiGrid-root MuiGrid-item MuiGrid-grid-xs-10 MuiGrid-grid-md-2 css-1y7gpk0\"><style data-emotion=\"css tgyajb\">.css-tgyajb{-webkit-text-decoration:underline;text-decoration:underline;text-decoration-color:rgba(0, 0, 0, 0.4);}.css-tgyajb:hover{text-decoration-color:inherit;}</style><style data-emotion=\"css mctcqb\">.css-mctcqb{margin:0;font:inherit;color:#000;-webkit-text-decoration:underline;text-decoration:underline;text-decoration-color:rgba(0, 0, 0, 0.4);}.css-mctcqb:hover{text-decoration-color:inherit;}</style><a class=\"MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineAlways jss4 css-mctcqb\" href=\"/\"><style data-emotion=\"css 19sf0qu\">.css-19sf0qu{max-width:170px;}</style><div class=\"MuiBox-root css-19sf0qu\"><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 741.46 299.57\"><path fill=\"#407569\" d=\"M283.82 176.65a23.6 23.6 0 0 0-16.11-11.04 25.91 25.91 0 0 0-17.48 3.01 23.63 23.63 0 0 0-6.88 5.81 22.48 22.48 0 0 0-4.97 17.02 25.77 25.77 0 0 0 15.75 20.49 24.1 24.1 0 0 0 9.18 1.84 23.78 23.78 0 0 0 18.05-8.47 23.75 23.75 0 0 0 4.95-9.3 24.42 24.42 0 0 0-2.49-19.37Z\"></path><path fill=\"#559482\" d=\"M224.98 226.38a21.73 21.73 0 0 0-15.45 5.02l-.34.29a21.7 21.7 0 0 0-7.17 14.6 24.05 24.05 0 0 0 4.25 16.07 22.06 22.06 0 0 0 15.38 9.35l.24.03a22.8 22.8 0 0 0 17.48-5.56 22.84 22.84 0 0 0 7.98-16.52v-.26a22.06 22.06 0 0 0-7.07-16.54 24 24 0 0 0-15.32-6.48Z\"></path><path fill=\"#e5dcc1\" d=\"M171.54 260.92a22.25 22.25 0 0 0-6.53-3.15 20.1 20.1 0 0 0-7.71-.58l-.2.02a18.4 18.4 0 0 0-7.58 2.74 20.62 20.62 0 0 0-5.67 5.07 22.94 22.94 0 0 0-4.77 14.75 20.33 20.33 0 0 0 7.35 15.02 21.38 21.38 0 0 0 7.49 3.98l.27.08a22.49 22.49 0 0 0 8.5.55c2.88-.31 5.68-1.3 8.64-3.07a19.91 19.91 0 0 0 6.28-6.02 20.28 20.28 0 0 0 2.82-16.43 22.61 22.61 0 0 0-8.89-12.95Z\"></path><path fill=\"#1d5d9e\" d=\"M98.01 250.35a16.99 16.99 0 0 0-3.47-1.13 16.55 16.55 0 0 0-3.51-.46 19.4 19.4 0 0 0-6.91 1.12 20.85 20.85 0 0 0-11.23 9.13 18.8 18.8 0 0 0-1.82 15.26 19.2 19.2 0 0 0 3.94 6.89 21.6 21.6 0 0 0 2.92 2.73l.19.14c1.09.78 2.29 1.47 3.49 2.02a19.51 19.51 0 0 0 15.92.35 18.85 18.85 0 0 0 10.39-11.38 21.01 21.01 0 0 0-.39-14.35 18.53 18.53 0 0 0-9.52-10.31Z\"></path><path fill=\"#eebaad\" d=\"m51.52 212.14-.09-.14a16.84 16.84 0 0 0-10.44-7.13 19.19 19.19 0 0 0-13.22 1.51 17.15 17.15 0 0 0-8.95 10.94 17.81 17.81 0 0 0 2.35 14.21 17.32 17.32 0 0 0 5.39 5.48 17.76 17.76 0 0 0 6.74 2.66 17.24 17.24 0 0 0 13.55-3.64 19.08 19.08 0 0 0 6.84-11.37c.45-2.24.49-4.42.12-6.54a17.4 17.4 0 0 0-2.3-5.98Z\"></path><path fill=\"#df1316\" d=\"M32.74 153.88c.09-3.74-1.42-7.4-4.41-10.63a17.67 17.67 0 0 0-10.98-5.37c-4.49-.46-8.77.93-12.01 3.87-3.32 2.89-5.21 7.17-5.34 12.04v.18c.13 4.87 2.02 9.15 5.29 12.02a15.3 15.3 0 0 0 12.05 3.9 17.78 17.78 0 0 0 11.02-5.42c2.95-3.19 4.46-6.85 4.37-10.59Z\"></path><path fill=\"#407569\" d=\"M29.25 98.46a15.9 15.9 0 0 0 10.94 1.26c3.57-.8 6.52-2.8 8.55-5.83.9-1.44 1.52-3.07 1.86-4.87.29-1.65.25-3.43-.12-5.25a15.86 15.86 0 0 0-5.68-9.48 13.96 13.96 0 0 0-11.01-2.95 14.37 14.37 0 0 0-5.43 2.16 14 14 0 0 0-4.39 4.44c-2.28 3.41-3 7.68-1.97 11.74a13.85 13.85 0 0 0 7.25 8.79Z\"></path><path fill=\"#df1316\" d=\"M86.23 51.68c1.5.52 3.08.82 4.6.77.76-.02 1.52-.12 2.26-.3.75-.15 1.5-.38 2.22-.71a12.1 12.1 0 0 0 6.12-6.71 14.41 14.41 0 0 0 .3-9.91 12.26 12.26 0 0 0-6.76-7.44 13.02 13.02 0 0 0-10.54.24c-.89.4-1.72.87-2.47 1.42a15 15 0 0 0-2.01 1.88 12.53 12.53 0 0 0-2.6 4.51 12.3 12.3 0 0 0 1.21 9.98 14.4 14.4 0 0 0 7.69 6.26Z\"></path><path fill=\"#1d5d9e\" d=\"M145.23 54.78c3.35 2.1 7 3.41 10.86 3.89l.38.04c1.15.12 2.27.18 3.36.18 2.61 0 5.05-.34 7.38-1.01 3.1-.88 6.12-2.33 8.97-4.3l.19-.13a30.69 30.69 0 0 0 11.99-17.56c1.97-7.86.55-16.2-3.9-22.89a28.02 28.02 0 0 0-8.86-8.53l-.16-.1A29.28 29.28 0 0 0 163.73.25 30.72 30.72 0 0 0 152.1 1l-.55.15a29.24 29.24 0 0 0-10.26 5.43 28.52 28.52 0 0 0-10.42 21.1 31.22 31.22 0 0 0 6.52 20.13 28.73 28.73 0 0 0 7.8 6.97Z\"></path><path fill=\"#eebaad\" d=\"m205.9 79.71.5.43a26.86 26.86 0 0 0 18.84 6.14 28.94 28.94 0 0 0 18.41-7.8 26.88 26.88 0 0 0 8.62-20.18v-.39a27.82 27.82 0 0 0-9.68-20.03 27.74 27.74 0 0 0-21.2-6.73l-.36.04a27.27 27.27 0 0 0-18.78 11.4 29.02 29.02 0 0 0-5.12 19.33 26.86 26.86 0 0 0 8.76 17.8Z\"></path><path fill=\"#df1316\" d=\"M287.91 111.41a25.63 25.63 0 0 0-5.37-10.09 25.25 25.25 0 0 0-29.03-7.02 27.38 27.38 0 0 0-13.99 12.88l-.07.15a26.5 26.5 0 0 0-2.69 8.7c-.37 3.07-.13 6.24.73 9.55a25.42 25.42 0 0 0 12.01 15.03 27.72 27.72 0 0 0 18.5 3.15 25.2 25.2 0 0 0 17.19-11.74 26.19 26.19 0 0 0 3.48-9.76c.52-3.48.26-7.17-.75-10.85Z\"></path><path fill=\"#407569\" d=\"M75.31 136.46a11.73 11.73 0 0 0 8 5.48c2.95.54 5.94.03 8.67-1.49a11.8 11.8 0 0 0 5.56-7c.38-1.48.49-2.95.33-4.33a12.76 12.76 0 0 0-7.82-10.17 11.92 11.92 0 0 0-4.55-.91 11.8 11.8 0 0 0-8.96 4.21 11.82 11.82 0 0 0-2.46 4.61 12.2 12.2 0 0 0 1.23 9.61Z\"></path><path fill=\"#559482\" d=\"M104.51 111.78a10.8 10.8 0 0 0 7.67-2.49l.17-.14c2.1-1.9 3.33-4.41 3.56-7.24.27-2.82-.48-5.65-2.11-7.98a10.94 10.94 0 0 0-7.63-4.64h-.12a11.32 11.32 0 0 0-8.67 2.74 11.36 11.36 0 0 0-3.96 8.2v.13a10.93 10.93 0 0 0 3.51 8.21 11.99 11.99 0 0 0 7.6 3.22Z\"></path><path fill=\"#e5dcc1\" d=\"M131.03 94.64a9.91 9.91 0 0 0 7.07 1.85h.1a9.4 9.4 0 0 0 3.76-1.37 10.02 10.02 0 0 0 2.81-2.52 11.38 11.38 0 0 0 2.36-7.32 10.04 10.04 0 0 0-3.65-7.45 10.5 10.5 0 0 0-3.72-1.97l-.14-.04a11.3 11.3 0 0 0-4.21-.27 10.63 10.63 0 0 0-7.41 4.51 10.07 10.07 0 0 0-1.4 8.15c.65 2.58 2.2 4.85 4.41 6.43Z\"></path><path fill=\"#1d5d9e\" d=\"M167.51 99.89c.54.24 1.12.43 1.72.56a9.37 9.37 0 0 0 5.17-.33 10.3 10.3 0 0 0 5.57-4.53 9.32 9.32 0 0 0-1.05-10.99c-.43-.49-.92-.95-1.45-1.36l-.09-.07a10.35 10.35 0 0 0-5.87-1.93 9.37 9.37 0 0 0-8.93 6.41c-.78 2.31-.7 4.84.2 7.12a9.18 9.18 0 0 0 4.73 5.12Z\"></path><path fill=\"#eebaad\" d=\"m190.59 118.85.04.07a8.36 8.36 0 0 0 5.18 3.54c2.21.54 4.54.27 6.56-.75a8.5 8.5 0 0 0 4.44-5.43 8.84 8.84 0 0 0-1.17-7.05 8.6 8.6 0 0 0-2.68-2.72 8.77 8.77 0 0 0-4.7-1.43c-1.94 0-3.81.66-5.37 1.91a9.4 9.4 0 0 0-3.39 5.64 8.9 8.9 0 0 0-.06 3.25 8.69 8.69 0 0 0 1.14 2.96Z\"></path><path fill=\"#df1316\" d=\"M199.9 147.76a7.5 7.5 0 0 0 2.19 5.28 8.85 8.85 0 0 0 5.45 2.67 7.6 7.6 0 0 0 5.96-1.92 8.12 8.12 0 0 0 2.65-5.98v-.08a8.03 8.03 0 0 0-2.63-5.96 7.61 7.61 0 0 0-5.99-1.94c-2.07.21-4 1.16-5.47 2.69a7.45 7.45 0 0 0-2.17 5.25Z\"></path><path fill=\"#407569\" d=\"M201.63 175.26a7.9 7.9 0 0 0-5.43-.63 6.82 6.82 0 0 0-4.24 2.89 6.84 6.84 0 0 0-.86 5.03 7.82 7.82 0 0 0 2.82 4.7 6.97 6.97 0 0 0 5.47 1.47 7.18 7.18 0 0 0 2.7-1.07 7.04 7.04 0 0 0 2.18-2.2 7.26 7.26 0 0 0 .98-5.82 6.9 6.9 0 0 0-3.6-4.36Z\"></path><path fill=\"#eebaad\" d=\"M173.36 198.47a6.3 6.3 0 0 0-2.29-.38c-.38 0-.75.06-1.12.15-.37.08-.74.19-1.1.35a6 6 0 0 0-3.04 3.33 7.2 7.2 0 0 0-.15 4.92 6.09 6.09 0 0 0 3.36 3.69c1.55.65 3.48.71 5.23-.12.44-.2.85-.43 1.23-.7.37-.28.7-.6 1-.93a6.1 6.1 0 0 0 .69-7.19 7.1 7.1 0 0 0-3.82-3.1Z\"></path><path fill=\"#1d5d9e\" d=\"M144.08 196.93a13.15 13.15 0 0 0-5.39-1.93l-.19-.02a13.26 13.26 0 0 0-5.33.41 15.28 15.28 0 0 0-4.45 2.13l-.09.07a15.23 15.23 0 0 0-5.95 8.71 14.3 14.3 0 0 0 1.93 11.36c1.12 1.7 2.6 3.13 4.39 4.23l.08.05a14.6 14.6 0 0 0 5.81 2.05c1.95.24 3.9.12 5.77-.37l.27-.08a14.15 14.15 0 0 0 10.26-13.16c.14-3.54-1-7.07-3.24-9.99a14.32 14.32 0 0 0-3.87-3.46Z\"></path><path fill=\"#eebaad\" d=\"m113.97 184.56-.25-.22a13.3 13.3 0 0 0-8.53-3.07c-.27 0-.55 0-.82.02-3.4.16-6.64 1.53-9.14 3.87a13.33 13.33 0 0 0-4.28 10.01v.2c.16 3.86 1.9 7.47 4.81 9.94a13.78 13.78 0 0 0 10.52 3.34l.18-.02a13.5 13.5 0 0 0 9.32-5.66 14.36 14.36 0 0 0 2.54-9.59 13.32 13.32 0 0 0-4.35-8.83Z\"></path><path fill=\"#df1316\" d=\"M73.28 168.83a12.75 12.75 0 0 0 2.66 5.01 12.52 12.52 0 0 0 14.4 3.48c3-1.23 5.47-3.5 6.94-6.39l.04-.07a13.05 13.05 0 0 0 1.33-4.32 11.97 11.97 0 0 0-2.65-9.11 12.58 12.58 0 0 0-3.67-3.09 13.82 13.82 0 0 0-9.18-1.57 12.5 12.5 0 0 0-10.26 10.67c-.26 1.73-.13 3.56.37 5.38Z\"></path><path fill=\"#1d5d9e\" d=\"M144.46 132.54a17.25 17.25 0 1 0 0 34.5 17.25 17.25 0 0 0 0-34.5Z\"></path><path fill=\"#231f20\" d=\"M361.96 107.57c10.32-1.47 16.95-3.39 16.95-11.35V25.45c0-3.98-1.47-5.01-4.86-5.01h-2.8c-12.53 0-22.41 4.28-24.62 9.58-1.33 3.39-7.22 2.8-6.49 0 1.48-4.72 2.65-10.32 3.54-18.58.29-3.24 1.77-2.95 4.57-2.65 8.7.88 13.12 1.18 42.31 1.18s37.45-.29 46.88-1.18c2.65-.3 5.16-.59 4.13 2.65a173.13 173.13 0 0 0-4.72 18.58c-.44 2.51-4.87 2.95-5.6 0-1.62-5.01-8.7-9.58-20.64-9.58h-3.54c-3.54 0-5.89 1.03-5.89 5.01v70.77c0 7.96 6.63 9.88 17.1 11.35 1.18.15.29 5.6-1.03 5.6h-54.4c-1.18 0-2.21-5.45-.88-5.6Zm132.4-1.91c-5.45 2.21-17.1 9.88-20.2 9.88-19.46 0-42.61-7.96-42.61-34.35 0-18.13 11.5-39.22 37.74-39.22 22.26 0 25.21 16.22 25.21 22.11 0 3.83-1.33 10.47-3.24 14.3l-40.54 1.18c3.1 16.51 16.22 23.59 28.31 23.59 1.33 0 7.67-.74 13.42-1.92 1.33-.29 2.65 4.13 1.91 4.42Zm-44.38-34.79 27.57-.88c1.47-9.29-4.13-17.4-13.71-17.4-10.32 0-13.71 7.81-13.86 18.28Zm48.96 10.02c0-17.69 11.5-38.92 40.99-38.92 8.99 0 20.35 2.8 19.02 7.52l-1.62 5.9c-3.54 14.15-11.21-2.8-25.36-2.8-9.73 0-13.71 8.99-13.71 19.17 0 19.61 15.18 31.4 24.77 31.4 1.33 0 6.49-.59 14.01-2.21 1.33-.29 2.8 4.28 2.06 4.57-5.31 2.65-16.07 10.02-19.17 10.02-17.69 0-40.99-8.99-40.99-34.65Z\"></path><path fill=\"#231f20\" d=\"M558.85 108.02c4.42-.59 10.02-2.65 10.02-11.2V32.98c0-15.92-2.21-18.72-10.47-19.61-1.33-.15-.59-4.42.59-4.87l29.48-6.19a1.94 1.94 0 0 1 2.21 2.65c-2.36 9.14-2.8 27.86-2.8 39.66 0 3.69 2.06 5.01 4.27 4.28 7.52-2.51 14.89-6.93 23.59-6.93 14.74 0 19.02 11.06 19.02 20.05v34.79c0 8.55 5.75 10.61 10.02 11.2 1.18.15.15 5.16-.88 5.16h-36.12c-.88 0-1.62-5.01-.74-5.16 5.9-.89 8.7-3.83 8.7-11.2V70.86c0-12.38-3.84-15.63-14.3-15.63-5.9 0-13.56 1.62-13.56 5.46v36.12c0 6.78 3.54 10.32 10.17 11.2 1.03.15.15 5.16-1.03 5.16h-37.15c-1.18 0-2.21-5.01-1.03-5.16Zm-163.41 83.72v20.05c0 10.32 7.52 12.09 16.22 13.27 1.03.15.29 5.75-.89 5.75h-48.06c-1.18 0-2.07-5.6-.88-5.75 7.96-1.03 11.94-4.42 11.94-13.27v-64.28c0-9.73-5.01-12.53-11.94-14.45-1.18-.29-.44-5.9.88-5.75 5.6.74 11.94.89 17.25.89 12.53 0 22.11-.89 29.48-.89 24.33 0 43.49 8.55 43.49 31.55 0 25.8-24.62 37.59-57.5 32.88Zm0-44.23v36.27c23.15 2.95 34.2-3.98 34.2-21.38 0-14.74-8.84-26.39-24.77-26.39-7.67 0-9.44 2.8-9.44 11.5Zm58.89 49.69c0-21.38 15.48-37.59 37.15-37.59 20.49 0 36.42 14.3 36.42 36.12s-15.19 37.45-37.15 37.45c-20.49 0-36.42-14.3-36.42-35.97Zm54.7 6.34c0-19.17-8.99-33.76-22.26-33.76-6.34 0-13.57 3.83-13.57 19.17 0 19.46 8.99 34.06 22.11 34.06 6.49 0 13.71-3.83 13.71-19.46Z\"></path><path fill=\"#231f20\" d=\"M527.66 225.65c4.42-.59 9.88-2.65 9.88-11.2v-63.1c0-16.36-2.21-19.46-11.21-20.34-1.33-.15-.59-4.42.59-4.57l30.22-6.49c1.18-.29 2.8.74 2.21 2.65-.88 4.72-2.8 14.74-2.8 34.65v57.2c0 8.55 5.31 10.61 9.73 11.2 1.18.15.15 5.16-1.03 5.16h-36.56c-1.18 0-2.21-5.01-1.03-5.16Z\"></path><path fill=\"#231f20\" d=\"M564.18 225.65c4.57-.59 10.17-2.65 10.17-11.2v-30.81c0-9.29-2.36-11.35-9.73-12.24-1.33-.15-.59-4.57.59-4.87l28.75-6.63c1.47-.15 2.21.74 1.77 2.65a116.38 116.38 0 0 0-2.36 23.15v28.75c0 8.55 5.45 10.61 9.88 11.2 1.03.15.15 5.16-1.03 5.16h-37c-1.18 0-2.21-5.01-1.03-5.16Zm5.6-90.23c0-4.72 8.55-12.53 12.68-12.53s12.68 7.81 12.68 12.53-8.55 12.53-12.68 12.53-12.68-7.67-12.68-12.53Z\"></path><path fill=\"#231f20\" d=\"M601.19 198.52c0-17.69 11.5-38.92 40.99-38.92 8.99 0 20.35 2.8 19.02 7.52l-1.62 5.9c-3.54 14.15-11.21-2.8-25.36-2.8-9.73 0-13.71 8.99-13.71 19.17 0 19.61 15.18 31.4 24.77 31.4 1.33 0 6.49-.59 14.01-2.21 1.33-.29 2.8 4.28 2.06 4.57-5.31 2.65-16.07 10.02-19.17 10.02-17.69 0-40.99-8.99-40.99-34.65Z\"></path><path fill=\"#231f20\" d=\"M740.22 168.3c-4.13 1.18-8.25 5.46-12.53 15.04l-28.45 63.99c-4.86 10.61-16.07 12.09-21.08 12.09-8.55 0-12.53-4.57-14.89-10.76-2.8-8.11.59-4.72 11.5-4.72 9.88 0 17.84-2.36 22.41-12.53l-21.23-48.06c-4.57-10.32-8.26-14.3-12.53-15.04-1.62-.29-1.62-6.04.15-6.04h33.17c2.21 0 2.21 4.87.29 6.04-3.69 2.21-4.86 5.46-.44 15.04l10.76 24.47 10.47-24.18c4.27-10.02 3.54-14.6-3.1-15.33-1.62-.15-1.62-6.04.15-6.04h25.06c2.07 0 1.92 5.6.29 6.04Z\"></path><path fill=\"#1d5d9e\" d=\"M360.99 292c0-1.92 3.38-4.96 5.01-4.96s5.02 3.03 5.02 4.96-3.38 4.96-5.02 4.96-5.01-3.03-5.01-4.96Zm29.1-11.08v7.93c0 4.08 2.97 4.78 6.41 5.25.41.06.12 2.27-.35 2.27h-19.01c-.47 0-.82-2.22-.35-2.27 3.15-.41 4.72-1.75 4.72-5.25v-25.42c0-3.85-1.98-4.96-4.72-5.72-.47-.12-.18-2.33.35-2.27 2.22.29 4.72.35 6.82.35 4.96 0 8.75-.35 11.66-.35 9.62 0 17.2 3.38 17.2 12.48 0 10.2-9.74 14.87-22.74 13Zm0-17.49v14.34c9.15 1.17 13.53-1.57 13.53-8.46 0-5.83-3.5-10.44-9.8-10.44-3.03 0-3.73 1.11-3.73 4.55Zm73.01 33.12c-4.32 1.17-9.74 1.4-13.7-3.67l-8.81-11.31c-2.62-3.44-5.13-3.79-8.98-3.85v11.14c0 4.08 2.97 4.78 6.41 5.25.41.06.12 2.27-.35 2.27h-19.01c-.47 0-.82-2.22-.35-2.27 3.15-.41 4.72-1.75 4.72-5.25v-25.42c0-3.85-1.98-4.96-4.72-5.72-.47-.12-.18-2.33.35-2.27 2.22.29 4.72.35 6.82.35 4.96 0 9.5-.35 12.42-.35 9.62 0 15.16 3.85 15.16 10.79 0 6.47-5.07 9.8-10.73 10.09v.29c2.68 0 4.72 1.11 7.46 4.49l8.16 10.38c2.1 2.57 4.14 3.27 5.13 3.27.47 0 .29 1.75 0 1.81Zm-18.95-28.63c0-6.12-3.56-9.04-8.46-9.04-3.27 0-4.08 1.34-4.08 4.55v11.31h1.46c8.57 0 11.08-1.46 11.08-6.82Zm21.74 26.06c3.32-.87 5.89-1.4 5.89-5.72v-25.48c0-3.5-2.33-4.43-4.78-5.13-.47-.12-.12-2.27.23-2.22 4.2.64 13.35.35 15.69.35 5.31 0 8.98-.23 14.05-.35 1.46 0 1.52.93 1.22 2.33l-1.34 5.6c-.18.87-1.69.87-1.92 0-.99-3.03-2.57-4.26-9.68-4.26-3.61 0-4.9 1.05-4.9 3.79v9.21c0 1.52.76 1.81 1.92 1.81h1.52c4.02 0 8.4-.64 10.5-2.33.64-.53 1.98-.41 1.4.87l-3.15 7.35c-.52 1.17-1.52 1.05-2.16.12-1.28-1.92-4.14-2.74-7-2.74h-1.11c-1.17 0-1.92.29-1.92 1.81v9.27c0 3.27 1.17 4.66 5.72 4.66 7.76 0 12.07-4.37 13.35-6.24.35-.47 2.22 0 2.22.87 0 2.51-2.68 9.04-6.53 8.92-3.97-.18-6.36-.35-11.08-.35-5.31 0-12.6-.18-17.78.35-.58.06-.82-2.39-.35-2.51Zm41.63-1.34.64-2.39c1.81-6.82 4.02 2.86 13.65 2.86 4.61 0 6.24-2.22 6.24-5.19 0-2.22-1.05-3.15-5.83-6.24l-4.2-2.92c-6.88-4.55-9.85-6.82-9.85-11.72 0-7.58 7.58-12.42 14.52-12.42 4.37 0 10.26 1.98 9.56 3.97l-.76 2.33c-2.1 6.36-3.38-2.04-11.37-2.04-3.61 0-5.6 1.75-5.6 4.66 0 2.74 1.63 4.08 5.48 6.53l4.96 3.32c6.59 4.26 9.27 6.82 9.27 11.31 0 7.52-7.23 12.6-15.05 12.6-4.72 0-12.42-1.92-11.66-4.66Zm33.18 0 .64-2.39c1.81-6.82 4.02 2.86 13.65 2.86 4.61 0 6.24-2.22 6.24-5.19 0-2.22-1.05-3.15-5.83-6.24l-4.2-2.92c-6.88-4.55-9.85-6.82-9.85-11.72 0-7.58 7.58-12.42 14.52-12.42 4.37 0 10.26 1.98 9.56 3.97l-.76 2.33c-2.1 6.36-3.38-2.04-11.37-2.04-3.61 0-5.6 1.75-5.6 4.66 0 2.74 1.63 4.08 5.48 6.53l4.96 3.32c6.59 4.26 9.27 6.82 9.27 11.31 0 7.52-7.23 12.6-15.05 12.6-4.72 0-12.42-1.92-11.66-4.66Z\"></path></svg></div><style data-emotion=\"css 1sm5mum\">.css-1sm5mum{margin:0;font-size:14px;line-height:1.4;font-family:'Libre Baskerville',serif;font-weight:400;display:none;}</style><p class=\"MuiTypography-root MuiTypography-body1 css-1sm5mum\">Home</p></a></div><style data-emotion=\"css 1cb5ytm\">.css-1cb5ytm{box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;width:100%;margin:0;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;margin-top:-32px;width:calc(100% + 32px);margin-left:-32px;-webkit-flex-basis:calc(16.666667% + 32px);-ms-flex-preferred-size:calc(16.666667% + 32px);flex-basis:calc(16.666667% + 32px);-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:calc(16.666667% + 32px);-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:end;-ms-flex-pack:end;-webkit-justify-content:flex-end;justify-content:flex-end;}.css-1cb5ytm>.MuiGrid-item{padding-top:32px;}.css-1cb5ytm>.MuiGrid-item{padding-left:32px;}@media (min-width:600px){.css-1cb5ytm{-webkit-flex-basis:calc(16.666667% + 32px);-ms-flex-preferred-size:calc(16.666667% + 32px);flex-basis:calc(16.666667% + 32px);-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:calc(16.666667% + 32px);}}@media (min-width:900px){.css-1cb5ytm{-webkit-flex-basis:calc(83.333333% + 32px);-ms-flex-preferred-size:calc(83.333333% + 32px);flex-basis:calc(83.333333% + 32px);-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:calc(83.333333% + 32px);}}@media (min-width:1200px){.css-1cb5ytm{-webkit-flex-basis:calc(83.333333% + 32px);-ms-flex-preferred-size:calc(83.333333% + 32px);flex-basis:calc(83.333333% + 32px);-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:calc(83.333333% + 32px);}}@media (min-width:1536px){.css-1cb5ytm{-webkit-flex-basis:calc(83.333333% + 32px);-ms-flex-preferred-size:calc(83.333333% + 32px);flex-basis:calc(83.333333% + 32px);-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:calc(83.333333% + 32px);}}</style><div class=\"MuiGrid-root MuiGrid-container MuiGrid-item MuiGrid-spacing-xs-4 MuiGrid-grid-xs-2 MuiGrid-grid-md-10 jss5 css-1cb5ytm\"><style data-emotion=\"css 1waopz6\">.css-1waopz6{box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;width:100%;margin:0;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;margin-top:-48px;width:calc(100% + 48px);margin-left:-48px;-webkit-flex-basis:calc(100% + 48px);-ms-flex-preferred-size:calc(100% + 48px);flex-basis:calc(100% + 48px);-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:calc(100% + 48px);-webkit-align-items:flex-end;-webkit-box-align:flex-end;-ms-flex-align:flex-end;align-items:flex-end;-webkit-box-pack:justify;-webkit-justify-content:space-between;justify-content:space-between;}.css-1waopz6>.MuiGrid-item{padding-top:48px;}.css-1waopz6>.MuiGrid-item{padding-left:48px;}@media (min-width:600px){.css-1waopz6{-webkit-flex-basis:calc(100% + 48px);-ms-flex-preferred-size:calc(100% + 48px);flex-basis:calc(100% + 48px);-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:calc(100% + 48px);}}@media (min-width:900px){.css-1waopz6{-webkit-flex-basis:calc(100% + 48px);-ms-flex-preferred-size:calc(100% + 48px);flex-basis:calc(100% + 48px);-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:calc(100% + 48px);}}@media (min-width:1200px){.css-1waopz6{-webkit-flex-basis:calc(100% + 48px);-ms-flex-preferred-size:calc(100% + 48px);flex-basis:calc(100% + 48px);-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:calc(100% + 48px);}}@media (min-width:1536px){.css-1waopz6{-webkit-flex-basis:calc(100% + 48px);-ms-flex-preferred-size:calc(100% + 48px);flex-basis:calc(100% + 48px);-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:calc(100% + 48px);}}</style><div class=\"MuiGrid-root MuiGrid-container MuiGrid-item MuiGrid-spacing-xs-6 MuiGrid-grid-xs-12 css-1waopz6\"><style data-emotion=\"css iplmjk\">.css-iplmjk{box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;width:100%;margin:0;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;margin-top:-8px;width:calc(100% + 8px);margin-left:-8px;-webkit-flex-basis:calc(75% + 8px);-ms-flex-preferred-size:calc(75% + 8px);flex-basis:calc(75% + 8px);-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:calc(75% + 8px);margin-top:8px;-webkit-box-flex-wrap:nowrap;-webkit-flex-wrap:nowrap;-ms-flex-wrap:nowrap;flex-wrap:nowrap;-webkit-box-pack:justify;-webkit-justify-content:space-between;justify-content:space-between;}.css-iplmjk>.MuiGrid-item{padding-top:8px;}.css-iplmjk>.MuiGrid-item{padding-left:8px;}@media (min-width:600px){.css-iplmjk{-webkit-flex-basis:calc(75% + 8px);-ms-flex-preferred-size:calc(75% + 8px);flex-basis:calc(75% + 8px);-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:calc(75% + 8px);}}@media (min-width:900px){.css-iplmjk{-webkit-flex-basis:calc(75% + 8px);-ms-flex-preferred-size:calc(75% + 8px);flex-basis:calc(75% + 8px);-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:calc(75% + 8px);}}@media (min-width:1200px){.css-iplmjk{-webkit-flex-basis:calc(75% + 8px);-ms-flex-preferred-size:calc(75% + 8px);flex-basis:calc(75% + 8px);-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:calc(75% + 8px);}}@media (min-width:1536px){.css-iplmjk{-webkit-flex-basis:calc(75% + 8px);-ms-flex-preferred-size:calc(75% + 8px);flex-basis:calc(75% + 8px);-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:calc(75% + 8px);}}</style><div class=\"MuiGrid-root MuiGrid-container MuiGrid-item MuiGrid-spacing-xs-1 MuiGrid-grid-xs-9 css-iplmjk\"><style data-emotion=\"css 1wxaqej\">.css-1wxaqej{box-sizing:border-box;margin:0;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;}</style><div class=\"MuiGrid-root MuiGrid-item css-1wxaqej\"><style data-emotion=\"css 1jk0jc8\">.css-1jk0jc8{font-family:'Libre Baskerville',serif;font-weight:500;font-size:0.875rem;line-height:1.75;text-transform:uppercase;min-width:64px;padding:6px 8px;border-radius:4px;-webkit-transition:background-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,box-shadow 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,border-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:background-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,box-shadow 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,border-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;color:#000;color:#000;font-family:'Lexend',sans-serif;text-align:center;text-transform:none;font-size:1em;font-weight:500;margin-top:3px;padding-top:0px;text-transform:none;}.css-1jk0jc8:hover{-webkit-text-decoration:none;text-decoration:none;background-color:rgba(0, 0, 0, 0.04);}@media (hover: none){.css-1jk0jc8:hover{background-color:transparent;}}.css-1jk0jc8.Mui-disabled{color:rgba(0, 0, 0, 0.26);}.css-1jk0jc8:active,.css-1jk0jc8:focus,.css-1jk0jc8:hover{background-color:#f2f2f2;border-radius:0;}</style><style data-emotion=\"css 1h1zga1\">.css-1h1zga1{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;position:relative;box-sizing:border-box;-webkit-tap-highlight-color:transparent;background-color:transparent;outline:0;border:0;margin:0;border-radius:0;padding:0;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;vertical-align:middle;-moz-appearance:none;-webkit-appearance:none;-webkit-text-decoration:none;text-decoration:none;color:inherit;font-family:'Libre Baskerville',serif;font-weight:500;font-size:0.875rem;line-height:1.75;text-transform:uppercase;min-width:64px;padding:6px 8px;border-radius:4px;-webkit-transition:background-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,box-shadow 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,border-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:background-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,box-shadow 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,border-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;color:#000;color:#000;font-family:'Lexend',sans-serif;text-align:center;text-transform:none;font-size:1em;font-weight:500;margin-top:3px;padding-top:0px;text-transform:none;}.css-1h1zga1::-moz-focus-inner{border-style:none;}.css-1h1zga1.Mui-disabled{pointer-events:none;cursor:default;}@media print{.css-1h1zga1{-webkit-print-color-adjust:exact;color-adjust:exact;}}.css-1h1zga1:hover{-webkit-text-decoration:none;text-decoration:none;background-color:rgba(0, 0, 0, 0.04);}@media (hover: none){.css-1h1zga1:hover{background-color:transparent;}}.css-1h1zga1.Mui-disabled{color:rgba(0, 0, 0, 0.26);}.css-1h1zga1:active,.css-1h1zga1:focus,.css-1h1zga1:hover{background-color:#f2f2f2;border-radius:0;}</style><button class=\"MuiButtonBase-root MuiButton-root MuiButton-text MuiButton-textPrimary MuiButton-sizeMedium MuiButton-textSizeMedium MuiButton-root MuiButton-text MuiButton-textPrimary MuiButton-sizeMedium MuiButton-textSizeMedium css-1h1zga1\" tabindex=\"0\" type=\"button\" id=\"topics-button\" aria-haspopup=\"true\">Topics<style data-emotion=\"css pt151d\">.css-pt151d{display:inherit;margin-right:-4px;margin-left:8px;}.css-pt151d>*:nth-of-type(1){font-size:20px;}</style><span class=\"MuiButton-endIcon MuiButton-iconSizeMedium css-pt151d\"><style data-emotion=\"css vubbuv\">.css-vubbuv{-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;width:1em;height:1em;display:inline-block;fill:currentColor;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;-webkit-transition:fill 200ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:fill 200ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;font-size:1.5rem;}</style><svg class=\"MuiSvgIcon-root MuiSvgIcon-fontSizeMedium css-vubbuv\" focusable=\"false\" aria-hidden=\"true\" viewBox=\"0 0 24 24\" data-testid=\"ArrowDropDownIcon\"><path d=\"m7 10 5 5 5-5z\"></path></svg></span></button><style data-emotion=\"css krqjsm\">.css-krqjsm{margin-top:32px;}.css-krqjsm ul{display:grid;grid-template-columns:repeat(4, 1fr);max-width:60vw!important;padding:24px;width:60vw;}</style><style data-emotion=\"css 1ahz2t2\">.css-1ahz2t2{margin-top:32px;}.css-1ahz2t2 ul{display:grid;grid-template-columns:repeat(4, 1fr);max-width:60vw!important;padding:24px;width:60vw;}</style></div><div class=\"MuiGrid-root MuiGrid-item css-1wxaqej\"><style data-emotion=\"css 1lsxddw\">.css-1lsxddw{margin:0;font-family:'Lexend',sans-serif;font-size:1em;font-weight:700;margin-bottom:20px;text-transform:uppercase;line-height:1.235;font-weight:500;margin-bottom:0px;padding:8px;text-transform:none;}.css-1lsxddw:active,.css-1lsxddw:focus,.css-1lsxddw:hover{background:#f2f2f2;}</style><div class=\"MuiTypography-root MuiTypography-h4 css-1lsxddw\"><a class=\"MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineAlways jss3 css-mctcqb\" href=\"/tracker\">Policy Tracker</a></div></div><div class=\"MuiGrid-root MuiGrid-item css-1wxaqej\"><div class=\"MuiTypography-root MuiTypography-h4 css-1lsxddw\"><a class=\"MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineAlways jss3 css-mctcqb\" href=\"/newsletter\">Newsletter</a></div></div><div class=\"MuiGrid-root MuiGrid-item css-1wxaqej\"><div class=\"MuiTypography-root MuiTypography-h4 css-1lsxddw\"><a class=\"MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineAlways jss3 css-mctcqb\" href=\"/podcast\">Podcast</a></div></div><div class=\"MuiGrid-root MuiGrid-item css-1wxaqej\"><button class=\"MuiButtonBase-root MuiButton-root MuiButton-text MuiButton-textPrimary MuiButton-sizeMedium MuiButton-textSizeMedium MuiButton-root MuiButton-text MuiButton-textPrimary MuiButton-sizeMedium MuiButton-textSizeMedium css-1h1zga1\" tabindex=\"0\" type=\"button\" id=\"projects-button\" aria-haspopup=\"true\">Projects<span class=\"MuiButton-endIcon MuiButton-iconSizeMedium css-pt151d\"><svg class=\"MuiSvgIcon-root MuiSvgIcon-fontSizeMedium css-vubbuv\" focusable=\"false\" aria-hidden=\"true\" viewBox=\"0 0 24 24\" data-testid=\"ArrowDropDownIcon\"><path d=\"m7 10 5 5 5-5z\"></path></svg></span></button><style data-emotion=\"css 182hug8\">.css-182hug8{margin-top:32px;padding:24px;}.css-182hug8 ul{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;max-width:30vw;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;width:100%;}</style><style data-emotion=\"css 26s0vz\">.css-26s0vz{margin-top:32px;padding:24px;}.css-26s0vz ul{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;max-width:30vw;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;width:100%;}</style></div><div class=\"MuiGrid-root MuiGrid-item css-1wxaqej\"><div class=\"MuiTypography-root MuiTypography-h4 css-1lsxddw\"><a class=\"MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineAlways jss3 css-mctcqb\" href=\"/contributors\">Contributors</a></div></div><div class=\"MuiGrid-root MuiGrid-item css-1wxaqej\"><div class=\"MuiTypography-root MuiTypography-h4 css-1lsxddw\"><a class=\"MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineAlways jss3 css-mctcqb\" href=\"/about-us\">About</a></div></div></div><style data-emotion=\"css scfx6e\">.css-scfx6e{box-sizing:border-box;margin:0;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-flex-basis:25%;-ms-flex-preferred-size:25%;flex-basis:25%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:25%;-webkit-box-flex:2;-webkit-flex-grow:2;-ms-flex-positive:2;flex-grow:2;}@media (min-width:600px){.css-scfx6e{-webkit-flex-basis:25%;-ms-flex-preferred-size:25%;flex-basis:25%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:25%;}}@media (min-width:900px){.css-scfx6e{-webkit-flex-basis:25%;-ms-flex-preferred-size:25%;flex-basis:25%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:25%;}}@media (min-width:1200px){.css-scfx6e{-webkit-flex-basis:25%;-ms-flex-preferred-size:25%;flex-basis:25%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:25%;}}@media (min-width:1536px){.css-scfx6e{-webkit-flex-basis:25%;-ms-flex-preferred-size:25%;flex-basis:25%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:25%;}}</style><div class=\"MuiGrid-root MuiGrid-item MuiGrid-grid-xs-3 css-scfx6e\"><style data-emotion=\"css r03b1s\">.css-r03b1s{text-align:center;-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;font-size:1.5rem;padding:8px;border-radius:50%;overflow:visible;color:rgba(0, 0, 0, 0.54);-webkit-transition:background-color 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:background-color 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;width:40px;}.css-r03b1s:hover{background-color:rgba(0, 0, 0, 0.04);}@media (hover: none){.css-r03b1s:hover{background-color:transparent;}}.css-r03b1s.Mui-disabled{background-color:transparent;color:rgba(0, 0, 0, 0.26);}</style><style data-emotion=\"css 1jrrc4c\">.css-1jrrc4c{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;position:relative;box-sizing:border-box;-webkit-tap-highlight-color:transparent;background-color:transparent;outline:0;border:0;margin:0;border-radius:0;padding:0;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;vertical-align:middle;-moz-appearance:none;-webkit-appearance:none;-webkit-text-decoration:none;text-decoration:none;color:inherit;text-align:center;-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;font-size:1.5rem;padding:8px;border-radius:50%;overflow:visible;color:rgba(0, 0, 0, 0.54);-webkit-transition:background-color 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:background-color 150ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;width:40px;}.css-1jrrc4c::-moz-focus-inner{border-style:none;}.css-1jrrc4c.Mui-disabled{pointer-events:none;cursor:default;}@media print{.css-1jrrc4c{-webkit-print-color-adjust:exact;color-adjust:exact;}}.css-1jrrc4c:hover{background-color:rgba(0, 0, 0, 0.04);}@media (hover: none){.css-1jrrc4c:hover{background-color:transparent;}}.css-1jrrc4c.Mui-disabled{background-color:transparent;color:rgba(0, 0, 0, 0.26);}</style><button class=\"MuiButtonBase-root MuiIconButton-root MuiIconButton-sizeMedium css-1jrrc4c\" tabindex=\"0\" type=\"search\" aria-label=\"search\"><style data-emotion=\"css o261au\">.css-o261au{-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;width:1em;height:1em;display:inline-block;fill:currentColor;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;-webkit-transition:fill 200ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:fill 200ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;font-size:1.5rem;color:#000;}</style><svg class=\"MuiSvgIcon-root MuiSvgIcon-fontSizeMedium css-o261au\" focusable=\"false\" aria-hidden=\"true\" viewBox=\"0 0 24 24\" data-testid=\"SearchIcon\"><path d=\"M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z\"></path></svg></button><style data-emotion=\"css 1mxq86i\">.css-1mxq86i{font-family:'Libre Baskerville',serif;font-weight:500;font-size:0.875rem;line-height:1.75;text-transform:uppercase;min-width:64px;padding:6px 16px;border-radius:4px;-webkit-transition:background-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,box-shadow 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,border-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:background-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,box-shadow 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,border-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;background-color:#273649;box-shadow:0px 3px 1px -2px rgba(0,0,0,0.2),0px 2px 2px 0px rgba(0,0,0,0.14),0px 1px 5px 0px rgba(0,0,0,0.12);color:#000;font-family:'Lexend',sans-serif;text-align:center;text-transform:none;border-radius:4px;color:#FFF;background-color:#DF1316;font-family:\"Roboto\",sans-serif;font-size:13px;font-weight:500;position:relative;text-transform:uppercase;margin-left:24px;}.css-1mxq86i:hover{-webkit-text-decoration:none;text-decoration:none;box-shadow:0px 2px 4px -1px rgba(0,0,0,0.2),0px 4px 5px 0px rgba(0,0,0,0.14),0px 1px 10px 0px rgba(0,0,0,0.12);}@media (hover: none){.css-1mxq86i:hover{background-color:#273649;}}.css-1mxq86i:active{box-shadow:0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);}.css-1mxq86i.Mui-focusVisible{box-shadow:0px 3px 5px -1px rgba(0,0,0,0.2),0px 6px 10px 0px rgba(0,0,0,0.14),0px 1px 18px 0px rgba(0,0,0,0.12);}.css-1mxq86i.Mui-disabled{color:rgba(0, 0, 0, 0.26);box-shadow:none;background-color:rgba(0, 0, 0, 0.12);}</style><style data-emotion=\"css iojclc\">.css-iojclc{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-ms-flex-pack:center;-webkit-justify-content:center;justify-content:center;position:relative;box-sizing:border-box;-webkit-tap-highlight-color:transparent;background-color:transparent;outline:0;border:0;margin:0;border-radius:0;padding:0;cursor:pointer;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;vertical-align:middle;-moz-appearance:none;-webkit-appearance:none;-webkit-text-decoration:none;text-decoration:none;color:inherit;font-family:'Libre Baskerville',serif;font-weight:500;font-size:0.875rem;line-height:1.75;text-transform:uppercase;min-width:64px;padding:6px 16px;border-radius:4px;-webkit-transition:background-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,box-shadow 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,border-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:background-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,box-shadow 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,border-color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms,color 250ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;background-color:#273649;box-shadow:0px 3px 1px -2px rgba(0,0,0,0.2),0px 2px 2px 0px rgba(0,0,0,0.14),0px 1px 5px 0px rgba(0,0,0,0.12);color:#000;font-family:'Lexend',sans-serif;text-align:center;text-transform:none;border-radius:4px;color:#FFF;background-color:#DF1316;font-family:\"Roboto\",sans-serif;font-size:13px;font-weight:500;position:relative;text-transform:uppercase;margin-left:24px;}.css-iojclc::-moz-focus-inner{border-style:none;}.css-iojclc.Mui-disabled{pointer-events:none;cursor:default;}@media print{.css-iojclc{-webkit-print-color-adjust:exact;color-adjust:exact;}}.css-iojclc:hover{-webkit-text-decoration:none;text-decoration:none;box-shadow:0px 2px 4px -1px rgba(0,0,0,0.2),0px 4px 5px 0px rgba(0,0,0,0.14),0px 1px 10px 0px rgba(0,0,0,0.12);}@media (hover: none){.css-iojclc:hover{background-color:#273649;}}.css-iojclc:active{box-shadow:0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);}.css-iojclc.Mui-focusVisible{box-shadow:0px 3px 5px -1px rgba(0,0,0,0.2),0px 6px 10px 0px rgba(0,0,0,0.14),0px 1px 18px 0px rgba(0,0,0,0.12);}.css-iojclc.Mui-disabled{color:rgba(0, 0, 0, 0.26);box-shadow:none;background-color:rgba(0, 0, 0, 0.12);}</style><a class=\"MuiButtonBase-root MuiButton-root MuiButton-contained MuiButton-containedTertiary MuiButton-sizeMedium MuiButton-containedSizeMedium MuiButton-root MuiButton-contained MuiButton-containedTertiary MuiButton-sizeMedium MuiButton-containedSizeMedium css-iojclc\" tabindex=\"0\" href=\"/donate\">Donate</a></div></div></div></div></div></header><main id=\"main\"><style data-emotion=\"css 62igne\">.css-62igne{margin-top:48px;margin-bottom:48px;}</style><div class=\"MuiBox-root css-62igne\"><style data-emotion=\"css 1qsxih2\">.css-1qsxih2{width:100%;margin-left:auto;box-sizing:border-box;margin-right:auto;display:block;padding-left:16px;padding-right:16px;}@media (min-width:600px){.css-1qsxih2{padding-left:24px;padding-right:24px;}}@media (min-width:1200px){.css-1qsxih2{max-width:1200px;}}</style><div class=\"MuiContainer-root MuiContainer-maxWidthLg css-1qsxih2\"><style data-emotion=\"css 1l5mznc\">.css-1l5mznc{box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;width:100%;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;margin-top:-64px;width:calc(100% + 64px);margin-left:-64px;}.css-1l5mznc>.MuiGrid-item{padding-top:64px;}.css-1l5mznc>.MuiGrid-item{padding-left:64px;}</style><div class=\"MuiGrid-root MuiGrid-container MuiGrid-spacing-xs-8 css-1l5mznc\"><style data-emotion=\"css 1uc8nzd\">.css-1uc8nzd{box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;width:100%;margin:0;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;margin-top:-32px;width:calc(100% + 32px);margin-left:-32px;-webkit-flex-basis:calc(100% + 32px);-ms-flex-preferred-size:calc(100% + 32px);flex-basis:calc(100% + 32px);-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:calc(100% + 32px);}.css-1uc8nzd>.MuiGrid-item{padding-top:32px;}.css-1uc8nzd>.MuiGrid-item{padding-left:32px;}@media (min-width:600px){.css-1uc8nzd{-webkit-flex-basis:calc(100% + 32px);-ms-flex-preferred-size:calc(100% + 32px);flex-basis:calc(100% + 32px);-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:calc(100% + 32px);}}@media (min-width:900px){.css-1uc8nzd{-webkit-flex-basis:calc(66.666667% + 32px);-ms-flex-preferred-size:calc(66.666667% + 32px);flex-basis:calc(66.666667% + 32px);-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:calc(66.666667% + 32px);}}@media (min-width:1200px){.css-1uc8nzd{-webkit-flex-basis:calc(66.666667% + 32px);-ms-flex-preferred-size:calc(66.666667% + 32px);flex-basis:calc(66.666667% + 32px);-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:calc(66.666667% + 32px);}}@media (min-width:1536px){.css-1uc8nzd{-webkit-flex-basis:calc(66.666667% + 32px);-ms-flex-preferred-size:calc(66.666667% + 32px);flex-basis:calc(66.666667% + 32px);-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:calc(66.666667% + 32px);}}</style><div class=\"MuiGrid-root MuiGrid-container MuiGrid-item MuiGrid-spacing-xs-4 MuiGrid-grid-xs-12 MuiGrid-grid-md-8 css-1uc8nzd\"><style data-emotion=\"css svts4y\">.css-svts4y{box-sizing:border-box;margin:0;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;max-width:100%;}</style><div class=\"MuiGrid-root MuiGrid-item css-svts4y\"><style data-emotion=\"css 1ewr4v4\">.css-1ewr4v4{margin-bottom:16px;color:#fff;background-color:#376055;padding:4px 16px;border-radius:4px;display:inline-block;text-transform:uppercase;font-family:Lexend;font-size:12px;font-weight:500;line-height:1.75;}</style><div class=\"MuiBox-root css-1ewr4v4\">Analysis</div><style data-emotion=\"css i2risw\">.css-i2risw{margin:0;font-family:'Libre Baskerville',serif;font-size:2em;font-weight:700;margin-bottom:16px;border-bottom:1px solid #8AA29D;padding-bottom:16px;}</style><h1 class=\"MuiTypography-root MuiTypography-h2_article css-i2risw\">Synthetic Media Policy: Provenance and Authentication — Expert Insights and Questions</h1><style data-emotion=\"css 1bs141q\">.css-1bs141q{margin:0;font-family:'Lexend',sans-serif;font-weight:300;line-height:1.4;font-size:0.875rem;color:#616161;font-size:12px;text-transform:uppercase;}</style><span class=\"MuiTypography-root MuiTypography-body2 css-1bs141q\">Ellen P. Goodman, </span><span class=\"MuiTypography-root MuiTypography-body2 css-1bs141q\">Kaylee Williams, </span><span class=\"MuiTypography-root MuiTypography-body2 css-1bs141q\">Justin Hendrix / </span><span class=\"MuiTypography-root MuiTypography-body2 css-1bs141q\">May 2, 2025</span><style data-emotion=\"css 3vr8u\">.css-3vr8u{margin:0;font-size:14px;line-height:1.4;font-family:'Libre Baskerville',serif;font-weight:400;}</style><div class=\"MuiTypography-root MuiTypography-body1 html-to-react-article css-3vr8u\"><p></p><div style=\"position:relative;width:100%\"><figure><img alt=\" \" loading=\"lazy\" width=\"1024\" height=\"576\" decoding=\"async\" data-nimg=\"1\" style=\"color:transparent;aspect-ratio:1.7777777777777777;width:100%;height:auto\" src=\"https://cdn.sanity.io/images/3tzzh18d/production/8f56541566a9236d6fbd6ff606a02bb7fde08386-1200x675.png\"/><figcaption><div class=\"MuiTypography-root MuiTypography-body1 html-to-react-caption css-3vr8u\" style=\"color:#7C7B7B\"><p><a href=\"https://www.shutterstock.com/image-photo/kaunas-lithuania-2024-februrary-17-openai-2426496059\">Shutterstock</a></p></div></figcaption></figure></div><p>AI-generated or altered text, imagery, video, and audio—collectively referred to as “synthetic media”—now permeate the internet and have already begun transforming industries ranging from entertainment and advertising to journalism and education.</p><p>The rising prevalence of synthetic media has sparked intense debates over their potential to erode “reality,” undermine intellectual property rights, threaten the privacy and safety of private citizens, spread disinformation, enable scams and fraud, and sow discord on a global scale.</p><p>On December 13, 2024, just weeks after the US Presidential Election, a diverse group of experts—including computer scientists, First Amendment and information law scholars, government officials, and cybersecurity specialists—gathered for a ‘Roundtable on Synthetic Media Policy’ in Washington DC to discuss these threats and establish a shared research agenda for the coming year. Hosted by <strong>Rutgers Law School’s Institute for Information Policy and Law</strong> in partnership with <strong>Tech Policy Press</strong>, the event focused on open research questions and potential solutions—technical, regulatory, social, and structural—to the many challenges associated with synthetic media.</p><p>Participants reached consensus on a handful of shared priorities—such as the importance of harm reduction, increasing media literacy, and preserving free expression online—and, as importantly, identified areas of disagreement about matters such as provenance standards, tradeoffs between privacy and transparency, and the role of digital forensics in battling harmful digital clones and fakes.</p><p>The following outlines some of the findings of the convening, which do not reflect the precise views of every participant.</p><h4><strong>Question #1: What are the limits of synthetic media detection, and who are the intended consumers of detection-based products?</strong></h4><p>For years, research labs, intelligence agencies, and private companies have been designing forensic tools, protocols, and systems intended to help people determine whether a given piece of content (such as an image or a video) was likely generated or altered by AI. While these forensic detection technologies have grown more sophisticated over time, several experts agreed that even the most advanced synthetic media detection techniques are extremely time-consuming and resource-intensive, making them difficult to deploy at scale. Furthermore, there are only a small number (roughly “half a dozen,” according to one expert) of companies and research firms performing advanced work on forensics in the United States, a handful in Italy, and fewer in other democratic countries. This suggests that the resources required to scale robust AI detection as a way to combat social media harms—including fraud, disinformation, and non-consensual intimate imagery—are lacking, to say the least, particularly outside of the Global North.</p><p>Even when an expert forensics team applies its tools to a piece of potentially synthetic media, detection technologies do not yield clear, unequivocal results. Significantly, the best of these methods can only calculate a <em>likelihood</em> that a given image has been generated by AI or digitally altered from its original form. They cannot make a definitive determination that content is “synthetic” or “authentic,” as there is too much variation to achieve high-confidence, definitive results, even by the best detectors.</p><p>More importantly, even if there are definitive forensic determinations, there may be a misalignment with the public’s understanding of what it means for a piece of content to be “digitally altered” or “manipulated.” Not all manipulations are created equal. For example, most people would not consider an image “digitally altered” if it were simply cropped or color-corrected in Photoshop. People may be divided on other modifications, such as “touching up” subject faces and adding artistic filters. There is probably more consensus around the removal or addition of elements. The rising ubiquity and broad accessibility of AI-powered photo editing software, much of which is now built directly into smartphone cameras, is also changing public perception of what constitutes an “authentic” image, making the reliable identification of synthetic media <em>that changes the meaning </em>of that content much more difficult. To denote content as “altered” is a sociotechnical exercise that would ideally be tuned to evolving communications dynamics.</p><p>Ultimately, digital alteration does not necessarily cause deception. The gap between the technical term “manipulation” and the social/legal term “deception” is potentially problematic for assessing and addressing synthetic media harms. For example, labeling content as synthetic or manipulated may imply that it is deceptive or otherwise harmful when that may not be the case. Synthetic parodies and art illustrate the point. An obvious parody or imaginative work containing synthetic elements would technically constitute manipulated media, while rarely deceiving. By the same token, identifying content as authentic or minimally altered may imply that it is trustworthy when that may not be the case. For example, an infographic generated using an LLM might accurately display verifiable data, while a cleverly cropped but otherwise unaltered photograph might give viewers a distorted understanding of a real-world event. Labels that cleave content into synthetic/authentic or manipulated/unaltered binaries may not only create confusion for online consumers, but also for those around the world making high-stakes legal decisions based on visual evidence.</p><div style=\"position:relative;width:100%\"><figure><img alt=\" \" loading=\"lazy\" width=\"1024\" height=\"576\" decoding=\"async\" data-nimg=\"1\" style=\"color:transparent;aspect-ratio:1.3038263849229013;width:100%;height:auto\" src=\"https://cdn.sanity.io/images/3tzzh18d/production/8e1955b2fe8302c4998b9d1bb614348fce036478-2283x1751.png\"/><figcaption><div class=\"MuiTypography-root MuiTypography-body1 html-to-react-caption css-3vr8u\" style=\"color:#7C7B7B\"><p>Illustration: A matrix categorizing media content by its authenticity (Authentic vs. Synthetic) and veracity (Verifiably True vs. Verifiably False), with examples.</p></div></figcaption></figure></div><p>Despite these limitations, synthetic media detection remains a critical area of research for a variety of stakeholders, including the national security community, human rights defenders, lawyers, and journalists. While the technology may never be able to satisfy the public’s desire for a quick and easy way to verify whether an image is “authentic,” it will likely still play a crucial role in advancing trustworthy information, especially as the challenges that AI poses become more significant. To continue this work, digital forensics professionals and others in this space will need to prioritize certain use cases and stakeholders over others and develop tools tailored to those domains.</p><h4><strong>Question #2: How useful is content labeling and provenance disclosure?</strong></h4><p>Content provenance and watermarking are methods used to encode media with metadata indicating the source of origin and any alterations. Such metadata can be displayed to end users in the form of a provenance legend or content label. These methods are not foolproof; technically savvy actors can exploit metadata and watermarking techniques to make an authentic image look synthetic, or vice versa.</p><p>Workshop participants considered the utility of labeling and provenance disclosures in light of the literature on content labeling in general. In the years since 2016, when Facebook first started <a href=\"https://cssh.northeastern.edu/ethics/the-evolution-of-social-media-content-labeling-an-online-archive/\" target=\"_blank\" rel=\"noopener\">putting “content warnings”</a> next to verifiably false claims on the News Feed, dozens of academic studies have sought to measure the efficacy of fact-checking labels designed to alert readers to the presence of disputed or inaccurate information within a given post. The results of these studies vary widely depending on the design of the labels, users’ pre-existing beliefs about the subject matter, and other factors. But the research tends to suggest that labels have only a modest effect on the spread of disinformation and can create a variety of potential backfire effects, including seeding the misconception that unlabeled assertions are accurate—a phenomenon known as the “<a href=\"https://dspace.mit.edu/bitstream/handle/1721.1/130380/mnsc.2019.3478.pdf?sequence=2&amp;isAllowed=y\" target=\"_blank\" rel=\"noopener\">implied truth effect</a>.”</p><p>There have been fewer studies on the effects of labeling media as synthetic, manipulated, or otherwise generated by AI in whole or in part. Even so, many social media platforms are requiring synthetic media labels, particularly on content that could be perceived as meaningfully deceptive. For example, Meta has <a href=\"https://www.meta.com/help/artificial-intelligence/1783222608822690/\" target=\"_blank\" rel=\"noopener\">mandated</a> that users across its platforms label “photorealistic video or realistic-sounding audio that was digitally created, modified or altered, including with AI.” It does not, however, require a label for <em>all</em> synthetic media. This means that, for example, a “video of an outdoor landscape, created in a style resembling a cartoon” would not need to be labeled under Meta’s current policy. The distinction between the included and excluded content seems to track the distinction between deceptive and non-deceptive content, except that lots of “modified or altered” realistic-seeming content may not be deceptive. Strict compliance with the mandate (unlikely) could result in over-labeling and attendant loss of meaning.</p><p>Meanwhile, some state legislatures in the US have adopted similar requirements for synthetic media related to elections, with varying definitions of what constitutes “synthetic.” Arizona, for example, <a href=\"https://www.akingump.com/en/insights/ai-law-and-regulation-tracker/arizona-senate-bill-1359-signed-into-law-by-governor\" target=\"_blank\" rel=\"noopener\">now requires</a> “clear and conspicuous” disclosures to appear alongside any “image, audio recording or video recording of an individual&#x27;s appearance, speech or conduct that has been created or intentionally manipulated with the use of digital technology” within 90 days of an election. Indiana has <a href=\"https://legiscan.com/IN/text/HB1133/id/2869748\" target=\"_blank\" rel=\"noopener\">established</a> a civil right of action for political candidates who are deceptively depicted in “fabricated media,&quot; defined as “an audio or visual recording of an individual&#x27;s speech, appearance, or conduct that has been altered without the individual&#x27;s consent such that: (a) the media conveys a materially inaccurate depiction of the individual&#x27;s speech, appearance, or conduct as recorded in the unaltered recording; and (b) a reasonable person would be unable to recognize that the recording has been altered.” These disparate legal definitions further demonstrate the challenges associated with synthetic media detection described above; namely that “digitally manipulated” content is not always deceptive, and vice versa.</p><p>At least one of these laws (California’s AB 2655) has been <a href=\"https://www.techpolicy.press/tracker/kohls-v-bonta/\" target=\"_blank\" rel=\"noopener\">overturned</a> in federal court as a violation of the First Amendment by compelling speech in a way that is not sufficiently well tailored to the government&#x27;s interest in preventing deception. Significantly, the court expressed concerns that labels on parodies or other synthetic media that is not deceptive unduly burdened speakers and stigmatized their expression. The issue is not only that the “squeeze” of the labeling isn’t worth the “juice” of transparency with the public, but that the juice itself could sour if people come to conflate AI manipulation with deception. The contours of the First Amendment considerations are still very much uncertain when it comes to AI-related litigation, as are the implications of synthetic media labeling on consumer understanding.</p><p>Experts at the roundtable noted that clearly labeling synthetic media—to the extent that reliable provenance and detection methods even make that a reliable practice—is often perceived by politicians and others as an “all-encompassing solution” to the epistemic turmoil created by AI-generated images and video. This faith in labeling as <em>the </em>“solution” is misplaced, both because it is not easily operationalized and cannot address harms unrelated to consumer recognition of synthetic sources.</p><p>The prevailing theory underpinning the labeling strategy is that if average users can distinguish what is “real” from what is “AI-generated,” they will be less likely to be deceived and to share deceptive content. However, as one expert pointed out, this logic relies upon the fraught assumption that all content can be reliably sorted into mutually exclusive categories such as “human-made,” “AI-generated,” and that “synthetic” is more likely to correspond with “false” and “authentic” with “true.”</p><p>Several participants noted, drawing on communications literature, that trust is relational. People trust content based more on its source (original or intermediate) than on labels appended to it. In considering the utility of synthetic media labels or metadata, then, it might be better to focus on specialized consumers and contexts rather than on informing ordinary end users. For example, the identification of synthetic media, digital alterations, and provenance more generally is important for researchers, librarians, information specialists, model developers, agents, and fact-finders in many fields—even if an individual’s knowledge of these alterations in the ordinary flow of communications turns out to be less impactful.</p><p>Those whose work focuses on individual (as opposed to epistemic or societal) harms caused by synthetic media pointed out that content labels often fail to undo the damages inflicted by embarrassing, dehumanizing, and hateful synthetic images. One participant pointed out that sexually explicit deepfakes, for example, are often labeled as such by the creators and shared on websites dedicated explicitly to AI-generated content, which suggests that they are not, in fact, intended to fool anyone into thinking they are authentic depictions. These harms, along with those associated with other forms of nonconsensual synthetic depiction, such as AI-generated child sexual abuse material (CSAM), are not remedied via the use of content labels because the perceived “authenticity” of the content is beside the point of the content: to abuse the subject.</p><p>Areas where content provenance and labeling might be most useful and readily adopted are in enterprise domains where businesses depend on trusted communications and/or need to secure consumer trust. In such contexts, private actors have market incentives to be transparent about content origins and alterations. Workshop participants identified industry and business use cases where this might be the case, including insurance, financial services, and e-commerce areas. There remain questions about where the market will supply sufficient transparency and where it will not, and to what extent and how.</p><p>These insights suggest that while content labels and AI use disclosures—such as those enabled by provenance technologies—can play a valuable role in addressing the harms of digital clones, fakes, and other synthetic media, policymakers at both the platform and government levels should be cautious not to over-rely on them as standalone solutions.</p><h4><strong>Question #3: How do we address the social dynamics and norms underpinning the harms of synthetic media?</strong></h4><p>As the cases involving synthetic sexual abuse content demonstrate, many of the harms posed by synthetic media are not easily mitigated with informational or tech-based solutions alone. In fact, many of the most concerning threats are not new to the AI era. Instead, they represent the intensification of longstanding patterns of abuse and discrimination toward vulnerable groups for the purposes of maintaining existing social hierarchies.</p><p>For instance, the prevalence of nonconsensual sexual content reflects the systemic commodification of women’s bodies and the normalization of gender-based violence. Similarly, the weaponization of synthetic media for political disinformation and propaganda reflects prevailing social forces around racial inequality, othering “out” groups, stoking polarization, and amplifying conspiracy theories.</p><p>Addressing these harms requires a holistic approach that combines regulatory and technical solutions with broader efforts to challenge the social norms and power structures at play. This might include public awareness campaigns, education initiatives to foster digital literacy, and collaborations with civil society organizations to address the root causes behind various manifestations of online harm. Without tackling the underlying social dynamics, the experts gathered in DC agreed that interventions targeting synthetic media risk addressing the symptoms rather than the causes of those harms.</p><p>These issues are deeply entrenched in modern society and will not be entirely uprooted even with dramatic regulatory intervention targeting technology. The kinds of reforms necessary to address these systemic patterns need to be just that: systemic. As such, they will require buy-in (both political and financial) from various sectors and stakeholders, many of whom currently benefit from incentives and dynamics that exacerbate intractable problems, from racism and misogyny to economic exploitation (either directly or indirectly).</p><h4><strong>Question #4: What are the downstream risks of the “liar’s dividend”?</strong></h4><p>The “liar’s dividend”—as <a href=\"https://heinonline.org/HOL/Page?men_tab=srchresults&amp;handle=hein.journals/calr107&amp;id=1794&amp;size=2&amp;collection=journals&amp;terms=Liar%7Cliar&amp;termtype=phrase&amp;set_as_cursor=\" target=\"_blank\" rel=\"noopener\">defined</a> by legal scholars Bobby Chesney and Danielle Citron in 2019—refers to an information ecosystem that is so rife with false and otherwise deceptive information that actors can avoid accountability for wrongdoing by claiming that any documentation of misconduct is “fake news,” “misinformation,” “manipulated media” etc. Another way to put this is plausible deniability for any bit of content. In their 2019 paper, Chesney and Citron argue that pervasive, deceptive synthetic media contributes heavily to the liar’s dividend because its very existence undermines public trust in authentic content. In a world where any piece of media can plausibly be dismissed as fake, individuals and organizations can exploit widespread uncertainty about the facts to avoid accountability or obscure the truth. This dynamic has profound implications for journalism, the legal system, and democratic governance, as it challenges the fundamental ability to establish a shared reality.</p><p>As synthetic media become more sophisticated and accessible, the liar’s dividend may reach a tipping point where skepticism about media authenticity becomes the default. <a href=\"https://petapixel.com/2019/03/01/people-call-my-photos-fake-but-theyre-not/\" target=\"_blank\" rel=\"noopener\">Anecdotal accounts</a> argue that we are already there. This state of affairs could empower malicious actors to weaponize doubt, dismissing legitimate evidence of wrongdoing as fabricated. For instance, political leaders might evade accountability for harmful rhetoric or actions by claiming that leaked audio recordings or videos are AI-generated. One expert posited that the growing popularity of generative AI could result in a world of content manipulation so ubiquitous that there is an epistemic collapse.</p><p>The societal consequences of this potential collapse are far-reaching. If people cannot distinguish between truth and fabrication, public discourse will become increasingly polarized, with individuals retreating further into ideological silos where only content that aligns with their preexisting beliefs is accepted as legitimate. This environment may foster widespread cynicism, causing people to lose ever more confidence in institutions, in democracy, and in one another.</p><p>One expert noted that the role of synthetic media must be considered against the broader and systemic degradation of information fidelity. Systemic trust erosion is not necessarily tied to the authenticity of particular units of content. This expert argued that distrust in informational integrity poses a challenge to journalism and communications far beyond a liar’s intentional manipulation.</p><p>Addressing this systemic distrust requires proactive measures to restore faith in media and digital content. With respect to the narrow issue of synthetic media, this includes promoting the adoption of content authentication technologies, such as open technical standards like those popularized by the Coalition for Content Provenance and Authenticity (C2PA) to verify the provenance of authentic content. While the participants acknowledged it would be a long road to a fully interoperable internet that allows such standards to thrive, industry and business use cases will likely be adopted first.</p><p>Equally important are efforts to improve media literacy aimed at equipping individuals with the cognitive tools to critically evaluate the veracity of digital content. However, technical and educational solutions alone are insufficient. Policymakers, platforms, and civil society organizations must work together to establish norms and regulations that discourage the strategic weaponization of “plausible deniability” to evade public accountability. Without such efforts, the liar’s dividend threatens to deepen societal divides and erode the foundations of trust essential for democratic systems to function.</p><h4><strong>Question #5: How do we move past the “authentic” vs. “synthetic” binary?</strong></h4><p>Many of the issues discussed at the event alluded to a broader, conceptual challenge that the experts agreed requires urgent societal attention: the need to reframe how we think about the provenance and authenticity of digital content in an AI world. This issue is fundamentally tied to media literacy and public education, particularly as AI-powered tools become more deeply integrated into content generation across information industries like journalism.</p><div id=\"mlb2-5983225\" class=\"ml-form-embedContainer ml-subscribe-form ml-subscribe-form-5983225\"><div style=\"margin:32px 0 24px 0;border-top:1px solid #E2D7BB\"></div><div class=\"ml-form-align-center\"><div class=\"ml-form-embedWrapper embedForm\" style=\"max-width:100%\"><div class=\"ml-form-embedBody ml-form-embedBodyDefault row-form\" style=\"padding:25px 0 30px 0\"><div class=\"ml-form-embedContent\" style=\"margin-bottom:20px\"><h4 style=\"font-size:24px\">Our Content delivered to your inbox.</h4><div style=\"text-align:center;font-weight:400;line-height:22px;max-width:390px;margin-right:auto;margin-left:auto\">Join our newsletter on issues and ideas at the intersection of tech &amp; democracy</div></div><form class=\"ml-block-form\" action=\"https://static.mailerlite.com/webforms/submit/s8h5n5\" data-code=\"s8h5n5\" method=\"post\" target=\"_blank\"><div style=\"display:flex;justify-content:space-around\"><div class=\"jss7 MuiBox-root css-0\"><div class=\"ml-form-formContent\" style=\"width:221px;margin-bottom:0px\"><div class=\"ml-form-fieldRow ml-last-item\"><div class=\"ml-field-group ml-field-email ml-validate-email ml-validate-required\"><input aria-label=\"email\" aria-required=\"true\" type=\"email\" data-inputmask=\"\" name=\"fields[email]\" placeholder=\"Enter email address\" autoComplete=\"email\" style=\"padding:6px 10px !important\"/></div></div></div><input type=\"hidden\" name=\"ml-submit\" value=\"1\"/><div class=\"ml-form-embedSubmit\" style=\"width:153px;margin-bottom:0px\"><button type=\"submit\" class=\"primary\" style=\"font-family:Lexend, sans-serif!important;display:flex;justify-content:space-evenly;font-size:14px !important;line-height:normal !important;font-weight:400 !important;align-items:center;padding:5px 10px !important\">Subscribe <style data-emotion=\"css vubbuv\">.css-vubbuv{-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;width:1em;height:1em;display:inline-block;fill:currentColor;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;-webkit-transition:fill 200ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:fill 200ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;font-size:1.5rem;}</style><svg class=\"MuiSvgIcon-root MuiSvgIcon-fontSizeMedium css-vubbuv\" focusable=\"false\" aria-hidden=\"true\" viewBox=\"0 0 24 24\" data-testid=\"ChevronRightIcon\"><path d=\"M10 6 8.59 7.41 13.17 12l-4.58 4.59L10 18l6-6z\"></path></svg></button><button disabled=\"\" style=\"display:none\" type=\"button\" class=\"loading\"> <div class=\"ml-form-embedSubmitLoad\"></div> <span class=\"sr-only\">Loading...</span> </button></div></div></div><input type=\"hidden\" name=\"anticsrf\" value=\"true\"/></form></div><div class=\"ml-form-successBody row-success\" style=\"display:none\"><div class=\"ml-form-successContent\"><h4>Thank you!</h4><p style=\"text-align:center\">You have successfully joined our subscriber list.</p></div></div></div></div><div style=\"margin:24px 0 32px 0;border-top:1px solid #E2D7BB\"></div></div><p>As noted above, content labeling risks creating the false binary that a piece of content is either wholly “authentic” or entirely “synthetic.” In reality, the roundtable experts agreed that much of the content we encounter online today exists on a spectrum of human and machine involvement. For example, a video might be largely authentic but edited with AI-enhanced filters, or a news article might be written by a journalist who used AI tools to clean or analyze data. These forms of hybrid media challenge traditional notions of authenticity and truth, complicating how we assess the trustworthiness of what we see, hear, and read.</p><p>Moving past this binary requires a more nuanced understanding of how digital content is produced and a shift in public attitudes toward AI’s role in media creation. Public education efforts should emphasize that authenticity is not solely about the method of creation or modification but also about the intent and transparency behind the content, including who shared it. Tools that trace the provenance of digital media, such as metadata tagging or blockchain-based verification, could play a critical role in fostering trust without reinforcing outdated mental models. But there are complications with these tools as well, including potential implications for privacy and free expression, and significant technical challenges.</p><p>Ultimately, building a society capable of navigating the complexities of synthetic media will require collaboration between technologists, educators, policymakers, and civil society actors. <strong>By shifting the focus from “authentic vs. synthetic” to questions of accountability and transparency, the tech policy community will be able to seed a more sophisticated framework for understanding and engaging with synthetic media in the coming years.</strong></p><p>In addition to addressing these open questions, the roundtable participants worked together to brainstorm possible metrics to indicate progress on synthetic media-related issues. The following are some of the ideas floated:</p><ul><li>Tracking C2PA adoption as a proxy for understanding its effects and potential for broad interoperability across the information environment.</li><li>Estimating the number of news stories in which manipulated or AI-generated media play a role, including phenomena such as criminal or civil actions brought in relation to the propagation of such content.</li><li>Recording the number of scams or fraudulent activities reported to authorities that involved the use of synthetic media.</li><li>Tracking global Investment in distributed media forensics capacity.</li><li>Measuring the average time of platform takedown for nonconsensual synthetic pornography and other problematic forms of synthetic media.</li><li>Assessing public perception of viral incidents involving synthetic media.</li><li>Estimating the size of the customer base and understanding the markets for harmful synthetic depictions (including CSAM and NCII).</li><li>Identifying ways of measuring the liar’s dividend and intervening to counter it.</li><li>Further study on the effectiveness of content labeling, fact-checking, provenance verification, and similar efforts.</li><li>Recording the number of lawsuits that attempt to hold platform companies accountable for harms caused by synthetic media.</li><li>Recording the number of new regulations introduced by state and federal governments related to AI-generated content and their resilience to legal challenges.</li></ul><p>Going forward, it will be crucial to find creative ways to address these challenges and advance bipartisan proposals for regulatory and self-regulatory frameworks that can alleviate some of the threats described above. The latter half of the decade will require policymakers—and the public—to move beyond “synthetic or authentic” binaries. What is needed are broad coalitions of technologists, civil society actors, researchers, and others to partner to develop systemic interventions that may not yet exist.</p><h4><strong><em>With thanks to the Knight Foundation for providing financial support for the Workshop.</em></strong></h4><p><strong>Workshop Participants:</strong></p><ul><li><strong>Scott Babwah Brennen</strong>, Director, NYU Center on Technology Policy</li><li><strong>Bilva Chandra</strong>, Former Senior Policy Advisor &amp; Synthetic Content Lead, US AI Safety Institute</li><li><strong>Peter Chapman</strong>, Associate Director, Knight-Georgetown Institute</li><li><strong>Renée DiResta</strong>, Associate Research Professor, McCourt School of Public Policy, Georgetown University</li><li><strong>Nadine Farid Johnson</strong>, Policy Director, Knight First Amendment Institute at Columbia University</li><li><strong>Mary Anne Franks</strong>, Eugene L. and Barbara A. Bernard Professor in Intellectual Property, Technology, and Civil Rights Law at George Washington Law School, and President and Legislative &amp; Tech Policy Director of the Cyber Civil Rights Initiative</li><li><strong>Josh Goldstein</strong>, Research Fellow, Center for Security and Emerging Technology (CSET), Georgetown University</li><li><strong>Ellen P. Goodman</strong>, Professor at Rutgers Law School, Co-Director of the Rutgers Institute for Information Policy &amp; Law (RIIPL)</li><li><strong>Sam Gregory</strong>, Executive Director, WITNESS</li><li><strong>Justin Hendrix</strong>, CEO and Editor, Tech Policy Press</li><li><strong>Mounir Ibrahim</strong>, Chief Communications Officer &amp; Head of Public Affairs, Truepic</li><li><strong>Kate Kaye</strong>, Deputy Director, World Privacy Forum</li><li><strong>Claire Leibowicz</strong>, Head of AI and Media Integrity, Partnership on AI</li><li><strong>David Luebke</strong>, Vice President of Graphics Research, NVIDIA</li><li><strong>Siwei Lyu</strong>, SUNY Distinguished Professor, University at Buffalo, State University of New York</li><li><strong>Abhiram Reddy</strong>, AI Safety and Security Research Assistant, Center for Security and Emerging Technology (CSET), Georgetown University</li><li><strong>Aimee Rinehart</strong>, Senior Product Manager, AI Strategy, The Associated Press</li><li><strong>Matthew C. Stamm</strong>, Associate Professor, Department of Electrical &amp; Computer Engineering, Director, Multimedia and Information Security Laboratory, Drexel University</li><li><strong>Xiangnong (George) Wang</strong>, Staff Attorney, Knight First Amendment Institute</li><li><strong>Kaylee Williams</strong>, PhD Student, Columbia Journalism School and Research Associate, International Center for Journalists</li></ul><p><em><a href=\"https://cdn.sanity.io/files/3tzzh18d/production/15f7b0307678e77c38b7786dd63cba6f7664c1a3.pdf\" target=\"_blank\" rel=\"noopener\">Download this document as a PDF</a>.</em></p></div></div></div><style data-emotion=\"css 19egsyp\">.css-19egsyp{box-sizing:border-box;margin:0;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-flex-basis:100%;-ms-flex-preferred-size:100%;flex-basis:100%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:100%;}@media (min-width:600px){.css-19egsyp{-webkit-flex-basis:100%;-ms-flex-preferred-size:100%;flex-basis:100%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:100%;}}@media (min-width:900px){.css-19egsyp{-webkit-flex-basis:33.333333%;-ms-flex-preferred-size:33.333333%;flex-basis:33.333333%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:33.333333%;}}@media (min-width:1200px){.css-19egsyp{-webkit-flex-basis:33.333333%;-ms-flex-preferred-size:33.333333%;flex-basis:33.333333%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:33.333333%;}}@media (min-width:1536px){.css-19egsyp{-webkit-flex-basis:33.333333%;-ms-flex-preferred-size:33.333333%;flex-basis:33.333333%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:33.333333%;}}</style><div class=\"MuiGrid-root MuiGrid-item MuiGrid-grid-xs-12 MuiGrid-grid-md-4 css-19egsyp\"><style data-emotion=\"css 8qb8m4\">.css-8qb8m4{margin-bottom:48px;}</style><div class=\"MuiBox-root css-8qb8m4\"><style data-emotion=\"css nnwgpb\">.css-nnwgpb{margin:0;font-family:'Lexend',sans-serif;font-size:1em;font-weight:700;margin-bottom:20px;text-transform:uppercase;line-height:1.235;border-bottom:1px solid #8AA29D;padding-bottom:16px;width:100%;}</style><h2 class=\"MuiTypography-root MuiTypography-h4 css-nnwgpb\">Authors</h2><style data-emotion=\"css 1rrerex\">.css-1rrerex{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}.css-1rrerex>:not(style):not(style){margin:0;}.css-1rrerex>:not(style)~:not(style){margin-top:32px;}</style><div class=\"MuiStack-root css-1rrerex\"><style data-emotion=\"css 1k82yfd\">.css-1k82yfd{box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;width:100%;margin:0;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;margin-top:-16px;width:calc(100% + 16px);margin-left:-16px;-webkit-flex-basis:calc(100% + 16px);-ms-flex-preferred-size:calc(100% + 16px);flex-basis:calc(100% + 16px);-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:calc(100% + 16px);}.css-1k82yfd>.MuiGrid-item{padding-top:16px;}.css-1k82yfd>.MuiGrid-item{padding-left:16px;}@media (min-width:600px){.css-1k82yfd{-webkit-flex-basis:calc(100% + 16px);-ms-flex-preferred-size:calc(100% + 16px);flex-basis:calc(100% + 16px);-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:calc(100% + 16px);}}@media (min-width:900px){.css-1k82yfd{-webkit-flex-basis:calc(100% + 16px);-ms-flex-preferred-size:calc(100% + 16px);flex-basis:calc(100% + 16px);-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:calc(100% + 16px);}}@media (min-width:1200px){.css-1k82yfd{-webkit-flex-basis:calc(100% + 16px);-ms-flex-preferred-size:calc(100% + 16px);flex-basis:calc(100% + 16px);-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:calc(100% + 16px);}}@media (min-width:1536px){.css-1k82yfd{-webkit-flex-basis:calc(100% + 16px);-ms-flex-preferred-size:calc(100% + 16px);flex-basis:calc(100% + 16px);-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:calc(100% + 16px);}}</style><div class=\"MuiGrid-root MuiGrid-container MuiGrid-item MuiGrid-spacing-xs-2 MuiGrid-grid-xs-12 css-1k82yfd\"><style data-emotion=\"css q4iyp1\">.css-q4iyp1{box-sizing:border-box;margin:0;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-flex-basis:25%;-ms-flex-preferred-size:25%;flex-basis:25%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:25%;padding-left:0!important;}@media (min-width:600px){.css-q4iyp1{-webkit-flex-basis:25%;-ms-flex-preferred-size:25%;flex-basis:25%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:25%;}}@media (min-width:900px){.css-q4iyp1{-webkit-flex-basis:25%;-ms-flex-preferred-size:25%;flex-basis:25%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:25%;}}@media (min-width:1200px){.css-q4iyp1{-webkit-flex-basis:25%;-ms-flex-preferred-size:25%;flex-basis:25%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:25%;}}@media (min-width:1536px){.css-q4iyp1{-webkit-flex-basis:25%;-ms-flex-preferred-size:25%;flex-basis:25%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:25%;}}</style><div class=\"MuiGrid-root MuiGrid-item MuiGrid-grid-xs-3 css-q4iyp1\"><img alt=\"\" loading=\"lazy\" width=\"80\" height=\"80\" decoding=\"async\" data-nimg=\"1\" style=\"color:transparent;border-radius:50px\" src=\"https://cdn.sanity.io/images/3tzzh18d/production/dbffdf30f9fe5a4bde894465e60d23a88d9cd51e-2560x2175.jpg?fit=max&amp;auto=format\"/></div><style data-emotion=\"css 14ybvol\">.css-14ybvol{box-sizing:border-box;margin:0;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-flex-basis:75%;-ms-flex-preferred-size:75%;flex-basis:75%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:75%;}@media (min-width:600px){.css-14ybvol{-webkit-flex-basis:75%;-ms-flex-preferred-size:75%;flex-basis:75%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:75%;}}@media (min-width:900px){.css-14ybvol{-webkit-flex-basis:75%;-ms-flex-preferred-size:75%;flex-basis:75%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:75%;}}@media (min-width:1200px){.css-14ybvol{-webkit-flex-basis:75%;-ms-flex-preferred-size:75%;flex-basis:75%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:75%;}}@media (min-width:1536px){.css-14ybvol{-webkit-flex-basis:75%;-ms-flex-preferred-size:75%;flex-basis:75%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:75%;}}</style><div class=\"MuiGrid-root MuiGrid-item MuiGrid-grid-xs-9 css-14ybvol\"><style data-emotion=\"css 18fhwlr\">.css-18fhwlr{-webkit-text-decoration:underline;text-decoration:underline;text-decoration-color:rgba(0, 0, 0, 0.4);-webkit-text-decoration:none;text-decoration:none;margin-bottom:10px;display:block;}.css-18fhwlr:hover{text-decoration-color:inherit;}.css-18fhwlr:active,.css-18fhwlr:focus,.css-18fhwlr:hover{color:#000;-webkit-text-decoration:underline;text-decoration:underline;}</style><style data-emotion=\"css ch6i07\">.css-ch6i07{margin:0;font:inherit;color:#000;-webkit-text-decoration:underline;text-decoration:underline;text-decoration-color:rgba(0, 0, 0, 0.4);-webkit-text-decoration:none;text-decoration:none;margin-bottom:10px;display:block;}.css-ch6i07:hover{text-decoration-color:inherit;}.css-ch6i07:active,.css-ch6i07:focus,.css-ch6i07:hover{color:#000;-webkit-text-decoration:underline;text-decoration:underline;}</style><a class=\"MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineAlways css-ch6i07\" href=\"/author/ellen-p-goodman\"><style data-emotion=\"css 1ytgyi9\">.css-1ytgyi9{margin:0;font-family:'Lexend',sans-serif;font-size:1em;font-weight:700;margin-bottom:20px;text-transform:uppercase;line-height:1.235;color:#000;font-weight:400;}</style><span class=\"MuiTypography-root MuiTypography-h4 css-1ytgyi9\">Ellen P. Goodman</span></a><style data-emotion=\"css 1qd0hdj\">.css-1qd0hdj{margin:0;font-family:'Lexend',sans-serif;font-weight:300;line-height:1.4;font-size:0.875rem;color:rgba(0,0,0,0.48);}</style><div class=\"MuiTypography-root MuiTypography-body2 css-1qd0hdj\">Ellen P. Goodman is a Professor at Rutgers Law School, Co-Director of the Rutgers Institute for Information Policy &amp; Law (RIIPL), and a Senior Fellow at the Digital Innovation &amp; Democracy Institute at the German Marshall Fund.</div></div></div><div class=\"MuiGrid-root MuiGrid-container MuiGrid-item MuiGrid-spacing-xs-2 MuiGrid-grid-xs-12 css-1k82yfd\"><div class=\"MuiGrid-root MuiGrid-item MuiGrid-grid-xs-3 css-q4iyp1\"><img alt=\"\" loading=\"lazy\" width=\"80\" height=\"80\" decoding=\"async\" data-nimg=\"1\" style=\"color:transparent;border-radius:50px\" src=\"https://cdn.sanity.io/images/3tzzh18d/production/0716ab6ab2ae93f951d46e393fb5495cd4e27d73-1080x1080.png?fit=max&amp;auto=format\"/></div><div class=\"MuiGrid-root MuiGrid-item MuiGrid-grid-xs-9 css-14ybvol\"><a class=\"MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineAlways css-ch6i07\" href=\"/author/kaylee-williams\"><span class=\"MuiTypography-root MuiTypography-h4 css-1ytgyi9\">Kaylee Williams</span></a><div class=\"MuiTypography-root MuiTypography-body2 css-1qd0hdj\">Kaylee Williams is a PhD student at the Columbia Journalism School and a research associate at the International Center for Journalists. Her research specializes in technology-facilitated gender-based violence, with a particular emphasis on generative AI and non-consensual intimate imagery. Prior to<!-- -->...</div></div></div><div class=\"MuiGrid-root MuiGrid-container MuiGrid-item MuiGrid-spacing-xs-2 MuiGrid-grid-xs-12 css-1k82yfd\"><div class=\"MuiGrid-root MuiGrid-item MuiGrid-grid-xs-3 css-q4iyp1\"><img alt=\"\" loading=\"lazy\" width=\"80\" height=\"80\" decoding=\"async\" data-nimg=\"1\" style=\"color:transparent;border-radius:50px\" src=\"https://cdn.sanity.io/images/3tzzh18d/production/13e89d005fe677a1c18c1b8be04209d7849a7de8-748x748.jpg?fit=max&amp;auto=format\"/></div><div class=\"MuiGrid-root MuiGrid-item MuiGrid-grid-xs-9 css-14ybvol\"><a class=\"MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineAlways css-ch6i07\" href=\"/author/justin-hendrix\"><span class=\"MuiTypography-root MuiTypography-h4 css-1ytgyi9\">Justin Hendrix</span></a><div class=\"MuiTypography-root MuiTypography-body2 css-1qd0hdj\">Justin Hendrix is CEO and Editor of Tech Policy Press, a nonprofit media venture concerned with the intersection of technology and democracy. Previously, he was Executive Director of NYC Media Lab. He spent over a decade at The Economist in roles including Vice President of Business Development &amp; In<!-- -->...</div></div></div></div></div><section><style data-emotion=\"css 1d3bbye\">.css-1d3bbye{box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;width:100%;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;}</style><div class=\"MuiGrid-root MuiGrid-container css-1d3bbye\"><style data-emotion=\"css 8x8291\">.css-8x8291{box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;width:100%;margin:0;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:justify;-webkit-justify-content:space-between;justify-content:space-between;}</style><div class=\"MuiGrid-root MuiGrid-container MuiGrid-item css-8x8291\"><style data-emotion=\"css 15j76c0\">.css-15j76c0{box-sizing:border-box;margin:0;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-flex-basis:100%;-ms-flex-preferred-size:100%;flex-basis:100%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:100%;}@media (min-width:600px){.css-15j76c0{-webkit-flex-basis:100%;-ms-flex-preferred-size:100%;flex-basis:100%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:100%;}}@media (min-width:900px){.css-15j76c0{-webkit-flex-basis:100%;-ms-flex-preferred-size:100%;flex-basis:100%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:100%;}}@media (min-width:1200px){.css-15j76c0{-webkit-flex-basis:100%;-ms-flex-preferred-size:100%;flex-basis:100%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:100%;}}@media (min-width:1536px){.css-15j76c0{-webkit-flex-basis:100%;-ms-flex-preferred-size:100%;flex-basis:100%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:100%;}}</style><div class=\"MuiGrid-root MuiGrid-item MuiGrid-grid-xs-12 css-15j76c0\"><style data-emotion=\"css 1ht81qj\">.css-1ht81qj{margin:0;font-family:'Lexend',sans-serif;font-size:1em;font-weight:700;margin-bottom:20px;text-transform:uppercase;line-height:1.235;}</style><h2 class=\"MuiTypography-root MuiTypography-h4 css-1ht81qj\">Related</h2></div><style data-emotion=\"css iutjyj\">.css-iutjyj{margin-bottom:32px;padding-top:16px;border-top:1px solid #8AA29D;width:100%;}</style><div class=\"MuiBox-root css-iutjyj\"><style data-emotion=\"css yd8sa2\">.css-yd8sa2{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;gap:16px;}</style><div class=\"MuiBox-root css-yd8sa2\"><div class=\"jss8\"><style data-emotion=\"css 8t01r4\">.css-8t01r4{-webkit-text-decoration:underline;text-decoration:underline;text-decoration-color:rgba(0, 0, 0, 0.4);-webkit-text-decoration:none;text-decoration:none;}.css-8t01r4:hover{text-decoration-color:inherit;}</style><style data-emotion=\"css 1l2w1fg\">.css-1l2w1fg{margin:0;font:inherit;color:#000;-webkit-text-decoration:underline;text-decoration:underline;text-decoration-color:rgba(0, 0, 0, 0.4);-webkit-text-decoration:none;text-decoration:none;}.css-1l2w1fg:hover{text-decoration-color:inherit;}</style><a class=\"MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineAlways css-1l2w1fg\" href=\"/openais-sora-is-here-there-is-still-time-to-prepare-for-the-threat-such-technologies-pose\">OpenAI&#x27;s Sora Is Here. There Is Still Time To Prepare For The Threat Such Technologies Pose</a><style data-emotion=\"css ssjgjc\">.css-ssjgjc{margin:0;font-family:'Lexend',sans-serif;font-weight:300;line-height:1.4;font-size:0.875rem;color:#a7a7a7;font-size:14px;font-weight:400;margin-top:8px;text-transform:uppercase;}</style><span class=\"MuiTypography-root MuiTypography-body2 css-ssjgjc\">December 12, 2024</span></div><div class=\"jss8\"><a class=\"MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineAlways css-1l2w1fg\" href=\"/regulating-transparency-in-audiovisual-generative-ai-how-legislators-can-center-human-rights\">Regulating Transparency in Audiovisual Generative AI: How Legislators Can Center Human Rights</a><span class=\"MuiTypography-root MuiTypography-body2 css-ssjgjc\">October 18, 2023</span></div><div class=\"jss8\"><a class=\"MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineAlways css-1l2w1fg\" href=\"/governing-access-to-synthetic-media-detection-technology\">Governing Access to Synthetic Media Detection Technology</a><span class=\"MuiTypography-root MuiTypography-body2 css-ssjgjc\">September 7, 2021</span></div><div class=\"jss8\"><a class=\"MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineAlways css-1l2w1fg\" href=\"/lawmakers-push-for-ai-labels-but-ensuring-media-accuracy-is-no-easy-task\">Lawmakers Push for AI Labels, But Ensuring Media Accuracy Is No Easy Task</a><span class=\"MuiTypography-root MuiTypography-body2 css-ssjgjc\">September 9, 2024</span></div><div class=\"jss8\"><a class=\"MuiTypography-root MuiTypography-inherit MuiLink-root MuiLink-underlineAlways css-1l2w1fg\" href=\"/white-house-ai-executive-order-takes-on-complexity-of-content-integrity-issues\">White House AI Executive Order Takes On Complexity of Content Integrity Issues</a><span class=\"MuiTypography-root MuiTypography-body2 css-ssjgjc\">November 1, 2023</span></div></div></div></div></div></section><section><div class=\"MuiGrid-root MuiGrid-container css-1d3bbye\"><div class=\"MuiGrid-root MuiGrid-container MuiGrid-item css-8x8291\"><div class=\"MuiGrid-root MuiGrid-item MuiGrid-grid-xs-12 css-15j76c0\"><h2 class=\"MuiTypography-root MuiTypography-h4 css-1ht81qj\">Topics</h2></div><div class=\"MuiBox-root css-iutjyj\"><style data-emotion=\"css 1gjxtvh\">.css-1gjxtvh{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;}.css-1gjxtvh>:not(style):not(style){margin:0;}.css-1gjxtvh>:not(style)~:not(style){margin-left:8px;}</style><div class=\"MuiStack-root css-1gjxtvh\"></div></div></div></div></section></div></div></div></div></main><footer style=\"background-color:#3475BF;color:#FFF\"><style data-emotion=\"css uek6ck\">.css-uek6ck{padding-top:64px;padding-bottom:32px;}</style><div class=\"MuiBox-root css-uek6ck\"><style data-emotion=\"css 1qsxih2\">.css-1qsxih2{width:100%;margin-left:auto;box-sizing:border-box;margin-right:auto;display:block;padding-left:16px;padding-right:16px;}@media (min-width:600px){.css-1qsxih2{padding-left:24px;padding-right:24px;}}@media (min-width:1200px){.css-1qsxih2{max-width:1200px;}}</style><div class=\"MuiContainer-root MuiContainer-maxWidthLg css-1qsxih2\"><style data-emotion=\"css 1h77wgb\">.css-1h77wgb{box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;width:100%;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;margin-top:-24px;width:calc(100% + 24px);margin-left:-24px;}.css-1h77wgb>.MuiGrid-item{padding-top:24px;}.css-1h77wgb>.MuiGrid-item{padding-left:24px;}</style><div class=\"MuiGrid-root MuiGrid-container MuiGrid-spacing-xs-3 css-1h77wgb\"><style data-emotion=\"css 1t2vos\">.css-1t2vos{box-sizing:border-box;margin:0;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-flex-basis:100%;-ms-flex-preferred-size:100%;flex-basis:100%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:100%;}@media (min-width:600px){.css-1t2vos{-webkit-flex-basis:16.666667%;-ms-flex-preferred-size:16.666667%;flex-basis:16.666667%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:16.666667%;}}@media (min-width:900px){.css-1t2vos{-webkit-flex-basis:16.666667%;-ms-flex-preferred-size:16.666667%;flex-basis:16.666667%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:16.666667%;}}@media (min-width:1200px){.css-1t2vos{-webkit-flex-basis:16.666667%;-ms-flex-preferred-size:16.666667%;flex-basis:16.666667%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:16.666667%;}}@media (min-width:1536px){.css-1t2vos{-webkit-flex-basis:16.666667%;-ms-flex-preferred-size:16.666667%;flex-basis:16.666667%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:16.666667%;}}</style><div class=\"MuiGrid-root MuiGrid-item MuiGrid-grid-xs-12 MuiGrid-grid-sm-2 css-1t2vos\"><a href=\"/\"><style data-emotion=\"css 1gtfl7l\">.css-1gtfl7l{width:120px;}</style><div class=\"MuiBox-root css-1gtfl7l\"><svg xmlns=\"http://www.w3.org/2000/svg\" viewBox=\"0 0 741.5 299.6\"><g fill=\"#fff\"><path d=\"M284 177a24 24 0 0 0-16-11 26 26 0 0 0-18 3 24 24 0 0 0-7 5 22 22 0 0 0-5 17 26 26 0 0 0 16 21 24 24 0 0 0 9 2 24 24 0 0 0 18-9 24 24 0 0 0 5-9 24 24 0 0 0-2-19Zm-59 49a22 22 0 0 0-15 5l-1 1a22 22 0 0 0-7 14 24 24 0 0 0 4 16 22 22 0 0 0 16 10 23 23 0 0 0 17-6 23 23 0 0 0 8-16v-1a22 22 0 0 0-7-16 24 24 0 0 0-15-7Zm-53 35a22 22 0 0 0-7-3 20 20 0 0 0-8-1 18 18 0 0 0-7 3 21 21 0 0 0-6 5 23 23 0 0 0-5 15 20 20 0 0 0 7 15 21 21 0 0 0 8 4 22 22 0 0 0 9 0c3 0 5-1 8-3a20 20 0 0 0 7-6 20 20 0 0 0 2-16 23 23 0 0 0-8-13Zm-74-11a17 17 0 0 0-3-1 17 17 0 0 0-4 0 19 19 0 0 0-7 1 21 21 0 0 0-11 9 19 19 0 0 0-2 15 19 19 0 0 0 4 7 22 22 0 0 0 3 3l4 2a20 20 0 0 0 16 0 19 19 0 0 0 10-11 21 21 0 0 0 0-14 19 19 0 0 0-10-11Zm-46-38h-1a17 17 0 0 0-10-7 19 19 0 0 0-13 1 17 17 0 0 0-9 11 18 18 0 0 0 2 15 17 17 0 0 0 6 5 18 18 0 0 0 6 3 17 17 0 0 0 14-4 19 19 0 0 0 7-11v-7a17 17 0 0 0-2-6Zm-19-58c0-4-2-8-5-11a18 18 0 0 0-11-5c-4-1-8 1-12 4-3 3-5 7-5 12s2 9 5 12a15 15 0 0 0 12 4 18 18 0 0 0 11-6c3-3 5-6 5-10Zm-4-56a16 16 0 0 0 11 2c4-1 7-3 9-6a14 14 0 0 0 1-10 16 16 0 0 0-5-10 14 14 0 0 0-11-3 14 14 0 0 0-6 2 14 14 0 0 0-4 5c-2 3-3 8-2 12a14 14 0 0 0 7 8Zm57-46a13 13 0 0 0 7 0l2-1a12 12 0 0 0 6-6 14 14 0 0 0 1-10 12 12 0 0 0-7-8 13 13 0 0 0-11 1l-2 1a15 15 0 0 0-2 2 13 13 0 0 0-3 4c-1 4 0 7 2 10s4 6 7 7Zm59 3 11 4h4l7-1 9-4v-1a31 31 0 0 0 12-17c2-8 1-16-4-23a28 28 0 0 0-8-9h-1a29 29 0 0 0-11-4 31 31 0 0 0-12 1 29 29 0 0 0-11 6 29 29 0 0 0-10 21 31 31 0 0 0 6 20 29 29 0 0 0 8 7Zm61 25a27 27 0 0 0 19 6 29 29 0 0 0 19-8 27 27 0 0 0 8-20 28 28 0 0 0-9-20 28 28 0 0 0-22-7 27 27 0 0 0-19 12 29 29 0 0 0-5 19 27 27 0 0 0 9 18Zm82 31a26 26 0 0 0-5-10 25 25 0 0 0-29-7 27 27 0 0 0-14 13h-1a27 27 0 0 0-2 9v10a25 25 0 0 0 13 15 28 28 0 0 0 18 3 25 25 0 0 0 17-12 26 26 0 0 0 4-10l-1-11ZM75 136a12 12 0 0 0 8 6c3 0 6 0 9-2a12 12 0 0 0 6-7v-4a13 13 0 0 0-8-10 12 12 0 0 0-4-1 12 12 0 0 0-9 4 12 12 0 0 0-3 5 12 12 0 0 0 1 9Zm30-24a11 11 0 0 0 7-3c2-2 4-4 4-7l-2-8a11 11 0 0 0-8-5 11 11 0 0 0-9 3 11 11 0 0 0-4 8 11 11 0 0 0 4 9 12 12 0 0 0 8 3Zm26-17a10 10 0 0 0 7 1 9 9 0 0 0 4-1 10 10 0 0 0 3-2 11 11 0 0 0 2-8 10 10 0 0 0-4-7 11 11 0 0 0-3-2 11 11 0 0 0-5 0 11 11 0 0 0-7 4 10 10 0 0 0-1 8c0 3 2 5 4 7Zm37 5h1a9 9 0 0 0 5 0 10 10 0 0 0 6-4 9 9 0 0 0-1-11l-2-2a10 10 0 0 0-5-2 9 9 0 0 0-9 7v7a9 9 0 0 0 5 5Zm23 19a8 8 0 0 0 5 3h6a9 9 0 0 0 5-6 9 9 0 0 0-1-7 9 9 0 0 0-3-2 9 9 0 0 0-5-2l-5 2a9 9 0 0 0-3 6 9 9 0 0 0-1 3 9 9 0 0 0 2 3Zm9 29a8 8 0 0 0 2 5 9 9 0 0 0 6 3 8 8 0 0 0 5-2 8 8 0 0 0 3-6 8 8 0 0 0-2-6 8 8 0 0 0-6-2c-3 0-4 1-6 3a7 7 0 0 0-2 5Zm2 27a8 8 0 0 0-6 0 7 7 0 0 0-4 3 7 7 0 0 0-1 5 8 8 0 0 0 3 4 7 7 0 0 0 5 2 7 7 0 0 0 3-1 7 7 0 0 0 2-3 7 7 0 0 0 1-5 7 7 0 0 0-3-5Zm-29 23a6 6 0 0 0-2 0h-1l-1 1a6 6 0 0 0-3 3 7 7 0 0 0 0 5 6 6 0 0 0 3 4l5-1h1l1-1a6 6 0 0 0 1-7 7 7 0 0 0-4-4Zm-29-1a13 13 0 0 0-5-2 13 13 0 0 0-6 0 15 15 0 0 0-4 3 15 15 0 0 0-6 8 14 14 0 0 0 2 12l4 4a15 15 0 0 0 6 2h6a14 14 0 0 0 10-14c0-3-1-7-3-10a14 14 0 0 0-4-3Zm-30-12v-1a13 13 0 0 0-9-3h-1c-3 0-6 2-9 4a13 13 0 0 0-4 10c0 4 2 8 5 10a14 14 0 0 0 10 4 14 14 0 0 0 10-6 14 14 0 0 0 2-10 13 13 0 0 0-4-8Zm-41-16a13 13 0 0 0 3 5 13 13 0 0 0 14 3c3-1 6-3 7-6a13 13 0 0 0 2-4 12 12 0 0 0-3-10 13 13 0 0 0-4-3 14 14 0 0 0-9-1 13 13 0 0 0-10 10v6Zm71-36a17 17 0 1 0 0 34 17 17 0 0 0 0-34ZM362 108c10-2 17-4 17-12V25c0-4-2-5-5-5h-3c-12 0-22 5-24 10-2 3-8 3-7 0l4-19c0-3 1-3 4-2l43 1 46-1c3-1 6-1 5 2a173 173 0 0 0-5 19c-1 3-5 3-6 0-1-5-8-10-20-10h-4c-3 0-6 1-6 5v71c0 8 7 10 17 12 1 0 1 5-1 5h-54l-1-5Zm132-2c-5 2-17 10-20 10-19 0-42-8-42-35 0-18 11-39 37-39 23 0 26 16 26 22 0 4-2 11-4 14l-40 2c3 16 16 23 28 23l13-2c2 0 3 4 2 5Zm-44-35 28-1c1-9-5-17-14-17-10 0-14 7-14 18Zm49 10c0-18 11-39 41-39 9 0 20 3 19 7l-2 6c-3 15-11-2-25-2-10 0-14 9-14 19 0 19 15 31 25 31l14-2c1 0 3 4 2 5-5 2-16 10-19 10-18 0-41-9-41-35Z\"></path><path d=\"M559 108c4-1 10-3 10-11V33c0-16-2-19-11-20l1-5 29-6a2 2 0 0 1 3 3c-3 9-3 28-3 40 0 3 2 5 4 4 8-3 15-7 24-7 14 0 19 11 19 20v35c0 8 6 10 10 11l-1 5h-36l-1-5c6-1 9-4 9-11V71c0-13-4-16-15-16-5 0-13 2-13 6v36c0 7 3 10 10 11l-1 5h-37l-1-5Zm-164 84v20c0 10 8 12 17 13l-1 6h-48l-1-6c8-1 12-4 12-13v-64c0-10-5-13-12-15-1 0-1-6 1-6l17 1 29-1c25 0 44 9 44 32 0 26-25 37-58 33Zm0-44v36c24 3 35-4 35-22 0-14-9-26-25-26-8 0-10 3-10 12Zm59 49c0-21 16-37 37-37s37 14 37 36-15 37-37 37c-21 0-37-14-37-36Zm55 7c0-20-9-34-22-34-7 0-14 4-14 19 0 19 9 34 22 34 7 0 14-4 14-19Z\"></path><path d=\"M528 226c4-1 10-3 10-12v-63c0-16-3-19-12-20l1-5 30-6c1 0 3 1 2 3-1 4-2 14-2 34v57c0 9 5 11 9 12l-1 5h-36c-1 0-3-5-1-5Z\"></path><path d=\"M564 226c5-1 10-3 10-12v-30c0-10-2-12-9-13-2 0-1-4 0-4l29-7c1 0 2 1 2 3a116 116 0 0 0-3 23v28c0 9 6 11 10 12l-1 5h-37l-1-5Zm6-91c0-4 8-12 12-12s13 8 13 12-8 13-13 13-12-8-12-13Z\"></path><path d=\"M601 199c0-18 12-39 41-39 9 0 21 2 19 7l-1 6c-4 14-12-3-26-3-10 0-13 9-13 19 0 20 15 32 24 32l14-2c2-1 3 4 2 4-5 3-16 10-19 10-18 0-41-9-41-34ZM740 168c-4 1-8 6-12 15l-29 64c-5 11-16 12-21 12-8 0-12-4-15-10-3-8 1-5 12-5 10 0 18-2 22-13l-21-48c-5-10-8-14-13-15-1 0-1-6 1-6h33c2 0 2 5 0 6-4 3-5 6 0 15l10 25 11-24c4-10 3-15-3-16-2 0-2-6 0-6h25c2 0 2 6 0 6ZM361 292c0-2 3-5 5-5s5 3 5 5-3 5-5 5-5-3-5-5Zm29-11v8c0 4 3 5 6 5v2h-19v-2c3 0 5-2 5-5v-26c0-3-2-5-5-5v-3l7 1 12-1c9 0 17 4 17 13 0 10-10 15-23 13Zm0-18v15c9 1 14-2 14-9 0-6-4-10-10-10-3 0-4 1-4 4Zm73 34c-4 1-10 1-14-4l-8-11c-3-4-6-4-9-4v11c0 4 3 5 6 5v2h-19l-1-2c3 0 5-2 5-5v-26c0-3-2-5-5-5l1-3 6 1 13-1c10 0 15 4 15 11s-5 10-11 10v1c3 0 5 1 8 4l8 10c2 3 4 4 5 4v2Zm-19-29c0-6-3-9-8-9-4 0-4 1-4 4v12h1c9 0 11-2 11-7Zm22 26c3-1 6-1 6-6v-25c0-4-3-5-5-5v-3l16 1 14-1 1 3-1 5h-2c-1-3-3-4-10-4-3 0-5 1-5 4v9c0 2 1 2 2 2h2l10-2h2l-3 8h-3c-1-2-4-3-7-3h-1c-1 0-2 0-2 2v9c0 4 2 5 6 5 8 0 12-4 13-6 1-1 3 0 3 1 0 2-3 9-7 8h-29v-2Zm42-1v-3c2-7 4 3 14 3 4 0 6-2 6-5 0-2-1-3-6-6l-4-3c-7-5-10-7-10-12 0-8 8-12 15-12 4 0 10 2 9 4l-1 2c-2 6-3-2-11-2-3 0-5 2-5 5 0 2 1 4 5 6l5 3c7 5 9 7 9 12 0 7-7 12-15 12-5 0-12-2-11-4Zm33 0v-3c2-7 4 3 14 3 5 0 6-2 6-5 0-2-1-3-6-6l-4-3c-7-5-10-7-10-12 0-8 8-12 15-12 4 0 10 2 9 4v2c-2 6-4-2-12-2-3 0-5 2-5 5 0 2 1 4 5 6l5 3c7 5 9 7 9 12 0 7-7 12-15 12-4 0-12-2-11-4Z\"></path></g></svg></div><style data-emotion=\"css 1sm5mum\">.css-1sm5mum{margin:0;font-size:14px;line-height:1.4;font-family:'Libre Baskerville',serif;font-weight:400;display:none;}</style><span class=\"MuiTypography-root MuiTypography-body1 css-1sm5mum\">Home</span></a></div><style data-emotion=\"css h3o6is\">.css-h3o6is{box-sizing:border-box;margin:0;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-flex-basis:100%;-ms-flex-preferred-size:100%;flex-basis:100%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:100%;}@media (min-width:600px){.css-h3o6is{-webkit-flex-basis:33.333333%;-ms-flex-preferred-size:33.333333%;flex-basis:33.333333%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:33.333333%;}}@media (min-width:900px){.css-h3o6is{-webkit-flex-basis:33.333333%;-ms-flex-preferred-size:33.333333%;flex-basis:33.333333%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:33.333333%;}}@media (min-width:1200px){.css-h3o6is{-webkit-flex-basis:33.333333%;-ms-flex-preferred-size:33.333333%;flex-basis:33.333333%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:33.333333%;}}@media (min-width:1536px){.css-h3o6is{-webkit-flex-basis:33.333333%;-ms-flex-preferred-size:33.333333%;flex-basis:33.333333%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:33.333333%;}}</style><div class=\"MuiGrid-root MuiGrid-item MuiGrid-grid-xs-12 MuiGrid-grid-sm-4 css-h3o6is\"><style data-emotion=\"css 1x9sdfd\">.css-1x9sdfd{margin:0;font-family:'Lexend',sans-serif;font-weight:300;line-height:1.4;font-size:0.875rem;margin-bottom:16px;max-width:275px;}</style><div class=\"MuiTypography-root MuiTypography-body2 css-1x9sdfd\">A nonprofit media and community venture intended to provoke new ideas, debate and discussion at the intersection of technology and democracy.</div><a href=\"https://techpolicy.press/rss/feed.xml\"><style data-emotion=\"css aibun8\">.css-aibun8{-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;width:1em;height:1em;display:inline-block;fill:currentColor;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;-webkit-transition:fill 200ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:fill 200ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;font-size:1.5rem;background-color:#FFF;border-radius:4px;fill:#3475BF;margin-right:8px;}</style><svg class=\"MuiSvgIcon-root MuiSvgIcon-fontSizeMedium css-aibun8\" focusable=\"false\" aria-hidden=\"true\" viewBox=\"0 0 24 24\" data-testid=\"RssFeedIcon\"><circle cx=\"6.18\" cy=\"17.82\" r=\"2.18\"></circle><path d=\"M4 4.44v2.83c7.03 0 12.73 5.7 12.73 12.73h2.83c0-8.59-6.97-15.56-15.56-15.56zm0 5.66v2.83c3.9 0 7.07 3.17 7.07 7.07h2.83c0-5.47-4.43-9.9-9.9-9.9z\"></path></svg><span class=\"MuiTypography-root MuiTypography-body1 css-1sm5mum\">TPP RSS feed</span></a><a href=\"mailto:newsletter@techpolicy.press\"><style data-emotion=\"css 1ct922h\">.css-1ct922h{-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;width:1em;height:1em;display:inline-block;fill:currentColor;-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;-webkit-transition:fill 200ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;transition:fill 200ms cubic-bezier(0.4, 0, 0.2, 1) 0ms;font-size:1.5rem;background-color:#FFF;border-radius:4px;fill:#3475BF;}</style><svg class=\"MuiSvgIcon-root MuiSvgIcon-fontSizeMedium css-1ct922h\" focusable=\"false\" aria-hidden=\"true\" viewBox=\"0 0 24 24\" data-testid=\"EmailIcon\"><path d=\"M20 4H4c-1.1 0-1.99.9-1.99 2L2 18c0 1.1.9 2 2 2h16c1.1 0 2-.9 2-2V6c0-1.1-.9-2-2-2zm0 4-8 5-8-5V6l8 5 8-5v2z\"></path></svg><span class=\"MuiTypography-root MuiTypography-body1 css-1sm5mum\">Email TPP</span></a></div><style data-emotion=\"css 1xgnvjv\">.css-1xgnvjv{box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;width:100%;margin:0;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-flex-basis:100%;-ms-flex-preferred-size:100%;flex-basis:100%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:100%;-webkit-box-flex-wrap:wrap;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;height:150px;}.css-1xgnvjv>.MuiGrid-item{max-width:none;}@media (min-width:600px){.css-1xgnvjv{-webkit-flex-basis:50%;-ms-flex-preferred-size:50%;flex-basis:50%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:50%;}}@media (min-width:900px){.css-1xgnvjv{-webkit-flex-basis:50%;-ms-flex-preferred-size:50%;flex-basis:50%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:50%;}}@media (min-width:1200px){.css-1xgnvjv{-webkit-flex-basis:50%;-ms-flex-preferred-size:50%;flex-basis:50%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:50%;}}@media (min-width:1536px){.css-1xgnvjv{-webkit-flex-basis:50%;-ms-flex-preferred-size:50%;flex-basis:50%;-webkit-box-flex:0;-webkit-flex-grow:0;-ms-flex-positive:0;flex-grow:0;max-width:50%;}}</style><div class=\"MuiGrid-root MuiGrid-container MuiGrid-item MuiGrid-direction-xs-column MuiGrid-grid-xs-12 MuiGrid-grid-sm-6 css-1xgnvjv\"><style data-emotion=\"css kzxgfv\">.css-kzxgfv{box-sizing:border-box;margin:0;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;margin-top:8px;margin-bottom:8px;}</style><div class=\"MuiGrid-root MuiGrid-item css-kzxgfv\"><a style=\"text-decoration:none\" href=\"/about-us/\"><style data-emotion=\"css 1it5f8v\">.css-1it5f8v{margin:0;font-family:'Lexend',sans-serif;font-size:0.81em;margin-bottom:20px;text-transform:uppercase;font-weight:400;line-height:1.334;color:#FFF;font-size:14px;-webkit-text-decoration:none;text-decoration:none;text-transform:none;}.css-1it5f8v:hover,.css-1it5f8v:focus{-webkit-text-decoration:underline;text-decoration:underline;}</style><span class=\"MuiTypography-root MuiTypography-h5 css-1it5f8v\">About</span></a></div><div class=\"MuiGrid-root MuiGrid-item css-kzxgfv\"><a style=\"text-decoration:none\" href=\"/donate/\"><span class=\"MuiTypography-root MuiTypography-h5 css-1it5f8v\">Donate</span></a></div><div class=\"MuiGrid-root MuiGrid-item css-kzxgfv\"><a style=\"text-decoration:none\" href=\"/privacy/\"><span class=\"MuiTypography-root MuiTypography-h5 css-1it5f8v\">Privacy Policy</span></a></div><div class=\"MuiGrid-root MuiGrid-item css-kzxgfv\"><a style=\"text-decoration:none\" href=\"/search/\"><span class=\"MuiTypography-root MuiTypography-h5 css-1it5f8v\">Articles</span></a></div><div class=\"MuiGrid-root MuiGrid-item css-kzxgfv\"><a style=\"text-decoration:none\" href=\"/podcast/\"><span class=\"MuiTypography-root MuiTypography-h5 css-1it5f8v\">Podcast</span></a></div><div class=\"MuiGrid-root MuiGrid-item css-kzxgfv\"><a style=\"text-decoration:none\" href=\"/contributors/\"><span class=\"MuiTypography-root MuiTypography-h5 css-1it5f8v\">Contributors</span></a></div><div class=\"MuiGrid-root MuiGrid-item css-kzxgfv\"><a style=\"text-decoration:none\" href=\"/fellowships/\"><span class=\"MuiTypography-root MuiTypography-h5 css-1it5f8v\">Fellowships</span></a></div><div class=\"MuiGrid-root MuiGrid-item css-kzxgfv\"><a style=\"text-decoration:none\" href=\"/contributor-guidelines/\"><span class=\"MuiTypography-root MuiTypography-h5 css-1it5f8v\">Contributor Guidelines</span></a></div></div></div><style data-emotion=\"css 18p24us\">.css-18p24us{margin:0;font-family:'Lexend',sans-serif;font-size:0.81em;margin-bottom:20px;text-transform:uppercase;font-weight:400;line-height:1.334;font-size:14px;margin-top:32px;text-align:center;text-transform:none;}</style><div class=\"MuiTypography-root MuiTypography-h5 css-18p24us\">Tech Policy Press © 2025 — a 501(c)(3) organization</div></div></div></footer></div><script id=\"__NEXT_DATA__\" type=\"application/json\">{\"props\":{\"pageProps\":{\"page\":{\"_createdAt\":\"2025-05-01T02:57:30Z\",\"_id\":\"ade6c009-050e-41b6-b8ac-1c923a2c8b12\",\"_type\":\"post\",\"_updatedAt\":\"2025-05-01T19:09:46Z\",\"authors\":[{\"bio\":[{\"_key\":\"401e773f6938\",\"_type\":\"block\",\"children\":[{\"_key\":\"401e773f69380\",\"_type\":\"span\",\"marks\":[],\"text\":\"Ellen P. Goodman is a Professor at Rutgers Law School, Co-Director of the Rutgers Institute for Information Policy \\u0026 Law (RIIPL), and a Senior Fellow at the Digital Innovation \\u0026 Democracy Institute at the German Marshall Fund.\"}],\"markDefs\":[],\"style\":\"normal\"}],\"name\":\"Ellen P. Goodman\",\"photo\":{\"_type\":\"image\",\"asset\":{\"_ref\":\"image-dbffdf30f9fe5a4bde894465e60d23a88d9cd51e-2560x2175-jpg\",\"_type\":\"reference\"}},\"slug\":{\"current\":\"ellen-p-goodman\"}},{\"bio\":[{\"_key\":\"dbbb3a4dadca\",\"_type\":\"block\",\"children\":[{\"_key\":\"7d9a00e0a0ed0\",\"_type\":\"span\",\"marks\":[],\"text\":\"Kaylee Williams is a PhD student at the Columbia Journalism School and a research associate at the International Center for Journalists. Her research specializes in technology-facilitated gender-based violence, with a particular emphasis on generative AI and non-consensual intimate imagery. Prior to her doctoral studies, she was a research fellow at Harvard University's Shorenstein Center for Media, Politics \\u0026 Public Policy, where she investigated coordinated disinformation and cyberharassment campaigns. When time permits, she also covers tech policy and social media platforms as a freelance journalist. She holds a Master of Arts in Political Science from Columbia University.\"}],\"markDefs\":[],\"style\":\"normal\"}],\"name\":\"Kaylee Williams\",\"photo\":{\"_type\":\"image\",\"asset\":{\"_ref\":\"image-0716ab6ab2ae93f951d46e393fb5495cd4e27d73-1080x1080-png\",\"_type\":\"reference\"}},\"slug\":{\"current\":\"kaylee-williams\"}},{\"bio\":[{\"_key\":\"40e551f7591f\",\"_type\":\"block\",\"children\":[{\"_key\":\"40e551f7591f0\",\"_type\":\"span\",\"marks\":[],\"text\":\"Justin Hendrix is CEO and Editor of Tech Policy Press, a nonprofit media venture concerned with the intersection of technology and democracy. Previously, he was Executive Director of NYC Media Lab. He spent over a decade at The Economist in roles including Vice President of Business Development \\u0026 Innovation. He is an adjunct professor at NYU Tandon School of Engineering and a lecturer at Cornell Tech, and serves on the editorial board at Just Security. Opinions expressed here are his own.\"}],\"markDefs\":[],\"style\":\"normal\"}],\"name\":\"Justin Hendrix\",\"photo\":{\"_type\":\"image\",\"asset\":{\"_ref\":\"image-13e89d005fe677a1c18c1b8be04209d7849a7de8-748x748-jpg\",\"_type\":\"reference\"}},\"slug\":{\"current\":\"justin-hendrix\"}}],\"badge\":\"analysis\",\"body\":[{\"_key\":\"93bfa3ca038f\",\"_type\":\"block\",\"children\":[{\"_key\":\"9c82da62cf430\",\"_type\":\"span\",\"marks\":[],\"text\":\"\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"ab263a062ca9\",\"_type\":\"Image\",\"altText\":\"OpenAI Sora new text to video AI model illustration on screen. ChatGPT Sora is an AI model that can create realistic and imaginative scenes. \",\"asset\":{\"_ref\":\"image-8f56541566a9236d6fbd6ff606a02bb7fde08386-1200x675-png\",\"_type\":\"reference\"},\"caption\":[{\"_key\":\"3b9dd2e375de\",\"_type\":\"block\",\"children\":[{\"_key\":\"1a4e5365386f\",\"_type\":\"span\",\"marks\":[\"a67bf747a4f3\"],\"text\":\"Shutterstock\"}],\"markDefs\":[{\"_key\":\"a67bf747a4f3\",\"_type\":\"link\",\"href\":\"https://www.shutterstock.com/image-photo/kaunas-lithuania-2024-februrary-17-openai-2426496059\"}],\"style\":\"normal\"}]},{\"_key\":\"c62d0b8469e9\",\"_type\":\"block\",\"children\":[{\"_key\":\"66c393605e690\",\"_type\":\"span\",\"marks\":[],\"text\":\"AI-generated or altered text, imagery, video, and audio—collectively referred to as “synthetic media”—now permeate the internet and have already begun transforming industries ranging from entertainment and advertising to journalism and education.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"69ea58002022\",\"_type\":\"block\",\"children\":[{\"_key\":\"bd50b01958870\",\"_type\":\"span\",\"marks\":[],\"text\":\"The rising prevalence of synthetic media has sparked intense debates over their potential to erode “reality,” undermine intellectual property rights, threaten the privacy and safety of private citizens, spread disinformation, enable scams and fraud, and sow discord on a global scale.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"9b941f541363\",\"_type\":\"block\",\"children\":[{\"_key\":\"9ef77013993a0\",\"_type\":\"span\",\"marks\":[],\"text\":\"On December 13, 2024, just weeks after the US Presidential Election, a diverse group of experts—including computer scientists, First Amendment and information law scholars, government officials, and cybersecurity specialists—gathered for a ‘Roundtable on Synthetic Media Policy’ in Washington DC to discuss these threats and establish a shared research agenda for the coming year. Hosted by \"},{\"_key\":\"9ef77013993a1\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Rutgers Law School’s Institute for Information Policy and Law\"},{\"_key\":\"9ef77013993a2\",\"_type\":\"span\",\"marks\":[],\"text\":\" in partnership with \"},{\"_key\":\"9ef77013993a3\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Tech Policy Press\"},{\"_key\":\"9ef77013993a4\",\"_type\":\"span\",\"marks\":[],\"text\":\", the event focused on open research questions and potential solutions—technical, regulatory, social, and structural—to the many challenges associated with synthetic media.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"a8621492d9b9\",\"_type\":\"block\",\"children\":[{\"_key\":\"6f6fb7d30ca20\",\"_type\":\"span\",\"marks\":[],\"text\":\"Participants reached consensus on a handful of shared priorities—such as the importance of harm reduction, increasing media literacy, and preserving free expression online—and, as importantly, identified areas of disagreement about matters such as provenance standards, tradeoffs between privacy and transparency, and the role of digital forensics in battling harmful digital clones and fakes.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"e72049527097\",\"_type\":\"block\",\"children\":[{\"_key\":\"680c1f96b4210\",\"_type\":\"span\",\"marks\":[],\"text\":\"The following outlines some of the findings of the convening, which do not reflect the precise views of every participant.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"3ede9d78eee8\",\"_type\":\"block\",\"children\":[{\"_key\":\"6b4153e12ed70\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Question #1: What are the limits of synthetic media detection, and who are the intended consumers of detection-based products?\"}],\"markDefs\":[],\"style\":\"h4\"},{\"_key\":\"c170af11a1ef\",\"_type\":\"block\",\"children\":[{\"_key\":\"37160a1d69420\",\"_type\":\"span\",\"marks\":[],\"text\":\"For years, research labs, intelligence agencies, and private companies have been designing forensic tools, protocols, and systems intended to help people determine whether a given piece of content (such as an image or a video) was likely generated or altered by AI. While these forensic detection technologies have grown more sophisticated over time, several experts agreed that even the most advanced synthetic media detection techniques are extremely time-consuming and resource-intensive, making them difficult to deploy at scale. Furthermore, there are only a small number (roughly “half a dozen,” according to one expert) of companies and research firms performing advanced work on forensics in the United States, a handful in Italy, and fewer in other democratic countries. This suggests that the resources required to scale robust AI detection as a way to combat social media harms—including fraud, disinformation, and non-consensual intimate imagery—are lacking, to say the least, particularly outside of the Global North.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"5abf647bed13\",\"_type\":\"block\",\"children\":[{\"_key\":\"32f6814fb5000\",\"_type\":\"span\",\"marks\":[],\"text\":\"Even when an expert forensics team applies its tools to a piece of potentially synthetic media, detection technologies do not yield clear, unequivocal results. Significantly, the best of these methods can only calculate a \"},{\"_key\":\"32f6814fb5001\",\"_type\":\"span\",\"marks\":[\"em\"],\"text\":\"likelihood\"},{\"_key\":\"32f6814fb5002\",\"_type\":\"span\",\"marks\":[],\"text\":\" that a given image has been generated by AI or digitally altered from its original form. They cannot make a definitive determination that content is “synthetic” or “authentic,” as there is too much variation to achieve high-confidence, definitive results, even by the best detectors.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"6d3060f58401\",\"_type\":\"block\",\"children\":[{\"_key\":\"deab6665e28c0\",\"_type\":\"span\",\"marks\":[],\"text\":\"More importantly, even if there are definitive forensic determinations, there may be a misalignment with the public’s understanding of what it means for a piece of content to be “digitally altered” or “manipulated.” Not all manipulations are created equal. For example, most people would not consider an image “digitally altered” if it were simply cropped or color-corrected in Photoshop. People may be divided on other modifications, such as “touching up” subject faces and adding artistic filters. There is probably more consensus around the removal or addition of elements. The rising ubiquity and broad accessibility of AI-powered photo editing software, much of which is now built directly into smartphone cameras, is also changing public perception of what constitutes an “authentic” image, making the reliable identification of synthetic media \"},{\"_key\":\"deab6665e28c1\",\"_type\":\"span\",\"marks\":[\"em\"],\"text\":\"that changes the meaning \"},{\"_key\":\"deab6665e28c2\",\"_type\":\"span\",\"marks\":[],\"text\":\"of that content much more difficult. To denote content as “altered” is a sociotechnical exercise that would ideally be tuned to evolving communications dynamics.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"db801e82bed5\",\"_type\":\"block\",\"children\":[{\"_key\":\"d34d76407d700\",\"_type\":\"span\",\"marks\":[],\"text\":\"Ultimately, digital alteration does not necessarily cause deception. The gap between the technical term “manipulation” and the social/legal term “deception” is potentially problematic for assessing and addressing synthetic media harms. For example, labeling content as synthetic or manipulated may imply that it is deceptive or otherwise harmful when that may not be the case. Synthetic parodies and art illustrate the point. An obvious parody or imaginative work containing synthetic elements would technically constitute manipulated media, while rarely deceiving. By the same token, identifying content as authentic or minimally altered may imply that it is trustworthy when that may not be the case. For example, an infographic generated using an LLM might accurately display verifiable data, while a cleverly cropped but otherwise unaltered photograph might give viewers a distorted understanding of a real-world event. Labels that cleave content into synthetic/authentic or manipulated/unaltered binaries may not only create confusion for online consumers, but also for those around the world making high-stakes legal decisions based on visual evidence.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"05ac30996c42\",\"_type\":\"Image\",\"altText\":\"A 2x2 matrix chart categorizes media types based on two axes: “Verifiably truthful” (top) to “Verifiably false” (bottom), and “Authentic” (left) to “Synthetic” (right).\\n\\nTop-left quadrant (Authentic + Verifiably truthful):\\n\\n\\\"Media produced with state of the art provenance and authenticity badges\\\"\\n\\n\\\"Media verifiable by comparison to multiple sources\\\"\\n\\n\\\"Eyewitness videos shared by credible though unofficial sources\\\"\\n\\nTop-right quadrant (Synthetic + Verifiably truthful):\\n\\n\\\"Synthetic rendering of verifiable speeches or texts\\\"\\n\\n\\\"3D reconstructions or simulations based on verified data\\\"\\n\\n\\\"AI-generated but accurate educational video\\\"\\n\\nBottom-left quadrant (Authentic + Verifiably false):\\n\\n\\\"Authentic content that is used outside of a truthful context\\\"\\n\\n\\\"Detectable false elements in a real media asset\\\"\\n\\n\\\"Selective editing to mislead or distort (e.g., cutting out key context)\\\"\\n\\nBottom-right quadrant (Synthetic + Verifiably false):\\n\\n\\\"AI generated material that is labeled as such by the creator\\\"\\n\\n\\\"Deepfake detected at high confidence\\\"\\n\\nCenter-left (Authentic, uncertain truthfulness):\\n\\n\\\"Authentic detected at low confidence\\\"\\n\\n\\\"A staged event\\\"\\n\\nCenter-right (Synthetic, uncertain truthfulness):\\n\\n\\\"AI-generated satire or parody\\\"\\n\\n\\\"Deepfake detected at low confidence\\\"\",\"asset\":{\"_ref\":\"image-8e1955b2fe8302c4998b9d1bb614348fce036478-2283x1751-png\",\"_type\":\"reference\"},\"caption\":[{\"_key\":\"3d7219d4d11b\",\"_type\":\"block\",\"children\":[{\"_key\":\"bc2a3c39a0070\",\"_type\":\"span\",\"marks\":[],\"text\":\"Illustration: A matrix categorizing media content by its authenticity (Authentic vs. Synthetic) and veracity (Verifiably True vs. Verifiably False), with examples.\"}],\"markDefs\":[],\"style\":\"normal\"}]},{\"_key\":\"fb77115a5034\",\"_type\":\"block\",\"children\":[{\"_key\":\"b7e4dc399e2e0\",\"_type\":\"span\",\"marks\":[],\"text\":\"Despite these limitations, synthetic media detection remains a critical area of research for a variety of stakeholders, including the national security community, human rights defenders, lawyers, and journalists. While the technology may never be able to satisfy the public’s desire for a quick and easy way to verify whether an image is “authentic,” it will likely still play a crucial role in advancing trustworthy information, especially as the challenges that AI poses become more significant. To continue this work, digital forensics professionals and others in this space will need to prioritize certain use cases and stakeholders over others and develop tools tailored to those domains.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"88792124e378\",\"_type\":\"block\",\"children\":[{\"_key\":\"12208fa084640\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Question #2: How useful is content labeling and provenance disclosure?\"}],\"markDefs\":[],\"style\":\"h4\"},{\"_key\":\"8e75e5d7a9f2\",\"_type\":\"block\",\"children\":[{\"_key\":\"15b4e1770ae20\",\"_type\":\"span\",\"marks\":[],\"text\":\"Content provenance and watermarking are methods used to encode media with metadata indicating the source of origin and any alterations. Such metadata can be displayed to end users in the form of a provenance legend or content label. These methods are not foolproof; technically savvy actors can exploit metadata and watermarking techniques to make an authentic image look synthetic, or vice versa.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"379225a6ebc6\",\"_type\":\"block\",\"children\":[{\"_key\":\"3efc2abe5b8d0\",\"_type\":\"span\",\"marks\":[],\"text\":\"Workshop participants considered the utility of labeling and provenance disclosures in light of the literature on content labeling in general. In the years since 2016, when Facebook first started \"},{\"_key\":\"3efc2abe5b8d1\",\"_type\":\"span\",\"marks\":[\"051f15c2feb8\"],\"text\":\"putting “content warnings”\"},{\"_key\":\"3efc2abe5b8d2\",\"_type\":\"span\",\"marks\":[],\"text\":\" next to verifiably false claims on the News Feed, dozens of academic studies have sought to measure the efficacy of fact-checking labels designed to alert readers to the presence of disputed or inaccurate information within a given post. The results of these studies vary widely depending on the design of the labels, users’ pre-existing beliefs about the subject matter, and other factors. But the research tends to suggest that labels have only a modest effect on the spread of disinformation and can create a variety of potential backfire effects, including seeding the misconception that unlabeled assertions are accurate—a phenomenon known as the “\"},{\"_key\":\"3efc2abe5b8d3\",\"_type\":\"span\",\"marks\":[\"bb75f5bcca8f\"],\"text\":\"implied truth effect\"},{\"_key\":\"3efc2abe5b8d4\",\"_type\":\"span\",\"marks\":[],\"text\":\".”\"}],\"markDefs\":[{\"_key\":\"051f15c2feb8\",\"_type\":\"link\",\"href\":\"https://cssh.northeastern.edu/ethics/the-evolution-of-social-media-content-labeling-an-online-archive/\"},{\"_key\":\"bb75f5bcca8f\",\"_type\":\"link\",\"href\":\"https://dspace.mit.edu/bitstream/handle/1721.1/130380/mnsc.2019.3478.pdf?sequence=2\\u0026isAllowed=y\"}],\"style\":\"normal\"},{\"_key\":\"fed39b655fc7\",\"_type\":\"block\",\"children\":[{\"_key\":\"bd26162536fb0\",\"_type\":\"span\",\"marks\":[],\"text\":\"There have been fewer studies on the effects of labeling media as synthetic, manipulated, or otherwise generated by AI in whole or in part. Even so, many social media platforms are requiring synthetic media labels, particularly on content that could be perceived as meaningfully deceptive. For example, Meta has \"},{\"_key\":\"bd26162536fb1\",\"_type\":\"span\",\"marks\":[\"9d2066326ca5\"],\"text\":\"mandated\"},{\"_key\":\"bd26162536fb2\",\"_type\":\"span\",\"marks\":[],\"text\":\" that users across its platforms label “photorealistic video or realistic-sounding audio that was digitally created, modified or altered, including with AI.” It does not, however, require a label for \"},{\"_key\":\"dc3860ca72b91\",\"_type\":\"span\",\"marks\":[\"em\"],\"text\":\"all\"},{\"_key\":\"dc3860ca72b92\",\"_type\":\"span\",\"marks\":[],\"text\":\" synthetic media. This means that, for example, a “video of an outdoor landscape, created in a style resembling a cartoon” would not need to be labeled under Meta’s current policy. The distinction between the included and excluded content seems to track the distinction between deceptive and non-deceptive content, except that lots of “modified or altered” realistic-seeming content may not be deceptive. Strict compliance with the mandate (unlikely) could result in over-labeling and attendant loss of meaning.\"}],\"markDefs\":[{\"_key\":\"9d2066326ca5\",\"_type\":\"link\",\"href\":\"https://www.meta.com/help/artificial-intelligence/1783222608822690/\"}],\"style\":\"normal\"},{\"_key\":\"3f30567a477e\",\"_type\":\"block\",\"children\":[{\"_key\":\"ab54207c267e0\",\"_type\":\"span\",\"marks\":[],\"text\":\"Meanwhile, some state legislatures in the US have adopted similar requirements for synthetic media related to elections, with varying definitions of what constitutes “synthetic.” Arizona, for example, \"},{\"_key\":\"ab54207c267e1\",\"_type\":\"span\",\"marks\":[\"79e26bb47471\"],\"text\":\"now requires\"},{\"_key\":\"ab54207c267e2\",\"_type\":\"span\",\"marks\":[],\"text\":\" “clear and conspicuous” disclosures to appear alongside any “image, audio recording or video recording of an individual's appearance, speech or conduct that has been created or intentionally manipulated with the use of digital technology” within 90 days of an election. Indiana has \"},{\"_key\":\"ab54207c267e3\",\"_type\":\"span\",\"marks\":[\"9225601d0c33\"],\"text\":\"established\"},{\"_key\":\"ab54207c267e4\",\"_type\":\"span\",\"marks\":[],\"text\":\" a civil right of action for political candidates who are deceptively depicted in “fabricated media,\\\" defined as “an audio or visual recording of an individual's speech, appearance, or conduct that has been altered without the individual's consent such that: (a) the media conveys a materially inaccurate depiction of the individual's speech, appearance, or conduct as recorded in the unaltered recording; and (b) a reasonable person would be unable to recognize that the recording has been altered.” These disparate legal definitions further demonstrate the challenges associated with synthetic media detection described above; namely that “digitally manipulated” content is not always deceptive, and vice versa.\"}],\"markDefs\":[{\"_key\":\"79e26bb47471\",\"_type\":\"link\",\"href\":\"https://www.akingump.com/en/insights/ai-law-and-regulation-tracker/arizona-senate-bill-1359-signed-into-law-by-governor\"},{\"_key\":\"9225601d0c33\",\"_type\":\"link\",\"href\":\"https://legiscan.com/IN/text/HB1133/id/2869748\"}],\"style\":\"normal\"},{\"_key\":\"c8042829e177\",\"_type\":\"block\",\"children\":[{\"_key\":\"fece2d6a3a780\",\"_type\":\"span\",\"marks\":[],\"text\":\"At least one of these laws (California’s AB 2655) has been \"},{\"_key\":\"fece2d6a3a781\",\"_type\":\"span\",\"marks\":[\"ec0e94a95b67\"],\"text\":\"overturned\"},{\"_key\":\"fece2d6a3a782\",\"_type\":\"span\",\"marks\":[],\"text\":\" in federal court as a violation of the First Amendment by compelling speech in a way that is not sufficiently well tailored to the government's interest in preventing deception. Significantly, the court expressed concerns that labels on parodies or other synthetic media that is not deceptive unduly burdened speakers and stigmatized their expression. The issue is not only that the “squeeze” of the labeling isn’t worth the “juice” of transparency with the public, but that the juice itself could sour if people come to conflate AI manipulation with deception. The contours of the First Amendment considerations are still very much uncertain when it comes to AI-related litigation, as are the implications of synthetic media labeling on consumer understanding.\"}],\"markDefs\":[{\"_key\":\"ec0e94a95b67\",\"_type\":\"link\",\"href\":\"https://www.techpolicy.press/tracker/kohls-v-bonta/\"}],\"style\":\"normal\"},{\"_key\":\"bef753dbe0aa\",\"_type\":\"block\",\"children\":[{\"_key\":\"21d114ee47c00\",\"_type\":\"span\",\"marks\":[],\"text\":\"Experts at the roundtable noted that clearly labeling synthetic media—to the extent that reliable provenance and detection methods even make that a reliable practice—is often perceived by politicians and others as an “all-encompassing solution” to the epistemic turmoil created by AI-generated images and video. This faith in labeling as \"},{\"_key\":\"21d114ee47c01\",\"_type\":\"span\",\"marks\":[\"em\"],\"text\":\"the \"},{\"_key\":\"21d114ee47c02\",\"_type\":\"span\",\"marks\":[],\"text\":\"“solution” is misplaced, both because it is not easily operationalized and cannot address harms unrelated to consumer recognition of synthetic sources.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"88eee6940ebb\",\"_type\":\"block\",\"children\":[{\"_key\":\"0f76d73899160\",\"_type\":\"span\",\"marks\":[],\"text\":\"The prevailing theory underpinning the labeling strategy is that if average users can distinguish what is “real” from what is “AI-generated,” they will be less likely to be deceived and to share deceptive content. However, as one expert pointed out, this logic relies upon the fraught assumption that all content can be reliably sorted into mutually exclusive categories such as “human-made,” “AI-generated,” and that “synthetic” is more likely to correspond with “false” and “authentic” with “true.”\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"f956144949c3\",\"_type\":\"block\",\"children\":[{\"_key\":\"3e3e644258ca0\",\"_type\":\"span\",\"marks\":[],\"text\":\"Several participants noted, drawing on communications literature, that trust is relational. People trust content based more on its source (original or intermediate) than on labels appended to it. In considering the utility of synthetic media labels or metadata, then, it might be better to focus on specialized consumers and contexts rather than on informing ordinary end users. For example, the identification of synthetic media, digital alterations, and provenance more generally is important for researchers, librarians, information specialists, model developers, agents, and fact-finders in many fields—even if an individual’s knowledge of these alterations in the ordinary flow of communications turns out to be less impactful.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"3d3024c40818\",\"_type\":\"block\",\"children\":[{\"_key\":\"d745e724217d0\",\"_type\":\"span\",\"marks\":[],\"text\":\"Those whose work focuses on individual (as opposed to epistemic or societal) harms caused by synthetic media pointed out that content labels often fail to undo the damages inflicted by embarrassing, dehumanizing, and hateful synthetic images. One participant pointed out that sexually explicit deepfakes, for example, are often labeled as such by the creators and shared on websites dedicated explicitly to AI-generated content, which suggests that they are not, in fact, intended to fool anyone into thinking they are authentic depictions. These harms, along with those associated with other forms of nonconsensual synthetic depiction, such as AI-generated child sexual abuse material (CSAM), are not remedied via the use of content labels because the perceived “authenticity” of the content is beside the point of the content: to abuse the subject.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"7c539ab3f4c1\",\"_type\":\"block\",\"children\":[{\"_key\":\"8d563001bce20\",\"_type\":\"span\",\"marks\":[],\"text\":\"Areas where content provenance and labeling might be most useful and readily adopted are in enterprise domains where businesses depend on trusted communications and/or need to secure consumer trust. In such contexts, private actors have market incentives to be transparent about content origins and alterations. Workshop participants identified industry and business use cases where this might be the case, including insurance, financial services, and e-commerce areas. There remain questions about where the market will supply sufficient transparency and where it will not, and to what extent and how.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"99e89558df35\",\"_type\":\"block\",\"children\":[{\"_key\":\"946024e6b64e0\",\"_type\":\"span\",\"marks\":[],\"text\":\"These insights suggest that while content labels and AI use disclosures—such as those enabled by provenance technologies—can play a valuable role in addressing the harms of digital clones, fakes, and other synthetic media, policymakers at both the platform and government levels should be cautious not to over-rely on them as standalone solutions.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"81d1e31a1c83\",\"_type\":\"block\",\"children\":[{\"_key\":\"657dcf5de9860\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Question #3: How do we address the social dynamics and norms underpinning the harms of synthetic media?\"}],\"markDefs\":[],\"style\":\"h4\"},{\"_key\":\"710bb3c03308\",\"_type\":\"block\",\"children\":[{\"_key\":\"210328933bb60\",\"_type\":\"span\",\"marks\":[],\"text\":\"As the cases involving synthetic sexual abuse content demonstrate, many of the harms posed by synthetic media are not easily mitigated with informational or tech-based solutions alone. In fact, many of the most concerning threats are not new to the AI era. Instead, they represent the intensification of longstanding patterns of abuse and discrimination toward vulnerable groups for the purposes of maintaining existing social hierarchies.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"7e0345ee17d9\",\"_type\":\"block\",\"children\":[{\"_key\":\"4d2a798bb02a0\",\"_type\":\"span\",\"marks\":[],\"text\":\"For instance, the prevalence of nonconsensual sexual content reflects the systemic commodification of women’s bodies and the normalization of gender-based violence. Similarly, the weaponization of synthetic media for political disinformation and propaganda reflects prevailing social forces around racial inequality, othering “out” groups, stoking polarization, and amplifying conspiracy theories.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"f732893db414\",\"_type\":\"block\",\"children\":[{\"_key\":\"f96c3e8952690\",\"_type\":\"span\",\"marks\":[],\"text\":\"Addressing these harms requires a holistic approach that combines regulatory and technical solutions with broader efforts to challenge the social norms and power structures at play. This might include public awareness campaigns, education initiatives to foster digital literacy, and collaborations with civil society organizations to address the root causes behind various manifestations of online harm. Without tackling the underlying social dynamics, the experts gathered in DC agreed that interventions targeting synthetic media risk addressing the symptoms rather than the causes of those harms.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"5c7d5eafc3a7\",\"_type\":\"block\",\"children\":[{\"_key\":\"4bc7ec8971c70\",\"_type\":\"span\",\"marks\":[],\"text\":\"These issues are deeply entrenched in modern society and will not be entirely uprooted even with dramatic regulatory intervention targeting technology. The kinds of reforms necessary to address these systemic patterns need to be just that: systemic. As such, they will require buy-in (both political and financial) from various sectors and stakeholders, many of whom currently benefit from incentives and dynamics that exacerbate intractable problems, from racism and misogyny to economic exploitation (either directly or indirectly).\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"9b9b9f332a99\",\"_type\":\"block\",\"children\":[{\"_key\":\"f1775a26b7930\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Question #4: What are the downstream risks of the “liar’s dividend”?\"}],\"markDefs\":[],\"style\":\"h4\"},{\"_key\":\"3e9234f92ec6\",\"_type\":\"block\",\"children\":[{\"_key\":\"6c69e7aec8a10\",\"_type\":\"span\",\"marks\":[],\"text\":\"The “liar’s dividend”—as \"},{\"_key\":\"6c69e7aec8a11\",\"_type\":\"span\",\"marks\":[\"9756b6b74f0f\"],\"text\":\"defined\"},{\"_key\":\"6c69e7aec8a12\",\"_type\":\"span\",\"marks\":[],\"text\":\" by legal scholars Bobby Chesney and Danielle Citron in 2019—refers to an information ecosystem that is so rife with false and otherwise deceptive information that actors can avoid accountability for wrongdoing by claiming that any documentation of misconduct is “fake news,” “misinformation,” “manipulated media” etc. Another way to put this is plausible deniability for any bit of content. In their 2019 paper, Chesney and Citron argue that pervasive, deceptive synthetic media contributes heavily to the liar’s dividend because its very existence undermines public trust in authentic content. In a world where any piece of media can plausibly be dismissed as fake, individuals and organizations can exploit widespread uncertainty about the facts to avoid accountability or obscure the truth. This dynamic has profound implications for journalism, the legal system, and democratic governance, as it challenges the fundamental ability to establish a shared reality.\"}],\"markDefs\":[{\"_key\":\"9756b6b74f0f\",\"_type\":\"link\",\"href\":\"https://heinonline.org/HOL/Page?men_tab=srchresults\\u0026handle=hein.journals/calr107\\u0026id=1794\\u0026size=2\\u0026collection=journals\\u0026terms=Liar%7Cliar\\u0026termtype=phrase\\u0026set_as_cursor=\"}],\"style\":\"normal\"},{\"_key\":\"8f906e50a9c5\",\"_type\":\"block\",\"children\":[{\"_key\":\"dad37bc89a9e0\",\"_type\":\"span\",\"marks\":[],\"text\":\"As synthetic media become more sophisticated and accessible, the liar’s dividend may reach a tipping point where skepticism about media authenticity becomes the default. \"},{\"_key\":\"dad37bc89a9e1\",\"_type\":\"span\",\"marks\":[\"e195c0620ef2\"],\"text\":\"Anecdotal accounts\"},{\"_key\":\"dad37bc89a9e2\",\"_type\":\"span\",\"marks\":[],\"text\":\" argue that we are already there. This state of affairs could empower malicious actors to weaponize doubt, dismissing legitimate evidence of wrongdoing as fabricated. For instance, political leaders might evade accountability for harmful rhetoric or actions by claiming that leaked audio recordings or videos are AI-generated. One expert posited that the growing popularity of generative AI could result in a world of content manipulation so ubiquitous that there is an epistemic collapse.\"}],\"markDefs\":[{\"_key\":\"e195c0620ef2\",\"_type\":\"link\",\"href\":\"https://petapixel.com/2019/03/01/people-call-my-photos-fake-but-theyre-not/\"}],\"style\":\"normal\"},{\"_key\":\"2a465d8fce46\",\"_type\":\"block\",\"children\":[{\"_key\":\"ffa69402d8330\",\"_type\":\"span\",\"marks\":[],\"text\":\"The societal consequences of this potential collapse are far-reaching. If people cannot distinguish between truth and fabrication, public discourse will become increasingly polarized, with individuals retreating further into ideological silos where only content that aligns with their preexisting beliefs is accepted as legitimate. This environment may foster widespread cynicism, causing people to lose ever more confidence in institutions, in democracy, and in one another.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"49f67d1c3fa0\",\"_type\":\"block\",\"children\":[{\"_key\":\"c031d6423f760\",\"_type\":\"span\",\"marks\":[],\"text\":\"One expert noted that the role of synthetic media must be considered against the broader and systemic degradation of information fidelity. Systemic trust erosion is not necessarily tied to the authenticity of particular units of content. This expert argued that distrust in informational integrity poses a challenge to journalism and communications far beyond a liar’s intentional manipulation.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"1687df37c0a8\",\"_type\":\"block\",\"children\":[{\"_key\":\"c100bd3e3bc50\",\"_type\":\"span\",\"marks\":[],\"text\":\"Addressing this systemic distrust requires proactive measures to restore faith in media and digital content. With respect to the narrow issue of synthetic media, this includes promoting the adoption of content authentication technologies, such as open technical standards like those popularized by the Coalition for Content Provenance and Authenticity (C2PA) to verify the provenance of authentic content. While the participants acknowledged it would be a long road to a fully interoperable internet that allows such standards to thrive, industry and business use cases will likely be adopted first.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"c5ba3adb6316\",\"_type\":\"block\",\"children\":[{\"_key\":\"a080dc0b60fb0\",\"_type\":\"span\",\"marks\":[],\"text\":\"Equally important are efforts to improve media literacy aimed at equipping individuals with the cognitive tools to critically evaluate the veracity of digital content. However, technical and educational solutions alone are insufficient. Policymakers, platforms, and civil society organizations must work together to establish norms and regulations that discourage the strategic weaponization of “plausible deniability” to evade public accountability. Without such efforts, the liar’s dividend threatens to deepen societal divides and erode the foundations of trust essential for democratic systems to function.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"d7f0f877695b\",\"_type\":\"block\",\"children\":[{\"_key\":\"e61fc8eae92c0\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Question #5: How do we move past the “authentic” vs. “synthetic” binary?\"}],\"markDefs\":[],\"style\":\"h4\"},{\"_key\":\"2a81e15246f0\",\"_type\":\"block\",\"children\":[{\"_key\":\"3739a3462f1a0\",\"_type\":\"span\",\"marks\":[],\"text\":\"Many of the issues discussed at the event alluded to a broader, conceptual challenge that the experts agreed requires urgent societal attention: the need to reframe how we think about the provenance and authenticity of digital content in an AI world. This issue is fundamentally tied to media literacy and public education, particularly as AI-powered tools become more deeply integrated into content generation across information industries like journalism.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"41f0a1c8140c\",\"_type\":\"block\",\"children\":[{\"_key\":\"2600fe1700f00\",\"_type\":\"span\",\"marks\":[],\"text\":\"As noted above, content labeling risks creating the false binary that a piece of content is either wholly “authentic” or entirely “synthetic.” In reality, the roundtable experts agreed that much of the content we encounter online today exists on a spectrum of human and machine involvement. For example, a video might be largely authentic but edited with AI-enhanced filters, or a news article might be written by a journalist who used AI tools to clean or analyze data. These forms of hybrid media challenge traditional notions of authenticity and truth, complicating how we assess the trustworthiness of what we see, hear, and read.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"cabb05cbfd59\",\"_type\":\"block\",\"children\":[{\"_key\":\"31c9623abc540\",\"_type\":\"span\",\"marks\":[],\"text\":\"Moving past this binary requires a more nuanced understanding of how digital content is produced and a shift in public attitudes toward AI’s role in media creation. Public education efforts should emphasize that authenticity is not solely about the method of creation or modification but also about the intent and transparency behind the content, including who shared it. Tools that trace the provenance of digital media, such as metadata tagging or blockchain-based verification, could play a critical role in fostering trust without reinforcing outdated mental models. But there are complications with these tools as well, including potential implications for privacy and free expression, and significant technical challenges.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"6e25e9313a4f\",\"_type\":\"block\",\"children\":[{\"_key\":\"251ace2019130\",\"_type\":\"span\",\"marks\":[],\"text\":\"Ultimately, building a society capable of navigating the complexities of synthetic media will require collaboration between technologists, educators, policymakers, and civil society actors. \"},{\"_key\":\"251ace2019131\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"By shifting the focus from “authentic vs. synthetic” to questions of accountability and transparency, the tech policy community will be able to seed a more sophisticated framework for understanding and engaging with synthetic media in the coming years.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"229b878fa3ab\",\"_type\":\"block\",\"children\":[{\"_key\":\"bc6ab613fae00\",\"_type\":\"span\",\"marks\":[],\"text\":\"In addition to addressing these open questions, the roundtable participants worked together to brainstorm possible metrics to indicate progress on synthetic media-related issues. The following are some of the ideas floated:\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"c882cfed0849\",\"_type\":\"block\",\"children\":[{\"_key\":\"0b989678c1ce0\",\"_type\":\"span\",\"marks\":[],\"text\":\"Tracking C2PA adoption as a proxy for understanding its effects and potential for broad interoperability across the information environment.\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"4fd45a8cbdef\",\"_type\":\"block\",\"children\":[{\"_key\":\"8c31b5e05c1e0\",\"_type\":\"span\",\"marks\":[],\"text\":\"Estimating the number of news stories in which manipulated or AI-generated media play a role, including phenomena such as criminal or civil actions brought in relation to the propagation of such content.\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"99350ac61893\",\"_type\":\"block\",\"children\":[{\"_key\":\"39d5cbbbc3e90\",\"_type\":\"span\",\"marks\":[],\"text\":\"Recording the number of scams or fraudulent activities reported to authorities that involved the use of synthetic media.\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"2ad8ceab48eb\",\"_type\":\"block\",\"children\":[{\"_key\":\"1dc321aa41140\",\"_type\":\"span\",\"marks\":[],\"text\":\"Tracking global Investment in distributed media forensics capacity.\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"3ac7694b87d4\",\"_type\":\"block\",\"children\":[{\"_key\":\"436ee79cc17a0\",\"_type\":\"span\",\"marks\":[],\"text\":\"Measuring the average time of platform takedown for nonconsensual synthetic pornography and other problematic forms of synthetic media.\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"9f6a334391a9\",\"_type\":\"block\",\"children\":[{\"_key\":\"5d8277311cb60\",\"_type\":\"span\",\"marks\":[],\"text\":\"Assessing public perception of viral incidents involving synthetic media.\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"b67f7770750b\",\"_type\":\"block\",\"children\":[{\"_key\":\"9045575765290\",\"_type\":\"span\",\"marks\":[],\"text\":\"Estimating the size of the customer base and understanding the markets for harmful synthetic depictions (including CSAM and NCII).\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"a79319d5f3b3\",\"_type\":\"block\",\"children\":[{\"_key\":\"0b9230362a9a0\",\"_type\":\"span\",\"marks\":[],\"text\":\"Identifying ways of measuring the liar’s dividend and intervening to counter it.\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"036ea6214ee1\",\"_type\":\"block\",\"children\":[{\"_key\":\"73fd76e45b750\",\"_type\":\"span\",\"marks\":[],\"text\":\"Further study on the effectiveness of content labeling, fact-checking, provenance verification, and similar efforts.\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"3b2c3badc8ab\",\"_type\":\"block\",\"children\":[{\"_key\":\"bcbf4096bef50\",\"_type\":\"span\",\"marks\":[],\"text\":\"Recording the number of lawsuits that attempt to hold platform companies accountable for harms caused by synthetic media.\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"2309e761124c\",\"_type\":\"block\",\"children\":[{\"_key\":\"5c45ccdad95b0\",\"_type\":\"span\",\"marks\":[],\"text\":\"Recording the number of new regulations introduced by state and federal governments related to AI-generated content and their resilience to legal challenges.\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"cfab64c0aec4\",\"_type\":\"block\",\"children\":[{\"_key\":\"3d5c81ead9a30\",\"_type\":\"span\",\"marks\":[],\"text\":\"Going forward, it will be crucial to find creative ways to address these challenges and advance bipartisan proposals for regulatory and self-regulatory frameworks that can alleviate some of the threats described above. The latter half of the decade will require policymakers—and the public—to move beyond “synthetic or authentic” binaries. What is needed are broad coalitions of technologists, civil society actors, researchers, and others to partner to develop systemic interventions that may not yet exist.\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"8b0fd837ea02\",\"_type\":\"block\",\"children\":[{\"_key\":\"0563bcaf367a0\",\"_type\":\"span\",\"marks\":[\"strong\",\"em\"],\"text\":\"With thanks to the Knight Foundation for providing financial support for the Workshop.\"}],\"markDefs\":[],\"style\":\"h4\"},{\"_key\":\"4bbec5860e84\",\"_type\":\"block\",\"children\":[{\"_key\":\"72acd13e63d9\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Workshop Participants:\"}],\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"2f605f4e1835\",\"_type\":\"block\",\"children\":[{\"_key\":\"223ad1e34da10\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Scott Babwah Brennen\"},{\"_key\":\"223ad1e34da11\",\"_type\":\"span\",\"marks\":[],\"text\":\", Director, NYU Center on Technology Policy\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"e95a8f0dbe75\",\"_type\":\"block\",\"children\":[{\"_key\":\"824c520630910\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Bilva Chandra\"},{\"_key\":\"824c520630911\",\"_type\":\"span\",\"marks\":[],\"text\":\", Former Senior Policy Advisor \\u0026 Synthetic Content Lead, US AI Safety Institute\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"a1b5c4ecd85f\",\"_type\":\"block\",\"children\":[{\"_key\":\"da06dfc1e6ab0\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Peter Chapman\"},{\"_key\":\"da06dfc1e6ab1\",\"_type\":\"span\",\"marks\":[],\"text\":\", Associate Director, Knight-Georgetown Institute\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"3a0d3c39e56e\",\"_type\":\"block\",\"children\":[{\"_key\":\"f2e4bba26c240\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Renée DiResta\"},{\"_key\":\"f2e4bba26c241\",\"_type\":\"span\",\"marks\":[],\"text\":\", Associate Research Professor, McCourt School of Public Policy, Georgetown University\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"bb9c2f3258e4\",\"_type\":\"block\",\"children\":[{\"_key\":\"2be66563eda10\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Nadine Farid Johnson\"},{\"_key\":\"2be66563eda11\",\"_type\":\"span\",\"marks\":[],\"text\":\", Policy Director, Knight First Amendment Institute at Columbia University\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"ae48e4007fa4\",\"_type\":\"block\",\"children\":[{\"_key\":\"20268a452c680\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Mary Anne Franks\"},{\"_key\":\"20268a452c681\",\"_type\":\"span\",\"marks\":[],\"text\":\", Eugene L. and Barbara A. Bernard Professor in Intellectual Property, Technology, and Civil Rights Law at George Washington Law School, and President and Legislative \\u0026 Tech Policy Director of the Cyber Civil Rights Initiative\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"592cc1cee6c7\",\"_type\":\"block\",\"children\":[{\"_key\":\"b54b96f7e56a0\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Josh Goldstein\"},{\"_key\":\"b54b96f7e56a1\",\"_type\":\"span\",\"marks\":[],\"text\":\", Research Fellow, Center for Security and Emerging Technology (CSET), Georgetown University\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"0889b5ebcda3\",\"_type\":\"block\",\"children\":[{\"_key\":\"e8f421e32ecf0\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Ellen P. Goodman\"},{\"_key\":\"e8f421e32ecf1\",\"_type\":\"span\",\"marks\":[],\"text\":\", Professor at Rutgers Law School, Co-Director of the Rutgers Institute for Information Policy \\u0026 Law (RIIPL)\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"a6216681a9f2\",\"_type\":\"block\",\"children\":[{\"_key\":\"9750a77b9c8d0\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Sam Gregory\"},{\"_key\":\"9750a77b9c8d1\",\"_type\":\"span\",\"marks\":[],\"text\":\", Executive Director, WITNESS\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"b2475401863b\",\"_type\":\"block\",\"children\":[{\"_key\":\"b886671581650\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Justin Hendrix\"},{\"_key\":\"b886671581651\",\"_type\":\"span\",\"marks\":[],\"text\":\", CEO and Editor, Tech Policy Press\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"657269a16c7b\",\"_type\":\"block\",\"children\":[{\"_key\":\"011045152c530\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Mounir Ibrahim\"},{\"_key\":\"011045152c531\",\"_type\":\"span\",\"marks\":[],\"text\":\", Chief Communications Officer \\u0026 Head of Public Affairs, Truepic\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"0a352b3df337\",\"_type\":\"block\",\"children\":[{\"_key\":\"225f50b96e090\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Kate Kaye\"},{\"_key\":\"225f50b96e091\",\"_type\":\"span\",\"marks\":[],\"text\":\", Deputy Director, World Privacy Forum\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"7f576249128a\",\"_type\":\"block\",\"children\":[{\"_key\":\"66390633f99c0\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Claire Leibowicz\"},{\"_key\":\"66390633f99c1\",\"_type\":\"span\",\"marks\":[],\"text\":\", Head of AI and Media Integrity, Partnership on AI\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"28a5021a9030\",\"_type\":\"block\",\"children\":[{\"_key\":\"736130fdbf73\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"David Luebke\"},{\"_key\":\"f4b9e454b0d2\",\"_type\":\"span\",\"marks\":[],\"text\":\", Vice President of Graphics Research, NVIDIA\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"e900fc2cbef7\",\"_type\":\"block\",\"children\":[{\"_key\":\"2e1aee966d240\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Siwei Lyu\"},{\"_key\":\"2e1aee966d241\",\"_type\":\"span\",\"marks\":[],\"text\":\", SUNY Distinguished Professor, University at Buffalo, State University of New York\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"505a11d0fbbe\",\"_type\":\"block\",\"children\":[{\"_key\":\"53737b8e4f790\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Abhiram Reddy\"},{\"_key\":\"53737b8e4f791\",\"_type\":\"span\",\"marks\":[],\"text\":\", AI Safety and Security Research Assistant, Center for Security and Emerging Technology (CSET), Georgetown University\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"0127d8ce607a\",\"_type\":\"block\",\"children\":[{\"_key\":\"1968d1c1609d0\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Aimee Rinehart\"},{\"_key\":\"1968d1c1609d1\",\"_type\":\"span\",\"marks\":[],\"text\":\", Senior Product Manager, AI Strategy, The Associated Press\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"8cd1bdd495df\",\"_type\":\"block\",\"children\":[{\"_key\":\"0a1c243609820\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Matthew C. Stamm\"},{\"_key\":\"0a1c243609821\",\"_type\":\"span\",\"marks\":[],\"text\":\", Associate Professor, Department of Electrical \\u0026 Computer Engineering, Director, Multimedia and Information Security Laboratory, Drexel University\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"4949304d25c6\",\"_type\":\"block\",\"children\":[{\"_key\":\"da0de55ff47f0\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Xiangnong (George) Wang\"},{\"_key\":\"da0de55ff47f1\",\"_type\":\"span\",\"marks\":[],\"text\":\", Staff Attorney, Knight First Amendment Institute\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"548c5b7f2fa5\",\"_type\":\"block\",\"children\":[{\"_key\":\"3607c327adea0\",\"_type\":\"span\",\"marks\":[\"strong\"],\"text\":\"Kaylee Williams\"},{\"_key\":\"3607c327adea1\",\"_type\":\"span\",\"marks\":[],\"text\":\", PhD Student, Columbia Journalism School and Research Associate, International Center for Journalists\"}],\"level\":1,\"listItem\":\"bullet\",\"markDefs\":[],\"style\":\"normal\"},{\"_key\":\"aa8f030218da\",\"_type\":\"block\",\"children\":[{\"_key\":\"1c71d0702540\",\"_type\":\"span\",\"marks\":[\"em\",\"41737101def9\"],\"text\":\"Download this document as a PDF\"},{\"_key\":\"ea4c4205325f\",\"_type\":\"span\",\"marks\":[\"em\"],\"text\":\".\"}],\"markDefs\":[{\"_key\":\"41737101def9\",\"_type\":\"link\",\"href\":\"https://cdn.sanity.io/files/3tzzh18d/production/15f7b0307678e77c38b7786dd63cba6f7664c1a3.pdf\"}],\"style\":\"normal\"}],\"date\":\"2025-05-02T02:58:00.000Z\",\"disableNewsletterSignup\":null,\"featuredImage\":{\"_type\":\"image\",\"altText\":\"OpenAI Sora new text to video AI model illustration on screen. ChatGPT Sora is an AI model that can create realistic and imaginative scenes. \",\"asset\":{\"_ref\":\"image-8f56541566a9236d6fbd6ff606a02bb7fde08386-1200x675-png\",\"_type\":\"reference\"},\"caption\":[{\"_key\":\"4e60caa137f1\",\"_type\":\"block\",\"children\":[{\"_key\":\"abf9bb2fc8fa\",\"_type\":\"span\",\"marks\":[\"c702ded25421\"],\"text\":\"Shutterstock\"}],\"markDefs\":[{\"_key\":\"c702ded25421\",\"_type\":\"link\",\"href\":\"https://www.shutterstock.com/image-photo/kaunas-lithuania-2024-februrary-17-openai-2426496059\"}],\"style\":\"normal\"}]},\"heroContent\":null,\"layout\":null,\"relatedArticles\":[{\"authors\":[{\"firstName\":\"Sam\",\"lastName\":\"Gregory\"}],\"badge\":null,\"date\":\"2024-12-12T13:37:58.211Z\",\"slug\":{\"_type\":\"slug\",\"current\":\"openais-sora-is-here-there-is-still-time-to-prepare-for-the-threat-such-technologies-pose\"},\"title\":\"OpenAI's Sora Is Here. There Is Still Time To Prepare For The Threat Such Technologies Pose\"},{\"authors\":[{\"firstName\":\"Sam\",\"lastName\":\"Gregory\"},{\"firstName\":\"Raquel\",\"lastName\":\"Vazquez Llorente\"}],\"badge\":null,\"date\":\"2023-10-18T12:43:28.000Z\",\"slug\":{\"current\":\"regulating-transparency-in-audiovisual-generative-ai-how-legislators-can-center-human-rights\"},\"title\":\"Regulating Transparency in Audiovisual Generative AI: How Legislators Can Center Human Rights\"},{\"authors\":[{\"firstName\":\"Jonathan\",\"lastName\":\"Stray\"},{\"firstName\":\"Aviv\",\"lastName\":\"Ovadya\"},{\"firstName\":\"Claire\",\"lastName\":\"Leibowicz\"},{\"firstName\":\"Sam\",\"lastName\":\"Gregory\"}],\"badge\":null,\"date\":\"2021-09-07T22:00:00.000Z\",\"slug\":{\"current\":\"governing-access-to-synthetic-media-detection-technology\"},\"title\":\"Governing Access to Synthetic Media Detection Technology\"},{\"authors\":[{\"firstName\":\"Claire\",\"lastName\":\"Leibowicz\"}],\"badge\":null,\"date\":\"2024-09-09T11:01:20.576Z\",\"slug\":{\"_type\":\"slug\",\"current\":\"lawmakers-push-for-ai-labels-but-ensuring-media-accuracy-is-no-easy-task\"},\"title\":\"Lawmakers Push for AI Labels, But Ensuring Media Accuracy Is No Easy Task\"},{\"authors\":[{\"firstName\":\"Renée\",\"lastName\":\"DiResta\"},{\"firstName\":\"Dave\",\"lastName\":\"Willner\"}],\"badge\":null,\"date\":\"2023-11-01T17:01:22.000Z\",\"slug\":{\"current\":\"white-house-ai-executive-order-takes-on-complexity-of-content-integrity-issues\"},\"title\":\"White House AI Executive Order Takes On Complexity of Content Integrity Issues\"}],\"relatedCommentary\":null,\"relatedTopics\":[{\"displayName\":\"Artificial Intelligence\",\"name\":\"Artificial Intelligence\",\"slug\":{\"current\":\"artificial-intelligence\"},\"stackbit_model_type\":\"page\",\"type\":null},{\"displayName\":\"Content Moderation\",\"name\":\"Content Moderation\",\"slug\":{\"current\":\"content-moderation\"},\"stackbit_model_type\":\"page\",\"type\":null},{\"displayName\":\"Disinformation\",\"name\":\"Disinformation\",\"slug\":{\"current\":\"disinformation\"},\"stackbit_model_type\":\"page\",\"type\":null},{\"displayName\":\"media literacy\",\"name\":\"media literacy\",\"slug\":{\"_type\":\"slug\",\"current\":\"media-literacy\"},\"stackbit_model_type\":\"data\",\"type\":null},{\"displayName\":\"Ethics\",\"name\":\"Ethics\",\"slug\":{\"current\":\"ethics\"},\"stackbit_model_type\":\"data\",\"type\":null},{\"displayName\":\"Policy\",\"name\":\"Policy\",\"slug\":{\"current\":\"policy\"},\"stackbit_model_type\":\"data\",\"type\":null},{\"displayName\":\"Regulation\",\"name\":\"Regulation\",\"slug\":{\"current\":\"regulation\"},\"stackbit_model_type\":\"data\",\"type\":null},{\"displayName\":\"Synthetic Media\",\"name\":\"Synthetic Media\",\"slug\":{\"current\":\"synthetic-media\"},\"stackbit_model_type\":\"data\",\"type\":null},{\"displayName\":\"C2PA\",\"name\":\"C2PA\",\"slug\":{\"current\":\"c2pa\"},\"stackbit_model_type\":\"data\",\"type\":null},{\"displayName\":\"algorithmic bias\",\"name\":\"algorithmic bias\",\"slug\":{\"current\":\"algorithmic-bias\"},\"stackbit_model_type\":\"data\",\"type\":null},{\"displayName\":\"AI ethics\",\"name\":\"AI ethics\",\"slug\":{\"current\":\"ai-ethics\"},\"stackbit_model_type\":\"data\",\"type\":null},{\"displayName\":\"deepfakes\",\"name\":\"deepfakes\",\"slug\":{\"current\":\"deepfakes\"},\"stackbit_model_type\":\"data\",\"type\":null},{\"displayName\":\"digital rights\",\"name\":\"digital rights\",\"slug\":{\"current\":\"digital-rights\"},\"stackbit_model_type\":\"data\",\"type\":null},{\"displayName\":\"first amendment\",\"name\":\"first amendment\",\"slug\":{\"current\":\"first-amendment\"},\"stackbit_model_type\":\"data\",\"type\":null},{\"displayName\":\"liar's dividend\",\"name\":\"liar's dividend\",\"slug\":{\"current\":\"liars-dividend\"},\"stackbit_model_type\":\"data\",\"type\":null},{\"displayName\":\"misinformation\",\"name\":\"misinformation\",\"slug\":{\"current\":\"misinformation\"},\"stackbit_model_type\":\"data\",\"type\":null},{\"displayName\":\"watermarking\",\"name\":\"watermarking\",\"slug\":{\"current\":\"watermarking\"},\"stackbit_model_type\":\"data\",\"type\":null},{\"displayName\":\"Digital Forensics\",\"name\":\"Digital Forensics\",\"slug\":{\"_type\":\"slug\",\"current\":\"digital-forensics\"},\"stackbit_model_type\":\"data\",\"type\":null},{\"displayName\":\"Fact-Checking\",\"name\":\"Fact-Checking\",\"slug\":{\"_type\":\"slug\",\"current\":\"fact-checking\"},\"stackbit_model_type\":\"data\",\"type\":null},{\"displayName\":\"Online safety\",\"name\":\"online safety\",\"slug\":{\"current\":\"online-safety\"},\"stackbit_model_type\":\"page\",\"type\":null},{\"displayName\":\"Synthetic Media\",\"name\":\"Synthetic Media\",\"slug\":{\"current\":\"synthetic-media\"},\"stackbit_model_type\":\"data\",\"type\":null},{\"displayName\":\"Truepic\",\"name\":\"Truepic\",\"slug\":{\"current\":\"truepic\"},\"stackbit_model_type\":\"data\",\"type\":null},{\"displayName\":\"danielle citron\",\"name\":\"danielle citron\",\"slug\":{\"current\":\"danielle-citron\"},\"stackbit_model_type\":\"data\",\"type\":null}],\"sections\":null,\"seo\":{\"_type\":\"stackbit_page_meta\",\"description\":\"Policymakers and the public must move beyond “synthetic or authentic” binaries when considering responses to AI-generated media.\\n\",\"ogImage\":{\"_type\":\"image\",\"asset\":{\"_ref\":\"image-8f56541566a9236d6fbd6ff606a02bb7fde08386-1200x675-png\",\"_type\":\"reference\"},\"ogImageAlt\":\"OpenAI Sora new text to video AI model illustration on screen. ChatGPT Sora is an AI model that can create realistic and imaginative scenes. \"},\"title\":\"Synthetic Media Policy: Provenance and Authentication — Expert Insights and Questions\"},\"sidebar_content\":null,\"slug\":{\"_type\":\"slug\",\"current\":\"synthetic-media-policy-provenance-and-authentication-expert-insights-and-questions\"},\"stackbit_url_path\":null,\"title\":\"Synthetic Media Policy: Provenance and Authentication — Expert Insights and Questions\",\"toc\":null,\"tocTitle\":null,\"trackerText\":null},\"articles\":null,\"_type\":\"post\",\"authors\":null,\"path\":\"synthetic-media-policy-provenance-and-authentication-expert-insights-and-questions\",\"data\":{\"config\":{\"_createdAt\":\"2023-08-31T13:31:01Z\",\"_id\":\"config\",\"_rev\":\"o6ZfdrIEgMFuU3T2cxNpgT\",\"_type\":\"config\",\"_updatedAt\":\"2025-08-29T18:50:04Z\",\"favicon\":{\"_type\":\"image\",\"asset\":{\"_ref\":\"image-9a2224d300c1699fc1b87235aac36318e2c76cec-867x867-png\",\"_type\":\"reference\"}},\"footer\":{\"_type\":\"footer\",\"content\":\"A nonprofit media and community venture intended to provoke new ideas, debate and discussion at the intersection of technology and democracy.\",\"copyright\":\"Tech Policy Press © 2025 — a 501(c)(3) organization\",\"links\":[{\"_key\":\"383ecfdbb924\",\"_type\":\"action\",\"icon_class\":\"dev\",\"label\":\"About\",\"stackbit_model_type\":\"object\",\"style\":\"link\",\"type\":\"action\",\"url\":\"/about-us\"},{\"_key\":\"8d3176182c87\",\"_type\":\"action\",\"icon_class\":\"dev\",\"label\":\"Donate\",\"stackbit_model_type\":\"object\",\"style\":\"link\",\"type\":\"action\",\"url\":\"/donate\"},{\"_key\":\"8a19f618e7ef\",\"_type\":\"action\",\"icon_class\":\"dev\",\"label\":\"Privacy Policy\",\"stackbit_model_type\":\"object\",\"style\":\"link\",\"type\":\"action\",\"url\":\"/privacy\"},{\"_key\":\"5c1d6d4fbce4\",\"_type\":\"action\",\"icon_class\":\"dev\",\"label\":\"Articles\",\"stackbit_model_type\":\"object\",\"style\":\"link\",\"type\":\"action\",\"url\":\"/search\"},{\"_key\":\"03ab4085b977\",\"_type\":\"action\",\"icon_class\":\"dev\",\"label\":\"Podcast\",\"stackbit_model_type\":\"object\",\"style\":\"link\",\"type\":\"action\",\"url\":\"/podcast\"},{\"_key\":\"2fdb180c1d51\",\"_type\":\"action\",\"icon_class\":\"dev\",\"label\":\"Contributors\",\"stackbit_model_type\":\"object\",\"style\":\"link\",\"type\":\"action\",\"url\":\"/contributors\"},{\"_key\":\"a97a9b1c3c23\",\"_type\":\"action\",\"icon_class\":\"dev\",\"label\":\"Fellowships\",\"stackbit_model_type\":\"object\",\"style\":\"link\",\"type\":\"action\",\"url\":\"/fellowships\"},{\"_key\":\"80b2e742bc12\",\"_type\":\"action\",\"icon_class\":\"dev\",\"label\":\"Contributor Guidelines\",\"stackbit_model_type\":\"object\",\"style\":\"link\",\"type\":\"action\",\"url\":\"/contributor-guidelines\"}],\"stackbit_model_type\":\"object\",\"type\":\"footer\"},\"header\":{\"_type\":\"header\",\"projectsLinks\":[{\"_key\":\"aa5d73b183c7\",\"_type\":\"action\",\"icon_class\":\"dev\",\"label\":\"Fellowship Program\",\"stackbit_model_type\":\"object\",\"style\":\"link\",\"type\":\"action\",\"url\":\"/fellowships\"},{\"_key\":\"8904af9ec118\",\"_type\":\"action\",\"icon_class\":\"dev\",\"label\":\"Race, Ethnicity, Technology \\u0026 Elections\",\"stackbit_model_type\":\"object\",\"style\":\"link\",\"type\":\"action\",\"url\":\"/race-ethnicity-technology-elections\"}],\"stackbit_model_type\":\"object\",\"topicsLinks\":[{\"_key\":\"f76613b555e6\",\"_type\":\"action\",\"icon_class\":\"dev\",\"label\":\"Accessibility\",\"stackbit_model_type\":\"object\",\"style\":\"link\",\"type\":\"action\",\"url\":\"/category/access\"},{\"_key\":\"42364a6e2d91\",\"_type\":\"action\",\"icon_class\":\"dev\",\"label\":\"Antitrust\",\"stackbit_model_type\":\"object\",\"style\":\"link\",\"type\":\"action\",\"url\":\"/category/antitrust\"},{\"_key\":\"15c088e49ba3\",\"_type\":\"action\",\"icon_class\":\"dev\",\"label\":\"Artificial Intelligence\",\"stackbit_model_type\":\"object\",\"style\":\"link\",\"type\":\"action\",\"url\":\"/category/artificial-intelligence\"},{\"_key\":\"12763b68685d\",\"_type\":\"action\",\"icon_class\":\"dev\",\"label\":\"Content Moderation\",\"stackbit_model_type\":\"object\",\"style\":\"link\",\"type\":\"action\",\"url\":\"/category/content-moderation\"},{\"_key\":\"3c972905edac\",\"_type\":\"action\",\"icon_class\":\"dev\",\"label\":\"Competition\",\"stackbit_model_type\":\"object\",\"style\":\"link\",\"type\":\"action\",\"url\":\"/category/competition\"},{\"_key\":\"69b291dd4be4\",\"_type\":\"action\",\"icon_class\":\"dev\",\"label\":\"Cybersecurity\",\"stackbit_model_type\":\"object\",\"style\":\"link\",\"type\":\"action\",\"url\":\"/category/cybersecurity\"},{\"_key\":\"b7c10450718a\",\"_type\":\"action\",\"icon_class\":\"dev\",\"label\":\"Data Centers\",\"stackbit_model_type\":\"object\",\"style\":\"link\",\"type\":\"action\",\"url\":\"/category/data-centers/\"},{\"_key\":\"9397f4e99522\",\"_type\":\"action\",\"icon_class\":\"dev\",\"label\":\"Democracy\",\"stackbit_model_type\":\"object\",\"style\":\"link\",\"type\":\"action\",\"url\":\"/category/democracy\"},{\"_key\":\"06a9c2d7de8e\",\"_type\":\"action\",\"icon_class\":\"dev\",\"label\":\"Discrimination\",\"stackbit_model_type\":\"object\",\"style\":\"link\",\"type\":\"action\",\"url\":\"/category/discrimination\"},{\"_key\":\"dcb58f29e5b7\",\"_type\":\"action\",\"icon_class\":\"dev\",\"label\":\"Disinformation\",\"stackbit_model_type\":\"object\",\"style\":\"link\",\"type\":\"action\",\"url\":\"/category/disinformation\"},{\"_key\":\"541f65b05283\",\"_type\":\"action\",\"icon_class\":\"dev\",\"label\":\"Extremism\",\"stackbit_model_type\":\"object\",\"style\":\"link\",\"type\":\"action\",\"url\":\"/category/extremism\"},{\"_key\":\"3844982cc5a9\",\"_type\":\"action\",\"icon_class\":\"dev\",\"label\":\"Free Speech\",\"stackbit_model_type\":\"object\",\"style\":\"link\",\"type\":\"action\",\"url\":\"/category/free-speech\"},{\"_key\":\"831a6aecea0a\",\"_type\":\"action\",\"icon_class\":\"dev\",\"label\":\"Hate \\u0026 Harassment\",\"stackbit_model_type\":\"object\",\"style\":\"link\",\"type\":\"action\",\"url\":\"/category/hate-and-harassment\"},{\"_key\":\"d120d1dc6629\",\"_type\":\"action\",\"icon_class\":\"dev\",\"label\":\"Human Rights\",\"stackbit_model_type\":\"object\",\"style\":\"link\",\"type\":\"action\",\"url\":\"/category/human-rights\"},{\"_key\":\"d098b6cc2046\",\"_type\":\"action\",\"icon_class\":\"dev\",\"label\":\"Liability\",\"stackbit_model_type\":\"object\",\"style\":\"link\",\"type\":\"action\",\"url\":\"/category/liability\"},{\"_key\":\"480bfb08b718\",\"_type\":\"action\",\"icon_class\":\"dev\",\"label\":\"News \\u0026 Journalism\",\"stackbit_model_type\":\"object\",\"style\":\"link\",\"type\":\"action\",\"url\":\"/category/news-and-journalism\"},{\"_key\":\"621f0e3fa109\",\"_type\":\"action\",\"icon_class\":\"dev\",\"label\":\"Online Safety\",\"stackbit_model_type\":\"object\",\"style\":\"link\",\"type\":\"action\",\"url\":\"/category/online-safety\"},{\"_key\":\"1e95d7b8594f\",\"_type\":\"action\",\"icon_class\":\"dev\",\"label\":\"Privacy\",\"stackbit_model_type\":\"object\",\"style\":\"link\",\"type\":\"action\",\"url\":\"/category/privacy\"},{\"_key\":\"3376210663fa\",\"_type\":\"action\",\"icon_class\":\"dev\",\"label\":\"Public Health\",\"stackbit_model_type\":\"object\",\"style\":\"link\",\"type\":\"action\",\"url\":\"/category/public-health\"},{\"_key\":\"ccbda3672586\",\"_type\":\"action\",\"icon_class\":\"dev\",\"label\":\"Transparency\",\"stackbit_model_type\":\"object\",\"style\":\"link\",\"type\":\"action\",\"url\":\"/category/transparency\"}],\"type\":\"header\"},\"path_prefix\":\"http://127.0.0.1:3000\",\"stackbit_file_path\":\"content/data/config.json\",\"stackbit_model_type\":\"data\",\"title\":\"TechPolicy.Press\"},\"topics\":[{\"_id\":\"category-internet-access\",\"displayName\":\"Accessibility\",\"slug\":{\"current\":\"access\"}},{\"_id\":\"category-antitrust\",\"displayName\":\"Antitrust\",\"slug\":{\"current\":\"antitrust\"}},{\"_id\":\"category-artificial-intelligence\",\"displayName\":\"Artificial Intelligence\",\"slug\":{\"current\":\"artificial-intelligence\"}},{\"_id\":\"tag-competition\",\"displayName\":\"Competition\",\"slug\":{\"current\":\"competition\"}},{\"_id\":\"category-content-moderation\",\"displayName\":\"Content Moderation\",\"slug\":{\"current\":\"content-moderation\"}},{\"_id\":\"category-cybersecurity\",\"displayName\":\"Cybersecurity\",\"slug\":{\"current\":\"cybersecurity\"}},{\"_id\":\"category-democracy\",\"displayName\":\"Democracy\",\"slug\":{\"current\":\"democracy\"}},{\"_id\":\"tag-discrimination\",\"displayName\":\"Discrimination\",\"slug\":{\"current\":\"discrimination\"}},{\"_id\":\"category-disinformation\",\"displayName\":\"Disinformation\",\"slug\":{\"current\":\"disinformation\"}},{\"_id\":\"category-extremism\",\"displayName\":\"Extremism\",\"slug\":{\"current\":\"extremism\"}},{\"_id\":\"category-speech\",\"displayName\":\"Free speech\",\"slug\":{\"current\":\"free-speech\"}},{\"_id\":\"tag-hate-and-harassment\",\"displayName\":\"Hate and harassment\",\"slug\":{\"current\":\"hate-and-harassment\"}},{\"_id\":\"tag-human-rights\",\"displayName\":\"Human Rights\",\"slug\":{\"current\":\"human-rights\"}},{\"_id\":\"category-section-230\",\"displayName\":\"Liability\",\"slug\":{\"current\":\"liability\"}},{\"_id\":\"category-journalism-and-news-media\",\"displayName\":\"News and Journalism\",\"slug\":{\"current\":\"news-and-journalism\"}},{\"_id\":\"tag-online-safety\",\"displayName\":\"Online safety\",\"slug\":{\"current\":\"online-safety\"}},{\"_id\":\"category-privacy\",\"displayName\":\"Privacy\",\"slug\":{\"current\":\"privacy\"}},{\"_id\":\"tag-public-health\",\"displayName\":\"Public health\",\"slug\":{\"current\":\"public-health\"}},{\"_id\":\"tag-transparency\",\"displayName\":\"Transparency\",\"slug\":{\"current\":\"transparency\"}}]}},\"__N_SSG\":true},\"page\":\"/[...slug]\",\"query\":{\"slug\":[\"synthetic-media-policy-provenance-and-authentication-expert-insights-and-questions\"]},\"buildId\":\"2-BCTHWxu2tBlfW-GrJE7\",\"isFallback\":false,\"isExperimentalCompile\":false,\"gsp\":true,\"locale\":\"en\",\"locales\":[\"en\"],\"defaultLocale\":\"en\",\"scriptLoader\":[]}</script><script async=\"\" defer=\"\" src=\"https://scripts.simpleanalyticscdn.com/latest.js\"></script><noscript><img src=\"https://queue.simpleanalyticscdn.com/noscript.gif\" alt=\"\" referrerPolicy=\"no-referrer-when-downgrade\"/></noscript></body></html>","oembed":false,"readabilityObject":{"title":"Synthetic Media Policy: Provenance and Authentication — Expert Insights and Questions","content":"<div id=\"readability-page-1\" class=\"page\"><p><span>Ellen P. Goodman, </span><span>Kaylee Williams, </span><span>Justin Hendrix / </span><span>May 2, 2025</span></p><div><div><figure><img alt=\" \" loading=\"lazy\" width=\"1024\" height=\"576\" decoding=\"async\" data-nimg=\"1\" src=\"https://cdn.sanity.io/images/3tzzh18d/production/8f56541566a9236d6fbd6ff606a02bb7fde08386-1200x675.png\"><figcaption></figcaption></figure></div><p>AI-generated or altered text, imagery, video, and audio—collectively referred to as “synthetic media”—now permeate the internet and have already begun transforming industries ranging from entertainment and advertising to journalism and education.</p><p>The rising prevalence of synthetic media has sparked intense debates over their potential to erode “reality,” undermine intellectual property rights, threaten the privacy and safety of private citizens, spread disinformation, enable scams and fraud, and sow discord on a global scale.</p><p>On December 13, 2024, just weeks after the US Presidential Election, a diverse group of experts—including computer scientists, First Amendment and information law scholars, government officials, and cybersecurity specialists—gathered for a ‘Roundtable on Synthetic Media Policy’ in Washington DC to discuss these threats and establish a shared research agenda for the coming year. Hosted by <strong>Rutgers Law School’s Institute for Information Policy and Law</strong> in partnership with <strong>Tech Policy Press</strong>, the event focused on open research questions and potential solutions—technical, regulatory, social, and structural—to the many challenges associated with synthetic media.</p><p>Participants reached consensus on a handful of shared priorities—such as the importance of harm reduction, increasing media literacy, and preserving free expression online—and, as importantly, identified areas of disagreement about matters such as provenance standards, tradeoffs between privacy and transparency, and the role of digital forensics in battling harmful digital clones and fakes.</p><p>The following outlines some of the findings of the convening, which do not reflect the precise views of every participant.</p><h4><strong>Question #1: What are the limits of synthetic media detection, and who are the intended consumers of detection-based products?</strong></h4><p>For years, research labs, intelligence agencies, and private companies have been designing forensic tools, protocols, and systems intended to help people determine whether a given piece of content (such as an image or a video) was likely generated or altered by AI. While these forensic detection technologies have grown more sophisticated over time, several experts agreed that even the most advanced synthetic media detection techniques are extremely time-consuming and resource-intensive, making them difficult to deploy at scale. Furthermore, there are only a small number (roughly “half a dozen,” according to one expert) of companies and research firms performing advanced work on forensics in the United States, a handful in Italy, and fewer in other democratic countries. This suggests that the resources required to scale robust AI detection as a way to combat social media harms—including fraud, disinformation, and non-consensual intimate imagery—are lacking, to say the least, particularly outside of the Global North.</p><p>Even when an expert forensics team applies its tools to a piece of potentially synthetic media, detection technologies do not yield clear, unequivocal results. Significantly, the best of these methods can only calculate a <em>likelihood</em> that a given image has been generated by AI or digitally altered from its original form. They cannot make a definitive determination that content is “synthetic” or “authentic,” as there is too much variation to achieve high-confidence, definitive results, even by the best detectors.</p><p>More importantly, even if there are definitive forensic determinations, there may be a misalignment with the public’s understanding of what it means for a piece of content to be “digitally altered” or “manipulated.” Not all manipulations are created equal. For example, most people would not consider an image “digitally altered” if it were simply cropped or color-corrected in Photoshop. People may be divided on other modifications, such as “touching up” subject faces and adding artistic filters. There is probably more consensus around the removal or addition of elements. The rising ubiquity and broad accessibility of AI-powered photo editing software, much of which is now built directly into smartphone cameras, is also changing public perception of what constitutes an “authentic” image, making the reliable identification of synthetic media <em>that changes the meaning </em>of that content much more difficult. To denote content as “altered” is a sociotechnical exercise that would ideally be tuned to evolving communications dynamics.</p><p>Ultimately, digital alteration does not necessarily cause deception. The gap between the technical term “manipulation” and the social/legal term “deception” is potentially problematic for assessing and addressing synthetic media harms. For example, labeling content as synthetic or manipulated may imply that it is deceptive or otherwise harmful when that may not be the case. Synthetic parodies and art illustrate the point. An obvious parody or imaginative work containing synthetic elements would technically constitute manipulated media, while rarely deceiving. By the same token, identifying content as authentic or minimally altered may imply that it is trustworthy when that may not be the case. For example, an infographic generated using an LLM might accurately display verifiable data, while a cleverly cropped but otherwise unaltered photograph might give viewers a distorted understanding of a real-world event. Labels that cleave content into synthetic/authentic or manipulated/unaltered binaries may not only create confusion for online consumers, but also for those around the world making high-stakes legal decisions based on visual evidence.</p><div><figure><img alt=\" \" loading=\"lazy\" width=\"1024\" height=\"576\" decoding=\"async\" data-nimg=\"1\" src=\"https://cdn.sanity.io/images/3tzzh18d/production/8e1955b2fe8302c4998b9d1bb614348fce036478-2283x1751.png\"><figcaption><p>Illustration: A matrix categorizing media content by its authenticity (Authentic vs. Synthetic) and veracity (Verifiably True vs. Verifiably False), with examples.</p></figcaption></figure></div><p>Despite these limitations, synthetic media detection remains a critical area of research for a variety of stakeholders, including the national security community, human rights defenders, lawyers, and journalists. While the technology may never be able to satisfy the public’s desire for a quick and easy way to verify whether an image is “authentic,” it will likely still play a crucial role in advancing trustworthy information, especially as the challenges that AI poses become more significant. To continue this work, digital forensics professionals and others in this space will need to prioritize certain use cases and stakeholders over others and develop tools tailored to those domains.</p><h4><strong>Question #2: How useful is content labeling and provenance disclosure?</strong></h4><p>Content provenance and watermarking are methods used to encode media with metadata indicating the source of origin and any alterations. Such metadata can be displayed to end users in the form of a provenance legend or content label. These methods are not foolproof; technically savvy actors can exploit metadata and watermarking techniques to make an authentic image look synthetic, or vice versa.</p><p>Workshop participants considered the utility of labeling and provenance disclosures in light of the literature on content labeling in general. In the years since 2016, when Facebook first started <a href=\"https://cssh.northeastern.edu/ethics/the-evolution-of-social-media-content-labeling-an-online-archive/\" target=\"_blank\" rel=\"noopener\">putting “content warnings”</a> next to verifiably false claims on the News Feed, dozens of academic studies have sought to measure the efficacy of fact-checking labels designed to alert readers to the presence of disputed or inaccurate information within a given post. The results of these studies vary widely depending on the design of the labels, users’ pre-existing beliefs about the subject matter, and other factors. But the research tends to suggest that labels have only a modest effect on the spread of disinformation and can create a variety of potential backfire effects, including seeding the misconception that unlabeled assertions are accurate—a phenomenon known as the “<a href=\"https://dspace.mit.edu/bitstream/handle/1721.1/130380/mnsc.2019.3478.pdf?sequence=2&amp;isAllowed=y\" target=\"_blank\" rel=\"noopener\">implied truth effect</a>.”</p><p>There have been fewer studies on the effects of labeling media as synthetic, manipulated, or otherwise generated by AI in whole or in part. Even so, many social media platforms are requiring synthetic media labels, particularly on content that could be perceived as meaningfully deceptive. For example, Meta has <a href=\"https://www.meta.com/help/artificial-intelligence/1783222608822690/\" target=\"_blank\" rel=\"noopener\">mandated</a> that users across its platforms label “photorealistic video or realistic-sounding audio that was digitally created, modified or altered, including with AI.” It does not, however, require a label for <em>all</em> synthetic media. This means that, for example, a “video of an outdoor landscape, created in a style resembling a cartoon” would not need to be labeled under Meta’s current policy. The distinction between the included and excluded content seems to track the distinction between deceptive and non-deceptive content, except that lots of “modified or altered” realistic-seeming content may not be deceptive. Strict compliance with the mandate (unlikely) could result in over-labeling and attendant loss of meaning.</p><p>Meanwhile, some state legislatures in the US have adopted similar requirements for synthetic media related to elections, with varying definitions of what constitutes “synthetic.” Arizona, for example, <a href=\"https://www.akingump.com/en/insights/ai-law-and-regulation-tracker/arizona-senate-bill-1359-signed-into-law-by-governor\" target=\"_blank\" rel=\"noopener\">now requires</a> “clear and conspicuous” disclosures to appear alongside any “image, audio recording or video recording of an individual's appearance, speech or conduct that has been created or intentionally manipulated with the use of digital technology” within 90 days of an election. Indiana has <a href=\"https://legiscan.com/IN/text/HB1133/id/2869748\" target=\"_blank\" rel=\"noopener\">established</a> a civil right of action for political candidates who are deceptively depicted in “fabricated media,\" defined as “an audio or visual recording of an individual's speech, appearance, or conduct that has been altered without the individual's consent such that: (a) the media conveys a materially inaccurate depiction of the individual's speech, appearance, or conduct as recorded in the unaltered recording; and (b) a reasonable person would be unable to recognize that the recording has been altered.” These disparate legal definitions further demonstrate the challenges associated with synthetic media detection described above; namely that “digitally manipulated” content is not always deceptive, and vice versa.</p><p>At least one of these laws (California’s AB 2655) has been <a href=\"https://www.techpolicy.press/tracker/kohls-v-bonta/\" target=\"_blank\" rel=\"noopener\">overturned</a> in federal court as a violation of the First Amendment by compelling speech in a way that is not sufficiently well tailored to the government's interest in preventing deception. Significantly, the court expressed concerns that labels on parodies or other synthetic media that is not deceptive unduly burdened speakers and stigmatized their expression. The issue is not only that the “squeeze” of the labeling isn’t worth the “juice” of transparency with the public, but that the juice itself could sour if people come to conflate AI manipulation with deception. The contours of the First Amendment considerations are still very much uncertain when it comes to AI-related litigation, as are the implications of synthetic media labeling on consumer understanding.</p><p>Experts at the roundtable noted that clearly labeling synthetic media—to the extent that reliable provenance and detection methods even make that a reliable practice—is often perceived by politicians and others as an “all-encompassing solution” to the epistemic turmoil created by AI-generated images and video. This faith in labeling as <em>the </em>“solution” is misplaced, both because it is not easily operationalized and cannot address harms unrelated to consumer recognition of synthetic sources.</p><p>The prevailing theory underpinning the labeling strategy is that if average users can distinguish what is “real” from what is “AI-generated,” they will be less likely to be deceived and to share deceptive content. However, as one expert pointed out, this logic relies upon the fraught assumption that all content can be reliably sorted into mutually exclusive categories such as “human-made,” “AI-generated,” and that “synthetic” is more likely to correspond with “false” and “authentic” with “true.”</p><p>Several participants noted, drawing on communications literature, that trust is relational. People trust content based more on its source (original or intermediate) than on labels appended to it. In considering the utility of synthetic media labels or metadata, then, it might be better to focus on specialized consumers and contexts rather than on informing ordinary end users. For example, the identification of synthetic media, digital alterations, and provenance more generally is important for researchers, librarians, information specialists, model developers, agents, and fact-finders in many fields—even if an individual’s knowledge of these alterations in the ordinary flow of communications turns out to be less impactful.</p><p>Those whose work focuses on individual (as opposed to epistemic or societal) harms caused by synthetic media pointed out that content labels often fail to undo the damages inflicted by embarrassing, dehumanizing, and hateful synthetic images. One participant pointed out that sexually explicit deepfakes, for example, are often labeled as such by the creators and shared on websites dedicated explicitly to AI-generated content, which suggests that they are not, in fact, intended to fool anyone into thinking they are authentic depictions. These harms, along with those associated with other forms of nonconsensual synthetic depiction, such as AI-generated child sexual abuse material (CSAM), are not remedied via the use of content labels because the perceived “authenticity” of the content is beside the point of the content: to abuse the subject.</p><p>Areas where content provenance and labeling might be most useful and readily adopted are in enterprise domains where businesses depend on trusted communications and/or need to secure consumer trust. In such contexts, private actors have market incentives to be transparent about content origins and alterations. Workshop participants identified industry and business use cases where this might be the case, including insurance, financial services, and e-commerce areas. There remain questions about where the market will supply sufficient transparency and where it will not, and to what extent and how.</p><p>These insights suggest that while content labels and AI use disclosures—such as those enabled by provenance technologies—can play a valuable role in addressing the harms of digital clones, fakes, and other synthetic media, policymakers at both the platform and government levels should be cautious not to over-rely on them as standalone solutions.</p><h4><strong>Question #3: How do we address the social dynamics and norms underpinning the harms of synthetic media?</strong></h4><p>As the cases involving synthetic sexual abuse content demonstrate, many of the harms posed by synthetic media are not easily mitigated with informational or tech-based solutions alone. In fact, many of the most concerning threats are not new to the AI era. Instead, they represent the intensification of longstanding patterns of abuse and discrimination toward vulnerable groups for the purposes of maintaining existing social hierarchies.</p><p>For instance, the prevalence of nonconsensual sexual content reflects the systemic commodification of women’s bodies and the normalization of gender-based violence. Similarly, the weaponization of synthetic media for political disinformation and propaganda reflects prevailing social forces around racial inequality, othering “out” groups, stoking polarization, and amplifying conspiracy theories.</p><p>Addressing these harms requires a holistic approach that combines regulatory and technical solutions with broader efforts to challenge the social norms and power structures at play. This might include public awareness campaigns, education initiatives to foster digital literacy, and collaborations with civil society organizations to address the root causes behind various manifestations of online harm. Without tackling the underlying social dynamics, the experts gathered in DC agreed that interventions targeting synthetic media risk addressing the symptoms rather than the causes of those harms.</p><p>These issues are deeply entrenched in modern society and will not be entirely uprooted even with dramatic regulatory intervention targeting technology. The kinds of reforms necessary to address these systemic patterns need to be just that: systemic. As such, they will require buy-in (both political and financial) from various sectors and stakeholders, many of whom currently benefit from incentives and dynamics that exacerbate intractable problems, from racism and misogyny to economic exploitation (either directly or indirectly).</p><h4><strong>Question #4: What are the downstream risks of the “liar’s dividend”?</strong></h4><p>The “liar’s dividend”—as <a href=\"https://heinonline.org/HOL/Page?men_tab=srchresults&amp;handle=hein.journals/calr107&amp;id=1794&amp;size=2&amp;collection=journals&amp;terms=Liar%7Cliar&amp;termtype=phrase&amp;set_as_cursor=\" target=\"_blank\" rel=\"noopener\">defined</a> by legal scholars Bobby Chesney and Danielle Citron in 2019—refers to an information ecosystem that is so rife with false and otherwise deceptive information that actors can avoid accountability for wrongdoing by claiming that any documentation of misconduct is “fake news,” “misinformation,” “manipulated media” etc. Another way to put this is plausible deniability for any bit of content. In their 2019 paper, Chesney and Citron argue that pervasive, deceptive synthetic media contributes heavily to the liar’s dividend because its very existence undermines public trust in authentic content. In a world where any piece of media can plausibly be dismissed as fake, individuals and organizations can exploit widespread uncertainty about the facts to avoid accountability or obscure the truth. This dynamic has profound implications for journalism, the legal system, and democratic governance, as it challenges the fundamental ability to establish a shared reality.</p><p>As synthetic media become more sophisticated and accessible, the liar’s dividend may reach a tipping point where skepticism about media authenticity becomes the default. <a href=\"https://petapixel.com/2019/03/01/people-call-my-photos-fake-but-theyre-not/\" target=\"_blank\" rel=\"noopener\">Anecdotal accounts</a> argue that we are already there. This state of affairs could empower malicious actors to weaponize doubt, dismissing legitimate evidence of wrongdoing as fabricated. For instance, political leaders might evade accountability for harmful rhetoric or actions by claiming that leaked audio recordings or videos are AI-generated. One expert posited that the growing popularity of generative AI could result in a world of content manipulation so ubiquitous that there is an epistemic collapse.</p><p>The societal consequences of this potential collapse are far-reaching. If people cannot distinguish between truth and fabrication, public discourse will become increasingly polarized, with individuals retreating further into ideological silos where only content that aligns with their preexisting beliefs is accepted as legitimate. This environment may foster widespread cynicism, causing people to lose ever more confidence in institutions, in democracy, and in one another.</p><p>One expert noted that the role of synthetic media must be considered against the broader and systemic degradation of information fidelity. Systemic trust erosion is not necessarily tied to the authenticity of particular units of content. This expert argued that distrust in informational integrity poses a challenge to journalism and communications far beyond a liar’s intentional manipulation.</p><p>Addressing this systemic distrust requires proactive measures to restore faith in media and digital content. With respect to the narrow issue of synthetic media, this includes promoting the adoption of content authentication technologies, such as open technical standards like those popularized by the Coalition for Content Provenance and Authenticity (C2PA) to verify the provenance of authentic content. While the participants acknowledged it would be a long road to a fully interoperable internet that allows such standards to thrive, industry and business use cases will likely be adopted first.</p><p>Equally important are efforts to improve media literacy aimed at equipping individuals with the cognitive tools to critically evaluate the veracity of digital content. However, technical and educational solutions alone are insufficient. Policymakers, platforms, and civil society organizations must work together to establish norms and regulations that discourage the strategic weaponization of “plausible deniability” to evade public accountability. Without such efforts, the liar’s dividend threatens to deepen societal divides and erode the foundations of trust essential for democratic systems to function.</p><h4><strong>Question #5: How do we move past the “authentic” vs. “synthetic” binary?</strong></h4><p>Many of the issues discussed at the event alluded to a broader, conceptual challenge that the experts agreed requires urgent societal attention: the need to reframe how we think about the provenance and authenticity of digital content in an AI world. This issue is fundamentally tied to media literacy and public education, particularly as AI-powered tools become more deeply integrated into content generation across information industries like journalism.</p><div id=\"mlb2-5983225\"><h4>Our Content delivered to your inbox.</h4><p>Join our newsletter on issues and ideas at the intersection of tech &amp; democracy</p></div><p>As noted above, content labeling risks creating the false binary that a piece of content is either wholly “authentic” or entirely “synthetic.” In reality, the roundtable experts agreed that much of the content we encounter online today exists on a spectrum of human and machine involvement. For example, a video might be largely authentic but edited with AI-enhanced filters, or a news article might be written by a journalist who used AI tools to clean or analyze data. These forms of hybrid media challenge traditional notions of authenticity and truth, complicating how we assess the trustworthiness of what we see, hear, and read.</p><p>Moving past this binary requires a more nuanced understanding of how digital content is produced and a shift in public attitudes toward AI’s role in media creation. Public education efforts should emphasize that authenticity is not solely about the method of creation or modification but also about the intent and transparency behind the content, including who shared it. Tools that trace the provenance of digital media, such as metadata tagging or blockchain-based verification, could play a critical role in fostering trust without reinforcing outdated mental models. But there are complications with these tools as well, including potential implications for privacy and free expression, and significant technical challenges.</p><p>Ultimately, building a society capable of navigating the complexities of synthetic media will require collaboration between technologists, educators, policymakers, and civil society actors. <strong>By shifting the focus from “authentic vs. synthetic” to questions of accountability and transparency, the tech policy community will be able to seed a more sophisticated framework for understanding and engaging with synthetic media in the coming years.</strong></p><p>In addition to addressing these open questions, the roundtable participants worked together to brainstorm possible metrics to indicate progress on synthetic media-related issues. The following are some of the ideas floated:</p><ul><li>Tracking C2PA adoption as a proxy for understanding its effects and potential for broad interoperability across the information environment.</li><li>Estimating the number of news stories in which manipulated or AI-generated media play a role, including phenomena such as criminal or civil actions brought in relation to the propagation of such content.</li><li>Recording the number of scams or fraudulent activities reported to authorities that involved the use of synthetic media.</li><li>Tracking global Investment in distributed media forensics capacity.</li><li>Measuring the average time of platform takedown for nonconsensual synthetic pornography and other problematic forms of synthetic media.</li><li>Assessing public perception of viral incidents involving synthetic media.</li><li>Estimating the size of the customer base and understanding the markets for harmful synthetic depictions (including CSAM and NCII).</li><li>Identifying ways of measuring the liar’s dividend and intervening to counter it.</li><li>Further study on the effectiveness of content labeling, fact-checking, provenance verification, and similar efforts.</li><li>Recording the number of lawsuits that attempt to hold platform companies accountable for harms caused by synthetic media.</li><li>Recording the number of new regulations introduced by state and federal governments related to AI-generated content and their resilience to legal challenges.</li></ul><p>Going forward, it will be crucial to find creative ways to address these challenges and advance bipartisan proposals for regulatory and self-regulatory frameworks that can alleviate some of the threats described above. The latter half of the decade will require policymakers—and the public—to move beyond “synthetic or authentic” binaries. What is needed are broad coalitions of technologists, civil society actors, researchers, and others to partner to develop systemic interventions that may not yet exist.</p><h4><strong><em>With thanks to the Knight Foundation for providing financial support for the Workshop.</em></strong></h4><p><strong>Workshop Participants:</strong></p><ul><li><strong>Scott Babwah Brennen</strong>, Director, NYU Center on Technology Policy</li><li><strong>Bilva Chandra</strong>, Former Senior Policy Advisor &amp; Synthetic Content Lead, US AI Safety Institute</li><li><strong>Peter Chapman</strong>, Associate Director, Knight-Georgetown Institute</li><li><strong>Renée DiResta</strong>, Associate Research Professor, McCourt School of Public Policy, Georgetown University</li><li><strong>Nadine Farid Johnson</strong>, Policy Director, Knight First Amendment Institute at Columbia University</li><li><strong>Mary Anne Franks</strong>, Eugene L. and Barbara A. Bernard Professor in Intellectual Property, Technology, and Civil Rights Law at George Washington Law School, and President and Legislative &amp; Tech Policy Director of the Cyber Civil Rights Initiative</li><li><strong>Josh Goldstein</strong>, Research Fellow, Center for Security and Emerging Technology (CSET), Georgetown University</li><li><strong>Ellen P. Goodman</strong>, Professor at Rutgers Law School, Co-Director of the Rutgers Institute for Information Policy &amp; Law (RIIPL)</li><li><strong>Sam Gregory</strong>, Executive Director, WITNESS</li><li><strong>Justin Hendrix</strong>, CEO and Editor, Tech Policy Press</li><li><strong>Mounir Ibrahim</strong>, Chief Communications Officer &amp; Head of Public Affairs, Truepic</li><li><strong>Kate Kaye</strong>, Deputy Director, World Privacy Forum</li><li><strong>Claire Leibowicz</strong>, Head of AI and Media Integrity, Partnership on AI</li><li><strong>David Luebke</strong>, Vice President of Graphics Research, NVIDIA</li><li><strong>Siwei Lyu</strong>, SUNY Distinguished Professor, University at Buffalo, State University of New York</li><li><strong>Abhiram Reddy</strong>, AI Safety and Security Research Assistant, Center for Security and Emerging Technology (CSET), Georgetown University</li><li><strong>Aimee Rinehart</strong>, Senior Product Manager, AI Strategy, The Associated Press</li><li><strong>Matthew C. Stamm</strong>, Associate Professor, Department of Electrical &amp; Computer Engineering, Director, Multimedia and Information Security Laboratory, Drexel University</li><li><strong>Xiangnong (George) Wang</strong>, Staff Attorney, Knight First Amendment Institute</li><li><strong>Kaylee Williams</strong>, PhD Student, Columbia Journalism School and Research Associate, International Center for Journalists</li></ul><p><em><a href=\"https://cdn.sanity.io/files/3tzzh18d/production/15f7b0307678e77c38b7786dd63cba6f7664c1a3.pdf\" target=\"_blank\" rel=\"noopener\">Download this document as a PDF</a>.</em></p></div></div>","textContent":"Ellen P. Goodman, Kaylee Williams, Justin Hendrix / May 2, 2025AI-generated or altered text, imagery, video, and audio—collectively referred to as “synthetic media”—now permeate the internet and have already begun transforming industries ranging from entertainment and advertising to journalism and education.The rising prevalence of synthetic media has sparked intense debates over their potential to erode “reality,” undermine intellectual property rights, threaten the privacy and safety of private citizens, spread disinformation, enable scams and fraud, and sow discord on a global scale.On December 13, 2024, just weeks after the US Presidential Election, a diverse group of experts—including computer scientists, First Amendment and information law scholars, government officials, and cybersecurity specialists—gathered for a ‘Roundtable on Synthetic Media Policy’ in Washington DC to discuss these threats and establish a shared research agenda for the coming year. Hosted by Rutgers Law School’s Institute for Information Policy and Law in partnership with Tech Policy Press, the event focused on open research questions and potential solutions—technical, regulatory, social, and structural—to the many challenges associated with synthetic media.Participants reached consensus on a handful of shared priorities—such as the importance of harm reduction, increasing media literacy, and preserving free expression online—and, as importantly, identified areas of disagreement about matters such as provenance standards, tradeoffs between privacy and transparency, and the role of digital forensics in battling harmful digital clones and fakes.The following outlines some of the findings of the convening, which do not reflect the precise views of every participant.Question #1: What are the limits of synthetic media detection, and who are the intended consumers of detection-based products?For years, research labs, intelligence agencies, and private companies have been designing forensic tools, protocols, and systems intended to help people determine whether a given piece of content (such as an image or a video) was likely generated or altered by AI. While these forensic detection technologies have grown more sophisticated over time, several experts agreed that even the most advanced synthetic media detection techniques are extremely time-consuming and resource-intensive, making them difficult to deploy at scale. Furthermore, there are only a small number (roughly “half a dozen,” according to one expert) of companies and research firms performing advanced work on forensics in the United States, a handful in Italy, and fewer in other democratic countries. This suggests that the resources required to scale robust AI detection as a way to combat social media harms—including fraud, disinformation, and non-consensual intimate imagery—are lacking, to say the least, particularly outside of the Global North.Even when an expert forensics team applies its tools to a piece of potentially synthetic media, detection technologies do not yield clear, unequivocal results. Significantly, the best of these methods can only calculate a likelihood that a given image has been generated by AI or digitally altered from its original form. They cannot make a definitive determination that content is “synthetic” or “authentic,” as there is too much variation to achieve high-confidence, definitive results, even by the best detectors.More importantly, even if there are definitive forensic determinations, there may be a misalignment with the public’s understanding of what it means for a piece of content to be “digitally altered” or “manipulated.” Not all manipulations are created equal. For example, most people would not consider an image “digitally altered” if it were simply cropped or color-corrected in Photoshop. People may be divided on other modifications, such as “touching up” subject faces and adding artistic filters. There is probably more consensus around the removal or addition of elements. The rising ubiquity and broad accessibility of AI-powered photo editing software, much of which is now built directly into smartphone cameras, is also changing public perception of what constitutes an “authentic” image, making the reliable identification of synthetic media that changes the meaning of that content much more difficult. To denote content as “altered” is a sociotechnical exercise that would ideally be tuned to evolving communications dynamics.Ultimately, digital alteration does not necessarily cause deception. The gap between the technical term “manipulation” and the social/legal term “deception” is potentially problematic for assessing and addressing synthetic media harms. For example, labeling content as synthetic or manipulated may imply that it is deceptive or otherwise harmful when that may not be the case. Synthetic parodies and art illustrate the point. An obvious parody or imaginative work containing synthetic elements would technically constitute manipulated media, while rarely deceiving. By the same token, identifying content as authentic or minimally altered may imply that it is trustworthy when that may not be the case. For example, an infographic generated using an LLM might accurately display verifiable data, while a cleverly cropped but otherwise unaltered photograph might give viewers a distorted understanding of a real-world event. Labels that cleave content into synthetic/authentic or manipulated/unaltered binaries may not only create confusion for online consumers, but also for those around the world making high-stakes legal decisions based on visual evidence.Illustration: A matrix categorizing media content by its authenticity (Authentic vs. Synthetic) and veracity (Verifiably True vs. Verifiably False), with examples.Despite these limitations, synthetic media detection remains a critical area of research for a variety of stakeholders, including the national security community, human rights defenders, lawyers, and journalists. While the technology may never be able to satisfy the public’s desire for a quick and easy way to verify whether an image is “authentic,” it will likely still play a crucial role in advancing trustworthy information, especially as the challenges that AI poses become more significant. To continue this work, digital forensics professionals and others in this space will need to prioritize certain use cases and stakeholders over others and develop tools tailored to those domains.Question #2: How useful is content labeling and provenance disclosure?Content provenance and watermarking are methods used to encode media with metadata indicating the source of origin and any alterations. Such metadata can be displayed to end users in the form of a provenance legend or content label. These methods are not foolproof; technically savvy actors can exploit metadata and watermarking techniques to make an authentic image look synthetic, or vice versa.Workshop participants considered the utility of labeling and provenance disclosures in light of the literature on content labeling in general. In the years since 2016, when Facebook first started putting “content warnings” next to verifiably false claims on the News Feed, dozens of academic studies have sought to measure the efficacy of fact-checking labels designed to alert readers to the presence of disputed or inaccurate information within a given post. The results of these studies vary widely depending on the design of the labels, users’ pre-existing beliefs about the subject matter, and other factors. But the research tends to suggest that labels have only a modest effect on the spread of disinformation and can create a variety of potential backfire effects, including seeding the misconception that unlabeled assertions are accurate—a phenomenon known as the “implied truth effect.”There have been fewer studies on the effects of labeling media as synthetic, manipulated, or otherwise generated by AI in whole or in part. Even so, many social media platforms are requiring synthetic media labels, particularly on content that could be perceived as meaningfully deceptive. For example, Meta has mandated that users across its platforms label “photorealistic video or realistic-sounding audio that was digitally created, modified or altered, including with AI.” It does not, however, require a label for all synthetic media. This means that, for example, a “video of an outdoor landscape, created in a style resembling a cartoon” would not need to be labeled under Meta’s current policy. The distinction between the included and excluded content seems to track the distinction between deceptive and non-deceptive content, except that lots of “modified or altered” realistic-seeming content may not be deceptive. Strict compliance with the mandate (unlikely) could result in over-labeling and attendant loss of meaning.Meanwhile, some state legislatures in the US have adopted similar requirements for synthetic media related to elections, with varying definitions of what constitutes “synthetic.” Arizona, for example, now requires “clear and conspicuous” disclosures to appear alongside any “image, audio recording or video recording of an individual's appearance, speech or conduct that has been created or intentionally manipulated with the use of digital technology” within 90 days of an election. Indiana has established a civil right of action for political candidates who are deceptively depicted in “fabricated media,\" defined as “an audio or visual recording of an individual's speech, appearance, or conduct that has been altered without the individual's consent such that: (a) the media conveys a materially inaccurate depiction of the individual's speech, appearance, or conduct as recorded in the unaltered recording; and (b) a reasonable person would be unable to recognize that the recording has been altered.” These disparate legal definitions further demonstrate the challenges associated with synthetic media detection described above; namely that “digitally manipulated” content is not always deceptive, and vice versa.At least one of these laws (California’s AB 2655) has been overturned in federal court as a violation of the First Amendment by compelling speech in a way that is not sufficiently well tailored to the government's interest in preventing deception. Significantly, the court expressed concerns that labels on parodies or other synthetic media that is not deceptive unduly burdened speakers and stigmatized their expression. The issue is not only that the “squeeze” of the labeling isn’t worth the “juice” of transparency with the public, but that the juice itself could sour if people come to conflate AI manipulation with deception. The contours of the First Amendment considerations are still very much uncertain when it comes to AI-related litigation, as are the implications of synthetic media labeling on consumer understanding.Experts at the roundtable noted that clearly labeling synthetic media—to the extent that reliable provenance and detection methods even make that a reliable practice—is often perceived by politicians and others as an “all-encompassing solution” to the epistemic turmoil created by AI-generated images and video. This faith in labeling as the “solution” is misplaced, both because it is not easily operationalized and cannot address harms unrelated to consumer recognition of synthetic sources.The prevailing theory underpinning the labeling strategy is that if average users can distinguish what is “real” from what is “AI-generated,” they will be less likely to be deceived and to share deceptive content. However, as one expert pointed out, this logic relies upon the fraught assumption that all content can be reliably sorted into mutually exclusive categories such as “human-made,” “AI-generated,” and that “synthetic” is more likely to correspond with “false” and “authentic” with “true.”Several participants noted, drawing on communications literature, that trust is relational. People trust content based more on its source (original or intermediate) than on labels appended to it. In considering the utility of synthetic media labels or metadata, then, it might be better to focus on specialized consumers and contexts rather than on informing ordinary end users. For example, the identification of synthetic media, digital alterations, and provenance more generally is important for researchers, librarians, information specialists, model developers, agents, and fact-finders in many fields—even if an individual’s knowledge of these alterations in the ordinary flow of communications turns out to be less impactful.Those whose work focuses on individual (as opposed to epistemic or societal) harms caused by synthetic media pointed out that content labels often fail to undo the damages inflicted by embarrassing, dehumanizing, and hateful synthetic images. One participant pointed out that sexually explicit deepfakes, for example, are often labeled as such by the creators and shared on websites dedicated explicitly to AI-generated content, which suggests that they are not, in fact, intended to fool anyone into thinking they are authentic depictions. These harms, along with those associated with other forms of nonconsensual synthetic depiction, such as AI-generated child sexual abuse material (CSAM), are not remedied via the use of content labels because the perceived “authenticity” of the content is beside the point of the content: to abuse the subject.Areas where content provenance and labeling might be most useful and readily adopted are in enterprise domains where businesses depend on trusted communications and/or need to secure consumer trust. In such contexts, private actors have market incentives to be transparent about content origins and alterations. Workshop participants identified industry and business use cases where this might be the case, including insurance, financial services, and e-commerce areas. There remain questions about where the market will supply sufficient transparency and where it will not, and to what extent and how.These insights suggest that while content labels and AI use disclosures—such as those enabled by provenance technologies—can play a valuable role in addressing the harms of digital clones, fakes, and other synthetic media, policymakers at both the platform and government levels should be cautious not to over-rely on them as standalone solutions.Question #3: How do we address the social dynamics and norms underpinning the harms of synthetic media?As the cases involving synthetic sexual abuse content demonstrate, many of the harms posed by synthetic media are not easily mitigated with informational or tech-based solutions alone. In fact, many of the most concerning threats are not new to the AI era. Instead, they represent the intensification of longstanding patterns of abuse and discrimination toward vulnerable groups for the purposes of maintaining existing social hierarchies.For instance, the prevalence of nonconsensual sexual content reflects the systemic commodification of women’s bodies and the normalization of gender-based violence. Similarly, the weaponization of synthetic media for political disinformation and propaganda reflects prevailing social forces around racial inequality, othering “out” groups, stoking polarization, and amplifying conspiracy theories.Addressing these harms requires a holistic approach that combines regulatory and technical solutions with broader efforts to challenge the social norms and power structures at play. This might include public awareness campaigns, education initiatives to foster digital literacy, and collaborations with civil society organizations to address the root causes behind various manifestations of online harm. Without tackling the underlying social dynamics, the experts gathered in DC agreed that interventions targeting synthetic media risk addressing the symptoms rather than the causes of those harms.These issues are deeply entrenched in modern society and will not be entirely uprooted even with dramatic regulatory intervention targeting technology. The kinds of reforms necessary to address these systemic patterns need to be just that: systemic. As such, they will require buy-in (both political and financial) from various sectors and stakeholders, many of whom currently benefit from incentives and dynamics that exacerbate intractable problems, from racism and misogyny to economic exploitation (either directly or indirectly).Question #4: What are the downstream risks of the “liar’s dividend”?The “liar’s dividend”—as defined by legal scholars Bobby Chesney and Danielle Citron in 2019—refers to an information ecosystem that is so rife with false and otherwise deceptive information that actors can avoid accountability for wrongdoing by claiming that any documentation of misconduct is “fake news,” “misinformation,” “manipulated media” etc. Another way to put this is plausible deniability for any bit of content. In their 2019 paper, Chesney and Citron argue that pervasive, deceptive synthetic media contributes heavily to the liar’s dividend because its very existence undermines public trust in authentic content. In a world where any piece of media can plausibly be dismissed as fake, individuals and organizations can exploit widespread uncertainty about the facts to avoid accountability or obscure the truth. This dynamic has profound implications for journalism, the legal system, and democratic governance, as it challenges the fundamental ability to establish a shared reality.As synthetic media become more sophisticated and accessible, the liar’s dividend may reach a tipping point where skepticism about media authenticity becomes the default. Anecdotal accounts argue that we are already there. This state of affairs could empower malicious actors to weaponize doubt, dismissing legitimate evidence of wrongdoing as fabricated. For instance, political leaders might evade accountability for harmful rhetoric or actions by claiming that leaked audio recordings or videos are AI-generated. One expert posited that the growing popularity of generative AI could result in a world of content manipulation so ubiquitous that there is an epistemic collapse.The societal consequences of this potential collapse are far-reaching. If people cannot distinguish between truth and fabrication, public discourse will become increasingly polarized, with individuals retreating further into ideological silos where only content that aligns with their preexisting beliefs is accepted as legitimate. This environment may foster widespread cynicism, causing people to lose ever more confidence in institutions, in democracy, and in one another.One expert noted that the role of synthetic media must be considered against the broader and systemic degradation of information fidelity. Systemic trust erosion is not necessarily tied to the authenticity of particular units of content. This expert argued that distrust in informational integrity poses a challenge to journalism and communications far beyond a liar’s intentional manipulation.Addressing this systemic distrust requires proactive measures to restore faith in media and digital content. With respect to the narrow issue of synthetic media, this includes promoting the adoption of content authentication technologies, such as open technical standards like those popularized by the Coalition for Content Provenance and Authenticity (C2PA) to verify the provenance of authentic content. While the participants acknowledged it would be a long road to a fully interoperable internet that allows such standards to thrive, industry and business use cases will likely be adopted first.Equally important are efforts to improve media literacy aimed at equipping individuals with the cognitive tools to critically evaluate the veracity of digital content. However, technical and educational solutions alone are insufficient. Policymakers, platforms, and civil society organizations must work together to establish norms and regulations that discourage the strategic weaponization of “plausible deniability” to evade public accountability. Without such efforts, the liar’s dividend threatens to deepen societal divides and erode the foundations of trust essential for democratic systems to function.Question #5: How do we move past the “authentic” vs. “synthetic” binary?Many of the issues discussed at the event alluded to a broader, conceptual challenge that the experts agreed requires urgent societal attention: the need to reframe how we think about the provenance and authenticity of digital content in an AI world. This issue is fundamentally tied to media literacy and public education, particularly as AI-powered tools become more deeply integrated into content generation across information industries like journalism.Our Content delivered to your inbox.Join our newsletter on issues and ideas at the intersection of tech & democracyAs noted above, content labeling risks creating the false binary that a piece of content is either wholly “authentic” or entirely “synthetic.” In reality, the roundtable experts agreed that much of the content we encounter online today exists on a spectrum of human and machine involvement. For example, a video might be largely authentic but edited with AI-enhanced filters, or a news article might be written by a journalist who used AI tools to clean or analyze data. These forms of hybrid media challenge traditional notions of authenticity and truth, complicating how we assess the trustworthiness of what we see, hear, and read.Moving past this binary requires a more nuanced understanding of how digital content is produced and a shift in public attitudes toward AI’s role in media creation. Public education efforts should emphasize that authenticity is not solely about the method of creation or modification but also about the intent and transparency behind the content, including who shared it. Tools that trace the provenance of digital media, such as metadata tagging or blockchain-based verification, could play a critical role in fostering trust without reinforcing outdated mental models. But there are complications with these tools as well, including potential implications for privacy and free expression, and significant technical challenges.Ultimately, building a society capable of navigating the complexities of synthetic media will require collaboration between technologists, educators, policymakers, and civil society actors. By shifting the focus from “authentic vs. synthetic” to questions of accountability and transparency, the tech policy community will be able to seed a more sophisticated framework for understanding and engaging with synthetic media in the coming years.In addition to addressing these open questions, the roundtable participants worked together to brainstorm possible metrics to indicate progress on synthetic media-related issues. The following are some of the ideas floated:Tracking C2PA adoption as a proxy for understanding its effects and potential for broad interoperability across the information environment.Estimating the number of news stories in which manipulated or AI-generated media play a role, including phenomena such as criminal or civil actions brought in relation to the propagation of such content.Recording the number of scams or fraudulent activities reported to authorities that involved the use of synthetic media.Tracking global Investment in distributed media forensics capacity.Measuring the average time of platform takedown for nonconsensual synthetic pornography and other problematic forms of synthetic media.Assessing public perception of viral incidents involving synthetic media.Estimating the size of the customer base and understanding the markets for harmful synthetic depictions (including CSAM and NCII).Identifying ways of measuring the liar’s dividend and intervening to counter it.Further study on the effectiveness of content labeling, fact-checking, provenance verification, and similar efforts.Recording the number of lawsuits that attempt to hold platform companies accountable for harms caused by synthetic media.Recording the number of new regulations introduced by state and federal governments related to AI-generated content and their resilience to legal challenges.Going forward, it will be crucial to find creative ways to address these challenges and advance bipartisan proposals for regulatory and self-regulatory frameworks that can alleviate some of the threats described above. The latter half of the decade will require policymakers—and the public—to move beyond “synthetic or authentic” binaries. What is needed are broad coalitions of technologists, civil society actors, researchers, and others to partner to develop systemic interventions that may not yet exist.With thanks to the Knight Foundation for providing financial support for the Workshop.Workshop Participants:Scott Babwah Brennen, Director, NYU Center on Technology PolicyBilva Chandra, Former Senior Policy Advisor & Synthetic Content Lead, US AI Safety InstitutePeter Chapman, Associate Director, Knight-Georgetown InstituteRenée DiResta, Associate Research Professor, McCourt School of Public Policy, Georgetown UniversityNadine Farid Johnson, Policy Director, Knight First Amendment Institute at Columbia UniversityMary Anne Franks, Eugene L. and Barbara A. Bernard Professor in Intellectual Property, Technology, and Civil Rights Law at George Washington Law School, and President and Legislative & Tech Policy Director of the Cyber Civil Rights InitiativeJosh Goldstein, Research Fellow, Center for Security and Emerging Technology (CSET), Georgetown UniversityEllen P. Goodman, Professor at Rutgers Law School, Co-Director of the Rutgers Institute for Information Policy & Law (RIIPL)Sam Gregory, Executive Director, WITNESSJustin Hendrix, CEO and Editor, Tech Policy PressMounir Ibrahim, Chief Communications Officer & Head of Public Affairs, TruepicKate Kaye, Deputy Director, World Privacy ForumClaire Leibowicz, Head of AI and Media Integrity, Partnership on AIDavid Luebke, Vice President of Graphics Research, NVIDIASiwei Lyu, SUNY Distinguished Professor, University at Buffalo, State University of New YorkAbhiram Reddy, AI Safety and Security Research Assistant, Center for Security and Emerging Technology (CSET), Georgetown UniversityAimee Rinehart, Senior Product Manager, AI Strategy, The Associated PressMatthew C. Stamm, Associate Professor, Department of Electrical & Computer Engineering, Director, Multimedia and Information Security Laboratory, Drexel UniversityXiangnong (George) Wang, Staff Attorney, Knight First Amendment InstituteKaylee Williams, PhD Student, Columbia Journalism School and Research Associate, International Center for JournalistsDownload this document as a PDF.","length":26890,"excerpt":"Policymakers and the public must move beyond “synthetic or authentic” binaries when considering responses to AI-generated media.","byline":"Ellen P. Goodman, Kaylee Williams, Justin Hendrix","dir":null,"siteName":"Tech Policy Press","lang":"en"},"finalizedMeta":{"title":"Synthetic Media Policy: Provenance and Authentication — Expert Insights and Questions","description":"Policymakers and the public must move beyond “synthetic or authentic” binaries when considering responses to AI-generated media.\n","author":"Ellen P. Goodman, Kaylee Williams, Justin Hendrix","creator":"Ellen P. Goodman, Kaylee Williams, Justin Hendrix","publisher":"Tech Policy Press","date":"2025-05-01T19:09:46Z","topics":[]},"jsonLd":{"@type":"Article","headline":"Synthetic Media Policy: Provenance and Authentication — Expert Insights and Questions","description":"Policymakers and the public must move beyond “synthetic or authentic” binaries when considering responses to AI-generated media.\n","image":[],"mainEntityOfPage":{"@type":"WebPage","@id":"https://techpolicy.press/synthetic-media-policy-provenance-and-authentication-expert-insights-and-questions"},"datePublished":"2025-05-02T02:58:00.000Z","dateModified":"2025-05-01T19:09:46Z","isAccessibleForFree":true,"isPartOf":{"@type":[],"name":false,"productID":false},"discussionUrl":false,"license":false,"author":[{"@type":"Person","name":"Ellen P. Goodman","url":"https://techpolicy.press/author/ellen-p-goodman"},{"@type":"Person","name":"Kaylee Williams","url":"https://techpolicy.press/author/kaylee-williams"},{"@type":"Person","name":"Justin Hendrix","url":"https://techpolicy.press/author/justin-hendrix"}],"publisher":{"@type":"Organization","name":"Tech Policy Press","logo":{"@type":"ImageObject","url":"https://cdn.sanity.io/images/3tzzh18d/production/697d4cc6122b80fcb64b256d888010c242ce6beb-1200x675.png"}},"editor":{"@type":false,"name":false,"description":false,"sameAs":false,"image":{"@type":false,"url":false},"givenName":false,"familyName":false,"alternateName":false,"publishingPrinciples":false},"@context":"https://schema.org"},"twitterObj":false,"status":200,"metadata":{"author":"Ellen P. Goodman, Kaylee Williams, Justin Hendrix","title":"Synthetic Media Policy: Provenance and Authentication — Expert Insights and Questions | TechPolicy.Press","description":"Policymakers and the public must move beyond “synthetic or authentic” binaries when considering responses to AI-generated media.\n","canonical":"https://techpolicy.press/synthetic-media-policy-provenance-and-authentication-expert-insights-and-questions","keywords":[],"image":"https://sa.recoding.tech/noscript.gif","firstParagraph":"Home"},"dublinCore":{},"opengraph":{"title":"Synthetic Media Policy: Provenance and Authentication — Expert Insights and Questions | TechPolicy.Press","description":"Policymakers and the public must move beyond “synthetic or authentic” binaries when considering responses to AI-generated media.\n","url":"https://techpolicy.press/synthetic-media-policy-provenance-and-authentication-expert-insights-and-questions","site_name":"Tech Policy Press","locale":"en_US","type":"article","typeObject":{"published_time":"2025-05-02T02:58:00.000Z","modified_time":"2025-05-01T19:09:46Z","author":["http://techpolicy.press/author/ellen-p-goodman","http://techpolicy.press/author/kaylee-williams","http://techpolicy.press/author/justin-hendrix"],"publisher":false,"section":false,"tag":[]},"image":"https://cdn.sanity.io/images/3tzzh18d/production/8f56541566a9236d6fbd6ff606a02bb7fde08386-1200x675.png"},"twitter":{"site":"@TechPolicyPress","description":false,"card":"summary_large_image","creator":"@TechPolicyPress","title":false,"image":false},"archivedData":{"link":false,"wayback":false}}}