{"initialLink":"https://www.w3.org/TR/fingerprinting-guidance/","sanitizedLink":"https://www.w3.org/TR/fingerprinting-guidance/","finalLink":"https://www.w3.org/TR/fingerprinting-guidance/","htmlEmbed":"<script>window.contexterSetup=window.contexterSetup||function(){window.contexterSetupComplete=!0;class ContexterLink extends HTMLAnchorElement{constructor(){super()}connectedCallback(){this.setAttribute(\"target\",\"_blank\")}}customElements.define(\"contexter-link\",ContexterLink,{extends:\"a\"}),customElements.define(\"contexter-inner\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__inner\"}}),customElements.define(\"contexter-thumbnail\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__thumbnail\"}}),customElements.define(\"contexter-byline\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__byline\"}}),customElements.define(\"contexter-keywordset\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__keywordset\"}}),customElements.define(\"contexter-linkset\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__linkset\"}}),customElements.define(\"contexter-meta\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__meta\"}}),customElements.define(\"contexter-summary\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"p-summary entry-summary\"}}),customElements.define(\"contexter-box-head\",class extends HTMLElement{constructor(){super()}connectedCallback(){this.className=\"contexter-box__head\"}}),customElements.define(\"contexter-box-inner\",class extends HTMLElement{constructor(){super()}connectedCallback(){}});class ContexterBox extends HTMLElement{constructor(){super(),this.first=!0,this.shadow=this.attachShadow({mode:\"open\"})}connectedCallback(){if(this.first){this.first=!1;var style=document.createElement(\"style\"),lightDomStyle=(style.innerHTML=`:host {--background: #f5f6f7;--border: darkblue;--blue: #0000ee;--font-color: black;--inner-border: black;font-family: Franklin,Arial,Helvetica,sans-serif;font-size: 14px;background: var(--background);width: 600px;color: var(--font-color);min-height: 90px;display: block;padding: 8px;border: 1px solid var(--border);cursor: pointer;box-sizing: border-box;margin: 6px;contain: content;margin: 6px auto;}// can only select top-level nodes with slotted::slotted(*) {max-width: 100%;display:block;}::slotted([slot=thumbnail]) {max-width: 100%;display:block;}::slotted([slot=header]) {width: 100%;font-size: 1.25rem;font-weight: bold;display:block;margin-bottom: 6px;}::slotted([slot=author]) {max-width: 50%;font-size: 12px;display:inline-block;float: left;}::slotted([slot=time]) {max-width: 50%;font-size: 12px;display:inline-block;float: right;}::slotted([slot=summary]) {width: 100%;margin-top: 6px;padding: 10px 2px;border-top: 1px solid var(--inner-border);font-size: 15px;display:inline-block;margin-bottom: 6px;}contexter-meta {height: auto;margin-bottom: 4px;width: 100%;display: grid;position: relative;min-height: 16px;grid-template-columns: repeat(2, 1fr);}::slotted([slot=keywords]) {width: 80%;padding: 2px 4px;border-top: 1px solid var(--inner-border);font-size: 11px;display: block;float: right;font-style: italic;text-align: right;grid-column: 2/2;grid-row: 1;align-self: end;justify-self: end;}::slotted([slot=keywords]):empty {border-top: 0px solid var(--inner-border);}::slotted([slot=archive-link]) {font-size: 1em;display: inline;}::slotted([slot=archive-link])::after {content: \"|\";display: inline;color: var(--font-color);text-decoration: none;margin: 0 .5em;}::slotted([slot=read-link]) {font-size: 1em;display: inline;}contexter-linkset {width: 80%;padding: 2px 4px;font-size: 13px;float: left;font-weight: bold;grid-row: 1;grid-column: 1/2;align-self: end;justify-self: start;}/* Extra small devices (phones, 600px and down) */@media only screen and (max-width: 600px) {:host {width: 310px;}}/* Small devices (portrait tablets and large phones, 600px and up) */@media only screen and (min-width: 600px) {...}/* Medium devices (landscape tablets, 768px and up) */@media only screen and (min-width: 768px) {...}/* Large devices (laptops/desktops, 992px and up) */@media only screen and (min-width: 992px) {...}/* Extra large devices (large laptops and desktops, 1200px and up) */@media only screen and (min-width: 1200px) {...}@media (prefers-color-scheme: dark){:host {--background: #354150;--border: #1f2b37;--blue: #55b0ff;--font-color: #ffffff;--inner-border: #787a7c;background: var(--background);border: 1px solid var(--border)}}`,document.createElement(\"style\"));lightDomStyle.innerHTML=`contexter-box {contain: content;}contexter-box .read-link {font-weight: bold;}contexter-box a {color: #0000ee;}contexter-box img {width: 100%;border: 0;padding: 0;margin: 0;}/* Extra small devices (phones, 600px and down) */@media only screen and (max-width: 600px) {...}/* Small devices (portrait tablets and large phones, 600px and up) */@media only screen and (min-width: 600px) {...}/* Medium devices (landscape tablets, 768px and up) */@media only screen and (min-width: 768px) {...}/* Large devices (laptops/desktops, 992px and up) */@media only screen and (min-width: 992px) {...}/* Extra large devices (large laptops and desktops, 1200px and up) */@media only screen and (min-width: 1200px) {...}@media (prefers-color-scheme: dark){contexter-box a {color: #55b0ff;}}`,this.appendChild(lightDomStyle),this.shadow.appendChild(style);const innerContainer=document.createElement(\"contexter-box-inner\"),innerSlotThumbnail=(this.shadow.appendChild(innerContainer),document.createElement(\"slot\")),innerSlotHeader=(innerSlotThumbnail.name=\"thumbnail\",innerContainer.appendChild(innerSlotThumbnail),document.createElement(\"slot\")),innerSlotAuthor=(innerSlotHeader.name=\"header\",innerContainer.appendChild(innerSlotHeader),document.createElement(\"slot\")),innerSlotTime=(innerSlotAuthor.name=\"author\",innerContainer.appendChild(innerSlotAuthor),document.createElement(\"slot\")),innerSlotSummary=(innerSlotTime.name=\"time\",innerContainer.appendChild(innerSlotTime),document.createElement(\"slot\")),metaContainer=(innerSlotSummary.name=\"summary\",innerContainer.appendChild(innerSlotSummary),document.createElement(\"contexter-meta\")),innerSlotInfo=(innerContainer.appendChild(metaContainer),document.createElement(\"slot\")),linkContainer=(innerSlotInfo.name=\"keywords\",metaContainer.appendChild(innerSlotInfo),document.createElement(\"contexter-linkset\")),innerSlotArchiveLink=(metaContainer.appendChild(linkContainer),document.createElement(\"slot\")),innerSlotReadLink=(innerSlotArchiveLink.name=\"archive-link\",linkContainer.appendChild(innerSlotArchiveLink),document.createElement(\"slot\"));innerSlotReadLink.name=\"read-link\",linkContainer.appendChild(innerSlotReadLink),this.className=\"contexter-box\",this.onclick=e=>{if(!e.target.className.includes(\"read-link\")&&!e.target.className.includes(\"title-link\")){const mainLinks=this.querySelectorAll(\"a.main-link\");mainLinks[0].click()}}}}}customElements.define(\"contexter-box\",ContexterBox)},window.contexterSetupComplete||window.contexterSetup();</script><contexter-box class=\"link-card h-entry hentry\" itemscope=\"\" itemtype=\"https://schema.org/CreativeWork\"><contexter-thumbnail class=\"thumbnail\" slot=\"thumbnail\"></contexter-thumbnail><contexter-box-head slot=\"header\" class=\"p-name entry-title\" itemprop=\"headline\"><contexter-box-head slot=\"header\" class=\"p-name entry-title\" itemprop=\"headline\"><a is=\"contexter-link\" href=\"https://www.w3.org/TR/fingerprinting-guidance/\" itemprop=\"url\">Mitigating Browser Fingerprinting in Web Specifications</a></contexter-box-head></contexter-box-head><time class=\"dt-published published\" slot=\"time\" itemprop=\"datePublished\" datetime=\"2022-04-05T17:38:40.386Z\">3/5/2022</time><contexter-summary class=\"p-summary entry-summary\" itemprop=\"abstract\" slot=\"summary\"><p>This section describes the status of this document at the time of its publication. Other documents may supersede this document. A list of current W3C publications and the latest revision of this technical report can be found in the W3C technical reports index at https://www.w3.org/TR/.</p></contexter-summary><contexter-keywordset itemprop=\"keywords\" slot=\"keywords\"></contexter-keywordset><a is=\"contexter-link\" href=\"https://www.w3.org/TR/fingerprinting-guidance/\" class=\"read-link main-link\" itemprop=\"sameAs\" slot=\"read-link\">Read</a></contexter-box>","linkId":"eb9881a1af94b81f65a083db297cb0dccaa950a0","data":{"originalLink":"https://www.w3.org/TR/fingerprinting-guidance/","sanitizedLink":"https://www.w3.org/TR/fingerprinting-guidance/","canonical":"https://www.w3.org/TR/fingerprinting-guidance/","htmlText":"<!DOCTYPE html><html lang=\"en\" dir=\"ltr\"><head><meta charset=\"utf-8\"><meta name=\"generator\" content=\"ReSpec 24.7.0\"><meta name=\"viewport\" content=\"width=device-width, initial-scale=1, shrink-to-fit=no\"><style>/* --- ISSUES/NOTES --- */\n.issue-label {\n    text-transform: initial;\n}\n\n.warning > p:first-child { margin-top: 0 }\n.warning {\n    padding: .5em;\n    border-left-width: .5em;\n    border-left-style: solid;\n}\nspan.warning { padding: .1em .5em .15em; }\n\n.issue.closed span.issue-number {\n    text-decoration: line-through;\n}\n\n.warning {\n    border-color: #f11;\n    border-width: .2em;\n    border-style: solid;\n    background: #fbe9e9;\n}\n\n.warning-title:before{\n    content: \"⚠\"; /*U+26A0 WARNING SIGN*/\n    font-size: 3em;\n    float: left;\n    height: 100%;\n    padding-right: .3em;\n    vertical-align: top;\n    margin-top: -0.5em;\n}\n\nli.task-list-item {\n    list-style: none;\n}\n\ninput.task-list-item-checkbox {\n    margin: 0 0.35em 0.25em -1.6em;\n    vertical-align: middle;\n}\n\n.issue a.respec-gh-label {\n  padding: 5px;\n  margin: 0 2px 0 2px;\n  font-size: 10px;\n  text-transform: none;\n  text-decoration: none;\n  font-weight: bold;\n  border-radius: 4px;\n  position: relative;\n  bottom: 2px;\n  border: none;\n}\n\n.issue a.respec-label-dark {\n  color: #fff;\n  background-color: #000;\n}\n\n.issue a.respec-label-light {\n  color: #000;\n  background-color: #fff;\n}\n</style><style>/* --- Best Practices ---  */\n\nspan.practicelab {\n  display: block;\n  color: #005A9C;\n  margin-bottom: 1em;\n}\n\nspan.practicetitle {\n  color: #005A9C;\n  text-decoration: underline;\n  margin-bottom: 1em;\n}\n\np.practicedesc {\n  padding: 2em;\n  border-left-width: 0.5em;\n  border-left-style: solid;\n  border-color: #8CCBF2;\n  background: \n  rgb(241, 246, 253);\n}\n\n.practicebox {\n\n}\n\n@media (max-width: 767px) {\n  span.practicetitle {\n    display: block;\n  }\n}\n</style>\n    <title>Mitigating Browser Fingerprinting in Web Specifications</title>\n    \n    <style id=\"respec-mainstyle\">/*****************************************************************\n * ReSpec 3 CSS\n * Robin Berjon - http://berjon.com/\n *****************************************************************/\n\n/* Override code highlighter background */\n.hljs {\n  background: transparent !important;\n}\n\n/* --- INLINES --- */\nh1 abbr,\nh2 abbr,\nh3 abbr,\nh4 abbr,\nh5 abbr,\nh6 abbr,\na abbr {\n  border: none;\n}\n\ndfn {\n  font-weight: bold;\n}\n\na.internalDFN {\n  color: inherit;\n  border-bottom: 1px solid #99c;\n  text-decoration: none;\n}\n\na.externalDFN {\n  color: inherit;\n  border-bottom: 1px dotted #ccc;\n  text-decoration: none;\n}\n\na.bibref {\n  text-decoration: none;\n}\n\n#references :target {\n  background: #eaf3ff;\n}\n\ncite .bibref {\n  font-style: normal;\n}\n\ncode {\n  color: #c83500;\n}\n\nth code {\n  color: inherit;\n}\n\n/* --- TOC --- */\n\n.toc a,\n.tof a {\n  text-decoration: none;\n}\n\na .secno,\na .figno {\n  color: #000;\n}\n\nul.tof,\nol.tof {\n  list-style: none outside none;\n}\n\n.caption {\n  margin-top: 0.5em;\n  font-style: italic;\n}\n\n/* --- TABLE --- */\n\ntable.simple {\n  border-spacing: 0;\n  border-collapse: collapse;\n  border-bottom: 3px solid #005a9c;\n}\n\n.simple th {\n  background: #005a9c;\n  color: #fff;\n  padding: 3px 5px;\n  text-align: left;\n}\n\n.simple th[scope=\"row\"] {\n  background: inherit;\n  color: inherit;\n  border-top: 1px solid #ddd;\n}\n\n.simple td {\n  padding: 3px 10px;\n  border-top: 1px solid #ddd;\n}\n\n.simple tr:nth-child(even) {\n  background: #f0f6ff;\n}\n\n/* --- DL --- */\n\n.section dd>p:first-child {\n  margin-top: 0;\n}\n\n.section dd>p:last-child {\n  margin-bottom: 0;\n}\n\n.section dd {\n  margin-bottom: 1em;\n}\n\n.section dl.attrs dd,\n.section dl.eldef dd {\n  margin-bottom: 0;\n}\n\n#issue-summary>ul,\n.respec-dfn-list {\n  column-count: 2;\n}\n\n#issue-summary li,\n.respec-dfn-list li {\n  list-style: none;\n}\n\ndetails.respec-tests-details {\n  margin-left: 1em;\n  display: inline-block;\n  vertical-align: top;\n}\n\ndetails.respec-tests-details>* {\n  padding-right: 2em;\n}\n\ndetails.respec-tests-details[open] {\n  z-index: 999999;\n  position: absolute;\n  border: thin solid #cad3e2;\n  border-radius: 0.3em;\n  background-color: white;\n  padding-bottom: 0.5em;\n}\n\ndetails.respec-tests-details[open]>summary {\n  border-bottom: thin solid #cad3e2;\n  padding-left: 1em;\n  margin-bottom: 1em;\n  line-height: 2em;\n}\n\ndetails.respec-tests-details>ul {\n  width: 100%;\n  margin-top: -0.3em;\n}\n\ndetails.respec-tests-details>li {\n  padding-left: 1em;\n}\n\na[href].self-link:hover {\n  opacity: 1;\n  text-decoration: none;\n  background-color: transparent;\n}\n\nh2,\nh3,\nh4,\nh5,\nh6 {\n  position: relative;\n}\n\naside.example .marker > a.self-link {\n  color: inherit;\n}\n\nh2>a.self-link,\nh3>a.self-link,\nh4>a.self-link,\nh5>a.self-link,\nh6>a.self-link {\n  border: none;\n  color: inherit;\n  font-size: 83%;\n  height: 2em;\n  left: -1.6em;\n  opacity: .5;\n  position: absolute;\n  text-align: center;\n  text-decoration: none;\n  top: 0;\n  transition: opacity .2s;\n  width: 2em;\n}\n\nh2>a.self-link::before,\nh3>a.self-link::before,\nh4>a.self-link::before,\nh5>a.self-link::before,\nh6>a.self-link::before {\n  content: \"§\";\n  display: block;\n}\n\n@media (max-width: 767px) {\n  dd {\n    margin-left: 0;\n  }\n\n  /* Don't position self-link in headings off-screen */\n  h2>a.self-link,\n  h3>a.self-link,\n  h4>a.self-link,\n  h5>a.self-link,\n  h6>a.self-link {\n    left: auto;\n    top: auto;\n  }\n}\n\n@media print {\n  .removeOnSave {\n    display: none;\n  }\n}\n</style>\n    \n      <style type=\"text/css\" media=\"screen\">\n        img.fingerprint {\n          float: left; \n          margin-left: -25px;\n        }\n        ul.practicedesc {\n            margin-top: -2em;\n            padding-top: .5em;\n        }\n      </style>\n  <link rel=\"canonical\" href=\"https://www.w3.org/TR/fingerprinting-guidance/\"><style>/*\n\ngithub.com style (c) Vasily Polovnyov <vast@whiteants.net>\n\n*/\n\n.hljs {\n  display: block;\n  overflow-x: auto;\n  padding: 0.5em;\n  color: #333;\n  background: #f8f8f8;\n}\n\n.hljs-comment,\n.hljs-quote {\n  color: #998;\n  font-style: italic;\n}\n\n.hljs-keyword,\n.hljs-selector-tag,\n.hljs-subst {\n  color: #333;\n  font-weight: bold;\n}\n\n.hljs-number,\n.hljs-literal,\n.hljs-variable,\n.hljs-template-variable,\n.hljs-tag .hljs-attr {\n  color: #008080;\n}\n\n.hljs-string,\n.hljs-doctag {\n  color: #d14;\n}\n\n.hljs-title,\n.hljs-section,\n.hljs-selector-id {\n  color: #900;\n  font-weight: bold;\n}\n\n.hljs-subst {\n  font-weight: normal;\n}\n\n.hljs-type,\n.hljs-class .hljs-title {\n  color: #458;\n  font-weight: bold;\n}\n\n.hljs-tag,\n.hljs-name,\n.hljs-attribute {\n  color: #000080;\n  font-weight: normal;\n}\n\n.hljs-regexp,\n.hljs-link {\n  color: #009926;\n}\n\n.hljs-symbol,\n.hljs-bullet {\n  color: #990073;\n}\n\n.hljs-built_in,\n.hljs-builtin-name {\n  color: #0086b3;\n}\n\n.hljs-meta {\n  color: #999;\n  font-weight: bold;\n}\n\n.hljs-deletion {\n  background: #fdd;\n}\n\n.hljs-addition {\n  background: #dfd;\n}\n\n.hljs-emphasis {\n  font-style: italic;\n}\n\n.hljs-strong {\n  font-weight: bold;\n}\n</style><script id=\"initialUserConfig\" type=\"application/json\">{\n  \"specStatus\": \"IG-NOTE\",\n  \"noRecTrack\": true,\n  \"publishDate\": \"2019-03-28\",\n  \"shortName\": \"fingerprinting-guidance\",\n  \"previousPublishDate\": \"2015-11-24\",\n  \"previousMaturity\": \"IG-NOTE\",\n  \"edDraftURI\": \"https://w3c.github.io/fingerprinting-guidance/\",\n  \"editors\": [\n    {\n      \"name\": \"Nick Doty\",\n      \"url\": \"https://npdoty.name/\"\n    }\n  ],\n  \"otherLinks\": [\n    {\n      \"key\": \"Version history\",\n      \"data\": [\n        {\n          \"value\": \"GitHub commit history\",\n          \"href\": \"https://github.com/w3c/fingerprinting-guidance/commits/gh-pages\"\n        }\n      ]\n    },\n    {\n      \"key\": \"Issues list\",\n      \"data\": [\n        {\n          \"value\": \"GitHub issues list\",\n          \"href\": \"https://github.com/w3c/fingerprinting-guidance/issues\"\n        }\n      ]\n    }\n  ],\n  \"wg\": \"Privacy Interest Group\",\n  \"wgURI\": \"https://www.w3.org/Privacy/\",\n  \"wgPublicList\": \"public-privacy\",\n  \"wgPatentURI\": \"\",\n  \"charterDisclosureURI\": \"https://www.w3.org/2011/07/privacy-ig-charter.html\",\n  \"localBiblio\": {\n    \"EVERCOOKIE\": {\n      \"authors\": [\n        \"Samy Kamkar\"\n      ],\n      \"href\": \"https://samy.pl/evercookie/\",\n      \"title\": \"evercookie - virtually irrevocable persistent cookies\",\n      \"date\": \"September 2010\",\n      \"id\": \"evercookie\"\n    },\n    \"NDSS-FINGERPRINTING\": {\n      \"authors\": [\n        \"Ting-Fang Yen\",\n        \"Yinglian Xie\",\n        \"Fang Yu\",\n        \"Roger Peng Yu\",\n        \"Martin Abadi\"\n      ],\n      \"href\": \"https://www.microsoft.com/en-us/research/publication/host-fingerprinting-and-tracking-on-the-webprivacy-and-security-implications/\",\n      \"title\": \"Host Fingerprinting and Tracking on the Web: Privacy and Security Implications\",\n      \"date\": \"February 2012\",\n      \"publisher\": \"In Proceedings of the Network and Distributed System Security Symposium (NDSS)\",\n      \"id\": \"ndss-fingerprinting\"\n    },\n    \"RFC6973\": {\n      \"authors\": [\n        \"A. Cooper\",\n        \"H. Tschofenig\",\n        \"B. Aboba\",\n        \"J. Peterson\",\n        \"J. Morris\",\n        \"M. Hansen\",\n        \"R. Smith\"\n      ],\n      \"href\": \"https://www.rfc-editor.org/rfc/rfc6973.txt\",\n      \"title\": \"Privacy Considerations for Internet Protocols\",\n      \"date\": \"July 2013\",\n      \"status\": \"RFC\",\n      \"publisher\": \"IETF\",\n      \"id\": \"rfc6973\"\n    },\n    \"WEBSTORAGE-user-tracking\": {\n      \"href\": \"https://www.w3.org/TR/2013/REC-webstorage-20130730/#user-tracking\",\n      \"title\": \"Web Storage > Privacy > User tracking\",\n      \"date\": \"July 2013\",\n      \"authors\": [\n        \"Ian Hickson\"\n      ],\n      \"status\": \"Rec\",\n      \"publisher\": \"W3C\",\n      \"id\": \"webstorage-user-tracking\"\n    },\n    \"TAG-UNSANCTIONED\": {\n      \"href\": \"https://w3ctag.github.io/unsanctioned-tracking/\",\n      \"title\": \"Unsanctioned Web Tracking\",\n      \"date\": \"17 July 2015\",\n      \"authors\": [\n        \"Mark Nottingham\"\n      ],\n      \"publisher\": \"W3C Technical Architecture Group\",\n      \"id\": \"tag-unsanctioned\"\n    },\n    \"HIDING-CROWD\": {\n      \"href\": \"https://hal.inria.fr/hal-01718234v2\",\n      \"title\": \"Hiding in the Crowd: an Analysis of the Effectiveness of Browser Fingerprinting at Large Scale\",\n      \"date\": \"April 2018\",\n      \"authors\": [\n        \"Alejandro Gómez-Boix\",\n        \"Pierre Laperdrix\",\n        \"Benoit Baudry\"\n      ],\n      \"publisher\": \"WWW2018 - TheWebConf2018: 27th International World Wide Web Conference\",\n      \"id\": \"hiding-crowd\"\n    },\n    \"WPM-MILLION\": {\n      \"href\": \"https://webtransparency.cs.princeton.edu/webcensus/\",\n      \"authors\": [\n        \"Steven Englehardt\",\n        \"Arvind Narayanan\"\n      ],\n      \"date\": \"May 2016\",\n      \"title\": \"Online tracking: A 1-million-site measurement and analysis\",\n      \"id\": \"wpm-million\"\n    },\n    \"FLASHCOOKIES\": {\n      \"href\": \"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1446862\",\n      \"date\": \"10 August 2009\",\n      \"authors\": [\n        \"Ashkan Soltani\",\n        \"Shannon Canty\",\n        \"Quentin Mayo\",\n        \"Lauren Thomas\",\n        \"Chris Jay Hoofnagle\"\n      ],\n      \"title\": \"Flash Cookies and Privacy\",\n      \"id\": \"flashcookies\"\n    },\n    \"FLASHCOOKIES-2\": {\n      \"href\": \"https://ptolemy.berkeley.edu/projects/truststc/education/reu/11/Posters/AyensonMWambachDpaper.pdf\",\n      \"authors\": [\n        \"Mika Ayenson\",\n        \"Dietrich Wambach\",\n        \"Ashkan Soltani\",\n        \"Nathan Good\",\n        \"Chris Hoofnagle\"\n      ],\n      \"title\": \"Flash cookies and privacy II: Now with HTML5 and ETag respawning\",\n      \"id\": \"flashcookies-2\"\n    },\n    \"TOR-DESIGN\": {\n      \"title\": \"The Design and Implementation of the Tor Browser\",\n      \"href\": \"https://www.torproject.org/projects/torbrowser/design/\",\n      \"date\": \"15 June 2018\",\n      \"authors\": [\n        \"Mike Perry\",\n        \"Erinn Clark\",\n        \"Steven Murdoch\",\n        \"Georg Koppen\"\n      ],\n      \"id\": \"tor-design\"\n    },\n    \"TAG-MINIMIZATION\": {\n      \"href\": \"https://www.w3.org/2001/tag/doc/APIMinimization\",\n      \"date\": \"12 September 2011\",\n      \"authors\": [\n        \"Daniel Appelquist\"\n      ],\n      \"publisher\": \"W3C Technical Architecture Group\",\n      \"title\": \"Data Minimization in Web APIs\",\n      \"id\": \"tag-minimization\"\n    },\n    \"LEAKING-BATTERY\": {\n      \"href\": \"https://eprint.iacr.org/2015/616.pdf\",\n      \"date\": \"2015\",\n      \"authors\": [\n        \"Łukasz Olejnik\",\n        \"Gunes Acar\",\n        \"Claude Castelluccia\",\n        \"Claudia Diaz\"\n      ],\n      \"title\": \"The leaking battery: A privacy analysis of the HTML5 Battery Status API\",\n      \"id\": \"leaking-battery\"\n    },\n    \"BEAUTY-BEAST\": {\n      \"authors\": [\n        \"Pierre Laperdrix\",\n        \"Walter Rudametkin\",\n        \"Benoit Baudry\"\n      ],\n      \"title\": \"Beauty and the Beast: Diverting modern web browsers to build unique browser fingerprints\",\n      \"publisher\": \"IEEE Symposium on Security and Privacy (S&P 2016)\",\n      \"date\": \"May 2016\",\n      \"href\": \"https://hal.inria.fr/hal-01285470v2/\",\n      \"id\": \"beauty-beast\"\n    },\n    \"httpbis-client-hints\": {\n      \"href\": \"https://httpwg.org/http-extensions/client-hints.html\",\n      \"title\": \"HTTP Client Hints\",\n      \"authors\": [\n        \"Ilya Grigorik\"\n      ],\n      \"date\": \"January 2019\",\n      \"publisher\": \"HTTP Working Group\",\n      \"id\": \"httpbis-client-hints\"\n    },\n    \"security-privacy-questionnaire-tag\": {\n      \"href\": \"https://w3ctag.github.io/security-questionnaire/\",\n      \"authors\": [\n        \"Lukasz Olejnik\",\n        \"Jason Novak\"\n      ],\n      \"date\": \"December 2018\",\n      \"title\": \"Self-Review Questionnaire: Security and Privacy\",\n      \"publisher\": \"W3C Technical Architecture Group\",\n      \"id\": \"security-privacy-questionnaire-tag\"\n    }\n  },\n  \"publishISODate\": \"2019-03-28T00:00:00.000Z\",\n  \"generatedSubtitle\": \"Interest Group Note 28 March 2019\"\n}</script><link rel=\"stylesheet\" href=\"https://www.w3.org/StyleSheets/TR/2016/W3C-IG-NOTE\"></head>\n  <body class=\"h-entry informative\"><div class=\"head\">\n      <a href=\"https://www.w3.org/\" class=\"logo\"><img alt=\"W3C\" width=\"72\" height=\"48\" src=\"https://www.w3.org/StyleSheets/TR/2016/logos/W3C\"></a> <h1 id=\"title\" class=\"title p-name\">Mitigating Browser Fingerprinting in Web Specifications</h1>\n      \n      <h2>\n        <abbr title=\"World Wide Web Consortium\">W3C</abbr> Interest Group Note\n        <time class=\"dt-published\" datetime=\"2019-03-28\">28 March 2019</time>\n      </h2>\n      <dl>\n        <dt>This version:</dt><dd>\n                <a class=\"u-url\" href=\"https://www.w3.org/TR/2019/NOTE-fingerprinting-guidance-20190328/\">https://www.w3.org/TR/2019/NOTE-fingerprinting-guidance-20190328/</a>\n              </dd><dt>Latest published version:</dt><dd>\n                <a href=\"https://www.w3.org/TR/fingerprinting-guidance/\">https://www.w3.org/TR/fingerprinting-guidance/</a>\n              </dd>\n        <dt>Latest editor's draft:</dt><dd><a href=\"https://w3c.github.io/fingerprinting-guidance/\">https://w3c.github.io/fingerprinting-guidance/</a></dd>\n        \n        \n        \n        \n        <dt>Previous version:</dt><dd><a href=\"https://www.w3.org/TR/2015/NOTE-fingerprinting-guidance-20151124/\">https://www.w3.org/TR/2015/NOTE-fingerprinting-guidance-20151124/</a></dd>\n        \n        <dt>Editor:</dt>\n        <dd class=\"p-author h-card vcard\"><a class=\"u-url url p-name fn\" href=\"https://npdoty.name/\">Nick Doty</a></dd>\n        \n        \n        <dt>Version history:</dt><dd>\n      <a href=\"https://github.com/w3c/fingerprinting-guidance/commits/gh-pages\">GitHub commit history</a>\n    </dd><dt>Issues list:</dt><dd>\n      <a href=\"https://github.com/w3c/fingerprinting-guidance/issues\">GitHub issues list</a>\n    </dd>\n      </dl>\n      \n      \n      \n      <p class=\"copyright\">\n      <a href=\"https://www.w3.org/Consortium/Legal/ipr-notice#Copyright\">Copyright</a>\n      ©\n      2019\n      \n      <a href=\"https://www.w3.org/\"><abbr title=\"World Wide Web Consortium\">W3C</abbr></a><sup>®</sup> (<a href=\"https://www.csail.mit.edu/\"><abbr title=\"Massachusetts Institute of Technology\">MIT</abbr></a>,\n      <a href=\"https://www.ercim.eu/\"><abbr title=\"European Research Consortium for Informatics and Mathematics\">ERCIM</abbr></a>, <a href=\"https://www.keio.ac.jp/\">Keio</a>,\n      <a href=\"https://ev.buaa.edu.cn/\">Beihang</a>). \n      <abbr title=\"World Wide Web Consortium\">W3C</abbr> <a href=\"https://www.w3.org/Consortium/Legal/ipr-notice#Legal_Disclaimer\">liability</a>,\n      <a href=\"https://www.w3.org/Consortium/Legal/ipr-notice#W3C_Trademarks\">trademark</a> and <a rel=\"license\" href=\"https://www.w3.org/Consortium/Legal/2015/copyright-software-and-document\">permissive document license</a> rules\n      apply.\n    </p>\n      <hr title=\"Separator for header\">\n    </div>\n    <section id=\"abstract\" class=\"introductory\"><h2>Abstract</h2>\n      Exposure of settings and characteristics of browsers can harm user privacy by allowing for browser fingerprinting. This document defines different types of fingerprinting, considers distinct levels of mitigation for the related privacy risks and provides guidance for Web specification authors on how to balance these concerns when designing new Web features.\n    </section>\n    <section id=\"sotd\" class=\"introductory\"><h2>Status of This Document</h2><p><em>This section describes the status of this document at the time of its publication. Other documents may supersede this document. A list of current <abbr title=\"World Wide Web Consortium\">W3C</abbr> publications and the latest revision of this technical report can be found in the <a href=\"https://www.w3.org/TR/\"><abbr title=\"World Wide Web Consortium\">W3C</abbr> technical reports index</a> at https://www.w3.org/TR/.</em>\n      </p><p>\n\n            This document is an Interest Group Note providing best practices to Web specification\n            authors on mitigating the privacy impacts of browser fingerprinting.  It was developed\n            by the <a href=\"http://www.w3.org/Privacy/\"><abbr title=\"World Wide Web Consortium\">W3C</abbr> Privacy Interest Group (PING)</a> \n            in collaboration with\n\t    the <a href=\"http://www.w3.org/2001/tag/\"><abbr title=\"World Wide Web Consortium\">W3C</abbr> Technical Architecture Group</a> (<abbr title=\"Technical Architecture Group\">TAG</abbr>).\n            Since the last publication the list of best practices has been expanded and made\n            more specific, guidance has been provided on how to evaluate the severity of fingerprinting\n            surface, and additional references and examples have been provided. Constructive input of all\n            kinds is welcome. Send comments to the <a href=\"mailto:public-privacy@w3.org\">PING mailing list</a>\n\t    or <a href=\"https://github.com/w3c/fingerprinting-guidance/issues\">file issues in GitHub</a>.\n\n      </p><p data-deliverer=\"52497\">\n      Publication as an Interest Group Note does not imply endorsement by the\n      W3C Membership. The document may be updated, replaced or\n      obsoleted by other documents at any time.\n    </p><p>\n            The disclosure obligations of the Participants of this group are\n            described in the\n            <a href=\"https://www.w3.org/2011/07/privacy-ig-charter.html\">charter</a>.\n          \n    </p><p>\n                  This document is governed by the\n                  <a id=\"w3c_process_revision\" href=\"https://www.w3.org/2019/Process-20190301/\">1 March 2019 <abbr title=\"World Wide Web Consortium\">W3C</abbr> Process Document</a>.\n                </p></section><nav id=\"toc\"><h2 class=\"introductory\" id=\"table-of-contents\">Table of Contents</h2><ol class=\"toc\"><li class=\"tocline\"><a class=\"tocxref\" href=\"#browser-fingerprinting\"><span class=\"secno\">1. </span>Browser fingerprinting</a><ol class=\"toc\"><li class=\"tocline\"><a class=\"tocxref\" href=\"#what-is-fingerprinting\"><span class=\"secno\">1.1 </span>What is fingerprinting?</a></li><li class=\"tocline\"><a class=\"tocxref\" href=\"#privacy_threat_models\"><span class=\"secno\">1.2 </span>Privacy impacts and threat models</a><ol class=\"toc\"><li class=\"tocline\"><a class=\"tocxref\" href=\"#identify-a-user\"><span class=\"secno\">1.2.1 </span>Identify a user</a></li><li class=\"tocline\"><a class=\"tocxref\" href=\"#correlation-of-browsing-activity\"><span class=\"secno\">1.2.2 </span>Correlation of browsing activity</a></li><li class=\"tocline\"><a class=\"tocxref\" href=\"#tracking-without-transparency-or-user-control\"><span class=\"secno\">1.2.3 </span>Tracking without transparency or user control</a></li></ol></li><li class=\"tocline\"><a class=\"tocxref\" href=\"#what-can-we-do-about-it\"><span class=\"secno\">1.3 </span>What can we do about it?</a></li></ol></li><li class=\"tocline\"><a class=\"tocxref\" href=\"#bp-summary\"><span class=\"secno\">2. </span>Best Practices Summary</a></li><li class=\"tocline\"><a class=\"tocxref\" href=\"#types-of-fingerprinting\"><span class=\"secno\">3. </span>Types of fingerprinting</a><ol class=\"toc\"><li class=\"tocline\"><a class=\"tocxref\" href=\"#passive-0\"><span class=\"secno\">3.1 </span>Passive</a></li><li class=\"tocline\"><a class=\"tocxref\" href=\"#active-0\"><span class=\"secno\">3.2 </span>Active</a></li><li class=\"tocline\"><a class=\"tocxref\" href=\"#cookie-like\"><span class=\"secno\">3.3 </span>Cookie-like</a></li></ol></li><li class=\"tocline\"><a class=\"tocxref\" href=\"#feasibility\"><span class=\"secno\">4. </span>Feasibility</a><ol class=\"toc\"><li class=\"tocline\"><a class=\"tocxref\" href=\"#fingerprinting-mitigation-levels-of-success\"><span class=\"secno\">4.1 </span>Fingerprinting mitigation levels of success</a></li><li class=\"tocline\"><a class=\"tocxref\" href=\"#feasible-goals-for-specification-authors\"><span class=\"secno\">4.2 </span>Feasible goals for specification authors</a></li></ol></li><li class=\"tocline\"><a class=\"tocxref\" href=\"#identifying-fingerprinting-surface-and-evaluating-severity\"><span class=\"secno\">5. </span>Identifying fingerprinting surface and evaluating severity</a></li><li class=\"tocline\"><a class=\"tocxref\" href=\"#mitigations\"><span class=\"secno\">6. </span>Mitigations</a><ol class=\"toc\"><li class=\"tocline\"><a class=\"tocxref\" href=\"#weighing_increased_fingerprinting_surface\"><span class=\"secno\">6.1 </span>Weighing increased fingerprinting surface</a></li><li class=\"tocline\"><a class=\"tocxref\" href=\"#standardization\"><span class=\"secno\">6.2 </span>Standardization</a></li><li class=\"tocline\"><a class=\"tocxref\" href=\"#detectability\"><span class=\"secno\">6.3 </span>Detectability</a></li><li class=\"tocline\"><a class=\"tocxref\" href=\"#clearing-all-local-state\"><span class=\"secno\">6.4 </span>Clearing all local state</a></li><li class=\"tocline\"><a class=\"tocxref\" href=\"#do-not-track\"><span class=\"secno\">6.5 </span>Do Not Track</a></li></ol></li><li class=\"tocline\"><a class=\"tocxref\" href=\"#research\"><span class=\"secno\">A. </span>Research</a><ol class=\"toc\"><li class=\"tocline\"><a class=\"tocxref\" href=\"#browser-vendor-documentation\"><span class=\"secno\">A.1 </span>Browser vendor documentation</a></li><li class=\"tocline\"><a class=\"tocxref\" href=\"#academic-research\"><span class=\"secno\">A.2 </span>Academic research</a></li><li class=\"tocline\"><a class=\"tocxref\" href=\"#testing\"><span class=\"secno\">A.3 </span>Testing</a></li></ol></li><li class=\"tocline\"><a class=\"tocxref\" href=\"#acknowledgements\"><span class=\"secno\">B. </span>Acknowledgements</a></li><li class=\"tocline\"><a class=\"tocxref\" href=\"#references\"><span class=\"secno\">C. </span>References</a><ol class=\"toc\"><li class=\"tocline\"><a class=\"tocxref\" href=\"#informative-references\"><span class=\"secno\">C.1 </span>Informative references</a></li></ol></li></ol></nav>\n    <section id=\"browser-fingerprinting\">\n      <!--OddPage--><h2 id=\"x1-browser-fingerprinting\"><span class=\"secno\">1. </span>Browser fingerprinting<a class=\"self-link\" aria-label=\"§\" href=\"#browser-fingerprinting\"></a></h2>\n        <section id=\"what-is-fingerprinting\">\n        <h3 id=\"x1-1-what-is-fingerprinting\"><span class=\"secno\">1.1 </span>What is fingerprinting?<a class=\"self-link\" aria-label=\"§\" href=\"#what-is-fingerprinting\"></a></h3>\n        <p>In short, <dfn id=\"dfn-browser-fingerprinting\" data-export=\"\" data-dfn-type=\"dfn\">browser fingerprinting</dfn> is the capability of a site to identify or re-identify a visiting user, user agent or device via configuration settings or other observable characteristics.</p>\n        <p>A similar definition is provided by [<cite><a class=\"bibref\" href=\"#bib-rfc6973\">RFC6973</a></cite>]. A more detailed list of types of fingerprinting is included below. This document does not attempt to catalog all features currently used or usable for browser fingerprinting; however, <a href=\"#research\" class=\"sec-ref\"><span class=\"secno\">§&nbsp;A.</span> <span class=\"sec-title\">Research</span></a> provides links to browser vendor pages and academic findings.</p>\n        </section>\n        <section id=\"privacy_threat_models\">\n        <h3 id=\"x1-2-privacy-impacts-and-threat-models\"><span class=\"secno\">1.2 </span>Privacy impacts and threat models<a class=\"self-link\" aria-label=\"§\" href=\"#privacy_threat_models\"></a></h3>\n\n        <p>Browser fingerprinting can be used as a security measure (e.g. as means of authenticating the user). However, fingerprinting is also a potential threat to users' privacy on the Web. This document does not attempt to provide a single unifying definition of \"privacy\" or \"personal data\", but we highlight how browser fingerprinting might impact users' privacy. For example, browser fingerprinting can be used to:</p>\n        <ul>\n          <li>identify a user</li>\n          <li>correlate a user’s browsing activity within and across sessions</li>\n          <li>track users without transparency or control</li>\n        </ul>\n\n        <p>The privacy implications associated with each use case are discussed below. Following from the practice of security threat model analysis, we note that there are distinct models of privacy threats for fingerprinting. Defenses against these threats differ, depending on the particular privacy implication and the threat model of the user.</p>\n\n        <section id=\"identify-a-user\">\n          <h4 id=\"x1-2-1-identify-a-user\"><span class=\"secno\">1.2.1 </span>Identify a user<a class=\"self-link\" aria-label=\"§\" href=\"#identify-a-user\"></a></h4>\n          <p>There are many reasons why users might wish to remain anonymous or unidentified online, including: concerns about surveillance, personal physical safety, and concerns about discrimination against them based on what they read or write when using the Web. When a browser fingerprint is correlated with identifying information (like an email address, a recognized given and sur-name, or a government-issued identifier), an application or service provider may be able to identify an otherwise pseudonymous user. The adversary and consequences of this threat will vary by the particular user and use case, but can include nation-state intelligence agencies and threats of violence or imprisonment.</p>\n        </section>\n        \n        <section id=\"correlation-of-browsing-activity\">\n          <h4 id=\"x1-2-2-correlation-of-browsing-activity\"><span class=\"secno\">1.2.2 </span>Correlation of browsing activity<a class=\"self-link\" aria-label=\"§\" href=\"#correlation-of-browsing-activity\"></a></h4>\n          <p>Browser fingerprinting raises privacy concerns even when offline identities are not implicated. Some users may be surprised or concerned that an online party can correlate multiple visits (on the same or different sites) to develop a profile or history of the user. This concern may be heightened because (see below) it may occur without the user's knowledge or consent and tools such as clearing cookies do not prevent further correlation.</p>\n          <p>Browser fingerprinting also allows for tracking across <a class=\"externalDFN\" href=\"https://tools.ietf.org/html/rfc6454#section-4\">origins</a> [<cite><a class=\"bibref\" href=\"#bib-rfc6454\">RFC6454</a></cite>]: different sites may be able to combine information about a single user even where a cookie policy would block accessing of cookies between origins, because the fingerprint is relatively unique and the same for all origins.</p>\n        </section>\n        \n        <section id=\"tracking-without-transparency-or-user-control\">\n          <h4 id=\"x1-2-3-tracking-without-transparency-or-user-control\"><span class=\"secno\">1.2.3 </span>Tracking without transparency or user control<a class=\"self-link\" aria-label=\"§\" href=\"#tracking-without-transparency-or-user-control\"></a></h4>\n          <p>\n            In contrast to other mechanisms defined by Web standards for maintaining state (e.g. cookies), browser fingerprinting allows for collection of data about user activity without clear indications that such collection is happening. Transparency can be important for end users, to understand how ongoing collection is happening, but it also enables researchers, policymakers and others to document or regulate privacy-sensitive activity. Browser fingerprinting also allows for tracking of activity without clear or effective user controls: a browser fingerprint typically cannot be cleared or re-set. (See the finding on unsanctioned tracking [<cite><a class=\"bibref\" href=\"#bib-tag-unsanctioned\">TAG-UNSANCTIONED</a></cite>].)\n          </p>\n        </section>\n    </section>\n    <section id=\"what-can-we-do-about-it\">\n      <h3 id=\"x1-3-what-can-we-do-about-it\"><span class=\"secno\">1.3 </span>What can we do about it?<a class=\"self-link\" aria-label=\"§\" href=\"#what-can-we-do-about-it\"></a></h3>\n      <p>\n        Advances in techniques for browser fingerprinting (see <a href=\"#research\" class=\"sec-ref\"><span class=\"secno\">§&nbsp;A.</span> <span class=\"sec-title\">Research</span></a>, below), particularly in <a href=\"#dfn-active-fingerprinting\" class=\"internalDFN\" data-link-type=\"dfn\">active fingerprinting</a>, suggest that complete elimination of the capability of browser fingerprinting by a determined adversary through solely technical means that are widely deployed is implausible. However, mitigations in our technical specifications are possible, as described below (<a href=\"#mitigations\" class=\"sec-ref\"><span class=\"secno\">§&nbsp;6.</span> <span class=\"sec-title\">Mitigations</span></a>), and may achieve different levels of success (<a href=\"#feasibility\" class=\"sec-ref\"><span class=\"secno\">§&nbsp;4.</span> <span class=\"sec-title\">Feasibility</span></a>).\n      </p>\n      <p>\n        Mitigations recommended here are simply mitigations, not solutions. Users of the Web cannot confidently rely on sites being completely unable to correlate traffic, especially when executing client-side code. A fingerprinting surface extends across all implemented Web features for a particular user agent, and even to other layers of the stack; for example, differences in TCP connections. For example, a user might employ an onion routing system such as Tor to limit network-level linkability, but still face the risk of correlating Web-based activity through browser fingerprinting, or vice versa. In order to mitigate these privacy risks as a whole, fingerprinting must be considered during the design and development of all specifications.\n      </p>\n      <p>\n        The <abbr title=\"Technical Architecture Group\">TAG</abbr> finding on Unsanctioned Web Tracking, including browser fingerprinting, includes description of the limitations of technical measures and encourages minimizing and documenting new fingerprinting surface [<cite><a class=\"bibref\" href=\"#bib-tag-unsanctioned\">TAG-UNSANCTIONED</a></cite>]. The best practices below detail common actions that authors of specifications for Web features can take to mitigate the privacy impacts of browser fingerprinting. The Self-Review Questionnaire documents mitigations of privacy impacts in Web features more generally that may complement these practices [<cite><a class=\"bibref\" href=\"#bib-security-privacy-questionnaire-tag\">security-privacy-questionnaire-tag</a></cite>].\n      </p>\n    </section>\n    </section>\n    \n    <section id=\"bp-summary\"><!--OddPage--><h2 id=\"x2-best-practices-summary\"><span class=\"secno\">2. </span>Best Practices Summary<a class=\"self-link\" aria-label=\"§\" href=\"#bp-summary\"></a></h2><ul class=\"practicebox\"><li><a href=\"#avoid-passive-increases\">Best Practice 1</a>: Avoid unnecessary or severe increases to fingerprinting surface, especially for passive fingerprinting.</li><li><a href=\"#narrow-scope-availability\">Best Practice 2</a>: Narrow the scope and availability of a feature with fingerprinting surface to what is functionally necessary.</li><li><a href=\"#mark-fingerprinting\">Best Practice 3</a>: Mark features that contribute to fingerprintability.</li><li><a href=\"#specify-ordering\">Best Practice 4</a>: Specify orderings and non-functional differences.</li><li><a href=\"#api-minimization\">Best Practice 5</a>: Design APIs to access only the entropy necessary.</li><li><a href=\"#server-advertisement\">Best Practice 6</a>: Require servers to advertise or opt in to access data.</li><li><a href=\"#anticipate-disabled\">Best Practice 7</a>: Enable graceful degradation for privacy-conscious users or implementers.</li><li><a href=\"#no-new-cookies\">Best Practice 8</a>: Avoid unnecessary new local state mechanisms.</li><li><a href=\"#mark-cookie-like\">Best Practice 9</a>: Highlight any local state mechanisms to enable simultaneous clearing.</li><li><a href=\"#no-permanent\">Best Practice 10</a>: Limit permanent or persistent state.</li></ul></section>\n    \n    <section id=\"types-of-fingerprinting\">\n        <!--OddPage--><h2 id=\"types_of_fingerprinting\"><span class=\"secno\">3. </span>Types of fingerprinting<a class=\"self-link\" aria-label=\"§\" href=\"#types-of-fingerprinting\"></a></h2>\n        <section id=\"passive-0\">\n          <h3 id=\"passive\"><span class=\"secno\">3.1 </span>Passive<a class=\"self-link\" aria-label=\"§\" href=\"#passive-0\"></a></h3>\n          <p><dfn data-dfn-type=\"dfn\" id=\"dfn-passive-fingerprinting\">Passive fingerprinting</dfn> is browser fingerprinting based on characteristics observable in the contents of Web requests, without the use of any code executed on the client.</p>\n          <p>Passive fingerprinting would trivially include cookies (often unique identifiers sent in HTTP requests), the set of HTTP request headers and the IP address and other network-level information. The <a href=\"https://tools.ietf.org/html/rfc7231#section-5.5.3\">User-Agent string</a> [<cite><a class=\"bibref\" href=\"#bib-rfc7231\">RFC7231</a></cite>], for example, is an HTTP request header that typically identifies the browser, renderer, version and operating system. For some populations, the User-Agent and IP address will often uniquely identify a particular user's browser [<cite><a class=\"bibref\" href=\"#bib-ndss-fingerprinting\">NDSS-FINGERPRINTING</a></cite>].</p>\n        </section>\n        <section id=\"active-0\">\n          <h3 id=\"active\"><span class=\"secno\">3.2 </span>Active<a class=\"self-link\" aria-label=\"§\" href=\"#active-0\"></a></h3>\n          <p>For <dfn data-dfn-type=\"dfn\" id=\"dfn-active-fingerprinting\">active fingerprinting</dfn>, we also consider techniques where a site runs JavaScript or other code on the local client to observe additional characteristics about the browser, user, device or other context.</p>\n          <p>Techniques for active fingerprinting might include accessing the window size, enumerating fonts or plug-ins, evaluating performance characteristics, reading from device sensors, and rendering graphical patterns. Key to this distinction is that <a href=\"#dfn-active-fingerprinting\" class=\"internalDFN\" data-link-type=\"dfn\">active fingerprinting</a> takes place in a way that is potentially detectable on the client.</p>\n        </section>\n        <section id=\"cookie-like\">\n          <h3 id=\"cookie_like_setting_retrieving_local_state\"><span class=\"secno\">3.3 </span>Cookie-like<a class=\"self-link\" aria-label=\"§\" href=\"#cookie-like\"></a></h3>\n          <p>Users, user agents and devices may also be re-identified by a site that first sets and later retrieves state stored by a user agent or device. This <dfn data-dfn-type=\"dfn\" id=\"dfn-cookie-like-fingerprinting\">cookie-like fingerprinting</dfn> allows re-identification of a user or inferences about a user in the same way that HTTP cookies allow state management for the stateless HTTP protocol [<cite><a class=\"bibref\" href=\"#bib-rfc6265\">RFC6265</a></cite>].</p>\n          <p>Cookie-like fingerprinting can also circumvent user attempts to limit or clear cookies stored by the user agent, as demonstrated by the \"evercookie\" implementation [<cite><a class=\"bibref\" href=\"#bib-evercookie\">EVERCOOKIE</a></cite>]. Where state is maintained across user agents (as in the case of common plugins with local storage), across devices (as in the case of certain browser syncing mechanisms) or across software upgrades, cookie-like fingerprinting can allow re-identification of users, user agents or devices where active and passive fingerprinting might not. The Security and Privacy Self-Review Questionnaire also considers this threat in origin state that persists across browsing sessions [<cite><a class=\"bibref\" href=\"#bib-security-privacy-questionnaire-tag\">security-privacy-questionnaire-tag</a></cite>].</p>\n        </section>\n    </section>\n\n    <section id=\"feasibility\">\n      <!--OddPage--><h2 id=\"x4-feasibility\"><span class=\"secno\">4. </span>Feasibility<a class=\"self-link\" aria-label=\"§\" href=\"#feasibility\"></a></h2>\n      \n      <section id=\"fingerprinting-mitigation-levels-of-success\">\n          <h3 id=\"x4-1-fingerprinting-mitigation-levels-of-success\"><span class=\"secno\">4.1 </span>Fingerprinting mitigation levels of success<a class=\"self-link\" aria-label=\"§\" href=\"#fingerprinting-mitigation-levels-of-success\"></a></h3>\n          <p>There are different levels of success in mitigating browser fingerprinting:</p>\n          <dl>\n          <dt>Decreased fingerprinting surface</dt><dd>Removing the source of entropy or accessible attributes that can be used for fingerprinting.</dd>\n          <dt>Increased anonymity set</dt><dd>By standardization, convention or common implementation, increasing the commonality of particular configurations to decrease the likelihood of unique fingerprintability.</dd>\n          <dt>Detectable fingerprinting</dt><dd>Making fingerprinting observable to others, so that the user agent might block it or researchers can determine that it's happening.</dd>\n          <dt>Clearable local state</dt><dd>Helping users respond to fingerprinting by making state mechanisms clearable.</dd>\n          </dl>\n          <p>Research has shown feasible improvement in privacy protection in all of these areas. While lists of plugins remain a large fingerprinting surface, entropy has decreased over time with migration to Web APIs over plugins [<cite><a class=\"bibref\" href=\"#bib-hiding-crowd\">HIDING-CROWD</a></cite>]. Collected data on Web users has shown mobile devices to have substantially larger anonymity sets than desktop browsers [<cite><a class=\"bibref\" href=\"#bib-hiding-crowd\">HIDING-CROWD</a></cite>]. Research on forms of active fingerprinting has documented its use and demonstrated changes in use of those techniques as an apparent result of increased awareness [<cite><a class=\"bibref\" href=\"#bib-wpm-million\">WPM-MILLION</a></cite>]. Respawning of cookies has continued, with an increasing variety of techniques, but awareness and technical responses to the issue has made the practice less widespread [<cite><a class=\"bibref\" href=\"#bib-flashcookies-2\">FLASHCOOKIES-2</a></cite>].</p>\n      </section>\n      <section id=\"feasible-goals-for-specification-authors\">\n        <h3 id=\"x4-2-feasible-goals-for-specification-authors\"><span class=\"secno\">4.2 </span>Feasible goals for specification authors<a class=\"self-link\" aria-label=\"§\" href=\"#feasible-goals-for-specification-authors\"></a></h3>\n        <p>\n          This document works under the expectation that mitigations with different levels of success are feasible under different circumstances, for different threat models and against different types of fingerprinting. In general, active fingerprinting may be made detectable; we can minimize increases to the surface of passive fingerprinting; and cookie-like mechanisms can be made clearable.</p>\n        <p>\n          Some implementers and some users may be willing to accept reduced functionality or decreased performance in order to minimize browser fingerprinting. Documenting which features have fingerprinting risk eases the work of implementers building modes for these at-risk users; minimizing fingerprinting even in cases where common implementations will have easy active fingerprintability allows such users to reduce the functionality trade-offs necessary. Making browser fingerprinting more detectable also contributes to mitigations outside the standardization process; for example, though regulatory or policy means [<cite><a class=\"bibref\" href=\"#bib-tag-unsanctioned\">TAG-UNSANCTIONED</a></cite>].\n        </p>\n      </section>\n    </section>\n    <section id=\"identifying-fingerprinting-surface-and-evaluating-severity\">\n      <!--OddPage--><h2 id=\"identifying\"><span class=\"secno\">5. </span>Identifying fingerprinting surface and evaluating severity<a class=\"self-link\" aria-label=\"§\" href=\"#identifying-fingerprinting-surface-and-evaluating-severity\"></a></h2>      \n\n      <p>To mitigate browser fingerprinting in your specification:</p>\n      <ol>\n        <li>identify features that can be used for browser fingerprinting;</li>\n        <li>evaluate the severity of the fingerprinting surface based on <a href=\"#severity-list\">these five factors</a>; and,</li>\n        <li>apply mitigations described in the best practices below (<a href=\"#mitigations\" class=\"sec-ref\"><span class=\"secno\">§&nbsp;6.</span> <span class=\"sec-title\">Mitigations</span></a>), focused on limiting the severity of that fingerprinting surface.</li>\n      </ol>\n        \n      <p>The <dfn id=\"dfn-fingerprinting-surface\" data-export=\"\" data-dfn-type=\"dfn\">fingerprinting surface</dfn> of a user agent is the set of observable characteristics that can be used in concert to identify a user, user agent or device or correlate its activity.</p>\n\n      <p>Data sources that may be used for browser fingerprinting include:</p>\n      <ul>\n        <li>user configuration</li>\n        <li>device characteristics</li>\n        <li>environmental characteristics <em>(e.g. sensor readings)</em></li>\n        <li>operating system characteristics</li>\n        <li>user behavior</li>\n        <li>browser characteristics</li>\n      </ul>\n\n      <p>These data sources may be accessed directly for some features, but in many other cases they are inferred through some other observation. Timing channels, in particular, are commonly used to infer details of hardware (exactly how quickly different operations are completed may provide information on GPU capability, say), network information (via the latency or speed in loading a particular resource) or even user configuration (what items have been previously cached or what resources are not loaded). Consider the side effects of feature and how those side effects would allow inferences of any of these characteristics.</p>\n\n      <p>The <a href=\"https://www.torproject.org/projects/torbrowser/design/#fingerprinting-linkability\">Tor Browser design document</a> [<cite><a class=\"bibref\" href=\"#bib-tor-design\">TOR-DESIGN</a></cite>] has more details on these sources and their relative priorities; this document adds environmental characteristics in that sensor readings or data access may distinguish a user, user agent or device by information about the environment (location, for example).</p>\n\n      <p id=\"severity-list\">For each identified feature, consider the severity for the privacy impacts described above (<a href=\"#privacy_threat_models\" class=\"sec-ref\"><span class=\"secno\">§&nbsp;1.2</span> <span class=\"sec-title\">Privacy impacts and threat models</span></a>) based on the following factors:</p>\n\n      <dl>\n        <dt>entropy</dt><dd>How distinguishing is this new surface? Consider both the possible variations and the likely distribution of values. Adding 1-bit of entropy is typically of less concern; 30-some bits of entropy would be enough to uniquely identify every individual person. Different data sources may provide different distributions of variation; for example, some characteristics may reveal a common hardware class while other characteristics may reveal user configurations that vary between individual people.</dd>\n        <dt>detectability</dt><dd>Will use of this feature for browser fingerprinting be observable to the user agent or likely to be discoverable by researchers? Because detectability is an important — and perhaps the most feasible — mitigation, increases to the surface for <a href=\"#dfn-passive-fingerprinting\" class=\"internalDFN\" data-link-type=\"dfn\">passive fingerprinting</a> are of particular concern and should be avoided.</dd>\n        <dt>persistence</dt><dd>How long will the characteristics of this fingerprinting surface stay unchanged? Can users control or re-set these values to prevent long-lived identification? While short-lived characteristics may still enable unexpected correlation of activity (for example, between two browser profiles on the same device), persistent or permanent identifiers are particularly concerning for the lack of user control.</dd>\n        <dt>availability</dt><dd>Will this surface be accessible to the \"drive-by Web\" or only in certain contexts where a user has granted a particular sensor permission or directly authenticated? While browser fingerprinting is still something to mitigate in the permissioned context, the concern that a feature will end up used primarily for fingerprinting is reduced.</dd>\n        <dt>scope</dt><dd>Is this surface consistent across origins or only within a single origin? In general, characteristics or identifiers that are tied to a particular origin are of less concern and can be handled with the same tools as HTTP cookies.</dd>\n      </dl>\n\n      <p>While we do not recommend specific trade-offs, these factors can be used to weigh increases to that surface (<a href=\"#weighing_increased_fingerprinting_surface\" class=\"sec-ref\"><span class=\"secno\">§&nbsp;6.1</span> <span class=\"sec-title\">Weighing increased fingerprinting surface</span></a>) and suggest appropriate mitigations. Although each factor may suggest specific mitigations, in weighing whether to add <a href=\"#dfn-fingerprinting-surface\" class=\"internalDFN\" data-link-type=\"dfn\">fingerprinting surface</a> they should be considered in concert. For example, access to a new set of characteristics about the user may be high entropy, but be of less concern because it has limited availability and is easily detectable. A cross-origin, drive-by-accessible, permanent, passive unique identifier is incompatible with our expectations for privacy on the Web.</p>\n\n      <p>In conducting this analysis, it may be tempting to dismiss certain fingerprinting surface in a specification because of a comparison to fingerprinting surface exposed by other parts of the Web platform or other layers of the stack. Be cautious about making such claims. First, while similar information may be available through other means, similar is not identical: information disclosures may not be exactly the same and fingerprintability is promoted by combining these distinct sources. Second, where identical entropy is present, other factors of severity or accessibility may differ and those factors are important for feasible mitigation. Third, the platform is neither monolithic nor static; not all other features are implemented in all cases and may change (or be removed) in the future. Fourth, circular dependencies are a danger when so many new features are under development; two specifications sometimes refer to one another in arguing that fingerprinting surface already exists. It is more useful to reviewers and implementers to consider the fingerprinting surface provided by the particular Web feature itself, with specific references where surface may be accessible through other features as well.</p>\n\n    </section>\n    <section id=\"mitigations\">\n        <!--OddPage--><h2 id=\"x6-mitigations\"><span class=\"secno\">6. </span>Mitigations<a class=\"self-link\" aria-label=\"§\" href=\"#mitigations\"></a></h2>\n        <section id=\"weighing_increased_fingerprinting_surface\">\n          <h3 id=\"x6-1-weighing-increased-fingerprinting-surface\"><span class=\"secno\">6.1 </span>Weighing increased fingerprinting surface<a class=\"self-link\" aria-label=\"§\" href=\"#weighing_increased_fingerprinting_surface\"></a></h3>\n          <p>Web specification authors regularly attempt to strike a balance between new functionality and fingerprinting surface. For example, feature detection functionality allows for progressive enhancement with a small addition to fingerprinting surface; detailed enumerations of plugins, fonts, connected devices may provide a large fingerprinting surface with minimal functional support.</p>\n          <p>Authors and Working Groups determine the appropriate balance between these properties on a case-by-case basis, given their understanding of the functionality, its implementations and the severity of increased fingerprinting surface. However, given the distinct privacy impacts described above and in order to improve consistency across specifications, these practices provide some guidance:</p>\n          \n          <div class=\"practice\">\n            <p>\n              <span id=\"avoid-passive-increases\" class=\"practicelab\"><span class=\"practicetitle\">Best Practice 1</span>: Avoid unnecessary or severe increases to fingerprinting surface, especially for passive fingerprinting.</span>\n            </p>\n            <p class=\"practicedesc\">\n              Consider each of the <a href=\"#severity-list\">severity factors</a> described above and whether that functionality is necessary and whether comparable functionality is feasible with less severe increases to the fingerprinting surface.\n            </p>\n            <p class=\"practicedesc\">\n              In particular, unless a feature cannot reasonably be designed in any other way, increased passive fingerprintability should be avoided. Passive fingerprinting allows for easier and widely-available identification, without opportunities for external detection or control by users or third parties.\n            </p>\n          </div>\n\n          <div class=\"practice\">\n            <p>\n              <span id=\"narrow-scope-availability\" class=\"practicelab\"><span class=\"practicetitle\">Best Practice 2</span>: Narrow the scope and availability of a feature with fingerprinting surface to what is functionally necessary.</span>\n            </p>\n            <p class=\"practicedesc\">\n              What browsing contexts, resources and requests need access to a particular feature?  Identifiers can often be scoped to have a different value in different origins. Some configuration may only be necessary in top-level browsing contexts.\n            </p>\n            <p class=\"practicedesc\">\n              Should access to this functionality be limited to where users have granted a particular permission? While excessive permissions can create confusion and fatigue, limiting highly granular data to situations where a user has already granted permission to access sensitive data widely mitigates the risk of that feature being used primarily for browser fingerprinting in \"drive-by\" contexts. For example, Media Capture and Streams [<cite><a class=\"bibref\" href=\"#bib-mediacapture-streams\">mediacapture-streams</a></cite>] limits access to attached microphone and camera device labels to when the user has granted permission to access a camera or microphone (while still allowing access to the number and configuration of attached cameras and microphones in all contexts, a noted increase in drive-by fingerprinting surface).\n            </p>\n          </div>\n\n          <p>Some implementations may also limit the entropy of fingerprinting surface by not exposing different capabilities for different devices or installations of a user agent. Font lists, for example, can be limited to a whitelist commonly available on all devices that run a particular browser or operating system (as implemented in Tor Browser, Firefox and Safari).</p>\n          \n          <div class=\"practice\">\n            <p>\n              <span id=\"mark-fingerprinting\" class=\"practicelab\"><span class=\"practicetitle\">Best Practice 3</span>: Mark features that contribute to fingerprintability.</span>\n            </p>\n            <p class=\"practicedesc\">\n              <img src=\"https://www.w3.org/TR/html5/images/fingerprint.png\" class=\"fingerprint\" alt=\"This feature may contribute to browser fingerprintability.\" height=\"21\" width=\"15\">\n              Where a feature does contribute to the <a href=\"#dfn-fingerprinting-surface\" class=\"internalDFN\" data-link-type=\"dfn\">fingerprinting surface</a>, indicate that impact, by explaining the effect (and any known implementer mitigations) and marking the relevant section with a fingerprinting icon, as this paragraph is.            \n            </p>\n          </div>\n          <div class=\"example\">\n            The following code can be used to mark a paragraph with the fingerprint icon.\n            <pre class=\"highlight\" aria-busy=\"false\"><code class=\"hljs javascript\">&lt;img src=<span class=\"hljs-string\">\"https://www.w3.org/TR/html5/images/fingerprint.png\"</span> \n     <span class=\"hljs-class\"><span class=\"hljs-keyword\">class</span></span>=<span class=\"hljs-string\">\"fingerprint\"</span> \n     alt=<span class=\"hljs-string\">\"This feature may contribute to browser fingerprintability.\"</span>&gt;</code></pre>\n          </div>\n        </section>\n        <section id=\"standardization\">\n\t\t\t<h3 id=\"a_standardized_profile\"><span class=\"secno\">6.2 </span>Standardization<a class=\"self-link\" aria-label=\"§\" href=\"#standardization\"></a></h3>\n\t\t\t<p>\n        Specifications can mitigate against fingerprintability through standardization; by defining a consistent behavior, conformant implementations won't have variations that can be used for browser fingerprinting.\n\t\t\t</p>\n      <p>\n        Randomization of certain browser characteristics has been proposed as a way to combat browser fingerprinting. While this strategy may be pursued by some implementations, we expect in general it will be more effective for us to standardize or null values rather than setting a range over which they can vary. The Tor Browser design [<cite><a class=\"bibref\" href=\"#bib-tor-design\">TOR-DESIGN</a></cite>] provides more detailed information, but in short: it's difficult to measure how well randomization will work as a mitigation and it can be costly to implement in terms of usability (varying functionality or design in unwanted ways), processing (generating random numbers) and development (including the cost of introducing new security vulnerabilities). Standardization provides the benefit of an increased anonymity set for conformant browsers with the same configuration: that is, an individual can look the same as a larger group of people rather than trying to look like a number of different individuals.\n      </p>\n      <div class=\"practice\">\n        <p>\n          <span id=\"specify-ordering\" class=\"practicelab\"><span class=\"practicetitle\">Best Practice 4</span>: Specify orderings and non-functional differences.</span>\n        </p>\n        <p class=\"practicedesc\">\n          To reduce unnecessary entropy, specify aspects of API return values and behavior that don't contribute to functional differences. For example, if the ordering of return values in a list has no semantic value, specify a particular ordering (alphabetical order by a defined algorithm, for example) so that incidental differences don't expose fingerprinting surface.\n        </p>\n        <p class=\"practicedesc\">\n          Access to a list of system fonts via Flash or Java plugins notably returns the list sorted not in a standard alphabetical order, but in an unspecified order specific to the system. This ordering adds to the entropy available from that plugin in a way that provides no functional advantage. (See <a href=\"https://trac.webkit.org/wiki/Fingerprinting#ii.CollectingSystemFontsviaFlashPlugins\">Collecting System Fonts via Flash Plugins</a>.)\n        </p>\n      </div>\n      <p>\n        Standardization does <em>not</em> need to attempt to hide all differences between different browsers (e.g. Edge and Chrome); implemented functionality and behavior differences will always exist between different implementations. For that reason, removing <code>User-Agent</code> headers altogether is not a goal. However, variation in the <code>User-Agent</code> string that reveals additional information about the user or device has been shown to provide substantial fingerprinting surface [<cite><a class=\"bibref\" href=\"#bib-beauty-beast\">BEAUTY-BEAST</a></cite>].\n      </p>\n\t\t</section>\n        <section id=\"detectability\">\n          <h3 id=\"x6-3-detectability\"><span class=\"secno\">6.3 </span>Detectability<a class=\"self-link\" aria-label=\"§\" href=\"#detectability\"></a></h3>\n          <p>Where a client-side API provides some fingerprinting surface, authors can still mitigate the privacy concerns via detectability. If client-side fingerprinting activity is to some extent distinguishable from functional use of APIs, user agent implementations may have an opportunity to prevent ongoing fingerprinting or make it observable to users and external researchers (including academics or relevant regulators) who may be able to detect and investigate the use of fingerprinting.</p>\n          \n          <div class=\"practice\">\n            <p>\n              <span id=\"api-minimization\" class=\"practicelab\"><span class=\"practicetitle\">Best Practice 5</span>: Design APIs to access only the entropy necessary.</span>\n            </p>\n            <p class=\"practicedesc\">\n              Following the basic principle of <a href=\"https://tools.ietf.org/html/rfc6973#section-6.1\">data minimization</a> [<cite><a class=\"bibref\" href=\"#bib-rfc6973\">RFC6973</a></cite>], design your APIs such that a site can access (and does access by default) only the entropy necessary for particular functionality.\n            </p>\n            <p class=\"practicedesc\">\n              Authors might design an API to allow for querying of a particular value, rather than returning an enumeration of all values. User agents and researchers can then more easily distinguish between sites that query for one or two particular values (gaining minimal entropy) and those that query for all values (more likely attempting to fingerprint the browser); or implementations can cap the number of different values. For example, Tor Browser limits the number of fonts that can be queried with a <code>browser.display.max_font_attempts</code> preference.\n            </p>\n            <p class=\"practicedesc\">\n              The granularity or precision of information returned can be minimized in order to reduce entropy. For example, implementations of the Battery Status API [<cite><a class=\"bibref\" href=\"#bib-battery-status\">BATTERY-STATUS</a></cite>] allowed for high precision (double-precision, or 15-17 significant digits) readings of the current battery level, which provided a short-term identifier that could be used to correlate traffic across origins or clearance of local state. Rounding off values to lower precision mitigates browser fingerprinting while maintaining functional use cases. Alternatively, providing Boolean or a small enumeration of values might provide functionality without revealing underlying details; for example, the Boolean <code>near</code> property in the Proximity Sensor API [<cite><a class=\"bibref\" href=\"#bib-proximity\">PROXIMITY</a></cite>].\n            </p>\n            <p class=\"practicedesc\">\n              For more information, see:\n            </p>\n            <ul class=\"practicedesc\">\n              <li><a href=\"https://www.w3.org/TR/dap-privacy-reqs/\">Device API Privacy Requirements</a> [<cite><a class=\"bibref\" href=\"#bib-dap-privacy-reqs\">dap-privacy-reqs</a></cite>], <abbr title=\"Device APIs Working Group\">DAP</abbr> Working Group Note, June 2010.</li>\n              <li><a href=\"https://www.w3.org/2001/tag/doc/APIMinimization\">Data Minimization in Web APIs</a> [<cite><a class=\"bibref\" href=\"#bib-tag-minimization\">TAG-MINIMIZATION</a></cite>], <abbr title=\"World Wide Web Consortium\">W3C</abbr> <abbr title=\"Technical Architecture Group\">TAG</abbr>, September 2011.</li>\n              <li><a href=\"https://www.w3.org/TR/generic-sensor/#security-and-privacy\">Generic Sensor API: Security and privacy considerations</a> [<cite><a class=\"bibref\" href=\"#bib-generic-sensor\">generic-sensor</a></cite>], March 2018.</li>\n              <li><a href=\"https://eprint.iacr.org/2015/616.pdf\">The leaking battery: A privacy analysis of the HTML5 Battery Status API</a> [<cite><a class=\"bibref\" href=\"#bib-leaking-battery\">LEAKING-BATTERY</a></cite>], 2015.</li>\n            </ul>\n          </div>\n          <p>\n            Related, detectability is improved even with data sent in HTTP headers (what we would typically consider passive fingerprinting) if sites are required to request access (or \"opt in\") to information before it's sent.\n          </p>\n          <div class=\"practice\">\n              <p>\n                <span id=\"server-advertisement\" class=\"practicelab\"><span class=\"practicetitle\">Best Practice 6</span>: Require servers to advertise or opt in to access data.</span>\n              </p>\n              <p class=\"practicedesc\">\n                Even for data sent in HTTP request headers, requiring servers to advertise use of particular data, publicly document a policy, or \"opt in\" before clients send configuration data provides the possibility of detection by user agents or researchers.\n              </p>\n              <p class=\"practicedesc\">\n                For example, Client Hints [<cite><a class=\"bibref\" href=\"#bib-httpbis-client-hints\">httpbis-client-hints</a></cite>] proposes an <code>Accept-CH</code> response header for services to indicate that specific hints can be used for content negotiation, rather than all supporting clients sending all hints in all requests.\n              </p>\n              <div class=\"note\" role=\"note\" id=\"issue-container-generatedID\"><div role=\"heading\" class=\"note-title marker\" id=\"h-note\" aria-level=\"4\"><span>Note</span></div><p class=\"\">\n                This is a relatively new approach; we're still evaluating whether this provides meaningful and useful detectability.\n              </p></div>\n          </div>\n\n          <p>\n            Implementers can facilitate detectability by providing or enabling instrumentation so that users or third parties are able to calculate when fingerprinting surface is being accessed. Of particular importance for instrumentation are: access to all the different sources of fingerprinting surface; identification of the originating script; avoiding exposure that instrumentation is taking place. Beyond the minimization practice described above, these are largely implementation-specific (rather than Web specification) features.\n          </p>\n          <p>\n            If your specification exposes some fingerprinting surface (whether it's active or passive), some implementers (e.g. Tor Browser) are going to be compelled to disable those features for certain privacy-conscious users.\n          </p>\n          <div class=\"practice\">\n            <p>\n              <span id=\"anticipate-disabled\" class=\"practicelab\"><span class=\"practicetitle\">Best Practice 7</span>: Enable graceful degradation for privacy-conscious users or implementers.</span>\n            </p>\n            <p class=\"practicedesc\">\n              Following the principle of progressive enhancement, and to avoid further divergence (which might itself expose variation in users), consider whether some functionality in your specification is still possible if fingerprinting surface features are disabled. \n            </p>\n            <p class=\"practicedesc\">\n              Explicit hooks or API flags may be used so that browser extensions or certain user agents can easily disable specific features. For example, the <a href=\"https://www.w3.org/TR/html52/semantics-scripting.html#canvas-origin-clean\">origin-clean flag</a> [<cite><a class=\"bibref\" href=\"#bib-html52\">html52</a></cite>] allows control over whether an image canvas can be read, a significant fingerprinting surface.\n            </p>\n          </div>     \n        </section>\n        <section id=\"clearing-all-local-state\">\n          <h3 id=\"x6-4-clearing-all-local-state\"><span class=\"secno\">6.4 </span>Clearing all local state<a class=\"self-link\" aria-label=\"§\" href=\"#clearing-all-local-state\"></a></h3>\n          <p>Features which enable storage of data on the client and functionality for client- or server-side querying of that data can increase the ease of cookie-like fingerprinting. Storage can vary between large amounts of data (for example, the Web Storage API) or just a binary flag (has or has not provided a certain permission; has or has not cached a single resource).</p>\n          <div class=\"practice\">\n            <p>\n              <span id=\"no-new-cookies\" class=\"practicelab\"><span class=\"practicetitle\">Best Practice 8</span>: Avoid unnecessary new local state mechanisms.</span>\n            </p>\n            <p class=\"practicedesc\">\n              If functionality does not require maintaining client-side state in a way that is subsequently queryable (or otherwise observable), avoid creating a new cookie-like feature. Can the functionality be accomplished with existing HTTP cookies or an existing JavaScript local storage API?\n            </p>\n            <p class=\"practicedesc\">\n              For example, the Flash plugin's Local Shared Objects (LSOs) have often been used to duplicate and re-spawn HTTP cookies cleared by the user [<cite><a class=\"bibref\" href=\"#bib-flashcookies\">FLASHCOOKIES</a></cite>].\n            </p>\n          </div>\n          <p>Where features do require setting and retrieving local state, there are ways to mitigate the privacy impacts related to unexpected cookie-like behavior; in particular, you can help implementers prevent \"permanent\", \"zombie\", \"super\" or \"evercookies\".</p>\n          <div class=\"practice\">\n            <p>\n              <span id=\"mark-cookie-like\" class=\"practicelab\"><span class=\"practicetitle\">Best Practice 9</span>: Highlight any local state mechanisms to enable simultaneous clearing.</span>\n            </p>\n            <p class=\"practicedesc\">\n              Clearly note where state is being maintained and could be queried and provide guidance to implementers on enabling simultaneous deletion of local state for users. Such functionality can mitigate the threat of \"evercookies\"  because the presence of state in one such storage mechanism can't be used to persist and re-create an identifier.\n            </p>\n          </div>\n          <p>Permanent or persistent data (including any identifiers) are of particular risk because they undermine the ability for a user to clear or re-set the state of their device or to maintain different identities.</p>\n          <div class=\"practice\">\n            <p>\n              <span id=\"no-permanent\" class=\"practicelab\"><span class=\"practicetitle\">Best Practice 10</span>: Limit permanent or persistent state.</span>\n            </p>\n            <p class=\"practicedesc\">\n              Permanent identifiers or other state (for example, identifiers or keys set in hardware) should typically not be exposed. Where necessary, access to such identifiers would require user permission (however, explaining the implications of such permission to users may be difficult) and limitation to a particular origin (however, server-side collusion between origins will be difficult to detect).\n              As a result, your design should not rely on saving and later querying data on the client beyond a user's clearing cookies or other local state. That is, you should not expect any local state information to be permanent or to persist longer than other local state.\n            </p>\n          </div>\n          <p>Though not strictly browser fingerprinting, there are other privacy concerns regarding user tracking for features that provide local storage of data. Mitigations suggested in the Web Storage API specification include: white-listing, black-listing, expiration and secure deletion [<cite><a class=\"bibref\" href=\"#bib-webstorage-user-tracking\">WEBSTORAGE-user-tracking</a></cite>].</p>\n        </section>\n        <section id=\"do-not-track\"><h3 id=\"do_not_track_a_cooperative_approach\"><span class=\"secno\">6.5 </span>Do Not Track<a class=\"self-link\" aria-label=\"§\" href=\"#do-not-track\"></a></h3>\n          <p>Expressions of, and compliance with, a Do Not Track signal does not inhibit the capability of browser fingerprinting, but may mitigate some user concerns about fingerprinting, specifically around tracking as defined in those specifications [<cite><a class=\"bibref\" href=\"#bib-tracking-dnt\">TRACKING-DNT</a></cite>] [<cite><a class=\"bibref\" href=\"#bib-tracking-compliance\">TRACKING-COMPLIANCE</a></cite>] and as implemented by services that comply with those user preferences. That is, <abbr title=\"Do Not Track\">DNT</abbr> can mitigate concerns with cooperative sites.</p>\n          <p>The use of <abbr title=\"Do Not Track\">DNT</abbr> in this way typically does not require changes to other functional specifications. \n            If your specification expects a particular behavior upon receiving a particular <abbr title=\"Do Not Track\">DNT</abbr> signal, indicate that with a reference to [<cite><a class=\"bibref\" href=\"#bib-tracking-dnt\">TRACKING-DNT</a></cite>].\n            If your specification introduces a new communication channel that could be used for tracking, you might wish to define how a <abbr title=\"Do Not Track\">DNT</abbr> signal should be communicated.\n          </p>\n        </section>\n    </section>\n    \n    <section class=\"appendix\" id=\"research\">\n        <!--OddPage--><h2 id=\"a-research\"><span class=\"secno\">A. </span>Research<a class=\"self-link\" aria-label=\"§\" href=\"#research\"></a></h2>\n\n        <section id=\"browser-vendor-documentation\">\n          <h3 id=\"a-1-browser-vendor-documentation\"><span class=\"secno\">A.1 </span>Browser vendor documentation<a class=\"self-link\" aria-label=\"§\" href=\"#browser-vendor-documentation\"></a></h3>\n        \n        <p>Some browser developers maintain pages on browser fingerprinting, including: potential mitigations or modifications necessary to decrease the surface of that browser engine; different vectors that can be used for fingerprinting; potential future work. These are not cheery, optimistic documents.</p>\n        <ul>\n          <li>The Chromium Projects: <a href=\"https://sites.google.com/a/chromium.org/dev/Home/chromium-security/client-identification-mechanisms#TOC-Fingerprinting-prevention-and-detection-challenges\">Technical analysis of client identification mechanisms</a></li>\n          <li><a href=\"https://trac.webkit.org/wiki/Fingerprinting\">WebKit Wiki: Fingerprinting</a></li>\n          <li><a href=\"https://wiki.mozilla.org/Fingerprinting\">Mozilla Wiki: Fingerprinting</a></li>\n          <li><a href=\"https://www.torproject.org/projects/torbrowser/design/#fingerprinting-linkability\">The Design and Implementation of the Tor Browser: Cross-Origin Fingerprinting Unlinkability</a></li>\n        </ul>\n      </section>\n\n      <section id=\"academic-research\">\n        <h3 id=\"a-2-academic-research\"><span class=\"secno\">A.2 </span>Academic research<a class=\"self-link\" aria-label=\"§\" href=\"#academic-research\"></a></h3>        \n        <p>What are the key papers to read here, historically or to give the latest on fingerprinting techniques? What are some areas of open research that might be relevant?</p>\n        <ul>\n          <li>Eckersley, Peter. \"<a href=\"https://panopticlick.eff.org/static/browser-uniqueness.pdf\">How unique is your web browser?</a>\" <i>Privacy Enhancing Technologies</i>. Springer Berlin Heidelberg, 2010.</li>\n          <li>Mowery, Keaton, Dillon Bogenreif, Scott Yilek, and Hovav Shacham. “<a href=\"https://cseweb.ucsd.edu/~kmowery/papers/js-fingerprinting.pdf\">Fingerprinting Information in JavaScript Implementations</a>.” In <i>Web 2.0 Security and Privacy</i>, 2011.</li>\n          <li>Yen, Ting-Fang, et al. \"<a href=\"https://www.microsoft.com/en-us/research/publication/host-fingerprinting-and-tracking-on-the-webprivacy-and-security-implications/\">Host fingerprinting and tracking on the web: Privacy and security implications</a>.\" <em>Proceedings of NDSS</em>. 2012. [<cite><a class=\"bibref\" href=\"#bib-ndss-fingerprinting\">NDSS-FINGERPRINTING</a></cite>]</li>\n          <li>Mowery, Keaton, and Hovav Shacham. \"<a href=\"https://hovav.net/ucsd/dist/canvas.pdf\">Pixel perfect: Fingerprinting canvas in HTML5</a>.\" <i>Web 2.0 Security and Privacy</i>, 2012.</li>\n          <li id=\"wsj-orbitz\">Mattioli, Dana. \"<a href=\"https://www.wsj.com/articles/SB10001424052702304458604577488822667325882\">On Orbitz, Mac Users Steered to Pricier Hotels</a>\". <i>Wall Street Journal</i>, August 23, 2012.</li>\n          <li id=\"FPDetective\">Gunes Acar et al. \"<a href=\"https://dl.acm.org/citation.cfm?id=2516674\">FPDetective: dusting the web for fingerprinters</a>.\" In <i>CCS '13</i>.</li>\n          <li>Nikiforakis, Nick, et al. \"<a href=\"https://seclab.cs.ucsb.edu/media/uploads/papers/sp2013_cookieless.pdf\">Cookieless monster: Exploring the ecosystem of web-based device fingerprinting</a>.\" <i>IEEE Symposium on Security and Privacy (S&amp;P 2013)</i>, 2013.</li>\n          <li>G. Acar, C. Eubank, S. Englehardt, M. Juarez, A. Narayanan, C. Diaz. \"<a href=\"https://securehomes.esat.kuleuven.be/%7Egacar/persistent/\">The Web never forgets: Persistent tracking mechanisms in the wild</a>.\" In <i>Proceedings of CCS 2014</i>, Nov. 2014.</li>\n          <li>Steven Englehardt, Arvind Narayanan. \"<a href=\"https://webtransparency.cs.princeton.edu/webcensus/\">Online tracking: A 1-million-site measurement and analysis</a>.\" May 2016. [<cite><a class=\"bibref\" href=\"#bib-wpm-million\">WPM-MILLION</a></cite>]</li>\n          <li>Pierre Laperdrix, Walter Rudametkin, Benoit Baudry. \"<a href=\"https://hal.inria.fr/hal-01285470v2/\">Beauty and the Beast: Diverting modern web browsers to build unique browser fingerprints</a>.\" <i>IEEE Symposium on Security and Privacy (S&amp;P 2016)</i>, May 2016.</li>\n          <li>\n            \"<a href=\"https://hal.inria.fr/hal-01718234v2\">Hiding in the Crowd: an Analysis of the Effectiveness of Browser Fingerprinting at Large Scale</a>.\" <i>WWW2018 - TheWebConf 2018: 27th International World Wide Web Conference</i>, April 2018. [<cite><a class=\"bibref\" href=\"#bib-hiding-crowd\">HIDING-CROWD</a></cite>]\n          </li>\n        </ul>\n      </section>\n        <section id=\"testing\">\n        <h3 id=\"a-3-testing\"><span class=\"secno\">A.3 </span>Testing<a class=\"self-link\" aria-label=\"§\" href=\"#testing\"></a></h3>\n        <p>A non-exhaustive list of sites that allow the visitor to test their configuration for fingerprintability.</p>\n        <ul>\n          <li><a href=\"https://amiunique.org/\">amiunique.org</a> (INRIA)</li>\n          <li><a href=\"https://panopticlick.eff.org/\">panopticlick.eff.org</a> (EFF)</li>\n          <li><a href=\"https://browserspy.dk/\">BrowserSPY.dk</a></li>\n          <li><a href=\"https://fingerprint.pet-portal.eu/\">pet-portal cross-browser fingerprinting test</a></li>\n          <li><a href=\"http://lcamtuf.coredump.cx/p0f3/\">p0f v3</a> (purely passive fingerprinting)</li>\n        </ul>\n        </section>\n    </section>    \n    \n    <section class=\"appendix\" id=\"acknowledgements\">\n      <!--OddPage--><h2 id=\"b-acknowledgements\"><span class=\"secno\">B. </span>Acknowledgements<a class=\"self-link\" aria-label=\"§\" href=\"#acknowledgements\"></a></h2>\n      <p>\n        Many thanks to Robin Berjon for ReSpec and to Tobie Langel for Github advice; to the Privacy Interest Group and the Technical Architecture Group for review; to the Tor Browser designers for references and recommendations; and to Christine Runnegar for contributions.\n      </p>\n    </section>\n  \n\n<section id=\"references\" class=\"appendix\">\n      <!--OddPage--><h2 id=\"c-references\"><span class=\"secno\">C. </span>References<a class=\"self-link\" aria-label=\"§\" href=\"#references\"></a></h2>\n      \n    <section id=\"informative-references\">\n        <h3 id=\"c-1-informative-references\"><span class=\"secno\">C.1 </span>Informative references<a class=\"self-link\" aria-label=\"§\" href=\"#informative-references\"></a></h3>\n      <dl class=\"bibliography\">\n        <dt id=\"bib-battery-status\">[BATTERY-STATUS]</dt><dd><a href=\"https://www.w3.org/TR/battery-status/\"><cite>Battery Status API</cite></a>. Anssi Kostiainen; Mounir Lamouri. W3C. 7 July 2016. W3C Candidate Recommendation. URL: <a href=\"https://www.w3.org/TR/battery-status/\">https://www.w3.org/TR/battery-status/</a></dd><dt id=\"bib-beauty-beast\">[BEAUTY-BEAST]</dt><dd><a href=\"https://hal.inria.fr/hal-01285470v2/\"><cite>Beauty and the Beast: Diverting modern web browsers to build unique browser fingerprints</cite></a>. Pierre Laperdrix; Walter Rudametkin; Benoit Baudry. IEEE Symposium on Security and Privacy (S&amp;P 2016). May 2016. URL: <a href=\"https://hal.inria.fr/hal-01285470v2/\">https://hal.inria.fr/hal-01285470v2/</a></dd><dt id=\"bib-dap-privacy-reqs\">[dap-privacy-reqs]</dt><dd><a href=\"https://www.w3.org/TR/dap-privacy-reqs/\"><cite>Device API Privacy Requirements</cite></a>. Alissa Cooper; Frederick Hirsch; John Morris. W3C. 29 June 2010. W3C Note. URL: <a href=\"https://www.w3.org/TR/dap-privacy-reqs/\">https://www.w3.org/TR/dap-privacy-reqs/</a></dd><dt id=\"bib-evercookie\">[EVERCOOKIE]</dt><dd><a href=\"https://samy.pl/evercookie/\"><cite>evercookie - virtually irrevocable persistent cookies</cite></a>. Samy Kamkar.September 2010. URL: <a href=\"https://samy.pl/evercookie/\">https://samy.pl/evercookie/</a></dd><dt id=\"bib-flashcookies\">[FLASHCOOKIES]</dt><dd><a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1446862\"><cite>Flash Cookies and Privacy</cite></a>. Ashkan Soltani; Shannon Canty; Quentin Mayo; Lauren Thomas; Chris Jay Hoofnagle.10 August 2009. URL: <a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1446862\">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1446862</a></dd><dt id=\"bib-flashcookies-2\">[FLASHCOOKIES-2]</dt><dd><a href=\"https://ptolemy.berkeley.edu/projects/truststc/education/reu/11/Posters/AyensonMWambachDpaper.pdf\"><cite>Flash cookies and privacy II: Now with HTML5 and ETag respawning</cite></a>. Mika Ayenson; Dietrich Wambach; Ashkan Soltani; Nathan Good; Chris Hoofnagle.URL: <a href=\"https://ptolemy.berkeley.edu/projects/truststc/education/reu/11/Posters/AyensonMWambachDpaper.pdf\">https://ptolemy.berkeley.edu/projects/truststc/education/reu/11/Posters/AyensonMWambachDpaper.pdf</a></dd><dt id=\"bib-generic-sensor\">[generic-sensor]</dt><dd><a href=\"https://www.w3.org/TR/generic-sensor/\"><cite>Generic Sensor API</cite></a>. Mikhail Pozdnyakov; Alexander Shalamov; Tobie Langel. W3C. 7 March 2019. W3C Working Draft. URL: <a href=\"https://www.w3.org/TR/generic-sensor/\">https://www.w3.org/TR/generic-sensor/</a></dd><dt id=\"bib-hiding-crowd\">[HIDING-CROWD]</dt><dd><a href=\"https://hal.inria.fr/hal-01718234v2\"><cite>Hiding in the Crowd: an Analysis of the Effectiveness of Browser Fingerprinting at Large Scale</cite></a>. Alejandro Gómez-Boix; Pierre Laperdrix; Benoit Baudry. WWW2018 - TheWebConf2018: 27th International World Wide Web Conference. April 2018. URL: <a href=\"https://hal.inria.fr/hal-01718234v2\">https://hal.inria.fr/hal-01718234v2</a></dd><dt id=\"bib-html52\">[html52]</dt><dd><a href=\"https://www.w3.org/TR/html52/\"><cite>HTML 5.2</cite></a>. Steve Faulkner; Arron Eicholz; Travis Leithead; Alex Danilo; Sangwhan Moon. W3C. 14 December 2017. W3C Recommendation. URL: <a href=\"https://www.w3.org/TR/html52/\">https://www.w3.org/TR/html52/</a></dd><dt id=\"bib-httpbis-client-hints\">[httpbis-client-hints]</dt><dd><a href=\"https://httpwg.org/http-extensions/client-hints.html\"><cite>HTTP Client Hints</cite></a>. Ilya Grigorik. HTTP Working Group. January 2019. URL: <a href=\"https://httpwg.org/http-extensions/client-hints.html\">https://httpwg.org/http-extensions/client-hints.html</a></dd><dt id=\"bib-leaking-battery\">[LEAKING-BATTERY]</dt><dd><a href=\"https://eprint.iacr.org/2015/616.pdf\"><cite>The leaking battery: A privacy analysis of the HTML5 Battery Status API</cite></a>. Łukasz Olejnik; Gunes Acar; Claude Castelluccia; Claudia Diaz.2015. URL: <a href=\"https://eprint.iacr.org/2015/616.pdf\">https://eprint.iacr.org/2015/616.pdf</a></dd><dt id=\"bib-mediacapture-streams\">[mediacapture-streams]</dt><dd><a href=\"https://www.w3.org/TR/mediacapture-streams/\"><cite>Media Capture and Streams</cite></a>. Daniel Burnett; Adam Bergkvist; Cullen Jennings; Anant Narayanan; Bernard Aboba. W3C. 3 October 2017. W3C Candidate Recommendation. URL: <a href=\"https://www.w3.org/TR/mediacapture-streams/\">https://www.w3.org/TR/mediacapture-streams/</a></dd><dt id=\"bib-ndss-fingerprinting\">[NDSS-FINGERPRINTING]</dt><dd><a href=\"https://www.microsoft.com/en-us/research/publication/host-fingerprinting-and-tracking-on-the-webprivacy-and-security-implications/\"><cite>Host Fingerprinting and Tracking on the Web: Privacy and Security Implications</cite></a>. Ting-Fang Yen; Yinglian Xie; Fang Yu; Roger Peng Yu; Martin Abadi. In Proceedings of the Network and Distributed System Security Symposium (NDSS). February 2012. URL: <a href=\"https://www.microsoft.com/en-us/research/publication/host-fingerprinting-and-tracking-on-the-webprivacy-and-security-implications/\">https://www.microsoft.com/en-us/research/publication/host-fingerprinting-and-tracking-on-the-webprivacy-and-security-implications/</a></dd><dt id=\"bib-proximity\">[PROXIMITY]</dt><dd><a href=\"https://www.w3.org/TR/proximity/\"><cite>Proximity Sensor</cite></a>. Anssi Kostiainen; Rijubrata Bhaumik. W3C. 5 March 2019. W3C Working Draft. URL: <a href=\"https://www.w3.org/TR/proximity/\">https://www.w3.org/TR/proximity/</a></dd><dt id=\"bib-rfc6265\">[RFC6265]</dt><dd><a href=\"https://tools.ietf.org/html/rfc6265\"><cite>HTTP State Management Mechanism</cite></a>. A. Barth. IETF. April 2011. Proposed Standard. URL: <a href=\"https://tools.ietf.org/html/rfc6265\">https://tools.ietf.org/html/rfc6265</a></dd><dt id=\"bib-rfc6454\">[RFC6454]</dt><dd><a href=\"https://tools.ietf.org/html/rfc6454\"><cite>The Web Origin Concept</cite></a>. A. Barth. IETF. December 2011. Proposed Standard. URL: <a href=\"https://tools.ietf.org/html/rfc6454\">https://tools.ietf.org/html/rfc6454</a></dd><dt id=\"bib-rfc6973\">[RFC6973]</dt><dd><a href=\"https://www.rfc-editor.org/rfc/rfc6973.txt\"><cite>Privacy Considerations for Internet Protocols</cite></a>. A. Cooper; H. Tschofenig; B. Aboba; J. Peterson; J. Morris; M. Hansen; R. Smith. IETF. July 2013. RFC. URL: <a href=\"https://www.rfc-editor.org/rfc/rfc6973.txt\">https://www.rfc-editor.org/rfc/rfc6973.txt</a></dd><dt id=\"bib-rfc7231\">[RFC7231]</dt><dd><a href=\"https://tools.ietf.org/html/rfc7231\"><cite>Hypertext Transfer Protocol (HTTP/1.1): Semantics and Content</cite></a>. R. Fielding, Ed.; J. Reschke, Ed.. IETF. June 2014. Proposed Standard. URL: <a href=\"https://tools.ietf.org/html/rfc7231\">https://tools.ietf.org/html/rfc7231</a></dd><dt id=\"bib-security-privacy-questionnaire-tag\">[security-privacy-questionnaire-tag]</dt><dd><a href=\"https://w3ctag.github.io/security-questionnaire/\"><cite>Self-Review Questionnaire: Security and Privacy</cite></a>. Lukasz Olejnik; Jason Novak. W3C Technical Architecture Group. December 2018. URL: <a href=\"https://w3ctag.github.io/security-questionnaire/\">https://w3ctag.github.io/security-questionnaire/</a></dd><dt id=\"bib-tag-minimization\">[TAG-MINIMIZATION]</dt><dd><a href=\"https://www.w3.org/2001/tag/doc/APIMinimization\"><cite>Data Minimization in Web APIs</cite></a>. Daniel Appelquist. W3C Technical Architecture Group. 12 September 2011. URL: <a href=\"https://www.w3.org/2001/tag/doc/APIMinimization\">https://www.w3.org/2001/tag/doc/APIMinimization</a></dd><dt id=\"bib-tag-unsanctioned\">[TAG-UNSANCTIONED]</dt><dd><a href=\"https://w3ctag.github.io/unsanctioned-tracking/\"><cite>Unsanctioned Web Tracking</cite></a>. Mark Nottingham. W3C Technical Architecture Group. 17 July 2015. URL: <a href=\"https://w3ctag.github.io/unsanctioned-tracking/\">https://w3ctag.github.io/unsanctioned-tracking/</a></dd><dt id=\"bib-tor-design\">[TOR-DESIGN]</dt><dd><a href=\"https://www.torproject.org/projects/torbrowser/design/\"><cite>The Design and Implementation of the Tor Browser</cite></a>. Mike Perry; Erinn Clark; Steven Murdoch; Georg Koppen.15 June 2018. URL: <a href=\"https://www.torproject.org/projects/torbrowser/design/\">https://www.torproject.org/projects/torbrowser/design/</a></dd><dt id=\"bib-tracking-compliance\">[TRACKING-COMPLIANCE]</dt><dd><a href=\"https://www.w3.org/TR/tracking-compliance/\"><cite>Tracking Compliance and Scope</cite></a>. Nick Doty; Heather West; Justin Brookman; Sean Harvey; Erica Newland. W3C. 22 January 2019. W3C Note. URL: <a href=\"https://www.w3.org/TR/tracking-compliance/\">https://www.w3.org/TR/tracking-compliance/</a></dd><dt id=\"bib-tracking-dnt\">[TRACKING-DNT]</dt><dd><a href=\"https://www.w3.org/TR/tracking-dnt/\"><cite>Tracking Preference Expression (DNT)</cite></a>. Roy Fielding; David Singer. W3C. 17 January 2019. W3C Note. URL: <a href=\"https://www.w3.org/TR/tracking-dnt/\">https://www.w3.org/TR/tracking-dnt/</a></dd><dt id=\"bib-webstorage-user-tracking\">[WEBSTORAGE-user-tracking]</dt><dd><a href=\"https://www.w3.org/TR/2013/REC-webstorage-20130730/#user-tracking\"><cite>Web Storage &gt; Privacy &gt; User tracking</cite></a>. Ian Hickson. W3C. July 2013. Rec. URL: <a href=\"https://www.w3.org/TR/2013/REC-webstorage-20130730/#user-tracking\">https://www.w3.org/TR/2013/REC-webstorage-20130730/#user-tracking</a></dd><dt id=\"bib-wpm-million\">[WPM-MILLION]</dt><dd><a href=\"https://webtransparency.cs.princeton.edu/webcensus/\"><cite>Online tracking: A 1-million-site measurement and analysis</cite></a>. Steven Englehardt; Arvind Narayanan.May 2016. URL: <a href=\"https://webtransparency.cs.princeton.edu/webcensus/\">https://webtransparency.cs.princeton.edu/webcensus/</a></dd>\n      </dl></section></section><p role=\"navigation\" id=\"back-to-top\"><a href=\"#title\"><abbr title=\"Back to Top\">↑</abbr></a></p><script src=\"https://www.w3.org/scripts/TR/2016/fixup.js\"></script></body></html>\n","oembed":false,"readabilityObject":{"title":"Mitigating Browser Fingerprinting in Web Specifications","content":"<div id=\"readability-page-1\" class=\"page\">\n    <section id=\"abstract\"><h2>Abstract</h2>\n      Exposure of settings and characteristics of browsers can harm user privacy by allowing for browser fingerprinting. This document defines different types of fingerprinting, considers distinct levels of mitigation for the related privacy risks and provides guidance for Web specification authors on how to balance these concerns when designing new Web features.\n    </section>\n    <section id=\"sotd\"><h2>Status of This Document</h2><p><em>This section describes the status of this document at the time of its publication. Other documents may supersede this document. A list of current <abbr title=\"World Wide Web Consortium\">W3C</abbr> publications and the latest revision of this technical report can be found in the <a href=\"https://www.w3.org/TR/\"><abbr title=\"World Wide Web Consortium\">W3C</abbr> technical reports index</a> at https://www.w3.org/TR/.</em>\n      </p><p>\n\n            This document is an Interest Group Note providing best practices to Web specification\n            authors on mitigating the privacy impacts of browser fingerprinting.  It was developed\n            by the <a href=\"http://www.w3.org/Privacy/\"><abbr title=\"World Wide Web Consortium\">W3C</abbr> Privacy Interest Group (PING)</a> \n            in collaboration with\n\t    the <a href=\"http://www.w3.org/2001/tag/\"><abbr title=\"World Wide Web Consortium\">W3C</abbr> Technical Architecture Group</a> (<abbr title=\"Technical Architecture Group\">TAG</abbr>).\n            Since the last publication the list of best practices has been expanded and made\n            more specific, guidance has been provided on how to evaluate the severity of fingerprinting\n            surface, and additional references and examples have been provided. Constructive input of all\n            kinds is welcome. Send comments to the <a href=\"mailto:public-privacy@w3.org\">PING mailing list</a>\n\t    or <a href=\"https://github.com/w3c/fingerprinting-guidance/issues\">file issues in GitHub</a>.\n\n      </p><p data-deliverer=\"52497\">\n      Publication as an Interest Group Note does not imply endorsement by the\n      W3C Membership. The document may be updated, replaced or\n      obsoleted by other documents at any time.\n    </p><p>\n            The disclosure obligations of the Participants of this group are\n            described in the\n            <a href=\"https://www.w3.org/2011/07/privacy-ig-charter.html\">charter</a>.\n          \n    </p><p>\n                  This document is governed by the\n                  <a id=\"w3c_process_revision\" href=\"https://www.w3.org/2019/Process-20190301/\">1 March 2019 <abbr title=\"World Wide Web Consortium\">W3C</abbr> Process Document</a>.\n                </p></section><nav id=\"toc\"><h2 id=\"table-of-contents\">Table of Contents</h2><ol><li><a href=\"#browser-fingerprinting\"><span>1. </span>Browser fingerprinting</a><ol><li><a href=\"#what-is-fingerprinting\"><span>1.1 </span>What is fingerprinting?</a></li><li><a href=\"#privacy_threat_models\"><span>1.2 </span>Privacy impacts and threat models</a><ol><li><a href=\"#identify-a-user\"><span>1.2.1 </span>Identify a user</a></li><li><a href=\"#correlation-of-browsing-activity\"><span>1.2.2 </span>Correlation of browsing activity</a></li><li><a href=\"#tracking-without-transparency-or-user-control\"><span>1.2.3 </span>Tracking without transparency or user control</a></li></ol></li><li><a href=\"#what-can-we-do-about-it\"><span>1.3 </span>What can we do about it?</a></li></ol></li><li><a href=\"#bp-summary\"><span>2. </span>Best Practices Summary</a></li><li><a href=\"#types-of-fingerprinting\"><span>3. </span>Types of fingerprinting</a><ol><li><a href=\"#passive-0\"><span>3.1 </span>Passive</a></li><li><a href=\"#active-0\"><span>3.2 </span>Active</a></li><li><a href=\"#cookie-like\"><span>3.3 </span>Cookie-like</a></li></ol></li><li><a href=\"#feasibility\"><span>4. </span>Feasibility</a><ol><li><a href=\"#fingerprinting-mitigation-levels-of-success\"><span>4.1 </span>Fingerprinting mitigation levels of success</a></li><li><a href=\"#feasible-goals-for-specification-authors\"><span>4.2 </span>Feasible goals for specification authors</a></li></ol></li><li><a href=\"#identifying-fingerprinting-surface-and-evaluating-severity\"><span>5. </span>Identifying fingerprinting surface and evaluating severity</a></li><li><a href=\"#mitigations\"><span>6. </span>Mitigations</a><ol><li><a href=\"#weighing_increased_fingerprinting_surface\"><span>6.1 </span>Weighing increased fingerprinting surface</a></li><li><a href=\"#standardization\"><span>6.2 </span>Standardization</a></li><li><a href=\"#detectability\"><span>6.3 </span>Detectability</a></li><li><a href=\"#clearing-all-local-state\"><span>6.4 </span>Clearing all local state</a></li><li><a href=\"#do-not-track\"><span>6.5 </span>Do Not Track</a></li></ol></li><li><a href=\"#research\"><span>A. </span>Research</a><ol><li><a href=\"#browser-vendor-documentation\"><span>A.1 </span>Browser vendor documentation</a></li><li><a href=\"#academic-research\"><span>A.2 </span>Academic research</a></li><li><a href=\"#testing\"><span>A.3 </span>Testing</a></li></ol></li><li><a href=\"#acknowledgements\"><span>B. </span>Acknowledgements</a></li><li><a href=\"#references\"><span>C. </span>References</a><ol><li><a href=\"#informative-references\"><span>C.1 </span>Informative references</a></li></ol></li></ol></nav>\n    <section id=\"browser-fingerprinting\">\n      <!--OddPage--><h2 id=\"x1-browser-fingerprinting\"><span>1. </span>Browser fingerprinting<a aria-label=\"§\" href=\"#browser-fingerprinting\"></a></h2>\n        <section id=\"what-is-fingerprinting\">\n        <h3 id=\"x1-1-what-is-fingerprinting\"><span>1.1 </span>What is fingerprinting?<a aria-label=\"§\" href=\"#what-is-fingerprinting\"></a></h3>\n        <p>In short, <dfn id=\"dfn-browser-fingerprinting\" data-export=\"\" data-dfn-type=\"dfn\">browser fingerprinting</dfn> is the capability of a site to identify or re-identify a visiting user, user agent or device via configuration settings or other observable characteristics.</p>\n        <p>A similar definition is provided by [<cite><a href=\"#bib-rfc6973\">RFC6973</a></cite>]. A more detailed list of types of fingerprinting is included below. This document does not attempt to catalog all features currently used or usable for browser fingerprinting; however, <a href=\"#research\"><span>§&nbsp;A.</span> <span>Research</span></a> provides links to browser vendor pages and academic findings.</p>\n        </section>\n        <section id=\"privacy_threat_models\">\n        <h3 id=\"x1-2-privacy-impacts-and-threat-models\"><span>1.2 </span>Privacy impacts and threat models<a aria-label=\"§\" href=\"#privacy_threat_models\"></a></h3>\n\n        <p>Browser fingerprinting can be used as a security measure (e.g. as means of authenticating the user). However, fingerprinting is also a potential threat to users' privacy on the Web. This document does not attempt to provide a single unifying definition of \"privacy\" or \"personal data\", but we highlight how browser fingerprinting might impact users' privacy. For example, browser fingerprinting can be used to:</p>\n        <ul>\n          <li>identify a user</li>\n          <li>correlate a user’s browsing activity within and across sessions</li>\n          <li>track users without transparency or control</li>\n        </ul>\n\n        <p>The privacy implications associated with each use case are discussed below. Following from the practice of security threat model analysis, we note that there are distinct models of privacy threats for fingerprinting. Defenses against these threats differ, depending on the particular privacy implication and the threat model of the user.</p>\n\n        <section id=\"identify-a-user\">\n          <h4 id=\"x1-2-1-identify-a-user\"><span>1.2.1 </span>Identify a user<a aria-label=\"§\" href=\"#identify-a-user\"></a></h4>\n          <p>There are many reasons why users might wish to remain anonymous or unidentified online, including: concerns about surveillance, personal physical safety, and concerns about discrimination against them based on what they read or write when using the Web. When a browser fingerprint is correlated with identifying information (like an email address, a recognized given and sur-name, or a government-issued identifier), an application or service provider may be able to identify an otherwise pseudonymous user. The adversary and consequences of this threat will vary by the particular user and use case, but can include nation-state intelligence agencies and threats of violence or imprisonment.</p>\n        </section>\n        \n        <section id=\"correlation-of-browsing-activity\">\n          <h4 id=\"x1-2-2-correlation-of-browsing-activity\"><span>1.2.2 </span>Correlation of browsing activity<a aria-label=\"§\" href=\"#correlation-of-browsing-activity\"></a></h4>\n          <p>Browser fingerprinting raises privacy concerns even when offline identities are not implicated. Some users may be surprised or concerned that an online party can correlate multiple visits (on the same or different sites) to develop a profile or history of the user. This concern may be heightened because (see below) it may occur without the user's knowledge or consent and tools such as clearing cookies do not prevent further correlation.</p>\n          <p>Browser fingerprinting also allows for tracking across <a href=\"https://tools.ietf.org/html/rfc6454#section-4\">origins</a> [<cite><a href=\"#bib-rfc6454\">RFC6454</a></cite>]: different sites may be able to combine information about a single user even where a cookie policy would block accessing of cookies between origins, because the fingerprint is relatively unique and the same for all origins.</p>\n        </section>\n        \n        <section id=\"tracking-without-transparency-or-user-control\">\n          <h4 id=\"x1-2-3-tracking-without-transparency-or-user-control\"><span>1.2.3 </span>Tracking without transparency or user control<a aria-label=\"§\" href=\"#tracking-without-transparency-or-user-control\"></a></h4>\n          <p>\n            In contrast to other mechanisms defined by Web standards for maintaining state (e.g. cookies), browser fingerprinting allows for collection of data about user activity without clear indications that such collection is happening. Transparency can be important for end users, to understand how ongoing collection is happening, but it also enables researchers, policymakers and others to document or regulate privacy-sensitive activity. Browser fingerprinting also allows for tracking of activity without clear or effective user controls: a browser fingerprint typically cannot be cleared or re-set. (See the finding on unsanctioned tracking [<cite><a href=\"#bib-tag-unsanctioned\">TAG-UNSANCTIONED</a></cite>].)\n          </p>\n        </section>\n    </section>\n    <section id=\"what-can-we-do-about-it\">\n      <h3 id=\"x1-3-what-can-we-do-about-it\"><span>1.3 </span>What can we do about it?<a aria-label=\"§\" href=\"#what-can-we-do-about-it\"></a></h3>\n      <p>\n        Advances in techniques for browser fingerprinting (see <a href=\"#research\"><span>§&nbsp;A.</span> <span>Research</span></a>, below), particularly in <a href=\"#dfn-active-fingerprinting\" data-link-type=\"dfn\">active fingerprinting</a>, suggest that complete elimination of the capability of browser fingerprinting by a determined adversary through solely technical means that are widely deployed is implausible. However, mitigations in our technical specifications are possible, as described below (<a href=\"#mitigations\"><span>§&nbsp;6.</span> <span>Mitigations</span></a>), and may achieve different levels of success (<a href=\"#feasibility\"><span>§&nbsp;4.</span> <span>Feasibility</span></a>).\n      </p>\n      <p>\n        Mitigations recommended here are simply mitigations, not solutions. Users of the Web cannot confidently rely on sites being completely unable to correlate traffic, especially when executing client-side code. A fingerprinting surface extends across all implemented Web features for a particular user agent, and even to other layers of the stack; for example, differences in TCP connections. For example, a user might employ an onion routing system such as Tor to limit network-level linkability, but still face the risk of correlating Web-based activity through browser fingerprinting, or vice versa. In order to mitigate these privacy risks as a whole, fingerprinting must be considered during the design and development of all specifications.\n      </p>\n      <p>\n        The <abbr title=\"Technical Architecture Group\">TAG</abbr> finding on Unsanctioned Web Tracking, including browser fingerprinting, includes description of the limitations of technical measures and encourages minimizing and documenting new fingerprinting surface [<cite><a href=\"#bib-tag-unsanctioned\">TAG-UNSANCTIONED</a></cite>]. The best practices below detail common actions that authors of specifications for Web features can take to mitigate the privacy impacts of browser fingerprinting. The Self-Review Questionnaire documents mitigations of privacy impacts in Web features more generally that may complement these practices [<cite><a href=\"#bib-security-privacy-questionnaire-tag\">security-privacy-questionnaire-tag</a></cite>].\n      </p>\n    </section>\n    </section>\n    \n    <section id=\"bp-summary\"><!--OddPage--><h2 id=\"x2-best-practices-summary\"><span>2. </span>Best Practices Summary<a aria-label=\"§\" href=\"#bp-summary\"></a></h2><ul><li><a href=\"#avoid-passive-increases\">Best Practice 1</a>: Avoid unnecessary or severe increases to fingerprinting surface, especially for passive fingerprinting.</li><li><a href=\"#narrow-scope-availability\">Best Practice 2</a>: Narrow the scope and availability of a feature with fingerprinting surface to what is functionally necessary.</li><li><a href=\"#mark-fingerprinting\">Best Practice 3</a>: Mark features that contribute to fingerprintability.</li><li><a href=\"#specify-ordering\">Best Practice 4</a>: Specify orderings and non-functional differences.</li><li><a href=\"#api-minimization\">Best Practice 5</a>: Design APIs to access only the entropy necessary.</li><li><a href=\"#server-advertisement\">Best Practice 6</a>: Require servers to advertise or opt in to access data.</li><li><a href=\"#anticipate-disabled\">Best Practice 7</a>: Enable graceful degradation for privacy-conscious users or implementers.</li><li><a href=\"#no-new-cookies\">Best Practice 8</a>: Avoid unnecessary new local state mechanisms.</li><li><a href=\"#mark-cookie-like\">Best Practice 9</a>: Highlight any local state mechanisms to enable simultaneous clearing.</li><li><a href=\"#no-permanent\">Best Practice 10</a>: Limit permanent or persistent state.</li></ul></section>\n    \n    <section id=\"types-of-fingerprinting\">\n        <!--OddPage--><h2 id=\"types_of_fingerprinting\"><span>3. </span>Types of fingerprinting<a aria-label=\"§\" href=\"#types-of-fingerprinting\"></a></h2>\n        <section id=\"passive-0\">\n          <h3 id=\"passive\"><span>3.1 </span>Passive<a aria-label=\"§\" href=\"#passive-0\"></a></h3>\n          <p><dfn data-dfn-type=\"dfn\" id=\"dfn-passive-fingerprinting\">Passive fingerprinting</dfn> is browser fingerprinting based on characteristics observable in the contents of Web requests, without the use of any code executed on the client.</p>\n          <p>Passive fingerprinting would trivially include cookies (often unique identifiers sent in HTTP requests), the set of HTTP request headers and the IP address and other network-level information. The <a href=\"https://tools.ietf.org/html/rfc7231#section-5.5.3\">User-Agent string</a> [<cite><a href=\"#bib-rfc7231\">RFC7231</a></cite>], for example, is an HTTP request header that typically identifies the browser, renderer, version and operating system. For some populations, the User-Agent and IP address will often uniquely identify a particular user's browser [<cite><a href=\"#bib-ndss-fingerprinting\">NDSS-FINGERPRINTING</a></cite>].</p>\n        </section>\n        <section id=\"active-0\">\n          <h3 id=\"active\"><span>3.2 </span>Active<a aria-label=\"§\" href=\"#active-0\"></a></h3>\n          <p>For <dfn data-dfn-type=\"dfn\" id=\"dfn-active-fingerprinting\">active fingerprinting</dfn>, we also consider techniques where a site runs JavaScript or other code on the local client to observe additional characteristics about the browser, user, device or other context.</p>\n          <p>Techniques for active fingerprinting might include accessing the window size, enumerating fonts or plug-ins, evaluating performance characteristics, reading from device sensors, and rendering graphical patterns. Key to this distinction is that <a href=\"#dfn-active-fingerprinting\" data-link-type=\"dfn\">active fingerprinting</a> takes place in a way that is potentially detectable on the client.</p>\n        </section>\n        <section id=\"cookie-like\">\n          <h3 id=\"cookie_like_setting_retrieving_local_state\"><span>3.3 </span>Cookie-like<a aria-label=\"§\" href=\"#cookie-like\"></a></h3>\n          <p>Users, user agents and devices may also be re-identified by a site that first sets and later retrieves state stored by a user agent or device. This <dfn data-dfn-type=\"dfn\" id=\"dfn-cookie-like-fingerprinting\">cookie-like fingerprinting</dfn> allows re-identification of a user or inferences about a user in the same way that HTTP cookies allow state management for the stateless HTTP protocol [<cite><a href=\"#bib-rfc6265\">RFC6265</a></cite>].</p>\n          <p>Cookie-like fingerprinting can also circumvent user attempts to limit or clear cookies stored by the user agent, as demonstrated by the \"evercookie\" implementation [<cite><a href=\"#bib-evercookie\">EVERCOOKIE</a></cite>]. Where state is maintained across user agents (as in the case of common plugins with local storage), across devices (as in the case of certain browser syncing mechanisms) or across software upgrades, cookie-like fingerprinting can allow re-identification of users, user agents or devices where active and passive fingerprinting might not. The Security and Privacy Self-Review Questionnaire also considers this threat in origin state that persists across browsing sessions [<cite><a href=\"#bib-security-privacy-questionnaire-tag\">security-privacy-questionnaire-tag</a></cite>].</p>\n        </section>\n    </section>\n\n    <section id=\"feasibility\">\n      <!--OddPage--><h2 id=\"x4-feasibility\"><span>4. </span>Feasibility<a aria-label=\"§\" href=\"#feasibility\"></a></h2>\n      \n      <section id=\"fingerprinting-mitigation-levels-of-success\">\n          <h3 id=\"x4-1-fingerprinting-mitigation-levels-of-success\"><span>4.1 </span>Fingerprinting mitigation levels of success<a aria-label=\"§\" href=\"#fingerprinting-mitigation-levels-of-success\"></a></h3>\n          <p>There are different levels of success in mitigating browser fingerprinting:</p>\n          <dl>\n          <dt>Decreased fingerprinting surface</dt><dd>Removing the source of entropy or accessible attributes that can be used for fingerprinting.</dd>\n          <dt>Increased anonymity set</dt><dd>By standardization, convention or common implementation, increasing the commonality of particular configurations to decrease the likelihood of unique fingerprintability.</dd>\n          <dt>Detectable fingerprinting</dt><dd>Making fingerprinting observable to others, so that the user agent might block it or researchers can determine that it's happening.</dd>\n          <dt>Clearable local state</dt><dd>Helping users respond to fingerprinting by making state mechanisms clearable.</dd>\n          </dl>\n          <p>Research has shown feasible improvement in privacy protection in all of these areas. While lists of plugins remain a large fingerprinting surface, entropy has decreased over time with migration to Web APIs over plugins [<cite><a href=\"#bib-hiding-crowd\">HIDING-CROWD</a></cite>]. Collected data on Web users has shown mobile devices to have substantially larger anonymity sets than desktop browsers [<cite><a href=\"#bib-hiding-crowd\">HIDING-CROWD</a></cite>]. Research on forms of active fingerprinting has documented its use and demonstrated changes in use of those techniques as an apparent result of increased awareness [<cite><a href=\"#bib-wpm-million\">WPM-MILLION</a></cite>]. Respawning of cookies has continued, with an increasing variety of techniques, but awareness and technical responses to the issue has made the practice less widespread [<cite><a href=\"#bib-flashcookies-2\">FLASHCOOKIES-2</a></cite>].</p>\n      </section>\n      <section id=\"feasible-goals-for-specification-authors\">\n        <h3 id=\"x4-2-feasible-goals-for-specification-authors\"><span>4.2 </span>Feasible goals for specification authors<a aria-label=\"§\" href=\"#feasible-goals-for-specification-authors\"></a></h3>\n        <p>\n          This document works under the expectation that mitigations with different levels of success are feasible under different circumstances, for different threat models and against different types of fingerprinting. In general, active fingerprinting may be made detectable; we can minimize increases to the surface of passive fingerprinting; and cookie-like mechanisms can be made clearable.</p>\n        <p>\n          Some implementers and some users may be willing to accept reduced functionality or decreased performance in order to minimize browser fingerprinting. Documenting which features have fingerprinting risk eases the work of implementers building modes for these at-risk users; minimizing fingerprinting even in cases where common implementations will have easy active fingerprintability allows such users to reduce the functionality trade-offs necessary. Making browser fingerprinting more detectable also contributes to mitigations outside the standardization process; for example, though regulatory or policy means [<cite><a href=\"#bib-tag-unsanctioned\">TAG-UNSANCTIONED</a></cite>].\n        </p>\n      </section>\n    </section>\n    <section id=\"identifying-fingerprinting-surface-and-evaluating-severity\">\n      <!--OddPage--><h2 id=\"identifying\"><span>5. </span>Identifying fingerprinting surface and evaluating severity<a aria-label=\"§\" href=\"#identifying-fingerprinting-surface-and-evaluating-severity\"></a></h2>      \n\n      <p>To mitigate browser fingerprinting in your specification:</p>\n      <ol>\n        <li>identify features that can be used for browser fingerprinting;</li>\n        <li>evaluate the severity of the fingerprinting surface based on <a href=\"#severity-list\">these five factors</a>; and,</li>\n        <li>apply mitigations described in the best practices below (<a href=\"#mitigations\"><span>§&nbsp;6.</span> <span>Mitigations</span></a>), focused on limiting the severity of that fingerprinting surface.</li>\n      </ol>\n        \n      <p>The <dfn id=\"dfn-fingerprinting-surface\" data-export=\"\" data-dfn-type=\"dfn\">fingerprinting surface</dfn> of a user agent is the set of observable characteristics that can be used in concert to identify a user, user agent or device or correlate its activity.</p>\n\n      <p>Data sources that may be used for browser fingerprinting include:</p>\n      <ul>\n        <li>user configuration</li>\n        <li>device characteristics</li>\n        <li>environmental characteristics <em>(e.g. sensor readings)</em></li>\n        <li>operating system characteristics</li>\n        <li>user behavior</li>\n        <li>browser characteristics</li>\n      </ul>\n\n      <p>These data sources may be accessed directly for some features, but in many other cases they are inferred through some other observation. Timing channels, in particular, are commonly used to infer details of hardware (exactly how quickly different operations are completed may provide information on GPU capability, say), network information (via the latency or speed in loading a particular resource) or even user configuration (what items have been previously cached or what resources are not loaded). Consider the side effects of feature and how those side effects would allow inferences of any of these characteristics.</p>\n\n      <p>The <a href=\"https://www.torproject.org/projects/torbrowser/design/#fingerprinting-linkability\">Tor Browser design document</a> [<cite><a href=\"#bib-tor-design\">TOR-DESIGN</a></cite>] has more details on these sources and their relative priorities; this document adds environmental characteristics in that sensor readings or data access may distinguish a user, user agent or device by information about the environment (location, for example).</p>\n\n      <p id=\"severity-list\">For each identified feature, consider the severity for the privacy impacts described above (<a href=\"#privacy_threat_models\"><span>§&nbsp;1.2</span> <span>Privacy impacts and threat models</span></a>) based on the following factors:</p>\n\n      <dl>\n        <dt>entropy</dt><dd>How distinguishing is this new surface? Consider both the possible variations and the likely distribution of values. Adding 1-bit of entropy is typically of less concern; 30-some bits of entropy would be enough to uniquely identify every individual person. Different data sources may provide different distributions of variation; for example, some characteristics may reveal a common hardware class while other characteristics may reveal user configurations that vary between individual people.</dd>\n        <dt>detectability</dt><dd>Will use of this feature for browser fingerprinting be observable to the user agent or likely to be discoverable by researchers? Because detectability is an important — and perhaps the most feasible — mitigation, increases to the surface for <a href=\"#dfn-passive-fingerprinting\" data-link-type=\"dfn\">passive fingerprinting</a> are of particular concern and should be avoided.</dd>\n        <dt>persistence</dt><dd>How long will the characteristics of this fingerprinting surface stay unchanged? Can users control or re-set these values to prevent long-lived identification? While short-lived characteristics may still enable unexpected correlation of activity (for example, between two browser profiles on the same device), persistent or permanent identifiers are particularly concerning for the lack of user control.</dd>\n        <dt>availability</dt><dd>Will this surface be accessible to the \"drive-by Web\" or only in certain contexts where a user has granted a particular sensor permission or directly authenticated? While browser fingerprinting is still something to mitigate in the permissioned context, the concern that a feature will end up used primarily for fingerprinting is reduced.</dd>\n        <dt>scope</dt><dd>Is this surface consistent across origins or only within a single origin? In general, characteristics or identifiers that are tied to a particular origin are of less concern and can be handled with the same tools as HTTP cookies.</dd>\n      </dl>\n\n      <p>While we do not recommend specific trade-offs, these factors can be used to weigh increases to that surface (<a href=\"#weighing_increased_fingerprinting_surface\"><span>§&nbsp;6.1</span> <span>Weighing increased fingerprinting surface</span></a>) and suggest appropriate mitigations. Although each factor may suggest specific mitigations, in weighing whether to add <a href=\"#dfn-fingerprinting-surface\" data-link-type=\"dfn\">fingerprinting surface</a> they should be considered in concert. For example, access to a new set of characteristics about the user may be high entropy, but be of less concern because it has limited availability and is easily detectable. A cross-origin, drive-by-accessible, permanent, passive unique identifier is incompatible with our expectations for privacy on the Web.</p>\n\n      <p>In conducting this analysis, it may be tempting to dismiss certain fingerprinting surface in a specification because of a comparison to fingerprinting surface exposed by other parts of the Web platform or other layers of the stack. Be cautious about making such claims. First, while similar information may be available through other means, similar is not identical: information disclosures may not be exactly the same and fingerprintability is promoted by combining these distinct sources. Second, where identical entropy is present, other factors of severity or accessibility may differ and those factors are important for feasible mitigation. Third, the platform is neither monolithic nor static; not all other features are implemented in all cases and may change (or be removed) in the future. Fourth, circular dependencies are a danger when so many new features are under development; two specifications sometimes refer to one another in arguing that fingerprinting surface already exists. It is more useful to reviewers and implementers to consider the fingerprinting surface provided by the particular Web feature itself, with specific references where surface may be accessible through other features as well.</p>\n\n    </section>\n    <section id=\"mitigations\">\n        <!--OddPage--><h2 id=\"x6-mitigations\"><span>6. </span>Mitigations<a aria-label=\"§\" href=\"#mitigations\"></a></h2>\n        <section id=\"weighing_increased_fingerprinting_surface\">\n          <h3 id=\"x6-1-weighing-increased-fingerprinting-surface\"><span>6.1 </span>Weighing increased fingerprinting surface<a aria-label=\"§\" href=\"#weighing_increased_fingerprinting_surface\"></a></h3>\n          <p>Web specification authors regularly attempt to strike a balance between new functionality and fingerprinting surface. For example, feature detection functionality allows for progressive enhancement with a small addition to fingerprinting surface; detailed enumerations of plugins, fonts, connected devices may provide a large fingerprinting surface with minimal functional support.</p>\n          <p>Authors and Working Groups determine the appropriate balance between these properties on a case-by-case basis, given their understanding of the functionality, its implementations and the severity of increased fingerprinting surface. However, given the distinct privacy impacts described above and in order to improve consistency across specifications, these practices provide some guidance:</p>\n          \n          <div>\n            <p>\n              <span id=\"avoid-passive-increases\"><span>Best Practice 1</span>: Avoid unnecessary or severe increases to fingerprinting surface, especially for passive fingerprinting.</span>\n            </p>\n            <p>\n              Consider each of the <a href=\"#severity-list\">severity factors</a> described above and whether that functionality is necessary and whether comparable functionality is feasible with less severe increases to the fingerprinting surface.\n            </p>\n            <p>\n              In particular, unless a feature cannot reasonably be designed in any other way, increased passive fingerprintability should be avoided. Passive fingerprinting allows for easier and widely-available identification, without opportunities for external detection or control by users or third parties.\n            </p>\n          </div>\n\n          <div>\n            <p>\n              <span id=\"narrow-scope-availability\"><span>Best Practice 2</span>: Narrow the scope and availability of a feature with fingerprinting surface to what is functionally necessary.</span>\n            </p>\n            <p>\n              What browsing contexts, resources and requests need access to a particular feature?  Identifiers can often be scoped to have a different value in different origins. Some configuration may only be necessary in top-level browsing contexts.\n            </p>\n            <p>\n              Should access to this functionality be limited to where users have granted a particular permission? While excessive permissions can create confusion and fatigue, limiting highly granular data to situations where a user has already granted permission to access sensitive data widely mitigates the risk of that feature being used primarily for browser fingerprinting in \"drive-by\" contexts. For example, Media Capture and Streams [<cite><a href=\"#bib-mediacapture-streams\">mediacapture-streams</a></cite>] limits access to attached microphone and camera device labels to when the user has granted permission to access a camera or microphone (while still allowing access to the number and configuration of attached cameras and microphones in all contexts, a noted increase in drive-by fingerprinting surface).\n            </p>\n          </div>\n\n          <p>Some implementations may also limit the entropy of fingerprinting surface by not exposing different capabilities for different devices or installations of a user agent. Font lists, for example, can be limited to a whitelist commonly available on all devices that run a particular browser or operating system (as implemented in Tor Browser, Firefox and Safari).</p>\n          \n          <div>\n            <p>\n              <span id=\"mark-fingerprinting\"><span>Best Practice 3</span>: Mark features that contribute to fingerprintability.</span>\n            </p>\n            <p>\n              <img src=\"https://www.w3.org/TR/html5/images/fingerprint.png\" alt=\"This feature may contribute to browser fingerprintability.\" height=\"21\" width=\"15\">\n              Where a feature does contribute to the <a href=\"#dfn-fingerprinting-surface\" data-link-type=\"dfn\">fingerprinting surface</a>, indicate that impact, by explaining the effect (and any known implementer mitigations) and marking the relevant section with a fingerprinting icon, as this paragraph is.            \n            </p>\n          </div>\n          <div><p>\n            The following code can be used to mark a paragraph with the fingerprint icon.\n            </p><pre aria-busy=\"false\"><code>&lt;img src=<span>\"https://www.w3.org/TR/html5/images/fingerprint.png\"</span> \n     <span><span>class</span></span>=<span>\"fingerprint\"</span> \n     alt=<span>\"This feature may contribute to browser fingerprintability.\"</span>&gt;</code></pre>\n          </div>\n        </section>\n        <section id=\"standardization\">\n\t\t\t<h3 id=\"a_standardized_profile\"><span>6.2 </span>Standardization<a aria-label=\"§\" href=\"#standardization\"></a></h3>\n\t\t\t<p>\n        Specifications can mitigate against fingerprintability through standardization; by defining a consistent behavior, conformant implementations won't have variations that can be used for browser fingerprinting.\n\t\t\t</p>\n      <p>\n        Randomization of certain browser characteristics has been proposed as a way to combat browser fingerprinting. While this strategy may be pursued by some implementations, we expect in general it will be more effective for us to standardize or null values rather than setting a range over which they can vary. The Tor Browser design [<cite><a href=\"#bib-tor-design\">TOR-DESIGN</a></cite>] provides more detailed information, but in short: it's difficult to measure how well randomization will work as a mitigation and it can be costly to implement in terms of usability (varying functionality or design in unwanted ways), processing (generating random numbers) and development (including the cost of introducing new security vulnerabilities). Standardization provides the benefit of an increased anonymity set for conformant browsers with the same configuration: that is, an individual can look the same as a larger group of people rather than trying to look like a number of different individuals.\n      </p>\n      <div>\n        <p>\n          <span id=\"specify-ordering\"><span>Best Practice 4</span>: Specify orderings and non-functional differences.</span>\n        </p>\n        <p>\n          To reduce unnecessary entropy, specify aspects of API return values and behavior that don't contribute to functional differences. For example, if the ordering of return values in a list has no semantic value, specify a particular ordering (alphabetical order by a defined algorithm, for example) so that incidental differences don't expose fingerprinting surface.\n        </p>\n        <p>\n          Access to a list of system fonts via Flash or Java plugins notably returns the list sorted not in a standard alphabetical order, but in an unspecified order specific to the system. This ordering adds to the entropy available from that plugin in a way that provides no functional advantage. (See <a href=\"https://trac.webkit.org/wiki/Fingerprinting#ii.CollectingSystemFontsviaFlashPlugins\">Collecting System Fonts via Flash Plugins</a>.)\n        </p>\n      </div>\n      <p>\n        Standardization does <em>not</em> need to attempt to hide all differences between different browsers (e.g. Edge and Chrome); implemented functionality and behavior differences will always exist between different implementations. For that reason, removing <code>User-Agent</code> headers altogether is not a goal. However, variation in the <code>User-Agent</code> string that reveals additional information about the user or device has been shown to provide substantial fingerprinting surface [<cite><a href=\"#bib-beauty-beast\">BEAUTY-BEAST</a></cite>].\n      </p>\n\t\t</section>\n        <section id=\"detectability\">\n          <h3 id=\"x6-3-detectability\"><span>6.3 </span>Detectability<a aria-label=\"§\" href=\"#detectability\"></a></h3>\n          <p>Where a client-side API provides some fingerprinting surface, authors can still mitigate the privacy concerns via detectability. If client-side fingerprinting activity is to some extent distinguishable from functional use of APIs, user agent implementations may have an opportunity to prevent ongoing fingerprinting or make it observable to users and external researchers (including academics or relevant regulators) who may be able to detect and investigate the use of fingerprinting.</p>\n          \n          <div>\n            <p>\n              <span id=\"api-minimization\"><span>Best Practice 5</span>: Design APIs to access only the entropy necessary.</span>\n            </p>\n            <p>\n              Following the basic principle of <a href=\"https://tools.ietf.org/html/rfc6973#section-6.1\">data minimization</a> [<cite><a href=\"#bib-rfc6973\">RFC6973</a></cite>], design your APIs such that a site can access (and does access by default) only the entropy necessary for particular functionality.\n            </p>\n            <p>\n              Authors might design an API to allow for querying of a particular value, rather than returning an enumeration of all values. User agents and researchers can then more easily distinguish between sites that query for one or two particular values (gaining minimal entropy) and those that query for all values (more likely attempting to fingerprint the browser); or implementations can cap the number of different values. For example, Tor Browser limits the number of fonts that can be queried with a <code>browser.display.max_font_attempts</code> preference.\n            </p>\n            <p>\n              The granularity or precision of information returned can be minimized in order to reduce entropy. For example, implementations of the Battery Status API [<cite><a href=\"#bib-battery-status\">BATTERY-STATUS</a></cite>] allowed for high precision (double-precision, or 15-17 significant digits) readings of the current battery level, which provided a short-term identifier that could be used to correlate traffic across origins or clearance of local state. Rounding off values to lower precision mitigates browser fingerprinting while maintaining functional use cases. Alternatively, providing Boolean or a small enumeration of values might provide functionality without revealing underlying details; for example, the Boolean <code>near</code> property in the Proximity Sensor API [<cite><a href=\"#bib-proximity\">PROXIMITY</a></cite>].\n            </p>\n            <p>\n              For more information, see:\n            </p>\n            <ul>\n              <li><a href=\"https://www.w3.org/TR/dap-privacy-reqs/\">Device API Privacy Requirements</a> [<cite><a href=\"#bib-dap-privacy-reqs\">dap-privacy-reqs</a></cite>], <abbr title=\"Device APIs Working Group\">DAP</abbr> Working Group Note, June 2010.</li>\n              <li><a href=\"https://www.w3.org/2001/tag/doc/APIMinimization\">Data Minimization in Web APIs</a> [<cite><a href=\"#bib-tag-minimization\">TAG-MINIMIZATION</a></cite>], <abbr title=\"World Wide Web Consortium\">W3C</abbr> <abbr title=\"Technical Architecture Group\">TAG</abbr>, September 2011.</li>\n              <li><a href=\"https://www.w3.org/TR/generic-sensor/#security-and-privacy\">Generic Sensor API: Security and privacy considerations</a> [<cite><a href=\"#bib-generic-sensor\">generic-sensor</a></cite>], March 2018.</li>\n              <li><a href=\"https://eprint.iacr.org/2015/616.pdf\">The leaking battery: A privacy analysis of the HTML5 Battery Status API</a> [<cite><a href=\"#bib-leaking-battery\">LEAKING-BATTERY</a></cite>], 2015.</li>\n            </ul>\n          </div>\n          <p>\n            Related, detectability is improved even with data sent in HTTP headers (what we would typically consider passive fingerprinting) if sites are required to request access (or \"opt in\") to information before it's sent.\n          </p>\n          <div>\n              <p>\n                <span id=\"server-advertisement\"><span>Best Practice 6</span>: Require servers to advertise or opt in to access data.</span>\n              </p>\n              <p>\n                Even for data sent in HTTP request headers, requiring servers to advertise use of particular data, publicly document a policy, or \"opt in\" before clients send configuration data provides the possibility of detection by user agents or researchers.\n              </p>\n              <p>\n                For example, Client Hints [<cite><a href=\"#bib-httpbis-client-hints\">httpbis-client-hints</a></cite>] proposes an <code>Accept-CH</code> response header for services to indicate that specific hints can be used for content negotiation, rather than all supporting clients sending all hints in all requests.\n              </p>\n              <div role=\"note\" id=\"issue-container-generatedID\"><p><span>Note</span></p><p>\n                This is a relatively new approach; we're still evaluating whether this provides meaningful and useful detectability.\n              </p></div>\n          </div>\n\n          <p>\n            Implementers can facilitate detectability by providing or enabling instrumentation so that users or third parties are able to calculate when fingerprinting surface is being accessed. Of particular importance for instrumentation are: access to all the different sources of fingerprinting surface; identification of the originating script; avoiding exposure that instrumentation is taking place. Beyond the minimization practice described above, these are largely implementation-specific (rather than Web specification) features.\n          </p>\n          <p>\n            If your specification exposes some fingerprinting surface (whether it's active or passive), some implementers (e.g. Tor Browser) are going to be compelled to disable those features for certain privacy-conscious users.\n          </p>\n          <div>\n            <p>\n              <span id=\"anticipate-disabled\"><span>Best Practice 7</span>: Enable graceful degradation for privacy-conscious users or implementers.</span>\n            </p>\n            <p>\n              Following the principle of progressive enhancement, and to avoid further divergence (which might itself expose variation in users), consider whether some functionality in your specification is still possible if fingerprinting surface features are disabled. \n            </p>\n            <p>\n              Explicit hooks or API flags may be used so that browser extensions or certain user agents can easily disable specific features. For example, the <a href=\"https://www.w3.org/TR/html52/semantics-scripting.html#canvas-origin-clean\">origin-clean flag</a> [<cite><a href=\"#bib-html52\">html52</a></cite>] allows control over whether an image canvas can be read, a significant fingerprinting surface.\n            </p>\n          </div>     \n        </section>\n        <section id=\"clearing-all-local-state\">\n          <h3 id=\"x6-4-clearing-all-local-state\"><span>6.4 </span>Clearing all local state<a aria-label=\"§\" href=\"#clearing-all-local-state\"></a></h3>\n          <p>Features which enable storage of data on the client and functionality for client- or server-side querying of that data can increase the ease of cookie-like fingerprinting. Storage can vary between large amounts of data (for example, the Web Storage API) or just a binary flag (has or has not provided a certain permission; has or has not cached a single resource).</p>\n          <div>\n            <p>\n              <span id=\"no-new-cookies\"><span>Best Practice 8</span>: Avoid unnecessary new local state mechanisms.</span>\n            </p>\n            <p>\n              If functionality does not require maintaining client-side state in a way that is subsequently queryable (or otherwise observable), avoid creating a new cookie-like feature. Can the functionality be accomplished with existing HTTP cookies or an existing JavaScript local storage API?\n            </p>\n            <p>\n              For example, the Flash plugin's Local Shared Objects (LSOs) have often been used to duplicate and re-spawn HTTP cookies cleared by the user [<cite><a href=\"#bib-flashcookies\">FLASHCOOKIES</a></cite>].\n            </p>\n          </div>\n          <p>Where features do require setting and retrieving local state, there are ways to mitigate the privacy impacts related to unexpected cookie-like behavior; in particular, you can help implementers prevent \"permanent\", \"zombie\", \"super\" or \"evercookies\".</p>\n          <div>\n            <p>\n              <span id=\"mark-cookie-like\"><span>Best Practice 9</span>: Highlight any local state mechanisms to enable simultaneous clearing.</span>\n            </p>\n            <p>\n              Clearly note where state is being maintained and could be queried and provide guidance to implementers on enabling simultaneous deletion of local state for users. Such functionality can mitigate the threat of \"evercookies\"  because the presence of state in one such storage mechanism can't be used to persist and re-create an identifier.\n            </p>\n          </div>\n          <p>Permanent or persistent data (including any identifiers) are of particular risk because they undermine the ability for a user to clear or re-set the state of their device or to maintain different identities.</p>\n          <div>\n            <p>\n              <span id=\"no-permanent\"><span>Best Practice 10</span>: Limit permanent or persistent state.</span>\n            </p>\n            <p>\n              Permanent identifiers or other state (for example, identifiers or keys set in hardware) should typically not be exposed. Where necessary, access to such identifiers would require user permission (however, explaining the implications of such permission to users may be difficult) and limitation to a particular origin (however, server-side collusion between origins will be difficult to detect).\n              As a result, your design should not rely on saving and later querying data on the client beyond a user's clearing cookies or other local state. That is, you should not expect any local state information to be permanent or to persist longer than other local state.\n            </p>\n          </div>\n          <p>Though not strictly browser fingerprinting, there are other privacy concerns regarding user tracking for features that provide local storage of data. Mitigations suggested in the Web Storage API specification include: white-listing, black-listing, expiration and secure deletion [<cite><a href=\"#bib-webstorage-user-tracking\">WEBSTORAGE-user-tracking</a></cite>].</p>\n        </section>\n        <section id=\"do-not-track\"><h3 id=\"do_not_track_a_cooperative_approach\"><span>6.5 </span>Do Not Track<a aria-label=\"§\" href=\"#do-not-track\"></a></h3>\n          <p>Expressions of, and compliance with, a Do Not Track signal does not inhibit the capability of browser fingerprinting, but may mitigate some user concerns about fingerprinting, specifically around tracking as defined in those specifications [<cite><a href=\"#bib-tracking-dnt\">TRACKING-DNT</a></cite>] [<cite><a href=\"#bib-tracking-compliance\">TRACKING-COMPLIANCE</a></cite>] and as implemented by services that comply with those user preferences. That is, <abbr title=\"Do Not Track\">DNT</abbr> can mitigate concerns with cooperative sites.</p>\n          <p>The use of <abbr title=\"Do Not Track\">DNT</abbr> in this way typically does not require changes to other functional specifications. \n            If your specification expects a particular behavior upon receiving a particular <abbr title=\"Do Not Track\">DNT</abbr> signal, indicate that with a reference to [<cite><a href=\"#bib-tracking-dnt\">TRACKING-DNT</a></cite>].\n            If your specification introduces a new communication channel that could be used for tracking, you might wish to define how a <abbr title=\"Do Not Track\">DNT</abbr> signal should be communicated.\n          </p>\n        </section>\n    </section>\n    \n    <section id=\"research\">\n        <!--OddPage--><h2 id=\"a-research\"><span>A. </span>Research<a aria-label=\"§\" href=\"#research\"></a></h2>\n\n        <section id=\"browser-vendor-documentation\">\n          <h3 id=\"a-1-browser-vendor-documentation\"><span>A.1 </span>Browser vendor documentation<a aria-label=\"§\" href=\"#browser-vendor-documentation\"></a></h3>\n        \n        <p>Some browser developers maintain pages on browser fingerprinting, including: potential mitigations or modifications necessary to decrease the surface of that browser engine; different vectors that can be used for fingerprinting; potential future work. These are not cheery, optimistic documents.</p>\n        <ul>\n          <li>The Chromium Projects: <a href=\"https://sites.google.com/a/chromium.org/dev/Home/chromium-security/client-identification-mechanisms#TOC-Fingerprinting-prevention-and-detection-challenges\">Technical analysis of client identification mechanisms</a></li>\n          <li><a href=\"https://trac.webkit.org/wiki/Fingerprinting\">WebKit Wiki: Fingerprinting</a></li>\n          <li><a href=\"https://wiki.mozilla.org/Fingerprinting\">Mozilla Wiki: Fingerprinting</a></li>\n          <li><a href=\"https://www.torproject.org/projects/torbrowser/design/#fingerprinting-linkability\">The Design and Implementation of the Tor Browser: Cross-Origin Fingerprinting Unlinkability</a></li>\n        </ul>\n      </section>\n\n      <section id=\"academic-research\">\n        <h3 id=\"a-2-academic-research\"><span>A.2 </span>Academic research<a aria-label=\"§\" href=\"#academic-research\"></a></h3>        \n        <p>What are the key papers to read here, historically or to give the latest on fingerprinting techniques? What are some areas of open research that might be relevant?</p>\n        <ul>\n          <li>Eckersley, Peter. \"<a href=\"https://panopticlick.eff.org/static/browser-uniqueness.pdf\">How unique is your web browser?</a>\" <i>Privacy Enhancing Technologies</i>. Springer Berlin Heidelberg, 2010.</li>\n          <li>Mowery, Keaton, Dillon Bogenreif, Scott Yilek, and Hovav Shacham. “<a href=\"https://cseweb.ucsd.edu/~kmowery/papers/js-fingerprinting.pdf\">Fingerprinting Information in JavaScript Implementations</a>.” In <i>Web 2.0 Security and Privacy</i>, 2011.</li>\n          <li>Yen, Ting-Fang, et al. \"<a href=\"https://www.microsoft.com/en-us/research/publication/host-fingerprinting-and-tracking-on-the-webprivacy-and-security-implications/\">Host fingerprinting and tracking on the web: Privacy and security implications</a>.\" <em>Proceedings of NDSS</em>. 2012. [<cite><a href=\"#bib-ndss-fingerprinting\">NDSS-FINGERPRINTING</a></cite>]</li>\n          <li>Mowery, Keaton, and Hovav Shacham. \"<a href=\"https://hovav.net/ucsd/dist/canvas.pdf\">Pixel perfect: Fingerprinting canvas in HTML5</a>.\" <i>Web 2.0 Security and Privacy</i>, 2012.</li>\n          <li id=\"wsj-orbitz\">Mattioli, Dana. \"<a href=\"https://www.wsj.com/articles/SB10001424052702304458604577488822667325882\">On Orbitz, Mac Users Steered to Pricier Hotels</a>\". <i>Wall Street Journal</i>, August 23, 2012.</li>\n          <li id=\"FPDetective\">Gunes Acar et al. \"<a href=\"https://dl.acm.org/citation.cfm?id=2516674\">FPDetective: dusting the web for fingerprinters</a>.\" In <i>CCS '13</i>.</li>\n          <li>Nikiforakis, Nick, et al. \"<a href=\"https://seclab.cs.ucsb.edu/media/uploads/papers/sp2013_cookieless.pdf\">Cookieless monster: Exploring the ecosystem of web-based device fingerprinting</a>.\" <i>IEEE Symposium on Security and Privacy (S&amp;P 2013)</i>, 2013.</li>\n          <li>G. Acar, C. Eubank, S. Englehardt, M. Juarez, A. Narayanan, C. Diaz. \"<a href=\"https://securehomes.esat.kuleuven.be/%7Egacar/persistent/\">The Web never forgets: Persistent tracking mechanisms in the wild</a>.\" In <i>Proceedings of CCS 2014</i>, Nov. 2014.</li>\n          <li>Steven Englehardt, Arvind Narayanan. \"<a href=\"https://webtransparency.cs.princeton.edu/webcensus/\">Online tracking: A 1-million-site measurement and analysis</a>.\" May 2016. [<cite><a href=\"#bib-wpm-million\">WPM-MILLION</a></cite>]</li>\n          <li>Pierre Laperdrix, Walter Rudametkin, Benoit Baudry. \"<a href=\"https://hal.inria.fr/hal-01285470v2/\">Beauty and the Beast: Diverting modern web browsers to build unique browser fingerprints</a>.\" <i>IEEE Symposium on Security and Privacy (S&amp;P 2016)</i>, May 2016.</li>\n          <li>\n            \"<a href=\"https://hal.inria.fr/hal-01718234v2\">Hiding in the Crowd: an Analysis of the Effectiveness of Browser Fingerprinting at Large Scale</a>.\" <i>WWW2018 - TheWebConf 2018: 27th International World Wide Web Conference</i>, April 2018. [<cite><a href=\"#bib-hiding-crowd\">HIDING-CROWD</a></cite>]\n          </li>\n        </ul>\n      </section>\n        <section id=\"testing\">\n        <h3 id=\"a-3-testing\"><span>A.3 </span>Testing<a aria-label=\"§\" href=\"#testing\"></a></h3>\n        <p>A non-exhaustive list of sites that allow the visitor to test their configuration for fingerprintability.</p>\n        <ul>\n          <li><a href=\"https://amiunique.org/\">amiunique.org</a> (INRIA)</li>\n          <li><a href=\"https://panopticlick.eff.org/\">panopticlick.eff.org</a> (EFF)</li>\n          <li><a href=\"https://browserspy.dk/\">BrowserSPY.dk</a></li>\n          <li><a href=\"https://fingerprint.pet-portal.eu/\">pet-portal cross-browser fingerprinting test</a></li>\n          <li><a href=\"http://lcamtuf.coredump.cx/p0f3/\">p0f v3</a> (purely passive fingerprinting)</li>\n        </ul>\n        </section>\n    </section>    \n    \n    <section id=\"acknowledgements\">\n      <!--OddPage--><h2 id=\"b-acknowledgements\"><span>B. </span>Acknowledgements<a aria-label=\"§\" href=\"#acknowledgements\"></a></h2>\n      <p>\n        Many thanks to Robin Berjon for ReSpec and to Tobie Langel for Github advice; to the Privacy Interest Group and the Technical Architecture Group for review; to the Tor Browser designers for references and recommendations; and to Christine Runnegar for contributions.\n      </p>\n    </section>\n  \n\n<section id=\"references\">\n      <!--OddPage--><h2 id=\"c-references\"><span>C. </span>References<a aria-label=\"§\" href=\"#references\"></a></h2>\n      \n    <section id=\"informative-references\">\n        <h3 id=\"c-1-informative-references\"><span>C.1 </span>Informative references<a aria-label=\"§\" href=\"#informative-references\"></a></h3>\n      <dl>\n        <dt id=\"bib-battery-status\">[BATTERY-STATUS]</dt><dd><a href=\"https://www.w3.org/TR/battery-status/\"><cite>Battery Status API</cite></a>. Anssi Kostiainen; Mounir Lamouri. W3C. 7 July 2016. W3C Candidate Recommendation. URL: <a href=\"https://www.w3.org/TR/battery-status/\">https://www.w3.org/TR/battery-status/</a></dd><dt id=\"bib-beauty-beast\">[BEAUTY-BEAST]</dt><dd><a href=\"https://hal.inria.fr/hal-01285470v2/\"><cite>Beauty and the Beast: Diverting modern web browsers to build unique browser fingerprints</cite></a>. Pierre Laperdrix; Walter Rudametkin; Benoit Baudry. IEEE Symposium on Security and Privacy (S&amp;P 2016). May 2016. URL: <a href=\"https://hal.inria.fr/hal-01285470v2/\">https://hal.inria.fr/hal-01285470v2/</a></dd><dt id=\"bib-dap-privacy-reqs\">[dap-privacy-reqs]</dt><dd><a href=\"https://www.w3.org/TR/dap-privacy-reqs/\"><cite>Device API Privacy Requirements</cite></a>. Alissa Cooper; Frederick Hirsch; John Morris. W3C. 29 June 2010. W3C Note. URL: <a href=\"https://www.w3.org/TR/dap-privacy-reqs/\">https://www.w3.org/TR/dap-privacy-reqs/</a></dd><dt id=\"bib-evercookie\">[EVERCOOKIE]</dt><dd><a href=\"https://samy.pl/evercookie/\"><cite>evercookie - virtually irrevocable persistent cookies</cite></a>. Samy Kamkar.September 2010. URL: <a href=\"https://samy.pl/evercookie/\">https://samy.pl/evercookie/</a></dd><dt id=\"bib-flashcookies\">[FLASHCOOKIES]</dt><dd><a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1446862\"><cite>Flash Cookies and Privacy</cite></a>. Ashkan Soltani; Shannon Canty; Quentin Mayo; Lauren Thomas; Chris Jay Hoofnagle.10 August 2009. URL: <a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1446862\">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1446862</a></dd><dt id=\"bib-flashcookies-2\">[FLASHCOOKIES-2]</dt><dd><a href=\"https://ptolemy.berkeley.edu/projects/truststc/education/reu/11/Posters/AyensonMWambachDpaper.pdf\"><cite>Flash cookies and privacy II: Now with HTML5 and ETag respawning</cite></a>. Mika Ayenson; Dietrich Wambach; Ashkan Soltani; Nathan Good; Chris Hoofnagle.URL: <a href=\"https://ptolemy.berkeley.edu/projects/truststc/education/reu/11/Posters/AyensonMWambachDpaper.pdf\">https://ptolemy.berkeley.edu/projects/truststc/education/reu/11/Posters/AyensonMWambachDpaper.pdf</a></dd><dt id=\"bib-generic-sensor\">[generic-sensor]</dt><dd><a href=\"https://www.w3.org/TR/generic-sensor/\"><cite>Generic Sensor API</cite></a>. Mikhail Pozdnyakov; Alexander Shalamov; Tobie Langel. W3C. 7 March 2019. W3C Working Draft. URL: <a href=\"https://www.w3.org/TR/generic-sensor/\">https://www.w3.org/TR/generic-sensor/</a></dd><dt id=\"bib-hiding-crowd\">[HIDING-CROWD]</dt><dd><a href=\"https://hal.inria.fr/hal-01718234v2\"><cite>Hiding in the Crowd: an Analysis of the Effectiveness of Browser Fingerprinting at Large Scale</cite></a>. Alejandro Gómez-Boix; Pierre Laperdrix; Benoit Baudry. WWW2018 - TheWebConf2018: 27th International World Wide Web Conference. April 2018. URL: <a href=\"https://hal.inria.fr/hal-01718234v2\">https://hal.inria.fr/hal-01718234v2</a></dd><dt id=\"bib-html52\">[html52]</dt><dd><a href=\"https://www.w3.org/TR/html52/\"><cite>HTML 5.2</cite></a>. Steve Faulkner; Arron Eicholz; Travis Leithead; Alex Danilo; Sangwhan Moon. W3C. 14 December 2017. W3C Recommendation. URL: <a href=\"https://www.w3.org/TR/html52/\">https://www.w3.org/TR/html52/</a></dd><dt id=\"bib-httpbis-client-hints\">[httpbis-client-hints]</dt><dd><a href=\"https://httpwg.org/http-extensions/client-hints.html\"><cite>HTTP Client Hints</cite></a>. Ilya Grigorik. HTTP Working Group. January 2019. URL: <a href=\"https://httpwg.org/http-extensions/client-hints.html\">https://httpwg.org/http-extensions/client-hints.html</a></dd><dt id=\"bib-leaking-battery\">[LEAKING-BATTERY]</dt><dd><a href=\"https://eprint.iacr.org/2015/616.pdf\"><cite>The leaking battery: A privacy analysis of the HTML5 Battery Status API</cite></a>. Łukasz Olejnik; Gunes Acar; Claude Castelluccia; Claudia Diaz.2015. URL: <a href=\"https://eprint.iacr.org/2015/616.pdf\">https://eprint.iacr.org/2015/616.pdf</a></dd><dt id=\"bib-mediacapture-streams\">[mediacapture-streams]</dt><dd><a href=\"https://www.w3.org/TR/mediacapture-streams/\"><cite>Media Capture and Streams</cite></a>. Daniel Burnett; Adam Bergkvist; Cullen Jennings; Anant Narayanan; Bernard Aboba. W3C. 3 October 2017. W3C Candidate Recommendation. URL: <a href=\"https://www.w3.org/TR/mediacapture-streams/\">https://www.w3.org/TR/mediacapture-streams/</a></dd><dt id=\"bib-ndss-fingerprinting\">[NDSS-FINGERPRINTING]</dt><dd><a href=\"https://www.microsoft.com/en-us/research/publication/host-fingerprinting-and-tracking-on-the-webprivacy-and-security-implications/\"><cite>Host Fingerprinting and Tracking on the Web: Privacy and Security Implications</cite></a>. Ting-Fang Yen; Yinglian Xie; Fang Yu; Roger Peng Yu; Martin Abadi. In Proceedings of the Network and Distributed System Security Symposium (NDSS). February 2012. URL: <a href=\"https://www.microsoft.com/en-us/research/publication/host-fingerprinting-and-tracking-on-the-webprivacy-and-security-implications/\">https://www.microsoft.com/en-us/research/publication/host-fingerprinting-and-tracking-on-the-webprivacy-and-security-implications/</a></dd><dt id=\"bib-proximity\">[PROXIMITY]</dt><dd><a href=\"https://www.w3.org/TR/proximity/\"><cite>Proximity Sensor</cite></a>. Anssi Kostiainen; Rijubrata Bhaumik. W3C. 5 March 2019. W3C Working Draft. URL: <a href=\"https://www.w3.org/TR/proximity/\">https://www.w3.org/TR/proximity/</a></dd><dt id=\"bib-rfc6265\">[RFC6265]</dt><dd><a href=\"https://tools.ietf.org/html/rfc6265\"><cite>HTTP State Management Mechanism</cite></a>. A. Barth. IETF. April 2011. Proposed Standard. URL: <a href=\"https://tools.ietf.org/html/rfc6265\">https://tools.ietf.org/html/rfc6265</a></dd><dt id=\"bib-rfc6454\">[RFC6454]</dt><dd><a href=\"https://tools.ietf.org/html/rfc6454\"><cite>The Web Origin Concept</cite></a>. A. Barth. IETF. December 2011. Proposed Standard. URL: <a href=\"https://tools.ietf.org/html/rfc6454\">https://tools.ietf.org/html/rfc6454</a></dd><dt id=\"bib-rfc6973\">[RFC6973]</dt><dd><a href=\"https://www.rfc-editor.org/rfc/rfc6973.txt\"><cite>Privacy Considerations for Internet Protocols</cite></a>. A. Cooper; H. Tschofenig; B. Aboba; J. Peterson; J. Morris; M. Hansen; R. Smith. IETF. July 2013. RFC. URL: <a href=\"https://www.rfc-editor.org/rfc/rfc6973.txt\">https://www.rfc-editor.org/rfc/rfc6973.txt</a></dd><dt id=\"bib-rfc7231\">[RFC7231]</dt><dd><a href=\"https://tools.ietf.org/html/rfc7231\"><cite>Hypertext Transfer Protocol (HTTP/1.1): Semantics and Content</cite></a>. R. Fielding, Ed.; J. Reschke, Ed.. IETF. June 2014. Proposed Standard. URL: <a href=\"https://tools.ietf.org/html/rfc7231\">https://tools.ietf.org/html/rfc7231</a></dd><dt id=\"bib-security-privacy-questionnaire-tag\">[security-privacy-questionnaire-tag]</dt><dd><a href=\"https://w3ctag.github.io/security-questionnaire/\"><cite>Self-Review Questionnaire: Security and Privacy</cite></a>. Lukasz Olejnik; Jason Novak. W3C Technical Architecture Group. December 2018. URL: <a href=\"https://w3ctag.github.io/security-questionnaire/\">https://w3ctag.github.io/security-questionnaire/</a></dd><dt id=\"bib-tag-minimization\">[TAG-MINIMIZATION]</dt><dd><a href=\"https://www.w3.org/2001/tag/doc/APIMinimization\"><cite>Data Minimization in Web APIs</cite></a>. Daniel Appelquist. W3C Technical Architecture Group. 12 September 2011. URL: <a href=\"https://www.w3.org/2001/tag/doc/APIMinimization\">https://www.w3.org/2001/tag/doc/APIMinimization</a></dd><dt id=\"bib-tag-unsanctioned\">[TAG-UNSANCTIONED]</dt><dd><a href=\"https://w3ctag.github.io/unsanctioned-tracking/\"><cite>Unsanctioned Web Tracking</cite></a>. Mark Nottingham. W3C Technical Architecture Group. 17 July 2015. URL: <a href=\"https://w3ctag.github.io/unsanctioned-tracking/\">https://w3ctag.github.io/unsanctioned-tracking/</a></dd><dt id=\"bib-tor-design\">[TOR-DESIGN]</dt><dd><a href=\"https://www.torproject.org/projects/torbrowser/design/\"><cite>The Design and Implementation of the Tor Browser</cite></a>. Mike Perry; Erinn Clark; Steven Murdoch; Georg Koppen.15 June 2018. URL: <a href=\"https://www.torproject.org/projects/torbrowser/design/\">https://www.torproject.org/projects/torbrowser/design/</a></dd><dt id=\"bib-tracking-compliance\">[TRACKING-COMPLIANCE]</dt><dd><a href=\"https://www.w3.org/TR/tracking-compliance/\"><cite>Tracking Compliance and Scope</cite></a>. Nick Doty; Heather West; Justin Brookman; Sean Harvey; Erica Newland. W3C. 22 January 2019. W3C Note. URL: <a href=\"https://www.w3.org/TR/tracking-compliance/\">https://www.w3.org/TR/tracking-compliance/</a></dd><dt id=\"bib-tracking-dnt\">[TRACKING-DNT]</dt><dd><a href=\"https://www.w3.org/TR/tracking-dnt/\"><cite>Tracking Preference Expression (DNT)</cite></a>. Roy Fielding; David Singer. W3C. 17 January 2019. W3C Note. URL: <a href=\"https://www.w3.org/TR/tracking-dnt/\">https://www.w3.org/TR/tracking-dnt/</a></dd><dt id=\"bib-webstorage-user-tracking\">[WEBSTORAGE-user-tracking]</dt><dd><a href=\"https://www.w3.org/TR/2013/REC-webstorage-20130730/#user-tracking\"><cite>Web Storage &gt; Privacy &gt; User tracking</cite></a>. Ian Hickson. W3C. July 2013. Rec. URL: <a href=\"https://www.w3.org/TR/2013/REC-webstorage-20130730/#user-tracking\">https://www.w3.org/TR/2013/REC-webstorage-20130730/#user-tracking</a></dd><dt id=\"bib-wpm-million\">[WPM-MILLION]</dt><dd><a href=\"https://webtransparency.cs.princeton.edu/webcensus/\"><cite>Online tracking: A 1-million-site measurement and analysis</cite></a>. Steven Englehardt; Arvind Narayanan.May 2016. URL: <a href=\"https://webtransparency.cs.princeton.edu/webcensus/\">https://webtransparency.cs.princeton.edu/webcensus/</a></dd>\n      </dl></section></section>\n</div>","textContent":"\n    Abstract\n      Exposure of settings and characteristics of browsers can harm user privacy by allowing for browser fingerprinting. This document defines different types of fingerprinting, considers distinct levels of mitigation for the related privacy risks and provides guidance for Web specification authors on how to balance these concerns when designing new Web features.\n    \n    Status of This DocumentThis section describes the status of this document at the time of its publication. Other documents may supersede this document. A list of current W3C publications and the latest revision of this technical report can be found in the W3C technical reports index at https://www.w3.org/TR/.\n      \n\n            This document is an Interest Group Note providing best practices to Web specification\n            authors on mitigating the privacy impacts of browser fingerprinting.  It was developed\n            by the W3C Privacy Interest Group (PING) \n            in collaboration with\n\t    the W3C Technical Architecture Group (TAG).\n            Since the last publication the list of best practices has been expanded and made\n            more specific, guidance has been provided on how to evaluate the severity of fingerprinting\n            surface, and additional references and examples have been provided. Constructive input of all\n            kinds is welcome. Send comments to the PING mailing list\n\t    or file issues in GitHub.\n\n      \n      Publication as an Interest Group Note does not imply endorsement by the\n      W3C Membership. The document may be updated, replaced or\n      obsoleted by other documents at any time.\n    \n            The disclosure obligations of the Participants of this group are\n            described in the\n            charter.\n          \n    \n                  This document is governed by the\n                  1 March 2019 W3C Process Document.\n                Table of Contents1. Browser fingerprinting1.1 What is fingerprinting?1.2 Privacy impacts and threat models1.2.1 Identify a user1.2.2 Correlation of browsing activity1.2.3 Tracking without transparency or user control1.3 What can we do about it?2. Best Practices Summary3. Types of fingerprinting3.1 Passive3.2 Active3.3 Cookie-like4. Feasibility4.1 Fingerprinting mitigation levels of success4.2 Feasible goals for specification authors5. Identifying fingerprinting surface and evaluating severity6. Mitigations6.1 Weighing increased fingerprinting surface6.2 Standardization6.3 Detectability6.4 Clearing all local state6.5 Do Not TrackA. ResearchA.1 Browser vendor documentationA.2 Academic researchA.3 TestingB. AcknowledgementsC. ReferencesC.1 Informative references\n    \n      1. Browser fingerprinting\n        \n        1.1 What is fingerprinting?\n        In short, browser fingerprinting is the capability of a site to identify or re-identify a visiting user, user agent or device via configuration settings or other observable characteristics.\n        A similar definition is provided by [RFC6973]. A more detailed list of types of fingerprinting is included below. This document does not attempt to catalog all features currently used or usable for browser fingerprinting; however, § A. Research provides links to browser vendor pages and academic findings.\n        \n        \n        1.2 Privacy impacts and threat models\n\n        Browser fingerprinting can be used as a security measure (e.g. as means of authenticating the user). However, fingerprinting is also a potential threat to users' privacy on the Web. This document does not attempt to provide a single unifying definition of \"privacy\" or \"personal data\", but we highlight how browser fingerprinting might impact users' privacy. For example, browser fingerprinting can be used to:\n        \n          identify a user\n          correlate a user’s browsing activity within and across sessions\n          track users without transparency or control\n        \n\n        The privacy implications associated with each use case are discussed below. Following from the practice of security threat model analysis, we note that there are distinct models of privacy threats for fingerprinting. Defenses against these threats differ, depending on the particular privacy implication and the threat model of the user.\n\n        \n          1.2.1 Identify a user\n          There are many reasons why users might wish to remain anonymous or unidentified online, including: concerns about surveillance, personal physical safety, and concerns about discrimination against them based on what they read or write when using the Web. When a browser fingerprint is correlated with identifying information (like an email address, a recognized given and sur-name, or a government-issued identifier), an application or service provider may be able to identify an otherwise pseudonymous user. The adversary and consequences of this threat will vary by the particular user and use case, but can include nation-state intelligence agencies and threats of violence or imprisonment.\n        \n        \n        \n          1.2.2 Correlation of browsing activity\n          Browser fingerprinting raises privacy concerns even when offline identities are not implicated. Some users may be surprised or concerned that an online party can correlate multiple visits (on the same or different sites) to develop a profile or history of the user. This concern may be heightened because (see below) it may occur without the user's knowledge or consent and tools such as clearing cookies do not prevent further correlation.\n          Browser fingerprinting also allows for tracking across origins [RFC6454]: different sites may be able to combine information about a single user even where a cookie policy would block accessing of cookies between origins, because the fingerprint is relatively unique and the same for all origins.\n        \n        \n        \n          1.2.3 Tracking without transparency or user control\n          \n            In contrast to other mechanisms defined by Web standards for maintaining state (e.g. cookies), browser fingerprinting allows for collection of data about user activity without clear indications that such collection is happening. Transparency can be important for end users, to understand how ongoing collection is happening, but it also enables researchers, policymakers and others to document or regulate privacy-sensitive activity. Browser fingerprinting also allows for tracking of activity without clear or effective user controls: a browser fingerprint typically cannot be cleared or re-set. (See the finding on unsanctioned tracking [TAG-UNSANCTIONED].)\n          \n        \n    \n    \n      1.3 What can we do about it?\n      \n        Advances in techniques for browser fingerprinting (see § A. Research, below), particularly in active fingerprinting, suggest that complete elimination of the capability of browser fingerprinting by a determined adversary through solely technical means that are widely deployed is implausible. However, mitigations in our technical specifications are possible, as described below (§ 6. Mitigations), and may achieve different levels of success (§ 4. Feasibility).\n      \n      \n        Mitigations recommended here are simply mitigations, not solutions. Users of the Web cannot confidently rely on sites being completely unable to correlate traffic, especially when executing client-side code. A fingerprinting surface extends across all implemented Web features for a particular user agent, and even to other layers of the stack; for example, differences in TCP connections. For example, a user might employ an onion routing system such as Tor to limit network-level linkability, but still face the risk of correlating Web-based activity through browser fingerprinting, or vice versa. In order to mitigate these privacy risks as a whole, fingerprinting must be considered during the design and development of all specifications.\n      \n      \n        The TAG finding on Unsanctioned Web Tracking, including browser fingerprinting, includes description of the limitations of technical measures and encourages minimizing and documenting new fingerprinting surface [TAG-UNSANCTIONED]. The best practices below detail common actions that authors of specifications for Web features can take to mitigate the privacy impacts of browser fingerprinting. The Self-Review Questionnaire documents mitigations of privacy impacts in Web features more generally that may complement these practices [security-privacy-questionnaire-tag].\n      \n    \n    \n    \n    2. Best Practices SummaryBest Practice 1: Avoid unnecessary or severe increases to fingerprinting surface, especially for passive fingerprinting.Best Practice 2: Narrow the scope and availability of a feature with fingerprinting surface to what is functionally necessary.Best Practice 3: Mark features that contribute to fingerprintability.Best Practice 4: Specify orderings and non-functional differences.Best Practice 5: Design APIs to access only the entropy necessary.Best Practice 6: Require servers to advertise or opt in to access data.Best Practice 7: Enable graceful degradation for privacy-conscious users or implementers.Best Practice 8: Avoid unnecessary new local state mechanisms.Best Practice 9: Highlight any local state mechanisms to enable simultaneous clearing.Best Practice 10: Limit permanent or persistent state.\n    \n    \n        3. Types of fingerprinting\n        \n          3.1 Passive\n          Passive fingerprinting is browser fingerprinting based on characteristics observable in the contents of Web requests, without the use of any code executed on the client.\n          Passive fingerprinting would trivially include cookies (often unique identifiers sent in HTTP requests), the set of HTTP request headers and the IP address and other network-level information. The User-Agent string [RFC7231], for example, is an HTTP request header that typically identifies the browser, renderer, version and operating system. For some populations, the User-Agent and IP address will often uniquely identify a particular user's browser [NDSS-FINGERPRINTING].\n        \n        \n          3.2 Active\n          For active fingerprinting, we also consider techniques where a site runs JavaScript or other code on the local client to observe additional characteristics about the browser, user, device or other context.\n          Techniques for active fingerprinting might include accessing the window size, enumerating fonts or plug-ins, evaluating performance characteristics, reading from device sensors, and rendering graphical patterns. Key to this distinction is that active fingerprinting takes place in a way that is potentially detectable on the client.\n        \n        \n          3.3 Cookie-like\n          Users, user agents and devices may also be re-identified by a site that first sets and later retrieves state stored by a user agent or device. This cookie-like fingerprinting allows re-identification of a user or inferences about a user in the same way that HTTP cookies allow state management for the stateless HTTP protocol [RFC6265].\n          Cookie-like fingerprinting can also circumvent user attempts to limit or clear cookies stored by the user agent, as demonstrated by the \"evercookie\" implementation [EVERCOOKIE]. Where state is maintained across user agents (as in the case of common plugins with local storage), across devices (as in the case of certain browser syncing mechanisms) or across software upgrades, cookie-like fingerprinting can allow re-identification of users, user agents or devices where active and passive fingerprinting might not. The Security and Privacy Self-Review Questionnaire also considers this threat in origin state that persists across browsing sessions [security-privacy-questionnaire-tag].\n        \n    \n\n    \n      4. Feasibility\n      \n      \n          4.1 Fingerprinting mitigation levels of success\n          There are different levels of success in mitigating browser fingerprinting:\n          \n          Decreased fingerprinting surfaceRemoving the source of entropy or accessible attributes that can be used for fingerprinting.\n          Increased anonymity setBy standardization, convention or common implementation, increasing the commonality of particular configurations to decrease the likelihood of unique fingerprintability.\n          Detectable fingerprintingMaking fingerprinting observable to others, so that the user agent might block it or researchers can determine that it's happening.\n          Clearable local stateHelping users respond to fingerprinting by making state mechanisms clearable.\n          \n          Research has shown feasible improvement in privacy protection in all of these areas. While lists of plugins remain a large fingerprinting surface, entropy has decreased over time with migration to Web APIs over plugins [HIDING-CROWD]. Collected data on Web users has shown mobile devices to have substantially larger anonymity sets than desktop browsers [HIDING-CROWD]. Research on forms of active fingerprinting has documented its use and demonstrated changes in use of those techniques as an apparent result of increased awareness [WPM-MILLION]. Respawning of cookies has continued, with an increasing variety of techniques, but awareness and technical responses to the issue has made the practice less widespread [FLASHCOOKIES-2].\n      \n      \n        4.2 Feasible goals for specification authors\n        \n          This document works under the expectation that mitigations with different levels of success are feasible under different circumstances, for different threat models and against different types of fingerprinting. In general, active fingerprinting may be made detectable; we can minimize increases to the surface of passive fingerprinting; and cookie-like mechanisms can be made clearable.\n        \n          Some implementers and some users may be willing to accept reduced functionality or decreased performance in order to minimize browser fingerprinting. Documenting which features have fingerprinting risk eases the work of implementers building modes for these at-risk users; minimizing fingerprinting even in cases where common implementations will have easy active fingerprintability allows such users to reduce the functionality trade-offs necessary. Making browser fingerprinting more detectable also contributes to mitigations outside the standardization process; for example, though regulatory or policy means [TAG-UNSANCTIONED].\n        \n      \n    \n    \n      5. Identifying fingerprinting surface and evaluating severity      \n\n      To mitigate browser fingerprinting in your specification:\n      \n        identify features that can be used for browser fingerprinting;\n        evaluate the severity of the fingerprinting surface based on these five factors; and,\n        apply mitigations described in the best practices below (§ 6. Mitigations), focused on limiting the severity of that fingerprinting surface.\n      \n        \n      The fingerprinting surface of a user agent is the set of observable characteristics that can be used in concert to identify a user, user agent or device or correlate its activity.\n\n      Data sources that may be used for browser fingerprinting include:\n      \n        user configuration\n        device characteristics\n        environmental characteristics (e.g. sensor readings)\n        operating system characteristics\n        user behavior\n        browser characteristics\n      \n\n      These data sources may be accessed directly for some features, but in many other cases they are inferred through some other observation. Timing channels, in particular, are commonly used to infer details of hardware (exactly how quickly different operations are completed may provide information on GPU capability, say), network information (via the latency or speed in loading a particular resource) or even user configuration (what items have been previously cached or what resources are not loaded). Consider the side effects of feature and how those side effects would allow inferences of any of these characteristics.\n\n      The Tor Browser design document [TOR-DESIGN] has more details on these sources and their relative priorities; this document adds environmental characteristics in that sensor readings or data access may distinguish a user, user agent or device by information about the environment (location, for example).\n\n      For each identified feature, consider the severity for the privacy impacts described above (§ 1.2 Privacy impacts and threat models) based on the following factors:\n\n      \n        entropyHow distinguishing is this new surface? Consider both the possible variations and the likely distribution of values. Adding 1-bit of entropy is typically of less concern; 30-some bits of entropy would be enough to uniquely identify every individual person. Different data sources may provide different distributions of variation; for example, some characteristics may reveal a common hardware class while other characteristics may reveal user configurations that vary between individual people.\n        detectabilityWill use of this feature for browser fingerprinting be observable to the user agent or likely to be discoverable by researchers? Because detectability is an important — and perhaps the most feasible — mitigation, increases to the surface for passive fingerprinting are of particular concern and should be avoided.\n        persistenceHow long will the characteristics of this fingerprinting surface stay unchanged? Can users control or re-set these values to prevent long-lived identification? While short-lived characteristics may still enable unexpected correlation of activity (for example, between two browser profiles on the same device), persistent or permanent identifiers are particularly concerning for the lack of user control.\n        availabilityWill this surface be accessible to the \"drive-by Web\" or only in certain contexts where a user has granted a particular sensor permission or directly authenticated? While browser fingerprinting is still something to mitigate in the permissioned context, the concern that a feature will end up used primarily for fingerprinting is reduced.\n        scopeIs this surface consistent across origins or only within a single origin? In general, characteristics or identifiers that are tied to a particular origin are of less concern and can be handled with the same tools as HTTP cookies.\n      \n\n      While we do not recommend specific trade-offs, these factors can be used to weigh increases to that surface (§ 6.1 Weighing increased fingerprinting surface) and suggest appropriate mitigations. Although each factor may suggest specific mitigations, in weighing whether to add fingerprinting surface they should be considered in concert. For example, access to a new set of characteristics about the user may be high entropy, but be of less concern because it has limited availability and is easily detectable. A cross-origin, drive-by-accessible, permanent, passive unique identifier is incompatible with our expectations for privacy on the Web.\n\n      In conducting this analysis, it may be tempting to dismiss certain fingerprinting surface in a specification because of a comparison to fingerprinting surface exposed by other parts of the Web platform or other layers of the stack. Be cautious about making such claims. First, while similar information may be available through other means, similar is not identical: information disclosures may not be exactly the same and fingerprintability is promoted by combining these distinct sources. Second, where identical entropy is present, other factors of severity or accessibility may differ and those factors are important for feasible mitigation. Third, the platform is neither monolithic nor static; not all other features are implemented in all cases and may change (or be removed) in the future. Fourth, circular dependencies are a danger when so many new features are under development; two specifications sometimes refer to one another in arguing that fingerprinting surface already exists. It is more useful to reviewers and implementers to consider the fingerprinting surface provided by the particular Web feature itself, with specific references where surface may be accessible through other features as well.\n\n    \n    \n        6. Mitigations\n        \n          6.1 Weighing increased fingerprinting surface\n          Web specification authors regularly attempt to strike a balance between new functionality and fingerprinting surface. For example, feature detection functionality allows for progressive enhancement with a small addition to fingerprinting surface; detailed enumerations of plugins, fonts, connected devices may provide a large fingerprinting surface with minimal functional support.\n          Authors and Working Groups determine the appropriate balance between these properties on a case-by-case basis, given their understanding of the functionality, its implementations and the severity of increased fingerprinting surface. However, given the distinct privacy impacts described above and in order to improve consistency across specifications, these practices provide some guidance:\n          \n          \n            \n              Best Practice 1: Avoid unnecessary or severe increases to fingerprinting surface, especially for passive fingerprinting.\n            \n            \n              Consider each of the severity factors described above and whether that functionality is necessary and whether comparable functionality is feasible with less severe increases to the fingerprinting surface.\n            \n            \n              In particular, unless a feature cannot reasonably be designed in any other way, increased passive fingerprintability should be avoided. Passive fingerprinting allows for easier and widely-available identification, without opportunities for external detection or control by users or third parties.\n            \n          \n\n          \n            \n              Best Practice 2: Narrow the scope and availability of a feature with fingerprinting surface to what is functionally necessary.\n            \n            \n              What browsing contexts, resources and requests need access to a particular feature?  Identifiers can often be scoped to have a different value in different origins. Some configuration may only be necessary in top-level browsing contexts.\n            \n            \n              Should access to this functionality be limited to where users have granted a particular permission? While excessive permissions can create confusion and fatigue, limiting highly granular data to situations where a user has already granted permission to access sensitive data widely mitigates the risk of that feature being used primarily for browser fingerprinting in \"drive-by\" contexts. For example, Media Capture and Streams [mediacapture-streams] limits access to attached microphone and camera device labels to when the user has granted permission to access a camera or microphone (while still allowing access to the number and configuration of attached cameras and microphones in all contexts, a noted increase in drive-by fingerprinting surface).\n            \n          \n\n          Some implementations may also limit the entropy of fingerprinting surface by not exposing different capabilities for different devices or installations of a user agent. Font lists, for example, can be limited to a whitelist commonly available on all devices that run a particular browser or operating system (as implemented in Tor Browser, Firefox and Safari).\n          \n          \n            \n              Best Practice 3: Mark features that contribute to fingerprintability.\n            \n            \n              \n              Where a feature does contribute to the fingerprinting surface, indicate that impact, by explaining the effect (and any known implementer mitigations) and marking the relevant section with a fingerprinting icon, as this paragraph is.            \n            \n          \n          \n            The following code can be used to mark a paragraph with the fingerprint icon.\n            <img src=\"https://www.w3.org/TR/html5/images/fingerprint.png\" \n     class=\"fingerprint\" \n     alt=\"This feature may contribute to browser fingerprintability.\">\n          \n        \n        \n\t\t\t6.2 Standardization\n\t\t\t\n        Specifications can mitigate against fingerprintability through standardization; by defining a consistent behavior, conformant implementations won't have variations that can be used for browser fingerprinting.\n\t\t\t\n      \n        Randomization of certain browser characteristics has been proposed as a way to combat browser fingerprinting. While this strategy may be pursued by some implementations, we expect in general it will be more effective for us to standardize or null values rather than setting a range over which they can vary. The Tor Browser design [TOR-DESIGN] provides more detailed information, but in short: it's difficult to measure how well randomization will work as a mitigation and it can be costly to implement in terms of usability (varying functionality or design in unwanted ways), processing (generating random numbers) and development (including the cost of introducing new security vulnerabilities). Standardization provides the benefit of an increased anonymity set for conformant browsers with the same configuration: that is, an individual can look the same as a larger group of people rather than trying to look like a number of different individuals.\n      \n      \n        \n          Best Practice 4: Specify orderings and non-functional differences.\n        \n        \n          To reduce unnecessary entropy, specify aspects of API return values and behavior that don't contribute to functional differences. For example, if the ordering of return values in a list has no semantic value, specify a particular ordering (alphabetical order by a defined algorithm, for example) so that incidental differences don't expose fingerprinting surface.\n        \n        \n          Access to a list of system fonts via Flash or Java plugins notably returns the list sorted not in a standard alphabetical order, but in an unspecified order specific to the system. This ordering adds to the entropy available from that plugin in a way that provides no functional advantage. (See Collecting System Fonts via Flash Plugins.)\n        \n      \n      \n        Standardization does not need to attempt to hide all differences between different browsers (e.g. Edge and Chrome); implemented functionality and behavior differences will always exist between different implementations. For that reason, removing User-Agent headers altogether is not a goal. However, variation in the User-Agent string that reveals additional information about the user or device has been shown to provide substantial fingerprinting surface [BEAUTY-BEAST].\n      \n\t\t\n        \n          6.3 Detectability\n          Where a client-side API provides some fingerprinting surface, authors can still mitigate the privacy concerns via detectability. If client-side fingerprinting activity is to some extent distinguishable from functional use of APIs, user agent implementations may have an opportunity to prevent ongoing fingerprinting or make it observable to users and external researchers (including academics or relevant regulators) who may be able to detect and investigate the use of fingerprinting.\n          \n          \n            \n              Best Practice 5: Design APIs to access only the entropy necessary.\n            \n            \n              Following the basic principle of data minimization [RFC6973], design your APIs such that a site can access (and does access by default) only the entropy necessary for particular functionality.\n            \n            \n              Authors might design an API to allow for querying of a particular value, rather than returning an enumeration of all values. User agents and researchers can then more easily distinguish between sites that query for one or two particular values (gaining minimal entropy) and those that query for all values (more likely attempting to fingerprint the browser); or implementations can cap the number of different values. For example, Tor Browser limits the number of fonts that can be queried with a browser.display.max_font_attempts preference.\n            \n            \n              The granularity or precision of information returned can be minimized in order to reduce entropy. For example, implementations of the Battery Status API [BATTERY-STATUS] allowed for high precision (double-precision, or 15-17 significant digits) readings of the current battery level, which provided a short-term identifier that could be used to correlate traffic across origins or clearance of local state. Rounding off values to lower precision mitigates browser fingerprinting while maintaining functional use cases. Alternatively, providing Boolean or a small enumeration of values might provide functionality without revealing underlying details; for example, the Boolean near property in the Proximity Sensor API [PROXIMITY].\n            \n            \n              For more information, see:\n            \n            \n              Device API Privacy Requirements [dap-privacy-reqs], DAP Working Group Note, June 2010.\n              Data Minimization in Web APIs [TAG-MINIMIZATION], W3C TAG, September 2011.\n              Generic Sensor API: Security and privacy considerations [generic-sensor], March 2018.\n              The leaking battery: A privacy analysis of the HTML5 Battery Status API [LEAKING-BATTERY], 2015.\n            \n          \n          \n            Related, detectability is improved even with data sent in HTTP headers (what we would typically consider passive fingerprinting) if sites are required to request access (or \"opt in\") to information before it's sent.\n          \n          \n              \n                Best Practice 6: Require servers to advertise or opt in to access data.\n              \n              \n                Even for data sent in HTTP request headers, requiring servers to advertise use of particular data, publicly document a policy, or \"opt in\" before clients send configuration data provides the possibility of detection by user agents or researchers.\n              \n              \n                For example, Client Hints [httpbis-client-hints] proposes an Accept-CH response header for services to indicate that specific hints can be used for content negotiation, rather than all supporting clients sending all hints in all requests.\n              \n              Note\n                This is a relatively new approach; we're still evaluating whether this provides meaningful and useful detectability.\n              \n          \n\n          \n            Implementers can facilitate detectability by providing or enabling instrumentation so that users or third parties are able to calculate when fingerprinting surface is being accessed. Of particular importance for instrumentation are: access to all the different sources of fingerprinting surface; identification of the originating script; avoiding exposure that instrumentation is taking place. Beyond the minimization practice described above, these are largely implementation-specific (rather than Web specification) features.\n          \n          \n            If your specification exposes some fingerprinting surface (whether it's active or passive), some implementers (e.g. Tor Browser) are going to be compelled to disable those features for certain privacy-conscious users.\n          \n          \n            \n              Best Practice 7: Enable graceful degradation for privacy-conscious users or implementers.\n            \n            \n              Following the principle of progressive enhancement, and to avoid further divergence (which might itself expose variation in users), consider whether some functionality in your specification is still possible if fingerprinting surface features are disabled. \n            \n            \n              Explicit hooks or API flags may be used so that browser extensions or certain user agents can easily disable specific features. For example, the origin-clean flag [html52] allows control over whether an image canvas can be read, a significant fingerprinting surface.\n            \n               \n        \n        \n          6.4 Clearing all local state\n          Features which enable storage of data on the client and functionality for client- or server-side querying of that data can increase the ease of cookie-like fingerprinting. Storage can vary between large amounts of data (for example, the Web Storage API) or just a binary flag (has or has not provided a certain permission; has or has not cached a single resource).\n          \n            \n              Best Practice 8: Avoid unnecessary new local state mechanisms.\n            \n            \n              If functionality does not require maintaining client-side state in a way that is subsequently queryable (or otherwise observable), avoid creating a new cookie-like feature. Can the functionality be accomplished with existing HTTP cookies or an existing JavaScript local storage API?\n            \n            \n              For example, the Flash plugin's Local Shared Objects (LSOs) have often been used to duplicate and re-spawn HTTP cookies cleared by the user [FLASHCOOKIES].\n            \n          \n          Where features do require setting and retrieving local state, there are ways to mitigate the privacy impacts related to unexpected cookie-like behavior; in particular, you can help implementers prevent \"permanent\", \"zombie\", \"super\" or \"evercookies\".\n          \n            \n              Best Practice 9: Highlight any local state mechanisms to enable simultaneous clearing.\n            \n            \n              Clearly note where state is being maintained and could be queried and provide guidance to implementers on enabling simultaneous deletion of local state for users. Such functionality can mitigate the threat of \"evercookies\"  because the presence of state in one such storage mechanism can't be used to persist and re-create an identifier.\n            \n          \n          Permanent or persistent data (including any identifiers) are of particular risk because they undermine the ability for a user to clear or re-set the state of their device or to maintain different identities.\n          \n            \n              Best Practice 10: Limit permanent or persistent state.\n            \n            \n              Permanent identifiers or other state (for example, identifiers or keys set in hardware) should typically not be exposed. Where necessary, access to such identifiers would require user permission (however, explaining the implications of such permission to users may be difficult) and limitation to a particular origin (however, server-side collusion between origins will be difficult to detect).\n              As a result, your design should not rely on saving and later querying data on the client beyond a user's clearing cookies or other local state. That is, you should not expect any local state information to be permanent or to persist longer than other local state.\n            \n          \n          Though not strictly browser fingerprinting, there are other privacy concerns regarding user tracking for features that provide local storage of data. Mitigations suggested in the Web Storage API specification include: white-listing, black-listing, expiration and secure deletion [WEBSTORAGE-user-tracking].\n        \n        6.5 Do Not Track\n          Expressions of, and compliance with, a Do Not Track signal does not inhibit the capability of browser fingerprinting, but may mitigate some user concerns about fingerprinting, specifically around tracking as defined in those specifications [TRACKING-DNT] [TRACKING-COMPLIANCE] and as implemented by services that comply with those user preferences. That is, DNT can mitigate concerns with cooperative sites.\n          The use of DNT in this way typically does not require changes to other functional specifications. \n            If your specification expects a particular behavior upon receiving a particular DNT signal, indicate that with a reference to [TRACKING-DNT].\n            If your specification introduces a new communication channel that could be used for tracking, you might wish to define how a DNT signal should be communicated.\n          \n        \n    \n    \n    \n        A. Research\n\n        \n          A.1 Browser vendor documentation\n        \n        Some browser developers maintain pages on browser fingerprinting, including: potential mitigations or modifications necessary to decrease the surface of that browser engine; different vectors that can be used for fingerprinting; potential future work. These are not cheery, optimistic documents.\n        \n          The Chromium Projects: Technical analysis of client identification mechanisms\n          WebKit Wiki: Fingerprinting\n          Mozilla Wiki: Fingerprinting\n          The Design and Implementation of the Tor Browser: Cross-Origin Fingerprinting Unlinkability\n        \n      \n\n      \n        A.2 Academic research        \n        What are the key papers to read here, historically or to give the latest on fingerprinting techniques? What are some areas of open research that might be relevant?\n        \n          Eckersley, Peter. \"How unique is your web browser?\" Privacy Enhancing Technologies. Springer Berlin Heidelberg, 2010.\n          Mowery, Keaton, Dillon Bogenreif, Scott Yilek, and Hovav Shacham. “Fingerprinting Information in JavaScript Implementations.” In Web 2.0 Security and Privacy, 2011.\n          Yen, Ting-Fang, et al. \"Host fingerprinting and tracking on the web: Privacy and security implications.\" Proceedings of NDSS. 2012. [NDSS-FINGERPRINTING]\n          Mowery, Keaton, and Hovav Shacham. \"Pixel perfect: Fingerprinting canvas in HTML5.\" Web 2.0 Security and Privacy, 2012.\n          Mattioli, Dana. \"On Orbitz, Mac Users Steered to Pricier Hotels\". Wall Street Journal, August 23, 2012.\n          Gunes Acar et al. \"FPDetective: dusting the web for fingerprinters.\" In CCS '13.\n          Nikiforakis, Nick, et al. \"Cookieless monster: Exploring the ecosystem of web-based device fingerprinting.\" IEEE Symposium on Security and Privacy (S&P 2013), 2013.\n          G. Acar, C. Eubank, S. Englehardt, M. Juarez, A. Narayanan, C. Diaz. \"The Web never forgets: Persistent tracking mechanisms in the wild.\" In Proceedings of CCS 2014, Nov. 2014.\n          Steven Englehardt, Arvind Narayanan. \"Online tracking: A 1-million-site measurement and analysis.\" May 2016. [WPM-MILLION]\n          Pierre Laperdrix, Walter Rudametkin, Benoit Baudry. \"Beauty and the Beast: Diverting modern web browsers to build unique browser fingerprints.\" IEEE Symposium on Security and Privacy (S&P 2016), May 2016.\n          \n            \"Hiding in the Crowd: an Analysis of the Effectiveness of Browser Fingerprinting at Large Scale.\" WWW2018 - TheWebConf 2018: 27th International World Wide Web Conference, April 2018. [HIDING-CROWD]\n          \n        \n      \n        \n        A.3 Testing\n        A non-exhaustive list of sites that allow the visitor to test their configuration for fingerprintability.\n        \n          amiunique.org (INRIA)\n          panopticlick.eff.org (EFF)\n          BrowserSPY.dk\n          pet-portal cross-browser fingerprinting test\n          p0f v3 (purely passive fingerprinting)\n        \n        \n        \n    \n    \n      B. Acknowledgements\n      \n        Many thanks to Robin Berjon for ReSpec and to Tobie Langel for Github advice; to the Privacy Interest Group and the Technical Architecture Group for review; to the Tor Browser designers for references and recommendations; and to Christine Runnegar for contributions.\n      \n    \n  \n\n\n      C. References\n      \n    \n        C.1 Informative references\n      \n        [BATTERY-STATUS]Battery Status API. Anssi Kostiainen; Mounir Lamouri. W3C. 7 July 2016. W3C Candidate Recommendation. URL: https://www.w3.org/TR/battery-status/[BEAUTY-BEAST]Beauty and the Beast: Diverting modern web browsers to build unique browser fingerprints. Pierre Laperdrix; Walter Rudametkin; Benoit Baudry. IEEE Symposium on Security and Privacy (S&P 2016). May 2016. URL: https://hal.inria.fr/hal-01285470v2/[dap-privacy-reqs]Device API Privacy Requirements. Alissa Cooper; Frederick Hirsch; John Morris. W3C. 29 June 2010. W3C Note. URL: https://www.w3.org/TR/dap-privacy-reqs/[EVERCOOKIE]evercookie - virtually irrevocable persistent cookies. Samy Kamkar.September 2010. URL: https://samy.pl/evercookie/[FLASHCOOKIES]Flash Cookies and Privacy. Ashkan Soltani; Shannon Canty; Quentin Mayo; Lauren Thomas; Chris Jay Hoofnagle.10 August 2009. URL: https://papers.ssrn.com/sol3/papers.cfm?abstract_id=1446862[FLASHCOOKIES-2]Flash cookies and privacy II: Now with HTML5 and ETag respawning. Mika Ayenson; Dietrich Wambach; Ashkan Soltani; Nathan Good; Chris Hoofnagle.URL: https://ptolemy.berkeley.edu/projects/truststc/education/reu/11/Posters/AyensonMWambachDpaper.pdf[generic-sensor]Generic Sensor API. Mikhail Pozdnyakov; Alexander Shalamov; Tobie Langel. W3C. 7 March 2019. W3C Working Draft. URL: https://www.w3.org/TR/generic-sensor/[HIDING-CROWD]Hiding in the Crowd: an Analysis of the Effectiveness of Browser Fingerprinting at Large Scale. Alejandro Gómez-Boix; Pierre Laperdrix; Benoit Baudry. WWW2018 - TheWebConf2018: 27th International World Wide Web Conference. April 2018. URL: https://hal.inria.fr/hal-01718234v2[html52]HTML 5.2. Steve Faulkner; Arron Eicholz; Travis Leithead; Alex Danilo; Sangwhan Moon. W3C. 14 December 2017. W3C Recommendation. URL: https://www.w3.org/TR/html52/[httpbis-client-hints]HTTP Client Hints. Ilya Grigorik. HTTP Working Group. January 2019. URL: https://httpwg.org/http-extensions/client-hints.html[LEAKING-BATTERY]The leaking battery: A privacy analysis of the HTML5 Battery Status API. Łukasz Olejnik; Gunes Acar; Claude Castelluccia; Claudia Diaz.2015. URL: https://eprint.iacr.org/2015/616.pdf[mediacapture-streams]Media Capture and Streams. Daniel Burnett; Adam Bergkvist; Cullen Jennings; Anant Narayanan; Bernard Aboba. W3C. 3 October 2017. W3C Candidate Recommendation. URL: https://www.w3.org/TR/mediacapture-streams/[NDSS-FINGERPRINTING]Host Fingerprinting and Tracking on the Web: Privacy and Security Implications. Ting-Fang Yen; Yinglian Xie; Fang Yu; Roger Peng Yu; Martin Abadi. In Proceedings of the Network and Distributed System Security Symposium (NDSS). February 2012. URL: https://www.microsoft.com/en-us/research/publication/host-fingerprinting-and-tracking-on-the-webprivacy-and-security-implications/[PROXIMITY]Proximity Sensor. Anssi Kostiainen; Rijubrata Bhaumik. W3C. 5 March 2019. W3C Working Draft. URL: https://www.w3.org/TR/proximity/[RFC6265]HTTP State Management Mechanism. A. Barth. IETF. April 2011. Proposed Standard. URL: https://tools.ietf.org/html/rfc6265[RFC6454]The Web Origin Concept. A. Barth. IETF. December 2011. Proposed Standard. URL: https://tools.ietf.org/html/rfc6454[RFC6973]Privacy Considerations for Internet Protocols. A. Cooper; H. Tschofenig; B. Aboba; J. Peterson; J. Morris; M. Hansen; R. Smith. IETF. July 2013. RFC. URL: https://www.rfc-editor.org/rfc/rfc6973.txt[RFC7231]Hypertext Transfer Protocol (HTTP/1.1): Semantics and Content. R. Fielding, Ed.; J. Reschke, Ed.. IETF. June 2014. Proposed Standard. URL: https://tools.ietf.org/html/rfc7231[security-privacy-questionnaire-tag]Self-Review Questionnaire: Security and Privacy. Lukasz Olejnik; Jason Novak. W3C Technical Architecture Group. December 2018. URL: https://w3ctag.github.io/security-questionnaire/[TAG-MINIMIZATION]Data Minimization in Web APIs. Daniel Appelquist. W3C Technical Architecture Group. 12 September 2011. URL: https://www.w3.org/2001/tag/doc/APIMinimization[TAG-UNSANCTIONED]Unsanctioned Web Tracking. Mark Nottingham. W3C Technical Architecture Group. 17 July 2015. URL: https://w3ctag.github.io/unsanctioned-tracking/[TOR-DESIGN]The Design and Implementation of the Tor Browser. Mike Perry; Erinn Clark; Steven Murdoch; Georg Koppen.15 June 2018. URL: https://www.torproject.org/projects/torbrowser/design/[TRACKING-COMPLIANCE]Tracking Compliance and Scope. Nick Doty; Heather West; Justin Brookman; Sean Harvey; Erica Newland. W3C. 22 January 2019. W3C Note. URL: https://www.w3.org/TR/tracking-compliance/[TRACKING-DNT]Tracking Preference Expression (DNT). Roy Fielding; David Singer. W3C. 17 January 2019. W3C Note. URL: https://www.w3.org/TR/tracking-dnt/[WEBSTORAGE-user-tracking]Web Storage > Privacy > User tracking. Ian Hickson. W3C. July 2013. Rec. URL: https://www.w3.org/TR/2013/REC-webstorage-20130730/#user-tracking[WPM-MILLION]Online tracking: A 1-million-site measurement and analysis. Steven Englehardt; Arvind Narayanan.May 2016. URL: https://webtransparency.cs.princeton.edu/webcensus/\n      \n","length":45108,"excerpt":"This section describes the status of this document at the time of its publication. Other documents may supersede this document. A list of current W3C publications and the latest revision of this technical report can be found in the W3C technical reports index at https://www.w3.org/TR/.","byline":"Nick Doty","dir":"ltr","siteName":null,"lang":"en"},"finalizedMeta":{"title":"Mitigating Browser Fingerprinting in Web Specifications","description":"This section describes the status of this document at the time of its publication. Other documents may supersede this document. A list of current W3C publications and the latest revision of this technical report can be found in the W3C technical reports index at https://www.w3.org/TR/.","author":false,"creator":"","publisher":false,"date":"2022-04-05T17:38:40.386Z","topics":[]},"jsonLd":{"@type":false,"headline":false,"description":false,"image":[],"mainEntityOfPage":{"@type":false,"@id":false},"datePublished":false,"dateModified":false,"isAccessibleForFree":false,"isPartOf":{"@type":[],"name":false,"productID":false},"discussionUrl":false,"license":false,"author":{"@type":false,"name":false,"description":false,"sameAs":false,"image":{"@type":false,"url":false},"givenName":false,"familyName":false,"alternateName":false,"publishingPrinciples":false},"publisher":{"@type":false,"name":false,"description":false,"sameAs":false,"logo":{"@type":false,"url":false},"publishingPrinciples":false},"editor":{"@type":false,"name":false,"description":false,"sameAs":false,"image":{"@type":false,"url":false},"givenName":false,"familyName":false,"alternateName":false,"publishingPrinciples":false}},"twitterObj":false,"status":200,"metadata":{"author":false,"title":"Mitigating Browser Fingerprinting in Web Specifications","description":false,"canonical":"https://www.w3.org/TR/fingerprinting-guidance/","keywords":[],"image":"https://www.w3.org/StyleSheets/TR/2016/logos/W3C","firstParagraph":"\n      Copyright\n      ©\n      2019\n      \n      W3C® (MIT,\n      ERCIM, Keio,\n      Beihang). \n      W3C liability,\n      trademark and permissive document license rules\n      apply.\n    "},"dublinCore":{},"opengraph":{"title":false,"description":false,"url":false,"site_name":false,"locale":false,"type":false,"typeObject":{"published_time":false,"modified_time":false,"author":false,"publisher":false,"section":false,"tag":[]},"image":false},"twitter":{"site":false,"description":false,"card":false,"creator":false,"title":false,"image":false},"archivedData":{"link":false,"wayback":false}}}