{"initialLink":"https://berjon.com/privacy-reality-check/","sanitizedLink":"https://berjon.com/privacy-reality-check/","finalLink":"https://berjon.com/privacy-reality-check/","htmlEmbed":"<script>window.contexterSetup=window.contexterSetup||function(){window.contexterSetupComplete=!0;class ContexterLink extends HTMLAnchorElement{constructor(){super()}connectedCallback(){this.setAttribute(\"target\",\"_blank\")}}customElements.define(\"contexter-link\",ContexterLink,{extends:\"a\"}),customElements.define(\"contexter-inner\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__inner\"}}),customElements.define(\"contexter-thumbnail\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__thumbnail\"}}),customElements.define(\"contexter-byline\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__byline\"}}),customElements.define(\"contexter-keywordset\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__keywordset\"}}),customElements.define(\"contexter-linkset\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__linkset\"}}),customElements.define(\"contexter-meta\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"contexter-box__meta\"}}),customElements.define(\"contexter-summary\",class extends HTMLElement{constructor(){super()}attributeChangedCallback(name,oldValue,newValue){}connectedCallback(){this.className=\"p-summary entry-summary\"}}),customElements.define(\"contexter-box-head\",class extends HTMLElement{constructor(){super()}connectedCallback(){this.className=\"contexter-box__head\"}}),customElements.define(\"contexter-box-inner\",class extends HTMLElement{constructor(){super()}connectedCallback(){}});class ContexterBox extends HTMLElement{constructor(){super(),this.first=!0,this.shadow=this.attachShadow({mode:\"open\"})}connectedCallback(){if(this.first){this.first=!1;var style=document.createElement(\"style\"),lightDomStyle=(style.innerHTML=`:host {--background: #f5f6f7;--border: darkblue;--blue: #0000ee;--font-color: black;--inner-border: black;font-family: Franklin,Arial,Helvetica,sans-serif;font-size: 14px;background: var(--background);width: 600px;color: var(--font-color);min-height: 90px;display: block;padding: 8px;border: 1px solid var(--border);cursor: pointer;box-sizing: border-box;margin: 6px;contain: content;margin: 6px auto;}// can only select top-level nodes with slotted::slotted(*) {max-width: 100%;display:block;}::slotted([slot=thumbnail]) {max-width: 100%;display:block;}::slotted([slot=header]) {width: 100%;font-size: 1.25rem;font-weight: bold;display:block;margin-bottom: 6px;}::slotted([slot=author]) {max-width: 50%;font-size: 12px;display:inline-block;float: left;}::slotted([slot=time]) {max-width: 50%;font-size: 12px;display:inline-block;float: right;}::slotted([slot=summary]) {width: 100%;margin-top: 6px;padding: 10px 2px;border-top: 1px solid var(--inner-border);font-size: 15px;display:inline-block;margin-bottom: 6px;}contexter-meta {height: auto;margin-bottom: 4px;width: 100%;display: grid;position: relative;min-height: 16px;grid-template-columns: repeat(2, 1fr);}::slotted([slot=keywords]) {width: 80%;padding: 2px 4px;border-top: 1px solid var(--inner-border);font-size: 11px;display: block;float: right;font-style: italic;text-align: right;grid-column: 2/2;grid-row: 1;align-self: end;justify-self: end;}::slotted([slot=keywords]):empty {border-top: 0px solid var(--inner-border);}::slotted([slot=archive-link]) {font-size: 1em;display: inline;}::slotted([slot=archive-link])::after {content: \"|\";display: inline;color: var(--font-color);text-decoration: none;margin: 0 .5em;}::slotted([slot=read-link]) {font-size: 1em;display: inline;}contexter-linkset {width: 80%;padding: 2px 4px;font-size: 13px;float: left;font-weight: bold;grid-row: 1;grid-column: 1/2;align-self: end;justify-self: start;}/* Extra small devices (phones, 600px and down) */@media only screen and (max-width: 600px) {:host {width: 310px;}}/* Small devices (portrait tablets and large phones, 600px and up) */@media only screen and (min-width: 600px) {...}/* Medium devices (landscape tablets, 768px and up) */@media only screen and (min-width: 768px) {...}/* Large devices (laptops/desktops, 992px and up) */@media only screen and (min-width: 992px) {...}/* Extra large devices (large laptops and desktops, 1200px and up) */@media only screen and (min-width: 1200px) {...}@media (prefers-color-scheme: dark){:host {--background: #354150;--border: #1f2b37;--blue: #55b0ff;--font-color: #ffffff;--inner-border: #787a7c;background: var(--background);border: 1px solid var(--border)}}`,document.createElement(\"style\"));lightDomStyle.innerHTML=`contexter-box {contain: content;}contexter-box .read-link {font-weight: bold;}contexter-box a {color: #0000ee;}contexter-box img {width: 100%;border: 0;padding: 0;margin: 0;}/* Extra small devices (phones, 600px and down) */@media only screen and (max-width: 600px) {...}/* Small devices (portrait tablets and large phones, 600px and up) */@media only screen and (min-width: 600px) {...}/* Medium devices (landscape tablets, 768px and up) */@media only screen and (min-width: 768px) {...}/* Large devices (laptops/desktops, 992px and up) */@media only screen and (min-width: 992px) {...}/* Extra large devices (large laptops and desktops, 1200px and up) */@media only screen and (min-width: 1200px) {...}@media (prefers-color-scheme: dark){contexter-box a {color: #55b0ff;}}`,this.appendChild(lightDomStyle),this.shadow.appendChild(style);const innerContainer=document.createElement(\"contexter-box-inner\"),innerSlotThumbnail=(this.shadow.appendChild(innerContainer),document.createElement(\"slot\")),innerSlotHeader=(innerSlotThumbnail.name=\"thumbnail\",innerContainer.appendChild(innerSlotThumbnail),document.createElement(\"slot\")),innerSlotAuthor=(innerSlotHeader.name=\"header\",innerContainer.appendChild(innerSlotHeader),document.createElement(\"slot\")),innerSlotTime=(innerSlotAuthor.name=\"author\",innerContainer.appendChild(innerSlotAuthor),document.createElement(\"slot\")),innerSlotSummary=(innerSlotTime.name=\"time\",innerContainer.appendChild(innerSlotTime),document.createElement(\"slot\")),metaContainer=(innerSlotSummary.name=\"summary\",innerContainer.appendChild(innerSlotSummary),document.createElement(\"contexter-meta\")),innerSlotInfo=(innerContainer.appendChild(metaContainer),document.createElement(\"slot\")),linkContainer=(innerSlotInfo.name=\"keywords\",metaContainer.appendChild(innerSlotInfo),document.createElement(\"contexter-linkset\")),innerSlotArchiveLink=(metaContainer.appendChild(linkContainer),document.createElement(\"slot\")),innerSlotReadLink=(innerSlotArchiveLink.name=\"archive-link\",linkContainer.appendChild(innerSlotArchiveLink),document.createElement(\"slot\"));innerSlotReadLink.name=\"read-link\",linkContainer.appendChild(innerSlotReadLink),this.className=\"contexter-box\",this.onclick=e=>{if(!e.target.className.includes(\"read-link\")&&!e.target.className.includes(\"title-link\")){const mainLinks=this.querySelectorAll(\"a.main-link\");mainLinks[0].click()}}}}}customElements.define(\"contexter-box\",ContexterBox)},window.contexterSetupComplete||window.contexterSetup();</script><contexter-box class=\"link-card h-entry hentry\" itemscope=\"\" itemtype=\"https://schema.org/CreativeWork\"><contexter-thumbnail class=\"thumbnail\" slot=\"thumbnail\"></contexter-thumbnail><contexter-box-head slot=\"header\" class=\"p-name entry-title\" itemprop=\"headline\"><contexter-box-head slot=\"header\" class=\"p-name entry-title\" itemprop=\"headline\"><a is=\"contexter-link\" href=\"https://berjon.com/privacy-reality-check/\" itemprop=\"url\">Privacy: A Quick Reality Check</a></contexter-box-head></contexter-box-head><time class=\"dt-published published\" slot=\"time\" itemprop=\"datePublished\" datetime=\"2022-04-05T17:38:36.920Z\">3/5/2022</time><contexter-summary class=\"p-summary entry-summary\" itemprop=\"abstract\" slot=\"summary\"><p>There has been ample debate in some tech circles as to just how much of a privacy war is really being waged. My personal sense is that it's not so much of a war as it is a reality check. It has become very painfully obvious that the same old simple solutions don't work — and some people are up in arms that reality is being inconvenient to them.</p></contexter-summary><contexter-keywordset itemprop=\"keywords\" slot=\"keywords\"></contexter-keywordset><a href=\"https://web.archive.org/web/20220405173940/https://berjon.com/privacy-reality-check/\" is=\"contexter-link\" target=\"_blank\" rel=\"timemap\" class=\"read-link archive-link\" itemprop=\"archivedAt\" slot=\"archive-link\">Archived</a><a is=\"contexter-link\" href=\"https://berjon.com/privacy-reality-check/\" class=\"read-link main-link\" itemprop=\"sameAs\" slot=\"read-link\">Read</a></contexter-box>","linkId":"09dfc5bf2342086854675e7aa7045fcc01b65e5b","data":{"originalLink":"https://berjon.com/privacy-reality-check/","sanitizedLink":"https://berjon.com/privacy-reality-check/","canonical":"https://berjon.com/privacy-reality-check/","htmlText":"<!DOCTYPE html>\n    <html lang=\"en\" dir=\"ltr\">\n      <head>\n        <meta charset=\"utf-8\">\n        <meta name=\"viewport\" content=\"width=device-width\">\n        <title>Privacy: A Quick Reality Check</title>\n        <link rel=\"icon\" href=\"/00539C.png\">\n        <link rel=\"stylesheet\" href=\"/berjon.min.css\">\n        \n        <link rel=\"alternate\" type=\"application/atom+xml\" href=\"/feed.atom\" title=\"Robin Berjon — Feed\">\n        <meta name=\"monetization\" content=\"$ilp.uphold.com/jPPaqHeeaWxU\">\n        <meta name=\"twitter:card\" content=\"summary_large_image\">\n        <meta name=\"twitter:site\" content=\"@robinberjon\">\n        \n        <meta name=\"twitter:title\" property=\"og:title\" content=\"Privacy: A Quick Reality Check\">\n        <meta name=\"twitter:description\" property=\"og:description\" content=\"There has been ample debate in some tech circles as to just how much of a privacy war is really being waged. My personal sense is that it&#x27;s not so much of a war as it is a reality check. It has become very painfully obvious that the same old simple solutions don&#x27;t work — and some people are up in arms that reality is being inconvenient to them.\">\n        <meta name=\"twitter:image\" property=\"og:image\" content=\"https://berjon.com/privacy-reality-check/storm.jpg\">\n        \n        <meta name=\"twitter:url\" property=\"og:url\" content=\"https://berjon.com/privacy-reality-check/\">\n        <meta property=\"og:site_name\" content=\"Robin Berjon\">\n        <meta property=\"og:type\" content=\"blog\">\n        <meta property=\"og:locale\" content=\"en_UK\">\n        <meta name=\"theme-color\" content=\"#00539C\">\n        <style nonce=\"bHl0NjhadFVE\">\n          body {\n            --primary-colour: #00539C;\n            --secondary-colour: #00539C;\n          }\n          \n        </style>\n      </head>\n      <body>\n        <header>\n          <p><a href=\"/\">Robin Berjon</a></p>\n        </header>\n        <main>\n          <article>\n      <header>\n        <p>Get Your Own Data, Not Your Own Facts</p>\n        <h1>Privacy: A Quick Reality Check</h1>\n        <div class=\"meta\">\n          <ul><li><span>\n    <a href=\"/people/robin\">Robin Berjon</a>\n  </span></li></ul>\n          <time datetime=\"2021-07-21T00:00:00.000Z\">2021-07-21</time>\n        </div>\n      </header>\n      <img src=\"/privacy-reality-check/storm.jpg\"   alt=\"\" role=\"presentation\">\n      <p>It often feels like there are many viewpoints about privacy, and that they cannot be reconciled.\n  In turn, this creates doubt that we can map a path forward towards a healthier digital ecosystem.\n  But not all opinions are equally valid, and concerning ourselves only with those based in fact\n  would lead to a much healthier debate.</p>\n<p>There has been ample discussion in some tech circles as to just how much of a <a\n    href=\"https://www.protocol.com/policy/w3c-privacy-war\">privacy war</a> is really being waged. My\n  personal sense is that it's not so much of a war as it is a reality check. It has become very\n  painfully obvious that the same old simple solutions don't work — and some people are up in arms\n  that reality is being inconvenient to them.</p>\n<p>Let's take consent, to start somewhere. Consent is just one tool in the privacy toolbox. Consent\n  is a bit like an avocado slicer: when you need to slice an avocado, it's pretty damn good. When\n  you need to bang in a nail, it's pretty damn useless. In the overwhelming majority of everyday\n  privacy contexts, we don't use consent because that would be absurd: is it okay that I listen\n  while you're\n  talking to me? Is it okay that I see you when you enter the room? Is it okay that, as your doctor,\n  I analyse the symptoms you just described to me?</p>\n<p>The answer to problems caused by consent isn't more consent, automated consent, or consent that\n  covers more processing. It's to use consent where and when it is the right tool to increase\n  people's autonomy, and to stop pretending that you can bang nails in with it in all the other\n  cases. And no matter how appealing it might feel on a priori grounds, if it can't be enforced at\n  scale and it is susceptible to hard-to-litigate gaming then it's just a bad approach to data\n  protection. There's a reason why data brokers love consent so much and won't ever stop talking\n  about \"<em>transparency and choice</em>\": it works in favour of whichever party has the time to\n  invest in creating a consent funnel, and that's never individuals.</p>\n<p>All that consent does is that it offloads privacy labour to the user, and only under very\n  specific conditions does it increase the user's autonomy. This isn't new information. There's <a\n    href=\"https://www.heinz.cmu.edu/~acquisti/papers/AcquistiBrandimarteLoewenstein-S-2015.pdf\">a\n    review article from </a><em><a\n      href=\"https://www.heinz.cmu.edu/~acquisti/papers/AcquistiBrandimarteLoewenstein-S-2015.pdf\">Science</a></em><a\n    href=\"https://www.heinz.cmu.edu/~acquisti/papers/AcquistiBrandimarteLoewenstein-S-2015.pdf\"> in\n    2015</a> that brings close to a hundred references to bear on the\n  fact that digital self-determination in the face of privacy issues is highly manipulable and\n  that's even <em>without</em> dark patterns. There are <a\n    href=\"https://bookshop.org/books/more-than-you-wanted-to-know-the-failure-of-mandated-disclosure/9780691161709\">entire\n    books about just the failure of notice regimes</a>. The\n  <a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3370433\">pathologies of digital\n    consent</a> are known. Lindsey Barrett summarised the situation well when she described notice\n  and choice as \"<em><a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3354129\">a method\n      of privacy regulation which promises transparency and agency but delivers neither.</a></em>\"\n</p>\n<p>Or we could look at the perennial question of pseudonymous data. To people who have no experience\n  in data protection, it sounds pretty reasonable. I mean, it's just a number, what do you really\n  learn about someone? Only just yesterday, <a\n    href=\"https://twitter.com/GerritD/status/1417606494472835078\">a priest was outed using\n    pseudonymous data</a>. There's <a\n    href=\"https://www.vice.com/en/article/epnmvz/industry-unmasks-at-scale-maid-to-pii\">an entire\n    industry offering deanonymisation services</a>. Those companies can get quite sophisticated, but\n  the basics of breaking identifiers are straightforward. Reporters — smart folks, yes, but not\n  professional data scientists — picked up the required skills for <a\n    href=\"https://www.nytimes.com/interactive/2018/12/10/business/location-data-privacy-apps.html\">a\n    stunning report</a> and then other colleagues of them <a\n    href=\"https://www.nytimes.com/interactive/2019/12/19/opinion/location-tracking-cell-phone.html\">did\n    it again for another</a>. In fact, Arvind Narayanan recently said that <a\n    href=\"https://twitter.com/random_walker/status/1417147060726505475?s=20\">it's so easy to do, you\n    can't even get a research paper published about the practice</a>. Even with rotating keys, the\n  protection is only good if you can protect against timing attacks and have sufficient k-anonymity.\n  You'd think we might learn because <a\n    href=\"https://arstechnica.com/tech-policy/2010/03/netflix-ditches-1-million-contest-in-wake-of-privacy-suit/\">Netflix\n    very publicly failed at this over ten years ago</a>, as did <a\n    href=\"https://www.nytimes.com/2006/08/09/technology/09aol.html\">AOL in 2006</a>.</p>\n<p>People who should know better are routinely wrong — by which I mean <em>mathematically </em>wrong\n  — about the safety of identifiers, how do we expect laypeople to meaningfully consent to this?</p>\n<p>Another evergreen proposal is that we can somehow use a web of contracts to ensure\n  self-regulation in the data market. We have that — <a\n    href=\"https://www.networkadvertising.org/code-enforcement/code\">we've had it since 2000</a>. The\n  deal struck in the negotiations that the FTC coordinated in 1999-2000 was essentially that the\n  tracking industry would be allowed to keep operating <a\n    href=\"https://web.archive.org/web/20100604134130/http://www.ftc.gov/os/2000/07/onlineprofiling.htm\">in\n    exchange for setting up a self-regulatory regime</a>. I don't think it's unreasonable to\n  consider that 20 years is more than enough of a chance for this approach to prove itself. We gave\n  it more than a fair shot; <a\n    href=\"https://digiday.com/marketing/when-the-white-house-invoked-the-s-word-it-gave-new-legitimacy-to-surveillance-advertising/\">it's\n    time to call the deal off</a>.</p>\n<p>Yet another recurring contention is that, after two decades of unfettered personal data\n  broadcasting led to some of the most significant market power concentration in the history of\n  humankind, what we really need is more unfettered personal data broadcasting because\n  that will clearly lead to greater competition. There's an emoji for what my face looks like when I\n  try to process that logic, but the Unicode Consortium is afraid to standardise it. I can see that\n  there are non-market factors at play in the current situation, but still: given the empirical\n  evidence, the burden of proof sits squarely with those who make that statement.</p>\n<p>From what I've read, it's not obvious that it is much more than wishful thinking. Data is\n  inherently relational, meaning it forms a network. The value of data depends in large part on its\n  volume and its variety. This can lead to network effects in which, when data is broadly available,\n  having even just a little bit more volume or variety than others <a\n    href=\"https://bookshop.org/books/big-data-and-competition-policy/9780198788140\">can lead to\n    winner-take-all outcomes from network effects</a>. The <a\n    href=\"https://www.oecd.org/sti/data-driven-innovation-9789264229358-en.htm\">OECD's analysis</a>\n  indicated that data enables multi-sided markets which can\n  combine with increased returns to scale and scope, leading to dominance, winner-take-all, and\n  competition for the market rather than in the market. In <a\n    href=\"https://www.oecd-ilibrary.org/science-and-technology/exploring-the-economics-of-personal-data_5k486qtxldmq-en\">a\n    separate study</a>, they point to non-linear returns and network effects, with obvious\n  competition implications.</p>\n<p>And speaking of dysfunctional markets, there's good evidence that the claim that people will\n  enter into a \"<em>value exchange</em>\" involving their data is <a\n    href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2820060\">an imaginary position that\n    only data marketers believe in</a>. People don't see a value exchange, they just hate you in\n  silence. I don't blame anyone for wishing such an exchange existed, but I believe that\n  reality-based marketing works better.</p>\n<p>Which brings us to another trope: that we somehow don't have a definition of privacy. I mean,\n  it's a somewhat contested space, but not <em>that</em> contested. We have <a\n    href=\"https://bookshop.org/books/privacy-in-context-technology-policy-and-the-integrity-of-social-life/9780804752374\">a\n    pretty broadly accepted definition</a> that works very well in the trenches (it's what I've used\n  at The Times for the past four years), that has <a href=\"https://privaci.info/\">its own\n    conference</a>, is <a\n    href=\"https://scholar.google.com/scholar?cites=9350695840146257775&amp;as_sdt=5,31&amp;sciodt=0,31&amp;hl=en\">massively\n    cited</a>, and is referenced in <a href=\"https://www.bitbybitbook.com/\">social and data science\n    textbooks</a>. I <a\n    href=\"https://open.nytimes.com/how-the-new-york-times-thinks-about-your-privacy-bc07d2171531\">covered\n    it for a general audience</a>. I also <a href=\"https://darobin.github.io/pup/\">introduced it for\n    use in a standards\n    context</a>, which hopefully <a href=\"https://tag.w3.org/\">TAG</a>/<a\n    href=\"https://www.w3.org/Privacy/IG/\">PING</a> can find some consensus around soon.</p>\n<p>I could keep going, but this might be enough of a literature review for today. The way I see it,\n  we have a pretty straightforward choice. We can keep loudly blustering that doing more of exactly\n  what we've done for the past two decades will somehow magically lead to different outcomes,\n  or we can actually bite the bullet, whether we like it or not, and find solutions that actually\n  work.</p>\n<p>Detractors often depict privacy work as being \"<em>ideological.</em>\" If believing that people\n  shouldn't live in fear of their tech betraying them is ideological, I'll take it. But there's a\n  purely profits-driven consideration if that's what you want: people don't want to be recognised\n  across contexts, and trying to force that to happen is an arms race against users which you'll\n  eventually lose.</p>\n<p>I know that these are not easy changes. We have yet to scale a business model that does not rely\n  on advertising (subscriptions are <em>highly</em> reliant on it), and much of advertising has, for\n  a while, been privacy-hostile. Changing that is a big reinvention. But we need to reform data and\n  advertising, despite the complexity and the risk, because it's the only discernible path forward\n  that has any sustainability to it.</p>\n<p>So with this in mind, I'd like to suggest that we stop wasting time revisiting the failed\n  strategies of a broken system, and instead invest in making it work. There's no path forward\n  listening to privacy denialists and not much in the way of facts to back them up — so let's stop\n  pretending bullshit should have a seat at the table.</p>\n<p></p>\n\n    </article>\n        </main>\n        <footer>\n          <nav>\n            <ul>\n              <li><a href=\"/\">home</a></li\n              ><li><a href=\"/about/\">about</a></li>\n            </ul>\n            <ul>\n              <li><a href=\"/2009/\">2009</a></li\n              ><li><a href=\"/2010/\">2010</a></li\n              ><li><a href=\"/2011/\">2011</a></li\n              ><li><a href=\"/2012/\">2012</a></li\n              ><li><a href=\"/2013/\">2013</a></li\n              ><li><a href=\"/2014/\">2014</a></li\n              ><li><a href=\"/2015/\">2015</a></li\n              ><li><a href=\"/2016/\">2016</a></li\n              ><li><a href=\"/2018/\">2018</a></li\n              ><li><a href=\"/2021/\">2021</a></li>\n              </ul>\n          </nav>\n          <p class=\"disclaimer\">\n            The opinions published on this site are mine and mine alone. It is disingenuous to tie\n            them to my employer one way or another.\n          </p>\n        </footer>\n      </body>\n    </html>\n  ","oembed":false,"readabilityObject":{"title":"Privacy: A Quick Reality Check","content":"<div id=\"readability-page-1\" class=\"page\"><div>\n          <article>\n      <header>\n        <p>Get Your Own Data, Not Your Own Facts</p>\n        \n        \n      </header>\n      <img src=\"/privacy-reality-check/storm.jpg\" alt=\"\" role=\"presentation\">\n      <p>It often feels like there are many viewpoints about privacy, and that they cannot be reconciled.\n  In turn, this creates doubt that we can map a path forward towards a healthier digital ecosystem.\n  But not all opinions are equally valid, and concerning ourselves only with those based in fact\n  would lead to a much healthier debate.</p>\n<p>There has been ample discussion in some tech circles as to just how much of a <a href=\"https://www.protocol.com/policy/w3c-privacy-war\">privacy war</a> is really being waged. My\n  personal sense is that it's not so much of a war as it is a reality check. It has become very\n  painfully obvious that the same old simple solutions don't work — and some people are up in arms\n  that reality is being inconvenient to them.</p>\n<p>Let's take consent, to start somewhere. Consent is just one tool in the privacy toolbox. Consent\n  is a bit like an avocado slicer: when you need to slice an avocado, it's pretty damn good. When\n  you need to bang in a nail, it's pretty damn useless. In the overwhelming majority of everyday\n  privacy contexts, we don't use consent because that would be absurd: is it okay that I listen\n  while you're\n  talking to me? Is it okay that I see you when you enter the room? Is it okay that, as your doctor,\n  I analyse the symptoms you just described to me?</p>\n<p>The answer to problems caused by consent isn't more consent, automated consent, or consent that\n  covers more processing. It's to use consent where and when it is the right tool to increase\n  people's autonomy, and to stop pretending that you can bang nails in with it in all the other\n  cases. And no matter how appealing it might feel on a priori grounds, if it can't be enforced at\n  scale and it is susceptible to hard-to-litigate gaming then it's just a bad approach to data\n  protection. There's a reason why data brokers love consent so much and won't ever stop talking\n  about \"<em>transparency and choice</em>\": it works in favour of whichever party has the time to\n  invest in creating a consent funnel, and that's never individuals.</p>\n<p>All that consent does is that it offloads privacy labour to the user, and only under very\n  specific conditions does it increase the user's autonomy. This isn't new information. There's <a href=\"https://www.heinz.cmu.edu/~acquisti/papers/AcquistiBrandimarteLoewenstein-S-2015.pdf\">a\n    review article from </a><em><a href=\"https://www.heinz.cmu.edu/~acquisti/papers/AcquistiBrandimarteLoewenstein-S-2015.pdf\">Science</a></em><a href=\"https://www.heinz.cmu.edu/~acquisti/papers/AcquistiBrandimarteLoewenstein-S-2015.pdf\"> in\n    2015</a> that brings close to a hundred references to bear on the\n  fact that digital self-determination in the face of privacy issues is highly manipulable and\n  that's even <em>without</em> dark patterns. There are <a href=\"https://bookshop.org/books/more-than-you-wanted-to-know-the-failure-of-mandated-disclosure/9780691161709\">entire\n    books about just the failure of notice regimes</a>. The\n  <a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3370433\">pathologies of digital\n    consent</a> are known. Lindsey Barrett summarised the situation well when she described notice\n  and choice as \"<em><a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3354129\">a method\n      of privacy regulation which promises transparency and agency but delivers neither.</a></em>\"\n</p>\n<p>Or we could look at the perennial question of pseudonymous data. To people who have no experience\n  in data protection, it sounds pretty reasonable. I mean, it's just a number, what do you really\n  learn about someone? Only just yesterday, <a href=\"https://twitter.com/GerritD/status/1417606494472835078\">a priest was outed using\n    pseudonymous data</a>. There's <a href=\"https://www.vice.com/en/article/epnmvz/industry-unmasks-at-scale-maid-to-pii\">an entire\n    industry offering deanonymisation services</a>. Those companies can get quite sophisticated, but\n  the basics of breaking identifiers are straightforward. Reporters — smart folks, yes, but not\n  professional data scientists — picked up the required skills for <a href=\"https://www.nytimes.com/interactive/2018/12/10/business/location-data-privacy-apps.html\">a\n    stunning report</a> and then other colleagues of them <a href=\"https://www.nytimes.com/interactive/2019/12/19/opinion/location-tracking-cell-phone.html\">did\n    it again for another</a>. In fact, Arvind Narayanan recently said that <a href=\"https://twitter.com/random_walker/status/1417147060726505475?s=20\">it's so easy to do, you\n    can't even get a research paper published about the practice</a>. Even with rotating keys, the\n  protection is only good if you can protect against timing attacks and have sufficient k-anonymity.\n  You'd think we might learn because <a href=\"https://arstechnica.com/tech-policy/2010/03/netflix-ditches-1-million-contest-in-wake-of-privacy-suit/\">Netflix\n    very publicly failed at this over ten years ago</a>, as did <a href=\"https://www.nytimes.com/2006/08/09/technology/09aol.html\">AOL in 2006</a>.</p>\n<p>People who should know better are routinely wrong — by which I mean <em>mathematically </em>wrong\n  — about the safety of identifiers, how do we expect laypeople to meaningfully consent to this?</p>\n<p>Another evergreen proposal is that we can somehow use a web of contracts to ensure\n  self-regulation in the data market. We have that — <a href=\"https://www.networkadvertising.org/code-enforcement/code\">we've had it since 2000</a>. The\n  deal struck in the negotiations that the FTC coordinated in 1999-2000 was essentially that the\n  tracking industry would be allowed to keep operating <a href=\"https://web.archive.org/web/20100604134130/http://www.ftc.gov/os/2000/07/onlineprofiling.htm\">in\n    exchange for setting up a self-regulatory regime</a>. I don't think it's unreasonable to\n  consider that 20 years is more than enough of a chance for this approach to prove itself. We gave\n  it more than a fair shot; <a href=\"https://digiday.com/marketing/when-the-white-house-invoked-the-s-word-it-gave-new-legitimacy-to-surveillance-advertising/\">it's\n    time to call the deal off</a>.</p>\n<p>Yet another recurring contention is that, after two decades of unfettered personal data\n  broadcasting led to some of the most significant market power concentration in the history of\n  humankind, what we really need is more unfettered personal data broadcasting because\n  that will clearly lead to greater competition. There's an emoji for what my face looks like when I\n  try to process that logic, but the Unicode Consortium is afraid to standardise it. I can see that\n  there are non-market factors at play in the current situation, but still: given the empirical\n  evidence, the burden of proof sits squarely with those who make that statement.</p>\n<p>From what I've read, it's not obvious that it is much more than wishful thinking. Data is\n  inherently relational, meaning it forms a network. The value of data depends in large part on its\n  volume and its variety. This can lead to network effects in which, when data is broadly available,\n  having even just a little bit more volume or variety than others <a href=\"https://bookshop.org/books/big-data-and-competition-policy/9780198788140\">can lead to\n    winner-take-all outcomes from network effects</a>. The <a href=\"https://www.oecd.org/sti/data-driven-innovation-9789264229358-en.htm\">OECD's analysis</a>\n  indicated that data enables multi-sided markets which can\n  combine with increased returns to scale and scope, leading to dominance, winner-take-all, and\n  competition for the market rather than in the market. In <a href=\"https://www.oecd-ilibrary.org/science-and-technology/exploring-the-economics-of-personal-data_5k486qtxldmq-en\">a\n    separate study</a>, they point to non-linear returns and network effects, with obvious\n  competition implications.</p>\n<p>And speaking of dysfunctional markets, there's good evidence that the claim that people will\n  enter into a \"<em>value exchange</em>\" involving their data is <a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2820060\">an imaginary position that\n    only data marketers believe in</a>. People don't see a value exchange, they just hate you in\n  silence. I don't blame anyone for wishing such an exchange existed, but I believe that\n  reality-based marketing works better.</p>\n<p>Which brings us to another trope: that we somehow don't have a definition of privacy. I mean,\n  it's a somewhat contested space, but not <em>that</em> contested. We have <a href=\"https://bookshop.org/books/privacy-in-context-technology-policy-and-the-integrity-of-social-life/9780804752374\">a\n    pretty broadly accepted definition</a> that works very well in the trenches (it's what I've used\n  at The Times for the past four years), that has <a href=\"https://privaci.info/\">its own\n    conference</a>, is <a href=\"https://scholar.google.com/scholar?cites=9350695840146257775&amp;as_sdt=5,31&amp;sciodt=0,31&amp;hl=en\">massively\n    cited</a>, and is referenced in <a href=\"https://www.bitbybitbook.com/\">social and data science\n    textbooks</a>. I <a href=\"https://open.nytimes.com/how-the-new-york-times-thinks-about-your-privacy-bc07d2171531\">covered\n    it for a general audience</a>. I also <a href=\"https://darobin.github.io/pup/\">introduced it for\n    use in a standards\n    context</a>, which hopefully <a href=\"https://tag.w3.org/\">TAG</a>/<a href=\"https://www.w3.org/Privacy/IG/\">PING</a> can find some consensus around soon.</p>\n<p>I could keep going, but this might be enough of a literature review for today. The way I see it,\n  we have a pretty straightforward choice. We can keep loudly blustering that doing more of exactly\n  what we've done for the past two decades will somehow magically lead to different outcomes,\n  or we can actually bite the bullet, whether we like it or not, and find solutions that actually\n  work.</p>\n<p>Detractors often depict privacy work as being \"<em>ideological.</em>\" If believing that people\n  shouldn't live in fear of their tech betraying them is ideological, I'll take it. But there's a\n  purely profits-driven consideration if that's what you want: people don't want to be recognised\n  across contexts, and trying to force that to happen is an arms race against users which you'll\n  eventually lose.</p>\n<p>I know that these are not easy changes. We have yet to scale a business model that does not rely\n  on advertising (subscriptions are <em>highly</em> reliant on it), and much of advertising has, for\n  a while, been privacy-hostile. Changing that is a big reinvention. But we need to reform data and\n  advertising, despite the complexity and the risk, because it's the only discernible path forward\n  that has any sustainability to it.</p>\n<p>So with this in mind, I'd like to suggest that we stop wasting time revisiting the failed\n  strategies of a broken system, and instead invest in making it work. There's no path forward\n  listening to privacy denialists and not much in the way of facts to back them up — so let's stop\n  pretending bullshit should have a seat at the table.</p>\n\n\n    </article>\n        </div></div>","textContent":"\n          \n      \n        Get Your Own Data, Not Your Own Facts\n        \n        \n      \n      \n      It often feels like there are many viewpoints about privacy, and that they cannot be reconciled.\n  In turn, this creates doubt that we can map a path forward towards a healthier digital ecosystem.\n  But not all opinions are equally valid, and concerning ourselves only with those based in fact\n  would lead to a much healthier debate.\nThere has been ample discussion in some tech circles as to just how much of a privacy war is really being waged. My\n  personal sense is that it's not so much of a war as it is a reality check. It has become very\n  painfully obvious that the same old simple solutions don't work — and some people are up in arms\n  that reality is being inconvenient to them.\nLet's take consent, to start somewhere. Consent is just one tool in the privacy toolbox. Consent\n  is a bit like an avocado slicer: when you need to slice an avocado, it's pretty damn good. When\n  you need to bang in a nail, it's pretty damn useless. In the overwhelming majority of everyday\n  privacy contexts, we don't use consent because that would be absurd: is it okay that I listen\n  while you're\n  talking to me? Is it okay that I see you when you enter the room? Is it okay that, as your doctor,\n  I analyse the symptoms you just described to me?\nThe answer to problems caused by consent isn't more consent, automated consent, or consent that\n  covers more processing. It's to use consent where and when it is the right tool to increase\n  people's autonomy, and to stop pretending that you can bang nails in with it in all the other\n  cases. And no matter how appealing it might feel on a priori grounds, if it can't be enforced at\n  scale and it is susceptible to hard-to-litigate gaming then it's just a bad approach to data\n  protection. There's a reason why data brokers love consent so much and won't ever stop talking\n  about \"transparency and choice\": it works in favour of whichever party has the time to\n  invest in creating a consent funnel, and that's never individuals.\nAll that consent does is that it offloads privacy labour to the user, and only under very\n  specific conditions does it increase the user's autonomy. This isn't new information. There's a\n    review article from Science in\n    2015 that brings close to a hundred references to bear on the\n  fact that digital self-determination in the face of privacy issues is highly manipulable and\n  that's even without dark patterns. There are entire\n    books about just the failure of notice regimes. The\n  pathologies of digital\n    consent are known. Lindsey Barrett summarised the situation well when she described notice\n  and choice as \"a method\n      of privacy regulation which promises transparency and agency but delivers neither.\"\n\nOr we could look at the perennial question of pseudonymous data. To people who have no experience\n  in data protection, it sounds pretty reasonable. I mean, it's just a number, what do you really\n  learn about someone? Only just yesterday, a priest was outed using\n    pseudonymous data. There's an entire\n    industry offering deanonymisation services. Those companies can get quite sophisticated, but\n  the basics of breaking identifiers are straightforward. Reporters — smart folks, yes, but not\n  professional data scientists — picked up the required skills for a\n    stunning report and then other colleagues of them did\n    it again for another. In fact, Arvind Narayanan recently said that it's so easy to do, you\n    can't even get a research paper published about the practice. Even with rotating keys, the\n  protection is only good if you can protect against timing attacks and have sufficient k-anonymity.\n  You'd think we might learn because Netflix\n    very publicly failed at this over ten years ago, as did AOL in 2006.\nPeople who should know better are routinely wrong — by which I mean mathematically wrong\n  — about the safety of identifiers, how do we expect laypeople to meaningfully consent to this?\nAnother evergreen proposal is that we can somehow use a web of contracts to ensure\n  self-regulation in the data market. We have that — we've had it since 2000. The\n  deal struck in the negotiations that the FTC coordinated in 1999-2000 was essentially that the\n  tracking industry would be allowed to keep operating in\n    exchange for setting up a self-regulatory regime. I don't think it's unreasonable to\n  consider that 20 years is more than enough of a chance for this approach to prove itself. We gave\n  it more than a fair shot; it's\n    time to call the deal off.\nYet another recurring contention is that, after two decades of unfettered personal data\n  broadcasting led to some of the most significant market power concentration in the history of\n  humankind, what we really need is more unfettered personal data broadcasting because\n  that will clearly lead to greater competition. There's an emoji for what my face looks like when I\n  try to process that logic, but the Unicode Consortium is afraid to standardise it. I can see that\n  there are non-market factors at play in the current situation, but still: given the empirical\n  evidence, the burden of proof sits squarely with those who make that statement.\nFrom what I've read, it's not obvious that it is much more than wishful thinking. Data is\n  inherently relational, meaning it forms a network. The value of data depends in large part on its\n  volume and its variety. This can lead to network effects in which, when data is broadly available,\n  having even just a little bit more volume or variety than others can lead to\n    winner-take-all outcomes from network effects. The OECD's analysis\n  indicated that data enables multi-sided markets which can\n  combine with increased returns to scale and scope, leading to dominance, winner-take-all, and\n  competition for the market rather than in the market. In a\n    separate study, they point to non-linear returns and network effects, with obvious\n  competition implications.\nAnd speaking of dysfunctional markets, there's good evidence that the claim that people will\n  enter into a \"value exchange\" involving their data is an imaginary position that\n    only data marketers believe in. People don't see a value exchange, they just hate you in\n  silence. I don't blame anyone for wishing such an exchange existed, but I believe that\n  reality-based marketing works better.\nWhich brings us to another trope: that we somehow don't have a definition of privacy. I mean,\n  it's a somewhat contested space, but not that contested. We have a\n    pretty broadly accepted definition that works very well in the trenches (it's what I've used\n  at The Times for the past four years), that has its own\n    conference, is massively\n    cited, and is referenced in social and data science\n    textbooks. I covered\n    it for a general audience. I also introduced it for\n    use in a standards\n    context, which hopefully TAG/PING can find some consensus around soon.\nI could keep going, but this might be enough of a literature review for today. The way I see it,\n  we have a pretty straightforward choice. We can keep loudly blustering that doing more of exactly\n  what we've done for the past two decades will somehow magically lead to different outcomes,\n  or we can actually bite the bullet, whether we like it or not, and find solutions that actually\n  work.\nDetractors often depict privacy work as being \"ideological.\" If believing that people\n  shouldn't live in fear of their tech betraying them is ideological, I'll take it. But there's a\n  purely profits-driven consideration if that's what you want: people don't want to be recognised\n  across contexts, and trying to force that to happen is an arms race against users which you'll\n  eventually lose.\nI know that these are not easy changes. We have yet to scale a business model that does not rely\n  on advertising (subscriptions are highly reliant on it), and much of advertising has, for\n  a while, been privacy-hostile. Changing that is a big reinvention. But we need to reform data and\n  advertising, despite the complexity and the risk, because it's the only discernible path forward\n  that has any sustainability to it.\nSo with this in mind, I'd like to suggest that we stop wasting time revisiting the failed\n  strategies of a broken system, and instead invest in making it work. There's no path forward\n  listening to privacy denialists and not much in the way of facts to back them up — so let's stop\n  pretending bullshit should have a seat at the table.\n\n\n    \n        ","length":8587,"excerpt":"There has been ample debate in some tech circles as to just how much of a privacy war is really being waged. My personal sense is that it's not so much of a war as it is a reality check. It has become very painfully obvious that the same old simple solutions don't work — and some people are up in arms that reality is being inconvenient to them.","byline":null,"dir":"ltr","siteName":"Robin Berjon","lang":"en"},"finalizedMeta":{"title":"Privacy: A Quick Reality Check","description":"There has been ample debate in some tech circles as to just how much of a privacy war is really being waged. My personal sense is that it's not so much of a war as it is a reality check. It has become very painfully obvious that the same old simple solutions don't work — and some people are up in arms that reality is being inconvenient to them.","author":false,"creator":"","publisher":false,"date":"2022-04-05T17:38:36.920Z","topics":[]},"jsonLd":{"@type":false,"headline":false,"description":false,"image":[],"mainEntityOfPage":{"@type":false,"@id":false},"datePublished":false,"dateModified":false,"isAccessibleForFree":false,"isPartOf":{"@type":[],"name":false,"productID":false},"discussionUrl":false,"license":false,"author":{"@type":false,"name":false,"description":false,"sameAs":false,"image":{"@type":false,"url":false},"givenName":false,"familyName":false,"alternateName":false,"publishingPrinciples":false},"publisher":{"@type":false,"name":false,"description":false,"sameAs":false,"logo":{"@type":false,"url":false},"publishingPrinciples":false},"editor":{"@type":false,"name":false,"description":false,"sameAs":false,"image":{"@type":false,"url":false},"givenName":false,"familyName":false,"alternateName":false,"publishingPrinciples":false}},"twitterObj":false,"status":200,"metadata":{"author":false,"title":"Privacy: A Quick Reality Check","description":false,"canonical":"https://berjon.com/privacy-reality-check/","keywords":[],"image":"/privacy-reality-check/storm.jpg","firstParagraph":"Robin Berjon"},"dublinCore":{},"opengraph":{"title":"Privacy: A Quick Reality Check","description":"There has been ample debate in some tech circles as to just how much of a privacy war is really being waged. My personal sense is that it's not so much of a war as it is a reality check. It has become very painfully obvious that the same old simple solutions don't work — and some people are up in arms that reality is being inconvenient to them.","url":"https://berjon.com/privacy-reality-check/","site_name":"Robin Berjon","locale":"en_UK","type":"blog","typeObject":{"published_time":false,"modified_time":false,"author":false,"publisher":false,"section":false,"tag":[]},"image":"https://berjon.com/privacy-reality-check/storm.jpg"},"twitter":{"site":"@robinberjon","description":"There has been ample debate in some tech circles as to just how much of a privacy war is really being waged. My personal sense is that it's not so much of a war as it is a reality check. It has become very painfully obvious that the same old simple solutions don't work — and some people are up in arms that reality is being inconvenient to them.","card":"summary_large_image","creator":false,"title":"Privacy: A Quick Reality Check","image":"https://berjon.com/privacy-reality-check/storm.jpg","url":"https://berjon.com/privacy-reality-check/"},"archivedData":{"link":"https://web.archive.org/web/20220405173940/https://berjon.com/privacy-reality-check/","wayback":"https://web.archive.org/web/20220405173940/https://berjon.com/privacy-reality-check/"}}}